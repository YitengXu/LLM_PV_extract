<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" xmlns:art="http://www.rsc.org/schema/rscart38" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:rsc="urn:rsc.org" xml:lang="en" lang="en"><head><!--Google Tag Manager--><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&amp;l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-56FZ7G');</script><!--End Google Tag Manager--><title>GFlowNets for AI-driven scientific discovery  - Digital Discovery (RSC Publishing) DOI:10.1039/D3DD00002H</title><link rel="canonical" href="https://pubs.rsc.org/en/content/articlehtml/2023/dd/d3dd00002h"/><meta http-equiv="content-type" content="application/xhtml+xml; charset=utf-8"/><script type="text/javascript">window.NREUM||(NREUM={});NREUM.info = {"beacon":"bam.nr-data.net","errorBeacon":"bam.nr-data.net","licenseKey":"NRJS-aaa897feae8feeca979","applicationID":"1313546638","transactionName":"M1wANxQFCEcDVU0PWgoWLzUlSyVbDEJcCEEnVgwXFAsKWAdEFgdHEFABDwMMElkO","queueTime":0,"applicationTime":51,"agent":"","atts":""}</script><script type="text/javascript">(window.NREUM||(NREUM={})).init={privacy:{cookies_enabled:true},ajax:{deny_list:["bam.nr-data.net"]},distributed_tracing:{enabled:true}};(window.NREUM||(NREUM={})).loader_config={agentID:"1386013924",accountID:"2851366",trustKey:"1029994",xpid:"Vg4CUFVVDhABV1BRAgUBUFcJ",licenseKey:"NRJS-aaa897feae8feeca979",applicationID:"1313546638"};;/*! For license information please see nr-loader-spa-1.236.0.min.js.LICENSE.txt */
(()=>{"use strict";var e,t,r={5763:(e,t,r)=>{r.d(t,{P_:()=>l,Mt:()=>g,C5:()=>s,DL:()=>v,OP:()=>T,lF:()=>D,Yu:()=>y,Dg:()=>h,CX:()=>c,GE:()=>b,sU:()=>_});var n=r(8632),i=r(9567);const o={beacon:n.ce.beacon,errorBeacon:n.ce.errorBeacon,licenseKey:void 0,applicationID:void 0,sa:void 0,queueTime:void 0,applicationTime:void 0,ttGuid:void 0,user:void 0,account:void 0,product:void 0,extra:void 0,jsAttributes:{},userAttributes:void 0,atts:void 0,transactionName:void 0,tNamePlain:void 0},a={};function s(e){if(!e)throw new Error("All info objects require an agent identifier!");if(!a[e])throw new Error("Info for ".concat(e," was never set"));return a[e]}function c(e,t){if(!e)throw new Error("All info objects require an agent identifier!");a[e]=(0,i.D)(t,o),(0,n.Qy)(e,a[e],"info")}var u=r(7056);const d=()=>{const e={blockSelector:"[data-nr-block]",maskInputOptions:{password:!0}};return{allow_bfcache:!0,privacy:{cookies_enabled:!0},ajax:{deny_list:void 0,enabled:!0,harvestTimeSeconds:10},distributed_tracing:{enabled:void 0,exclude_newrelic_header:void 0,cors_use_newrelic_header:void 0,cors_use_tracecontext_headers:void 0,allowed_origins:void 0},session:{domain:void 0,expiresMs:u.oD,inactiveMs:u.Hb},ssl:void 0,obfuscate:void 0,jserrors:{enabled:!0,harvestTimeSeconds:10},metrics:{enabled:!0},page_action:{enabled:!0,harvestTimeSeconds:30},page_view_event:{enabled:!0},page_view_timing:{enabled:!0,harvestTimeSeconds:30,long_task:!1},session_trace:{enabled:!0,harvestTimeSeconds:10},harvest:{tooManyRequestsDelay:60},session_replay:{enabled:!1,harvestTimeSeconds:60,sampleRate:.1,errorSampleRate:.1,maskTextSelector:"*",maskAllInputs:!0,get blockClass(){return"nr-block"},get ignoreClass(){return"nr-ignore"},get maskTextClass(){return"nr-mask"},get blockSelector(){return e.blockSelector},set blockSelector(t){e.blockSelector+=",".concat(t)},get maskInputOptions(){return e.maskInputOptions},set maskInputOptions(t){e.maskInputOptions={...t,password:!0}}},spa:{enabled:!0,harvestTimeSeconds:10}}},f={};function l(e){if(!e)throw new Error("All configuration objects require an agent identifier!");if(!f[e])throw new Error("Configuration for ".concat(e," was never set"));return f[e]}function h(e,t){if(!e)throw new Error("All configuration objects require an agent identifier!");f[e]=(0,i.D)(t,d()),(0,n.Qy)(e,f[e],"config")}function g(e,t){if(!e)throw new Error("All configuration objects require an agent identifier!");var r=l(e);if(r){for(var n=t.split("."),i=0;i<n.length-1;i++)if("object"!=typeof(r=r[n[i]]))return;r=r[n[n.length-1]]}return r}const p={accountID:void 0,trustKey:void 0,agentID:void 0,licenseKey:void 0,applicationID:void 0,xpid:void 0},m={};function v(e){if(!e)throw new Error("All loader-config objects require an agent identifier!");if(!m[e])throw new Error("LoaderConfig for ".concat(e," was never set"));return m[e]}function b(e,t){if(!e)throw new Error("All loader-config objects require an agent identifier!");m[e]=(0,i.D)(t,p),(0,n.Qy)(e,m[e],"loader_config")}const y=(0,n.mF)().o;var w=r(385),x=r(6818);const A={buildEnv:x.Re,bytesSent:{},queryBytesSent:{},customTransaction:void 0,disabled:!1,distMethod:x.gF,isolatedBacklog:!1,loaderType:void 0,maxBytes:3e4,offset:Math.floor(w._A?.performance?.timeOrigin||w._A?.performance?.timing?.navigationStart||Date.now()),onerror:void 0,origin:""+w._A.location,ptid:void 0,releaseIds:{},session:void 0,xhrWrappable:"function"==typeof w._A.XMLHttpRequest?.prototype?.addEventListener,version:x.q4},E={};function T(e){if(!e)throw new Error("All runtime objects require an agent identifier!");if(!E[e])throw new Error("Runtime for ".concat(e," was never set"));return E[e]}function _(e,t){if(!e)throw new Error("All runtime objects require an agent identifier!");E[e]=(0,i.D)(t,A),(0,n.Qy)(e,E[e],"runtime")}function D(e){return function(e){try{const t=s(e);return!!t.licenseKey&&!!t.errorBeacon&&!!t.applicationID}catch(e){return!1}}(e)}},9567:(e,t,r)=>{r.d(t,{D:()=>i});var n=r(50);function i(e,t){try{if(!e||"object"!=typeof e)return(0,n.Z)("Setting a Configurable requires an object as input");if(!t||"object"!=typeof t)return(0,n.Z)("Setting a Configurable requires a model to set its initial properties");const r=Object.create(Object.getPrototypeOf(t),Object.getOwnPropertyDescriptors(t)),o=0===Object.keys(r).length?e:r;for(let a in o)if(void 0!==e[a])try{"object"==typeof e[a]&&"object"==typeof t[a]?r[a]=i(e[a],t[a]):r[a]=e[a]}catch(e){(0,n.Z)("An error occurred while setting a property of a Configurable",e)}return r}catch(e){(0,n.Z)("An error occured while setting a Configurable",e)}}},6818:(e,t,r)=>{r.d(t,{Re:()=>i,gF:()=>o,q4:()=>n});const n="1.236.0",i="PROD",o="CDN"},385:(e,t,r)=>{r.d(t,{FN:()=>a,IF:()=>u,Nk:()=>f,Tt:()=>s,_A:()=>o,il:()=>n,pL:()=>c,v6:()=>i,w1:()=>d});const n="undefined"!=typeof window&&!!window.document,i="undefined"!=typeof WorkerGlobalScope&&("undefined"!=typeof self&&self instanceof WorkerGlobalScope&&self.navigator instanceof WorkerNavigator||"undefined"!=typeof globalThis&&globalThis instanceof WorkerGlobalScope&&globalThis.navigator instanceof WorkerNavigator),o=n?window:"undefined"!=typeof WorkerGlobalScope&&("undefined"!=typeof self&&self instanceof WorkerGlobalScope&&self||"undefined"!=typeof globalThis&&globalThis instanceof WorkerGlobalScope&&globalThis),a=""+o?.location,s=/iPad|iPhone|iPod/.test(navigator.userAgent),c=s&&"undefined"==typeof SharedWorker,u=(()=>{const e=navigator.userAgent.match(/Firefox[/\s](\d+\.\d+)/);return Array.isArray(e)&&e.length>=2?+e[1]:0})(),d=Boolean(n&&window.document.documentMode),f=!!navigator.sendBeacon},1117:(e,t,r)=>{r.d(t,{w:()=>o});var n=r(50);const i={agentIdentifier:"",ee:void 0};class o{constructor(e){try{if("object"!=typeof e)return(0,n.Z)("shared context requires an object as input");this.sharedContext={},Object.assign(this.sharedContext,i),Object.entries(e).forEach((e=>{let[t,r]=e;Object.keys(i).includes(t)&&(this.sharedContext[t]=r)}))}catch(e){(0,n.Z)("An error occured while setting SharedContext",e)}}}},8e3:(e,t,r)=>{r.d(t,{L:()=>d,R:()=>c});var n=r(2177),i=r(1284),o=r(4322),a=r(3325);const s={};function c(e,t){const r={staged:!1,priority:a.p[t]||0};u(e),s[e].get(t)||s[e].set(t,r)}function u(e){e&&(s[e]||(s[e]=new Map))}function d(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:"",t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:"feature";if(u(e),!e||!s[e].get(t))return a(t);s[e].get(t).staged=!0;const r=[...s[e]];function a(t){const r=e?n.ee.get(e):n.ee,a=o.X.handlers;if(r.backlog&&a){var s=r.backlog[t],c=a[t];if(c){for(var u=0;s&&u<s.length;++u)f(s[u],c);(0,i.D)(c,(function(e,t){(0,i.D)(t,(function(t,r){r[0].on(e,r[1])}))}))}delete a[t],r.backlog[t]=null,r.emit("drain-"+t,[])}}r.every((e=>{let[t,r]=e;return r.staged}))&&(r.sort(((e,t)=>e[1].priority-t[1].priority)),r.forEach((e=>{let[t]=e;a(t)})))}function f(e,t){var r=e[1];(0,i.D)(t[r],(function(t,r){var n=e[0];if(r[0]===n){var i=r[1],o=e[3],a=e[2];i.apply(o,a)}}))}},2177:(e,t,r)=>{r.d(t,{c:()=>f,ee:()=>u});var n=r(8632),i=r(2210),o=r(1284),a=r(5763),s="nr@context";let c=(0,n.fP)();var u;function d(){}function f(e){return(0,i.X)(e,s,l)}function l(){return new d}function h(){u.aborted=!0,u.backlog={}}c.ee?u=c.ee:(u=function e(t,r){var n={},c={},f={},g=!1;try{g=16===r.length&&(0,a.OP)(r).isolatedBacklog}catch(e){}var p={on:b,addEventListener:b,removeEventListener:y,emit:v,get:x,listeners:w,context:m,buffer:A,abort:h,aborted:!1,isBuffering:E,debugId:r,backlog:g?{}:t&&"object"==typeof t.backlog?t.backlog:{}};return p;function m(e){return e&&e instanceof d?e:e?(0,i.X)(e,s,l):l()}function v(e,r,n,i,o){if(!1!==o&&(o=!0),!u.aborted||i){t&&o&&t.emit(e,r,n);for(var a=m(n),s=w(e),d=s.length,f=0;f<d;f++)s[f].apply(a,r);var l=T()[c[e]];return l&&l.push([p,e,r,a]),a}}function b(e,t){n[e]=w(e).concat(t)}function y(e,t){var r=n[e];if(r)for(var i=0;i<r.length;i++)r[i]===t&&r.splice(i,1)}function w(e){return n[e]||[]}function x(t){return f[t]=f[t]||e(p,t)}function A(e,t){var r=T();p.aborted||(0,o.D)(e,(function(e,n){t=t||"feature",c[n]=t,t in r||(r[t]=[])}))}function E(e){return!!T()[c[e]]}function T(){return p.backlog}}(void 0,"globalEE"),c.ee=u)},5546:(e,t,r)=>{r.d(t,{E:()=>n,p:()=>i});var n=r(2177).ee.get("handle");function i(e,t,r,i,o){o?(o.buffer([e],i),o.emit(e,t,r)):(n.buffer([e],i),n.emit(e,t,r))}},4322:(e,t,r)=>{r.d(t,{X:()=>o});var n=r(5546);o.on=a;var i=o.handlers={};function o(e,t,r,o){a(o||n.E,i,e,t,r)}function a(e,t,r,i,o){o||(o="feature"),e||(e=n.E);var a=t[o]=t[o]||{};(a[r]=a[r]||[]).push([e,i])}},3239:(e,t,r)=>{r.d(t,{bP:()=>s,iz:()=>c,m$:()=>a});var n=r(385);let i=!1,o=!1;try{const e={get passive(){return i=!0,!1},get signal(){return o=!0,!1}};n._A.addEventListener("test",null,e),n._A.removeEventListener("test",null,e)}catch(e){}function a(e,t){return i||o?{capture:!!e,passive:i,signal:t}:!!e}function s(e,t){let r=arguments.length>2&&void 0!==arguments[2]&&arguments[2],n=arguments.length>3?arguments[3]:void 0;window.addEventListener(e,t,a(r,n))}function c(e,t){let r=arguments.length>2&&void 0!==arguments[2]&&arguments[2],n=arguments.length>3?arguments[3]:void 0;document.addEventListener(e,t,a(r,n))}},4402:(e,t,r)=>{r.d(t,{Ht:()=>u,M:()=>c,Rl:()=>a,ky:()=>s});var n=r(385);const i="xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx";function o(e,t){return e?15&e[t]:16*Math.random()|0}function a(){const e=n._A?.crypto||n._A?.msCrypto;let t,r=0;return e&&e.getRandomValues&&(t=e.getRandomValues(new Uint8Array(31))),i.split("").map((e=>"x"===e?o(t,++r).toString(16):"y"===e?(3&o()|8).toString(16):e)).join("")}function s(e){const t=n._A?.crypto||n._A?.msCrypto;let r,i=0;t&&t.getRandomValues&&(r=t.getRandomValues(new Uint8Array(31)));const a=[];for(var s=0;s<e;s++)a.push(o(r,++i).toString(16));return a.join("")}function c(){return s(16)}function u(){return s(32)}},7056:(e,t,r)=>{r.d(t,{Bq:()=>n,Hb:()=>o,oD:()=>i});const n="NRBA",i=144e5,o=18e5},7894:(e,t,r)=>{function n(){return Math.round(performance.now())}r.d(t,{z:()=>n})},7243:(e,t,r)=>{r.d(t,{e:()=>o});var n=r(385),i={};function o(e){if(e in i)return i[e];if(0===(e||"").indexOf("data:"))return{protocol:"data"};let t;var r=n._A?.location,o={};if(n.il)t=document.createElement("a"),t.href=e;else try{t=new URL(e,r.href)}catch(e){return o}o.port=t.port;var a=t.href.split("://");!o.port&&a[1]&&(o.port=a[1].split("/")[0].split("@").pop().split(":")[1]),o.port&&"0"!==o.port||(o.port="https"===a[0]?"443":"80"),o.hostname=t.hostname||r.hostname,o.pathname=t.pathname,o.protocol=a[0],"/"!==o.pathname.charAt(0)&&(o.pathname="/"+o.pathname);var s=!t.protocol||":"===t.protocol||t.protocol===r.protocol,c=t.hostname===r.hostname&&t.port===r.port;return o.sameOrigin=s&&(!t.hostname||c),"/"===o.pathname&&(i[e]=o),o}},50:(e,t,r)=>{function n(e,t){"function"==typeof console.warn&&(console.warn("New Relic: ".concat(e)),t&&console.warn(t))}r.d(t,{Z:()=>n})},2587:(e,t,r)=>{r.d(t,{N:()=>c,T:()=>u});var n=r(2177),i=r(5546),o=r(8e3),a=r(3325);const s={stn:[a.D.sessionTrace],err:[a.D.jserrors,a.D.metrics],ins:[a.D.pageAction],spa:[a.D.spa],sr:[a.D.sessionReplay,a.D.sessionTrace]};function c(e,t){const r=n.ee.get(t);e&&"object"==typeof e&&(Object.entries(e).forEach((e=>{let[t,n]=e;void 0===u[t]&&(s[t]?s[t].forEach((e=>{n?(0,i.p)("feat-"+t,[],void 0,e,r):(0,i.p)("block-"+t,[],void 0,e,r),(0,i.p)("rumresp-"+t,[Boolean(n)],void 0,e,r)})):n&&(0,i.p)("feat-"+t,[],void 0,void 0,r),u[t]=Boolean(n))})),Object.keys(s).forEach((e=>{void 0===u[e]&&(s[e]?.forEach((t=>(0,i.p)("rumresp-"+e,[!1],void 0,t,r))),u[e]=!1)})),(0,o.L)(t,a.D.pageViewEvent))}const u={}},2210:(e,t,r)=>{r.d(t,{X:()=>i});var n=Object.prototype.hasOwnProperty;function i(e,t,r){if(n.call(e,t))return e[t];var i=r();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(e,t,{value:i,writable:!0,enumerable:!1}),i}catch(e){}return e[t]=i,i}},1284:(e,t,r)=>{r.d(t,{D:()=>n});const n=(e,t)=>Object.entries(e||{}).map((e=>{let[r,n]=e;return t(r,n)}))},4351:(e,t,r)=>{r.d(t,{P:()=>o});var n=r(2177);const i=()=>{const e=new WeakSet;return(t,r)=>{if("object"==typeof r&&null!==r){if(e.has(r))return;e.add(r)}return r}};function o(e){try{return JSON.stringify(e,i())}catch(e){try{n.ee.emit("internal-error",[e])}catch(e){}}}},3960:(e,t,r)=>{r.d(t,{K:()=>a,b:()=>o});var n=r(3239);function i(){return"undefined"==typeof document||"complete"===document.readyState}function o(e,t){if(i())return e();(0,n.bP)("load",e,t)}function a(e){if(i())return e();(0,n.iz)("DOMContentLoaded",e)}},8632:(e,t,r)=>{r.d(t,{EZ:()=>u,Qy:()=>c,ce:()=>o,fP:()=>a,gG:()=>d,mF:()=>s});var n=r(7894),i=r(385);const o={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net"};function a(){return i._A.NREUM||(i._A.NREUM={}),void 0===i._A.newrelic&&(i._A.newrelic=i._A.NREUM),i._A.NREUM}function s(){let e=a();return e.o||(e.o={ST:i._A.setTimeout,SI:i._A.setImmediate,CT:i._A.clearTimeout,XHR:i._A.XMLHttpRequest,REQ:i._A.Request,EV:i._A.Event,PR:i._A.Promise,MO:i._A.MutationObserver,FETCH:i._A.fetch}),e}function c(e,t,r){let i=a();const o=i.initializedAgents||{},s=o[e]||{};return Object.keys(s).length||(s.initializedAt={ms:(0,n.z)(),date:new Date}),i.initializedAgents={...o,[e]:{...s,[r]:t}},i}function u(e,t){a()[e]=t}function d(){return function(){let e=a();const t=e.info||{};e.info={beacon:o.beacon,errorBeacon:o.errorBeacon,...t}}(),function(){let e=a();const t=e.init||{};e.init={...t}}(),s(),function(){let e=a();const t=e.loader_config||{};e.loader_config={...t}}(),a()}},7956:(e,t,r)=>{r.d(t,{N:()=>i});var n=r(3239);function i(e){let t=arguments.length>1&&void 0!==arguments[1]&&arguments[1],r=arguments.length>2?arguments[2]:void 0,i=arguments.length>3?arguments[3]:void 0;return void(0,n.iz)("visibilitychange",(function(){if(t)return void("hidden"==document.visibilityState&&e());e(document.visibilityState)}),r,i)}},1214:(e,t,r)=>{r.d(t,{em:()=>v,u5:()=>N,QU:()=>S,_L:()=>I,Gm:()=>L,Lg:()=>M,gy:()=>U,BV:()=>Q,Kf:()=>ee});var n=r(2177);const i="nr@original";var o=Object.prototype.hasOwnProperty,a=!1;function s(e,t){return e||(e=n.ee),r.inPlace=function(e,t,n,i,o){n||(n="");var a,s,c,u="-"===n.charAt(0);for(c=0;c<t.length;c++)d(a=e[s=t[c]])||(e[s]=r(a,u?s+n:n,i,s,o))},r.flag=i,r;function r(t,r,n,a,s){return d(t)?t:(r||(r=""),nrWrapper[i]=t,u(t,nrWrapper,e),nrWrapper);function nrWrapper(){var i,u,d,f;try{u=this,i=[...arguments],d="function"==typeof n?n(i,u):n||{}}catch(t){c([t,"",[i,u,a],d],e)}o(r+"start",[i,u,a],d,s);try{return f=t.apply(u,i)}catch(e){throw o(r+"err",[i,u,e],d,s),e}finally{o(r+"end",[i,u,f],d,s)}}}function o(r,n,i,o){if(!a||t){var s=a;a=!0;try{e.emit(r,n,i,t,o)}catch(t){c([t,r,n,i],e)}a=s}}}function c(e,t){t||(t=n.ee);try{t.emit("internal-error",e)}catch(e){}}function u(e,t,r){if(Object.defineProperty&&Object.keys)try{return Object.keys(e).forEach((function(r){Object.defineProperty(t,r,{get:function(){return e[r]},set:function(t){return e[r]=t,t}})})),t}catch(e){c([e],r)}for(var n in e)o.call(e,n)&&(t[n]=e[n]);return t}function d(e){return!(e&&e instanceof Function&&e.apply&&!e[i])}var f=r(2210),l=r(385);const h={},g=XMLHttpRequest,p="addEventListener",m="removeEventListener";function v(e){var t=function(e){return(e||n.ee).get("events")}(e);if(h[t.debugId]++)return t;h[t.debugId]=1;var r=s(t,!0);function i(e){r.inPlace(e,[p,m],"-",o)}function o(e,t){return e[1]}return"getPrototypeOf"in Object&&(l.il&&b(document,i),b(l._A,i),b(g.prototype,i)),t.on(p+"-start",(function(e,t){var n=e[1];if(null!==n&&("function"==typeof n||"object"==typeof n)){var i=(0,f.X)(n,"nr@wrapped",(function(){var e={object:function(){if("function"!=typeof n.handleEvent)return;return n.handleEvent.apply(n,arguments)},function:n}[typeof n];return e?r(e,"fn-",null,e.name||"anonymous"):n}));this.wrapped=e[1]=i}})),t.on(m+"-start",(function(e){e[1]=this.wrapped||e[1]})),t}function b(e,t){let r=e;for(;"object"==typeof r&&!Object.prototype.hasOwnProperty.call(r,p);)r=Object.getPrototypeOf(r);for(var n=arguments.length,i=new Array(n>2?n-2:0),o=2;o<n;o++)i[o-2]=arguments[o];r&&t(r,...i)}var y="fetch-",w=y+"body-",x=["arrayBuffer","blob","json","text","formData"],A=l._A.Request,E=l._A.Response,T="prototype",_="nr@context";const D={};function N(e){const t=function(e){return(e||n.ee).get("fetch")}(e);if(!(A&&E&&l._A.fetch))return t;if(D[t.debugId]++)return t;function r(e,r,n){var i=e[r];"function"==typeof i&&(e[r]=function(){var e,r=[...arguments],o={};t.emit(n+"before-start",[r],o),o[_]&&o[_].dt&&(e=o[_].dt);var a=i.apply(this,r);return t.emit(n+"start",[r,e],a),a.then((function(e){return t.emit(n+"end",[null,e],a),e}),(function(e){throw t.emit(n+"end",[e],a),e}))})}return D[t.debugId]=1,x.forEach((e=>{r(A[T],e,w),r(E[T],e,w)})),r(l._A,"fetch",y),t.on(y+"end",(function(e,r){var n=this;if(r){var i=r.headers.get("content-length");null!==i&&(n.rxSize=i),t.emit(y+"done",[null,r],n)}else t.emit(y+"done",[e],n)})),t}const O={},j=["pushState","replaceState"];function S(e){const t=function(e){return(e||n.ee).get("history")}(e);return!l.il||O[t.debugId]++||(O[t.debugId]=1,s(t).inPlace(window.history,j,"-")),t}var P=r(3239);const C={},R=["appendChild","insertBefore","replaceChild"];function I(e){const t=function(e){return(e||n.ee).get("jsonp")}(e);if(!l.il||C[t.debugId])return t;C[t.debugId]=!0;var r=s(t),i=/[?&](?:callback|cb)=([^&#]+)/,o=/(.*)\.([^.]+)/,a=/^(\w+)(\.|$)(.*)$/;function c(e,t){var r=e.match(a),n=r[1],i=r[3];return i?c(i,t[n]):t[n]}return r.inPlace(Node.prototype,R,"dom-"),t.on("dom-start",(function(e){!function(e){if(!e||"string"!=typeof e.nodeName||"script"!==e.nodeName.toLowerCase())return;if("function"!=typeof e.addEventListener)return;var n=(a=e.src,s=a.match(i),s?s[1]:null);var a,s;if(!n)return;var u=function(e){var t=e.match(o);if(t&&t.length>=3)return{key:t[2],parent:c(t[1],window)};return{key:e,parent:window}}(n);if("function"!=typeof u.parent[u.key])return;var d={};function f(){t.emit("jsonp-end",[],d),e.removeEventListener("load",f,(0,P.m$)(!1)),e.removeEventListener("error",l,(0,P.m$)(!1))}function l(){t.emit("jsonp-error",[],d),t.emit("jsonp-end",[],d),e.removeEventListener("load",f,(0,P.m$)(!1)),e.removeEventListener("error",l,(0,P.m$)(!1))}r.inPlace(u.parent,[u.key],"cb-",d),e.addEventListener("load",f,(0,P.m$)(!1)),e.addEventListener("error",l,(0,P.m$)(!1)),t.emit("new-jsonp",[e.src],d)}(e[0])})),t}var k=r(5763);const H={};function L(e){const t=function(e){return(e||n.ee).get("mutation")}(e);if(!l.il||H[t.debugId])return t;H[t.debugId]=!0;var r=s(t),i=k.Yu.MO;return i&&(window.MutationObserver=function(e){return this instanceof i?new i(r(e,"fn-")):i.apply(this,arguments)},MutationObserver.prototype=i.prototype),t}const z={};function M(e){const t=function(e){return(e||n.ee).get("promise")}(e);if(z[t.debugId])return t;z[t.debugId]=!0;var r=n.c,o=s(t),a=k.Yu.PR;return a&&function(){function e(r){var n=t.context(),i=o(r,"executor-",n,null,!1);const s=Reflect.construct(a,[i],e);return t.context(s).getCtx=function(){return n},s}l._A.Promise=e,Object.defineProperty(e,"name",{value:"Promise"}),e.toString=function(){return a.toString()},Object.setPrototypeOf(e,a),["all","race"].forEach((function(r){const n=a[r];e[r]=function(e){let i=!1;[...e||[]].forEach((e=>{this.resolve(e).then(a("all"===r),a(!1))}));const o=n.apply(this,arguments);return o;function a(e){return function(){t.emit("propagate",[null,!i],o,!1,!1),i=i||!e}}}})),["resolve","reject"].forEach((function(r){const n=a[r];e[r]=function(e){const r=n.apply(this,arguments);return e!==r&&t.emit("propagate",[e,!0],r,!1,!1),r}})),e.prototype=a.prototype;const n=a.prototype.then;a.prototype.then=function(){var e=this,i=r(e);i.promise=e;for(var a=arguments.length,s=new Array(a),c=0;c<a;c++)s[c]=arguments[c];s[0]=o(s[0],"cb-",i,null,!1),s[1]=o(s[1],"cb-",i,null,!1);const u=n.apply(this,s);return i.nextPromise=u,t.emit("propagate",[e,!0],u,!1,!1),u},a.prototype.then[i]=n,t.on("executor-start",(function(e){e[0]=o(e[0],"resolve-",this,null,!1),e[1]=o(e[1],"resolve-",this,null,!1)})),t.on("executor-err",(function(e,t,r){e[1](r)})),t.on("cb-end",(function(e,r,n){t.emit("propagate",[n,!0],this.nextPromise,!1,!1)})),t.on("propagate",(function(e,r,n){this.getCtx&&!r||(this.getCtx=function(){if(e instanceof Promise)var r=t.context(e);return r&&r.getCtx?r.getCtx():this})}))}(),t}const B={},F="requestAnimationFrame";function U(e){const t=function(e){return(e||n.ee).get("raf")}(e);if(!l.il||B[t.debugId]++)return t;B[t.debugId]=1;var r=s(t);return r.inPlace(window,[F],"raf-"),t.on("raf-start",(function(e){e[0]=r(e[0],"fn-")})),t}const q={},G="setTimeout",V="setInterval",X="clearTimeout",W="-start",Z="-",$=[G,"setImmediate",V,X,"clearImmediate"];function Q(e){const t=function(e){return(e||n.ee).get("timer")}(e);if(q[t.debugId]++)return t;q[t.debugId]=1;var r=s(t);return r.inPlace(l._A,$.slice(0,2),G+Z),r.inPlace(l._A,$.slice(2,3),V+Z),r.inPlace(l._A,$.slice(3),X+Z),t.on(V+W,(function(e,t,n){e[0]=r(e[0],"fn-",null,n)})),t.on(G+W,(function(e,t,n){this.method=n,this.timerDuration=isNaN(e[1])?0:+e[1],e[0]=r(e[0],"fn-",this,n)})),t}var Y=r(50);const K={},J=["open","send"];function ee(e){var t=e||n.ee;const r=function(e){return(e||n.ee).get("xhr")}(t);if(K[r.debugId]++)return r;K[r.debugId]=1,v(t);var i=s(r),o=k.Yu.XHR,a=k.Yu.MO,c=k.Yu.PR,u=k.Yu.SI,d="readystatechange",f=["onload","onerror","onabort","onloadstart","onloadend","onprogress","ontimeout"],h=[],g=l._A.XMLHttpRequest.listeners,p=l._A.XMLHttpRequest=function(e){var t=new o(e);function n(){try{r.emit("new-xhr",[t],t),t.addEventListener(d,b,(0,P.m$)(!1))}catch(e){(0,Y.Z)("An error occured while intercepting XHR",e);try{r.emit("internal-error",[e])}catch(e){}}}return this.listeners=g?[...g,n]:[n],this.listeners.forEach((e=>e())),t};function m(e,t){i.inPlace(t,["onreadystatechange"],"fn-",E)}function b(){var e=this,t=r.context(e);e.readyState>3&&!t.resolved&&(t.resolved=!0,r.emit("xhr-resolved",[],e)),i.inPlace(e,f,"fn-",E)}if(function(e,t){for(var r in e)t[r]=e[r]}(o,p),p.prototype=o.prototype,i.inPlace(p.prototype,J,"-xhr-",E),r.on("send-xhr-start",(function(e,t){m(e,t),function(e){h.push(e),a&&(y?y.then(A):u?u(A):(w=-w,x.data=w))}(t)})),r.on("open-xhr-start",m),a){var y=c&&c.resolve();if(!u&&!c){var w=1,x=document.createTextNode(w);new a(A).observe(x,{characterData:!0})}}else t.on("fn-end",(function(e){e[0]&&e[0].type===d||A()}));function A(){for(var e=0;e<h.length;e++)m(0,h[e]);h.length&&(h=[])}function E(e,t){return t}return r}},7825:(e,t,r)=>{r.d(t,{t:()=>n});const n=r(3325).D.ajax},6660:(e,t,r)=>{r.d(t,{A:()=>i,t:()=>n});const n=r(3325).D.jserrors,i="nr@seenError"},3081:(e,t,r)=>{r.d(t,{gF:()=>o,mY:()=>i,t9:()=>n,vz:()=>s,xS:()=>a});const n=r(3325).D.metrics,i="sm",o="cm",a="storeSupportabilityMetrics",s="storeEventMetrics"},4649:(e,t,r)=>{r.d(t,{t:()=>n});const n=r(3325).D.pageAction},7633:(e,t,r)=>{r.d(t,{Dz:()=>i,OJ:()=>a,qw:()=>o,t9:()=>n});const n=r(3325).D.pageViewEvent,i="firstbyte",o="domcontent",a="windowload"},9251:(e,t,r)=>{r.d(t,{t:()=>n});const n=r(3325).D.pageViewTiming},3614:(e,t,r)=>{r.d(t,{BST_RESOURCE:()=>i,END:()=>s,FEATURE_NAME:()=>n,FN_END:()=>u,FN_START:()=>c,PUSH_STATE:()=>d,RESOURCE:()=>o,START:()=>a});const n=r(3325).D.sessionTrace,i="bstResource",o="resource",a="-start",s="-end",c="fn"+a,u="fn"+s,d="pushState"},7836:(e,t,r)=>{r.d(t,{BODY:()=>A,CB_END:()=>E,CB_START:()=>u,END:()=>x,FEATURE_NAME:()=>i,FETCH:()=>_,FETCH_BODY:()=>v,FETCH_DONE:()=>m,FETCH_START:()=>p,FN_END:()=>c,FN_START:()=>s,INTERACTION:()=>l,INTERACTION_API:()=>d,INTERACTION_EVENTS:()=>o,JSONP_END:()=>b,JSONP_NODE:()=>g,JS_TIME:()=>T,MAX_TIMER_BUDGET:()=>a,REMAINING:()=>f,SPA_NODE:()=>h,START:()=>w,originalSetTimeout:()=>y});var n=r(5763);const i=r(3325).D.spa,o=["click","submit","keypress","keydown","keyup","change"],a=999,s="fn-start",c="fn-end",u="cb-start",d="api-ixn-",f="remaining",l="interaction",h="spaNode",g="jsonpNode",p="fetch-start",m="fetch-done",v="fetch-body-",b="jsonp-end",y=n.Yu.ST,w="-start",x="-end",A="-body",E="cb"+x,T="jsTime",_="fetch"},5938:(e,t,r)=>{r.d(t,{W:()=>o});var n=r(5763),i=r(2177);class o{constructor(e,t,r){this.agentIdentifier=e,this.aggregator=t,this.ee=i.ee.get(e,(0,n.OP)(this.agentIdentifier).isolatedBacklog),this.featureName=r,this.blocked=!1}}},9144:(e,t,r)=>{r.d(t,{j:()=>m});var n=r(3325),i=r(5763),o=r(5546),a=r(2177),s=r(7894),c=r(8e3),u=r(3960),d=r(385),f=r(50),l=r(3081),h=r(8632);function g(){const e=(0,h.gG)();["setErrorHandler","finished","addToTrace","inlineHit","addRelease","addPageAction","setCurrentRouteName","setPageViewName","setCustomAttribute","interaction","noticeError","setUserId"].forEach((t=>{e[t]=function(){for(var r=arguments.length,n=new Array(r),i=0;i<r;i++)n[i]=arguments[i];return function(t){for(var r=arguments.length,n=new Array(r>1?r-1:0),i=1;i<r;i++)n[i-1]=arguments[i];let o=[];return Object.values(e.initializedAgents).forEach((e=>{e.exposed&&e.api[t]&&o.push(e.api[t](...n))})),o.length>1?o:o[0]}(t,...n)}}))}var p=r(2587);function m(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},m=arguments.length>2?arguments[2]:void 0,v=arguments.length>3?arguments[3]:void 0,{init:b,info:y,loader_config:w,runtime:x={loaderType:m},exposed:A=!0}=t;const E=(0,h.gG)();y||(b=E.init,y=E.info,w=E.loader_config),(0,i.Dg)(e,b||{}),(0,i.GE)(e,w||{}),(0,i.sU)(e,x),y.jsAttributes??={},d.v6&&(y.jsAttributes.isWorker=!0),(0,i.CX)(e,y),g();const T=function(e,t){t||(0,c.R)(e,"api");const h={};var g=a.ee.get(e),p=g.get("tracer"),m="api-",v=m+"ixn-";function b(t,r,n,o){const a=(0,i.C5)(e);return null===r?delete a.jsAttributes[t]:(0,i.CX)(e,{...a,jsAttributes:{...a.jsAttributes,[t]:r}}),x(m,n,!0,o||null===r?"session":void 0)(t,r)}function y(){}["setErrorHandler","finished","addToTrace","inlineHit","addRelease"].forEach((e=>h[e]=x(m,e,!0,"api"))),h.addPageAction=x(m,"addPageAction",!0,n.D.pageAction),h.setCurrentRouteName=x(m,"routeName",!0,n.D.spa),h.setPageViewName=function(t,r){if("string"==typeof t)return"/"!==t.charAt(0)&&(t="/"+t),(0,i.OP)(e).customTransaction=(r||"http://custom.transaction")+t,x(m,"setPageViewName",!0)()},h.setCustomAttribute=function(e,t){let r=arguments.length>2&&void 0!==arguments[2]&&arguments[2];if("string"==typeof e){if(["string","number"].includes(typeof t)||null===t)return b(e,t,"setCustomAttribute",r);(0,f.Z)("Failed to execute setCustomAttribute.\nNon-null value must be a string or number type, but a type of <".concat(typeof t,"> was provided."))}else(0,f.Z)("Failed to execute setCustomAttribute.\nName must be a string type, but a type of <".concat(typeof e,"> was provided."))},h.setUserId=function(e){if("string"==typeof e||null===e)return b("enduser.id",e,"setUserId",!0);(0,f.Z)("Failed to execute setUserId.\nNon-null value must be a string type, but a type of <".concat(typeof e,"> was provided."))},h.interaction=function(){return(new y).get()};var w=y.prototype={createTracer:function(e,t){var r={},i=this,a="function"==typeof t;return(0,o.p)(v+"tracer",[(0,s.z)(),e,r],i,n.D.spa,g),function(){if(p.emit((a?"":"no-")+"fn-start",[(0,s.z)(),i,a],r),a)try{return t.apply(this,arguments)}catch(e){throw p.emit("fn-err",[arguments,this,"string"==typeof e?new Error(e):e],r),e}finally{p.emit("fn-end",[(0,s.z)()],r)}}}};function x(e,t,r,i){return function(){return(0,o.p)(l.xS,["API/"+t+"/called"],void 0,n.D.metrics,g),i&&(0,o.p)(e+t,[(0,s.z)(),...arguments],r?null:this,i,g),r?void 0:this}}function A(){r.e(439).then(r.bind(r,7438)).then((t=>{let{setAPI:r}=t;r(e),(0,c.L)(e,"api")})).catch((()=>(0,f.Z)("Downloading runtime APIs failed...")))}return["actionText","setName","setAttribute","save","ignore","onEnd","getContext","end","get"].forEach((e=>{w[e]=x(v,e,void 0,n.D.spa)})),h.noticeError=function(e,t){"string"==typeof e&&(e=new Error(e)),(0,o.p)(l.xS,["API/noticeError/called"],void 0,n.D.metrics,g),(0,o.p)("err",[e,(0,s.z)(),!1,t],void 0,n.D.jserrors,g)},d.il?(0,u.b)((()=>A()),!0):A(),h}(e,v);return(0,h.Qy)(e,T,"api"),(0,h.Qy)(e,A,"exposed"),(0,h.EZ)("activatedFeatures",p.T),T}},3325:(e,t,r)=>{r.d(t,{D:()=>n,p:()=>i});const n={ajax:"ajax",jserrors:"jserrors",metrics:"metrics",pageAction:"page_action",pageViewEvent:"page_view_event",pageViewTiming:"page_view_timing",sessionReplay:"session_replay",sessionTrace:"session_trace",spa:"spa"},i={[n.pageViewEvent]:1,[n.pageViewTiming]:2,[n.metrics]:3,[n.jserrors]:4,[n.ajax]:5,[n.sessionTrace]:6,[n.pageAction]:7,[n.spa]:8,[n.sessionReplay]:9}}},n={};function i(e){var t=n[e];if(void 0!==t)return t.exports;var o=n[e]={exports:{}};return r[e](o,o.exports,i),o.exports}i.m=r,i.d=(e,t)=>{for(var r in t)i.o(t,r)&&!i.o(e,r)&&Object.defineProperty(e,r,{enumerable:!0,get:t[r]})},i.f={},i.e=e=>Promise.all(Object.keys(i.f).reduce(((t,r)=>(i.f[r](e,t),t)),[])),i.u=e=>(({78:"page_action-aggregate",147:"metrics-aggregate",242:"session-manager",317:"jserrors-aggregate",348:"page_view_timing-aggregate",412:"lazy-feature-loader",439:"async-api",538:"recorder",590:"session_replay-aggregate",675:"compressor",733:"session_trace-aggregate",786:"page_view_event-aggregate",873:"spa-aggregate",898:"ajax-aggregate"}[e]||e)+"."+{78:"ac76d497",147:"3dc53903",148:"1a20d5fe",242:"2a64278a",317:"49e41428",348:"bd6de33a",412:"2f55ce66",439:"30bd804e",538:"1b18459f",590:"cf0efb30",675:"ae9f91a8",733:"83105561",786:"06482edd",860:"03a8b7a5",873:"e6b09d52",898:"998ef92b"}[e]+"-1.236.0.min.js"),i.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t),e={},t="NRBA:",i.l=(r,n,o,a)=>{if(e[r])e[r].push(n);else{var s,c;if(void 0!==o)for(var u=document.getElementsByTagName("script"),d=0;d<u.length;d++){var f=u[d];if(f.getAttribute("src")==r||f.getAttribute("data-webpack")==t+o){s=f;break}}s||(c=!0,(s=document.createElement("script")).charset="utf-8",s.timeout=120,i.nc&&s.setAttribute("nonce",i.nc),s.setAttribute("data-webpack",t+o),s.src=r),e[r]=[n];var l=(t,n)=>{s.onerror=s.onload=null,clearTimeout(h);var i=e[r];if(delete e[r],s.parentNode&&s.parentNode.removeChild(s),i&&i.forEach((e=>e(n))),t)return t(n)},h=setTimeout(l.bind(null,void 0,{type:"timeout",target:s}),12e4);s.onerror=l.bind(null,s.onerror),s.onload=l.bind(null,s.onload),c&&document.head.appendChild(s)}},i.r=e=>{"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},i.j=364,i.p="https://js-agent.newrelic.com/",(()=>{var e={364:0,953:0};i.f.j=(t,r)=>{var n=i.o(e,t)?e[t]:void 0;if(0!==n)if(n)r.push(n[2]);else{var o=new Promise(((r,i)=>n=e[t]=[r,i]));r.push(n[2]=o);var a=i.p+i.u(t),s=new Error;i.l(a,(r=>{if(i.o(e,t)&&(0!==(n=e[t])&&(e[t]=void 0),n)){var o=r&&("load"===r.type?"missing":r.type),a=r&&r.target&&r.target.src;s.message="Loading chunk "+t+" failed.\n("+o+": "+a+")",s.name="ChunkLoadError",s.type=o,s.request=a,n[1](s)}}),"chunk-"+t,t)}};var t=(t,r)=>{var n,o,[a,s,c]=r,u=0;if(a.some((t=>0!==e[t]))){for(n in s)i.o(s,n)&&(i.m[n]=s[n]);if(c)c(i)}for(t&&t(r);u<a.length;u++)o=a[u],i.o(e,o)&&e[o]&&e[o][0](),e[o]=0},r=window.webpackChunkNRBA=window.webpackChunkNRBA||[];r.forEach(t.bind(null,0)),r.push=t.bind(null,r.push.bind(r))})();var o={};(()=>{i.r(o);var e=i(3325),t=i(5763);const r=Object.values(e.D);function n(e){const n={};return r.forEach((r=>{n[r]=function(e,r){return!1!==(0,t.Mt)(r,"".concat(e,".enabled"))}(r,e)})),n}var a=i(9144);var s=i(5546),c=i(385),u=i(8e3),d=i(5938),f=i(3960),l=i(50);class h extends d.W{constructor(e,t,r){let n=!(arguments.length>3&&void 0!==arguments[3])||arguments[3];super(e,t,r),this.auto=n,this.abortHandler,this.featAggregate,this.onAggregateImported,n&&(0,u.R)(e,r)}importAggregator(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};if(this.featAggregate||!this.auto)return;const r=c.il&&!0===(0,t.Mt)(this.agentIdentifier,"privacy.cookies_enabled");let n;this.onAggregateImported=new Promise((e=>{n=e}));const o=async()=>{let t;try{if(r){const{setupAgentSession:e}=await Promise.all([i.e(860),i.e(242)]).then(i.bind(i,3228));t=e(this.agentIdentifier)}}catch(e){(0,l.Z)("A problem occurred when starting up session manager. This page will not start or extend any session.",e)}try{if(!this.shouldImportAgg(this.featureName,t))return void(0,u.L)(this.agentIdentifier,this.featureName);const{lazyFeatureLoader:r}=await i.e(412).then(i.bind(i,8582)),{Aggregate:o}=await r(this.featureName,"aggregate");this.featAggregate=new o(this.agentIdentifier,this.aggregator,e),n(!0)}catch(e){(0,l.Z)("Downloading and initializing ".concat(this.featureName," failed..."),e),this.abortHandler?.(),n(!1)}};c.il?(0,f.b)((()=>o()),!0):o()}shouldImportAgg(r,n){return r!==e.D.sessionReplay||!1!==(0,t.Mt)(this.agentIdentifier,"session_trace.enabled")&&(!!n?.isNew||!!n?.state.sessionReplay)}}var g=i(7633),p=i(7894);class m extends h{static featureName=g.t9;constructor(r,n){let i=!(arguments.length>2&&void 0!==arguments[2])||arguments[2];if(super(r,n,g.t9,i),("undefined"==typeof PerformanceNavigationTiming||c.Tt)&&"undefined"!=typeof PerformanceTiming){const n=(0,t.OP)(r);n[g.Dz]=Math.max(Date.now()-n.offset,0),(0,f.K)((()=>n[g.qw]=Math.max((0,p.z)()-n[g.Dz],0))),(0,f.b)((()=>{const t=(0,p.z)();n[g.OJ]=Math.max(t-n[g.Dz],0),(0,s.p)("timing",["load",t],void 0,e.D.pageViewTiming,this.ee)}))}this.importAggregator()}}var v=i(1117),b=i(1284);class y extends v.w{constructor(e){super(e),this.aggregatedData={}}store(e,t,r,n,i){var o=this.getBucket(e,t,r,i);return o.metrics=function(e,t){t||(t={count:0});return t.count+=1,(0,b.D)(e,(function(e,r){t[e]=w(r,t[e])})),t}(n,o.metrics),o}merge(e,t,r,n,i){var o=this.getBucket(e,t,n,i);if(o.metrics){var a=o.metrics;a.count+=r.count,(0,b.D)(r,(function(e,t){if("count"!==e){var n=a[e],i=r[e];i&&!i.c?a[e]=w(i.t,n):a[e]=function(e,t){if(!t)return e;t.c||(t=x(t.t));return t.min=Math.min(e.min,t.min),t.max=Math.max(e.max,t.max),t.t+=e.t,t.sos+=e.sos,t.c+=e.c,t}(i,a[e])}}))}else o.metrics=r}storeMetric(e,t,r,n){var i=this.getBucket(e,t,r);return i.stats=w(n,i.stats),i}getBucket(e,t,r,n){this.aggregatedData[e]||(this.aggregatedData[e]={});var i=this.aggregatedData[e][t];return i||(i=this.aggregatedData[e][t]={params:r||{}},n&&(i.custom=n)),i}get(e,t){return t?this.aggregatedData[e]&&this.aggregatedData[e][t]:this.aggregatedData[e]}take(e){for(var t={},r="",n=!1,i=0;i<e.length;i++)t[r=e[i]]=A(this.aggregatedData[r]),t[r].length&&(n=!0),delete this.aggregatedData[r];return n?t:null}}function w(e,t){return null==e?function(e){e?e.c++:e={c:1};return e}(t):t?(t.c||(t=x(t.t)),t.c+=1,t.t+=e,t.sos+=e*e,e>t.max&&(t.max=e),e<t.min&&(t.min=e),t):{t:e}}function x(e){return{t:e,min:e,max:e,sos:e*e,c:1}}function A(e){return"object"!=typeof e?[]:(0,b.D)(e,E)}function E(e,t){return t}var T=i(8632),_=i(4402),D=i(4351);var N=i(7956),O=i(3239),j=i(9251);class S extends h{static featureName=j.t;constructor(e,r){let n=!(arguments.length>2&&void 0!==arguments[2])||arguments[2];super(e,r,j.t,n),c.il&&((0,t.OP)(e).initHidden=Boolean("hidden"===document.visibilityState),(0,N.N)((()=>(0,s.p)("docHidden",[(0,p.z)()],void 0,j.t,this.ee)),!0),(0,O.bP)("pagehide",(()=>(0,s.p)("winPagehide",[(0,p.z)()],void 0,j.t,this.ee))),this.importAggregator())}}var P=i(3081);class C extends h{static featureName=P.t9;constructor(e,t){let r=!(arguments.length>2&&void 0!==arguments[2])||arguments[2];super(e,t,P.t9,r),this.importAggregator()}}var R,I=i(2210),k=i(1214),H=i(2177),L={};try{R=localStorage.getItem("__nr_flags").split(","),console&&"function"==typeof console.log&&(L.console=!0,-1!==R.indexOf("dev")&&(L.dev=!0),-1!==R.indexOf("nr_dev")&&(L.nrDev=!0))}catch(e){}function z(e){try{L.console&&z(e)}catch(e){}}L.nrDev&&H.ee.on("internal-error",(function(e){z(e.stack)})),L.dev&&H.ee.on("fn-err",(function(e,t,r){z(r.stack)})),L.dev&&(z("NR AGENT IN DEVELOPMENT MODE"),z("flags: "+(0,b.D)(L,(function(e,t){return e})).join(", ")));var M=i(6660);class B extends h{static featureName=M.t;constructor(r,n){let i=!(arguments.length>2&&void 0!==arguments[2])||arguments[2];super(r,n,M.t,i),this.skipNext=0;try{this.removeOnAbort=new AbortController}catch(e){}const o=this;o.ee.on("fn-start",(function(e,t,r){o.abortHandler&&(o.skipNext+=1)})),o.ee.on("fn-err",(function(t,r,n){o.abortHandler&&!n[M.A]&&((0,I.X)(n,M.A,(function(){return!0})),this.thrown=!0,(0,s.p)("err",[n,(0,p.z)()],void 0,e.D.jserrors,o.ee))})),o.ee.on("fn-end",(function(){o.abortHandler&&!this.thrown&&o.skipNext>0&&(o.skipNext-=1)})),o.ee.on("internal-error",(function(t){(0,s.p)("ierr",[t,(0,p.z)(),!0],void 0,e.D.jserrors,o.ee)})),this.origOnerror=c._A.onerror,c._A.onerror=this.onerrorHandler.bind(this),c._A.addEventListener("unhandledrejection",(t=>{const r=function(e){let t="Unhandled Promise Rejection: ";if(e instanceof Error)try{return e.message=t+e.message,e}catch(t){return e}if(void 0===e)return new Error(t);try{return new Error(t+(0,D.P)(e))}catch(e){return new Error(t)}}(t.reason);(0,s.p)("err",[r,(0,p.z)(),!1,{unhandledPromiseRejection:1}],void 0,e.D.jserrors,this.ee)}),(0,O.m$)(!1,this.removeOnAbort?.signal)),(0,k.gy)(this.ee),(0,k.BV)(this.ee),(0,k.em)(this.ee),(0,t.OP)(r).xhrWrappable&&(0,k.Kf)(this.ee),this.abortHandler=this.#e,this.importAggregator()}#e(){this.removeOnAbort?.abort(),this.abortHandler=void 0}onerrorHandler(t,r,n,i,o){"function"==typeof this.origOnerror&&this.origOnerror(...arguments);try{this.skipNext?this.skipNext-=1:(0,s.p)("err",[o||new F(t,r,n),(0,p.z)()],void 0,e.D.jserrors,this.ee)}catch(t){try{(0,s.p)("ierr",[t,(0,p.z)(),!0],void 0,e.D.jserrors,this.ee)}catch(e){}}return!1}}function F(e,t,r){this.message=e||"Uncaught error with no additional information",this.sourceURL=t,this.line=r}let U=1;const q="nr@id";function G(e){const t=typeof e;return!e||"object"!==t&&"function"!==t?-1:e===c._A?0:(0,I.X)(e,q,(function(){return U++}))}function V(e){if("string"==typeof e&&e.length)return e.length;if("object"==typeof e){if("undefined"!=typeof ArrayBuffer&&e instanceof ArrayBuffer&&e.byteLength)return e.byteLength;if("undefined"!=typeof Blob&&e instanceof Blob&&e.size)return e.size;if(!("undefined"!=typeof FormData&&e instanceof FormData))try{return(0,D.P)(e).length}catch(e){return}}}var X=i(7243);class W{constructor(e){this.agentIdentifier=e,this.generateTracePayload=this.generateTracePayload.bind(this),this.shouldGenerateTrace=this.shouldGenerateTrace.bind(this)}generateTracePayload(e){if(!this.shouldGenerateTrace(e))return null;var r=(0,t.DL)(this.agentIdentifier);if(!r)return null;var n=(r.accountID||"").toString()||null,i=(r.agentID||"").toString()||null,o=(r.trustKey||"").toString()||null;if(!n||!i)return null;var a=(0,_.M)(),s=(0,_.Ht)(),c=Date.now(),u={spanId:a,traceId:s,timestamp:c};return(e.sameOrigin||this.isAllowedOrigin(e)&&this.useTraceContextHeadersForCors())&&(u.traceContextParentHeader=this.generateTraceContextParentHeader(a,s),u.traceContextStateHeader=this.generateTraceContextStateHeader(a,c,n,i,o)),(e.sameOrigin&&!this.excludeNewrelicHeader()||!e.sameOrigin&&this.isAllowedOrigin(e)&&this.useNewrelicHeaderForCors())&&(u.newrelicHeader=this.generateTraceHeader(a,s,c,n,i,o)),u}generateTraceContextParentHeader(e,t){return"00-"+t+"-"+e+"-01"}generateTraceContextStateHeader(e,t,r,n,i){return i+"@nr=0-1-"+r+"-"+n+"-"+e+"----"+t}generateTraceHeader(e,t,r,n,i,o){if(!("function"==typeof c._A?.btoa))return null;var a={v:[0,1],d:{ty:"Browser",ac:n,ap:i,id:e,tr:t,ti:r}};return o&&n!==o&&(a.d.tk=o),btoa((0,D.P)(a))}shouldGenerateTrace(e){return this.isDtEnabled()&&this.isAllowedOrigin(e)}isAllowedOrigin(e){var r=!1,n={};if((0,t.Mt)(this.agentIdentifier,"distributed_tracing")&&(n=(0,t.P_)(this.agentIdentifier).distributed_tracing),e.sameOrigin)r=!0;else if(n.allowed_origins instanceof Array)for(var i=0;i<n.allowed_origins.length;i++){var o=(0,X.e)(n.allowed_origins[i]);if(e.hostname===o.hostname&&e.protocol===o.protocol&&e.port===o.port){r=!0;break}}return r}isDtEnabled(){var e=(0,t.Mt)(this.agentIdentifier,"distributed_tracing");return!!e&&!!e.enabled}excludeNewrelicHeader(){var e=(0,t.Mt)(this.agentIdentifier,"distributed_tracing");return!!e&&!!e.exclude_newrelic_header}useNewrelicHeaderForCors(){var e=(0,t.Mt)(this.agentIdentifier,"distributed_tracing");return!!e&&!1!==e.cors_use_newrelic_header}useTraceContextHeadersForCors(){var e=(0,t.Mt)(this.agentIdentifier,"distributed_tracing");return!!e&&!!e.cors_use_tracecontext_headers}}var Z=i(7825),$=["load","error","abort","timeout"],Q=$.length,Y=t.Yu.REQ,K=c._A.XMLHttpRequest;class J extends h{static featureName=Z.t;constructor(r,n){let i=!(arguments.length>2&&void 0!==arguments[2])||arguments[2];super(r,n,Z.t,i),(0,t.OP)(r).xhrWrappable&&(this.dt=new W(r),this.handler=(e,t,r,n)=>(0,s.p)(e,t,r,n,this.ee),(0,k.u5)(this.ee),(0,k.Kf)(this.ee),function(r,n,i,o){function a(e){var t=this;t.totalCbs=0,t.called=0,t.cbTime=0,t.end=E,t.ended=!1,t.xhrGuids={},t.lastSize=null,t.loadCaptureCalled=!1,t.params=this.params||{},t.metrics=this.metrics||{},e.addEventListener("load",(function(r){_(t,e)}),(0,O.m$)(!1)),c.IF||e.addEventListener("progress",(function(e){t.lastSize=e.loaded}),(0,O.m$)(!1))}function s(e){this.params={method:e[0]},T(this,e[1]),this.metrics={}}function u(e,n){var i=(0,t.DL)(r);i.xpid&&this.sameOrigin&&n.setRequestHeader("X-NewRelic-ID",i.xpid);var a=o.generateTracePayload(this.parsedOrigin);if(a){var s=!1;a.newrelicHeader&&(n.setRequestHeader("newrelic",a.newrelicHeader),s=!0),a.traceContextParentHeader&&(n.setRequestHeader("traceparent",a.traceContextParentHeader),a.traceContextStateHeader&&n.setRequestHeader("tracestate",a.traceContextStateHeader),s=!0),s&&(this.dt=a)}}function d(e,t){var r=this.metrics,i=e[0],o=this;if(r&&i){var a=V(i);a&&(r.txSize=a)}this.startTime=(0,p.z)(),this.listener=function(e){try{"abort"!==e.type||o.loadCaptureCalled||(o.params.aborted=!0),("load"!==e.type||o.called===o.totalCbs&&(o.onloadCalled||"function"!=typeof t.onload)&&"function"==typeof o.end)&&o.end(t)}catch(e){try{n.emit("internal-error",[e])}catch(e){}}};for(var s=0;s<Q;s++)t.addEventListener($[s],this.listener,(0,O.m$)(!1))}function f(e,t,r){this.cbTime+=e,t?this.onloadCalled=!0:this.called+=1,this.called!==this.totalCbs||!this.onloadCalled&&"function"==typeof r.onload||"function"!=typeof this.end||this.end(r)}function l(e,t){var r=""+G(e)+!!t;this.xhrGuids&&!this.xhrGuids[r]&&(this.xhrGuids[r]=!0,this.totalCbs+=1)}function h(e,t){var r=""+G(e)+!!t;this.xhrGuids&&this.xhrGuids[r]&&(delete this.xhrGuids[r],this.totalCbs-=1)}function g(){this.endTime=(0,p.z)()}function m(e,t){t instanceof K&&"load"===e[0]&&n.emit("xhr-load-added",[e[1],e[2]],t)}function v(e,t){t instanceof K&&"load"===e[0]&&n.emit("xhr-load-removed",[e[1],e[2]],t)}function b(e,t,r){t instanceof K&&("onload"===r&&(this.onload=!0),("load"===(e[0]&&e[0].type)||this.onload)&&(this.xhrCbStart=(0,p.z)()))}function y(e,t){this.xhrCbStart&&n.emit("xhr-cb-time",[(0,p.z)()-this.xhrCbStart,this.onload,t],t)}function w(e){var t,r=e[1]||{};"string"==typeof e[0]?t=e[0]:e[0]&&e[0].url?t=e[0].url:c._A?.URL&&e[0]&&e[0]instanceof URL&&(t=e[0].href),t&&(this.parsedOrigin=(0,X.e)(t),this.sameOrigin=this.parsedOrigin.sameOrigin);var n=o.generateTracePayload(this.parsedOrigin);if(n&&(n.newrelicHeader||n.traceContextParentHeader))if("string"==typeof e[0]||c._A?.URL&&e[0]&&e[0]instanceof URL){var i={};for(var a in r)i[a]=r[a];i.headers=new Headers(r.headers||{}),s(i.headers,n)&&(this.dt=n),e.length>1?e[1]=i:e.push(i)}else e[0]&&e[0].headers&&s(e[0].headers,n)&&(this.dt=n);function s(e,t){var r=!1;return t.newrelicHeader&&(e.set("newrelic",t.newrelicHeader),r=!0),t.traceContextParentHeader&&(e.set("traceparent",t.traceContextParentHeader),t.traceContextStateHeader&&e.set("tracestate",t.traceContextStateHeader),r=!0),r}}function x(e,t){this.params={},this.metrics={},this.startTime=(0,p.z)(),this.dt=t,e.length>=1&&(this.target=e[0]),e.length>=2&&(this.opts=e[1]);var r,n=this.opts||{},i=this.target;"string"==typeof i?r=i:"object"==typeof i&&i instanceof Y?r=i.url:c._A?.URL&&"object"==typeof i&&i instanceof URL&&(r=i.href),T(this,r);var o=(""+(i&&i instanceof Y&&i.method||n.method||"GET")).toUpperCase();this.params.method=o,this.txSize=V(n.body)||0}function A(t,r){var n;this.endTime=(0,p.z)(),this.params||(this.params={}),this.params.status=r?r.status:0,"string"==typeof this.rxSize&&this.rxSize.length>0&&(n=+this.rxSize);var o={txSize:this.txSize,rxSize:n,duration:(0,p.z)()-this.startTime};i("xhr",[this.params,o,this.startTime,this.endTime,"fetch"],this,e.D.ajax)}function E(t){var r=this.params,n=this.metrics;if(!this.ended){this.ended=!0;for(var o=0;o<Q;o++)t.removeEventListener($[o],this.listener,!1);r.aborted||(n.duration=(0,p.z)()-this.startTime,this.loadCaptureCalled||4!==t.readyState?null==r.status&&(r.status=0):_(this,t),n.cbTime=this.cbTime,i("xhr",[r,n,this.startTime,this.endTime,"xhr"],this,e.D.ajax))}}function T(e,t){var r=(0,X.e)(t),n=e.params;n.hostname=r.hostname,n.port=r.port,n.protocol=r.protocol,n.host=r.hostname+":"+r.port,n.pathname=r.pathname,e.parsedOrigin=r,e.sameOrigin=r.sameOrigin}function _(e,t){e.params.status=t.status;var r=function(e,t){var r=e.responseType;return"json"===r&&null!==t?t:"arraybuffer"===r||"blob"===r||"json"===r?V(e.response):"text"===r||""===r||void 0===r?V(e.responseText):void 0}(t,e.lastSize);if(r&&(e.metrics.rxSize=r),e.sameOrigin){var n=t.getResponseHeader("X-NewRelic-App-Data");n&&(e.params.cat=n.split(", ").pop())}e.loadCaptureCalled=!0}n.on("new-xhr",a),n.on("open-xhr-start",s),n.on("open-xhr-end",u),n.on("send-xhr-start",d),n.on("xhr-cb-time",f),n.on("xhr-load-added",l),n.on("xhr-load-removed",h),n.on("xhr-resolved",g),n.on("addEventListener-end",m),n.on("removeEventListener-end",v),n.on("fn-end",y),n.on("fetch-before-start",w),n.on("fetch-start",x),n.on("fn-start",b),n.on("fetch-done",A)}(r,this.ee,this.handler,this.dt),this.importAggregator())}}var ee=i(3614);const{BST_RESOURCE:te,RESOURCE:re,START:ne,END:ie,FEATURE_NAME:oe,FN_END:ae,FN_START:se,PUSH_STATE:ce}=ee;var ue=i(7836);const{FEATURE_NAME:de,START:fe,END:le,BODY:he,CB_END:ge,JS_TIME:pe,FETCH:me,FN_START:ve,CB_START:be,FN_END:ye}=ue;var we=i(4649);class xe extends h{static featureName=we.t;constructor(e,t){let r=!(arguments.length>2&&void 0!==arguments[2])||arguments[2];super(e,t,we.t,r),this.importAggregator()}}new class{constructor(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:(0,_.ky)(16);c._A?(this.agentIdentifier=t,this.sharedAggregator=new y({agentIdentifier:this.agentIdentifier}),this.features={},this.desiredFeatures=new Set(e.features||[]),this.desiredFeatures.add(m),Object.assign(this,(0,a.j)(this.agentIdentifier,e,e.loaderType||"agent")),this.start()):(0,l.Z)("Failed to initial the agent. Could not determine the runtime environment.")}get config(){return{info:(0,t.C5)(this.agentIdentifier),init:(0,t.P_)(this.agentIdentifier),loader_config:(0,t.DL)(this.agentIdentifier),runtime:(0,t.OP)(this.agentIdentifier)}}start(){const t="features";try{const r=n(this.agentIdentifier),i=[...this.desiredFeatures];i.sort(((t,r)=>e.p[t.featureName]-e.p[r.featureName])),i.forEach((t=>{if(r[t.featureName]||t.featureName===e.D.pageViewEvent){const n=function(t){switch(t){case e.D.ajax:return[e.D.jserrors];case e.D.sessionTrace:return[e.D.ajax,e.D.pageViewEvent];case e.D.sessionReplay:return[e.D.sessionTrace];case e.D.pageViewTiming:return[e.D.pageViewEvent];default:return[]}}(t.featureName);n.every((e=>r[e]))||(0,l.Z)("".concat(t.featureName," is enabled but one or more dependent features has been disabled (").concat((0,D.P)(n),"). This may cause unintended consequences or missing data...")),this.features[t.featureName]=new t(this.agentIdentifier,this.sharedAggregator)}})),(0,T.Qy)(this.agentIdentifier,this.features,t)}catch(e){(0,l.Z)("Failed to initialize all enabled instrument classes (agent aborted) -",e);for(const e in this.features)this.features[e].abortHandler?.();const r=(0,T.fP)();return delete r.initializedAgents[this.agentIdentifier]?.api,delete r.initializedAgents[this.agentIdentifier]?.[t],delete this.sharedAggregator,r.ee?.abort(),delete r.ee?.get(this.agentIdentifier),!1}}}({features:[J,m,S,class extends h{static featureName=oe;constructor(t,r){if(super(t,r,oe,!(arguments.length>2&&void 0!==arguments[2])||arguments[2]),!c.il)return;const n=this.ee;let i;(0,k.QU)(n),this.eventsEE=(0,k.em)(n),this.eventsEE.on(se,(function(e,t){this.bstStart=(0,p.z)()})),this.eventsEE.on(ae,(function(t,r){(0,s.p)("bst",[t[0],r,this.bstStart,(0,p.z)()],void 0,e.D.sessionTrace,n)})),n.on(ce+ne,(function(e){this.time=(0,p.z)(),this.startPath=location.pathname+location.hash})),n.on(ce+ie,(function(t){(0,s.p)("bstHist",[location.pathname+location.hash,this.startPath,this.time],void 0,e.D.sessionTrace,n)}));try{i=new PerformanceObserver((t=>{const r=t.getEntries();(0,s.p)(te,[r],void 0,e.D.sessionTrace,n)})),i.observe({type:re,buffered:!0})}catch(e){}this.importAggregator({resourceObserver:i})}},C,xe,B,class extends h{static featureName=de;constructor(e,r){if(super(e,r,de,!(arguments.length>2&&void 0!==arguments[2])||arguments[2]),!c.il)return;if(!(0,t.OP)(e).xhrWrappable)return;try{this.removeOnAbort=new AbortController}catch(e){}let n,i=0;const o=this.ee.get("tracer"),a=(0,k._L)(this.ee),s=(0,k.Lg)(this.ee),u=(0,k.BV)(this.ee),d=(0,k.Kf)(this.ee),f=this.ee.get("events"),l=(0,k.u5)(this.ee),h=(0,k.QU)(this.ee),g=(0,k.Gm)(this.ee);function m(e,t){h.emit("newURL",[""+window.location,t])}function v(){i++,n=window.location.hash,this[ve]=(0,p.z)()}function b(){i--,window.location.hash!==n&&m(0,!0);var e=(0,p.z)();this[pe]=~~this[pe]+e-this[ve],this[ye]=e}function y(e,t){e.on(t,(function(){this[t]=(0,p.z)()}))}this.ee.on(ve,v),s.on(be,v),a.on(be,v),this.ee.on(ye,b),s.on(ge,b),a.on(ge,b),this.ee.buffer([ve,ye,"xhr-resolved"],this.featureName),f.buffer([ve],this.featureName),u.buffer(["setTimeout"+le,"clearTimeout"+fe,ve],this.featureName),d.buffer([ve,"new-xhr","send-xhr"+fe],this.featureName),l.buffer([me+fe,me+"-done",me+he+fe,me+he+le],this.featureName),h.buffer(["newURL"],this.featureName),g.buffer([ve],this.featureName),s.buffer(["propagate",be,ge,"executor-err","resolve"+fe],this.featureName),o.buffer([ve,"no-"+ve],this.featureName),a.buffer(["new-jsonp","cb-start","jsonp-error","jsonp-end"],this.featureName),y(l,me+fe),y(l,me+"-done"),y(a,"new-jsonp"),y(a,"jsonp-end"),y(a,"cb-start"),h.on("pushState-end",m),h.on("replaceState-end",m),window.addEventListener("hashchange",m,(0,O.m$)(!0,this.removeOnAbort?.signal)),window.addEventListener("load",m,(0,O.m$)(!0,this.removeOnAbort?.signal)),window.addEventListener("popstate",(function(){m(0,i>1)}),(0,O.m$)(!0,this.removeOnAbort?.signal)),this.abortHandler=this.#e,this.importAggregator()}#e(){this.removeOnAbort?.abort(),this.abortHandler=void 0}}],loaderType:"spa"})})(),window.NRBA=o})();</script><meta charset="UTF-8"/><meta name="robots" content="index, follow"/><meta name="DC.Creator" content="Moksh Jain"/><meta name="DC.Creator" content="Tristan Deleu"/><meta name="DC.Creator" content="Jason Hartford"/><meta name="DC.Creator" content="Cheng-Hao Liu"/><meta name="DC.Creator" content="Alex Hernandez-Garcia"/><meta name="DC.Creator" content="Yoshua Bengio"/><meta name="DC.title" content="GFlowNets for AI-driven scientific discovery "/><meta name="DC.publisher" content="Royal Society of Chemistry"/><meta name="DC.Date" content="2023/06/12"/><meta name="DC.Identifier" scheme="doi" content="10.1039/D3DD00002H"/><meta name="DC.Language" content="en"/><meta name="citation_title" content="GFlowNets for AI-driven scientific discovery "/><meta name="citation_author" content="Moksh Jain"/><meta name="citation_author" content="Tristan Deleu"/><meta name="citation_author" content="Jason Hartford"/><meta name="citation_author" content="Cheng-Hao Liu"/><meta name="citation_author" content="Alex Hernandez-Garcia"/><meta name="citation_author" content="Yoshua Bengio"/><meta name="citation_online_date" content="2023/04/05"/><meta name="citation_date" content="2023"/><meta name="citation_journal_title" content="Digital Discovery"/><meta name="citation_volume" content="2"/><meta name="citation_issue" content="3"/><meta name="citation_firstpage" content="557"/><meta name="citation_lastpage" content="577"/><meta name="citation_doi" content="10.1039/D3DD00002H"/><meta name="citation_pdf_url" content="https://pubs.rsc.org/en/content/articlepdf/2023/dd/d3dd00002h"/><meta name="citation_abstract_html_url" content="https://pubs.rsc.org/en/content/articlelanding/2023/dd/d3dd00002h"/><meta name="citation_fulltext_html_url" content="https://pubs.rsc.org/en/content/articlehtml/2023/dd/d3dd00002h"/><link rel="shortcut icon" href=""/><link type="text/css" rel="stylesheet" href="/content/stylesheets/rschtml2.css?ver=6_2_1"/><link href="https://www.rsc-cdn.org/oxygen/assets/webfonts/fonts.min.css" rel="stylesheet" type="text/css"/><link type="text/css" rel="stylesheet" href="/content/stylesheets/pubs-ui.min.css"/><meta name="viewport" content="width=device-width, initial-scale=1"/><script type="text/javascript" src="/content/scripts/JQueryPlugins.min.js"> </script><script type="text/javascript" src="/content/scripts/GetAnchorText.js"> </script><script type="text/javascript">
    
      $(function() {
      $("table.tgroup tfoot th").attr("colspan", "100");
      $("table.tgroup.rtable").each( function (idx, el) {
      var tw = $(this).width();
      $(this).parent().css("min-width", tw+"px");
      });

      });
      
    </script><!--6_2_1--></head><body class="oxy-ui pubs-ui ahtml-page"><!--Google Tag Manager (noscript)--><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-56FZ7G" height="0" width="0" style="display:none;visibility:hidden"> </iframe></noscript><!--End Google Tag Manager (noscript)--><div class="viewport autopad"><div class="pnl pnl--drop autopad"><span id="top"/><div id="wrapper"><div class="left_head"><a class="simple" href="/"><img class="rsc-logo" border="0" src="/content/NewImages/royal-society-of-chemistry-logo.png" alt="Royal Society of Chemistry"/></a><br/><span class="btnContainer"><a class="btn btn--tiny btn--primary" target="_blank" title="Link to PDF version" href="/en/content/articlepdf/2023/dd/d3dd00002h">View PDF Version</a></span><span class="btnContainer"><a class="btn btn--tiny btn--nobg" title="Link to previous article (id:d3dd00022b)" href="/en/content/articlehtml/2023/dd/d3dd00022b" target="_BLANK">Previous Article</a></span><span class="btnContainer"><a class="btn btn--tiny btn--nobg" title="Link to next article (id:d2dd00147k)" href="/en/content/articlehtml/2023/dd/d2dd00147k" target="_BLANK">Next Article</a></span></div><div class="right_head"><div id="crossmark_container"><div id="crossmark-content"><a id="open-crossmark" href="#" data-target="crossmark"><img style="max-width:100px" id="crossmark-logo" src="https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_square.svg" alt="Check for updates"/></a><script src="https://crossmark-cdn.crossref.org/widget/v2.0/widget.js"> </script></div></div><br/><span class="oa"><img src="/content/newimages/open_access_blue.png" alt=""/> Open Access Article<br/><img src="/content/newimages/CCBY.svg" alt=""/>
This Open Access Article is licensed under a <br/><a rel="license" href="http://creativecommons.org/licenses/by/3.0/">Creative Commons Attribution 3.0 Unported Licence</a></span></div><div class="article_info"> DOI: <a target="_blank" title="Link to landing page via DOI" href="https://doi.org/10.1039/D3DD00002H">10.1039/D3DD00002H</a>
(Perspective)
<span class="italic"><a title="Link to journal home page" href="https://doi.org/10.1039/2635-098X/2022">Digital Discovery</a></span>, 2023, <strong>2</strong>, 557-577</div><h1 id="sect246"><span class="title_heading">GFlowNets for AI-driven scientific discovery</span></h1><p class="header_text">
      <span class="bold">
        
          
            Moksh 
            Jain
          
        
      </span>*<sup><span class="sup_ref italic">ab</span></sup>, 
      <span class="bold">
        
          
            Tristan 
            Deleu
          
        
      </span><sup><span class="sup_ref italic">ab</span></sup>, 
      <span class="bold">
        
          
            Jason 
            Hartford
          
        
      </span><sup><span class="sup_ref italic">ab</span></sup>, 
      <span class="bold">
        
          
            Cheng-Hao 
            Liu
          
        
      </span><sup><span class="sup_ref italic">cb</span></sup>, 
      <span class="bold">
        
          
            Alex 
            Hernandez-Garcia
          
        
      </span><sup><span class="sup_ref italic">ab</span></sup><span class="bold"> and </span>
      <span class="bold">
        
          
            Yoshua 
            Bengio
          
        
      </span><span class="orcid"><a target="_blank" title="Select to open ORCID record for Yoshua Bengio (orcid.org/0000-0002-9322-3515) in a new window" id="connect-orcid-link" href="http://orcid.org/0000-0002-9322-3515"><img id="orcid-id-logo" src="/content/NewImages/orcid_16x16.png" alt="ORCID logo"/></a></span><sup><span class="sup_ref italic">abd</span></sup>
      <br/><a id="affa"><sup><span class="sup_ref italic">a</span></sup></a><span class="italic">Université de Montréal, Canada. E-mail: <a href="mailto:moksh.jain@mila.quebec">moksh.jain@mila.quebec</a></span>
      <br/><a id="affb"><sup><span class="sup_ref italic">b</span></sup></a><span class="italic">Mila Quebec AI Institute, Canada</span>
      <br/><a id="affc"><sup><span class="sup_ref italic">c</span></sup></a><span class="italic">McGill University, Canada</span>
      <br/><a id="affd"><sup><span class="sup_ref italic">d</span></sup></a><span class="italic">CIFAR Fellow, IVADO, Canada</span>
    </p><div id="art-admin"><span class="italic bold">Received 
      12th January 2023
    </span><span class="bold italic">, Accepted 28th March 2023</span></div><p class="bold italic">First published on 5th April 2023</p><hr/><div class="abstract"><h2>Abstract</h2><p>Tackling the most pressing problems for humanity, such as the climate crisis and the threat of global pandemics, requires accelerating the pace of scientific discovery. While science has traditionally relied on trial and error and even serendipity to a large extent, the last few decades have seen a surge of data-driven scientific discoveries. However, in order to truly leverage large-scale data sets and high-throughput experimental setups, machine learning methods will need to be further improved and better integrated in the scientific discovery pipeline. A key challenge for current machine learning methods in this context is the efficient exploration of very large search spaces, which requires techniques for estimating reducible (epistemic) uncertainty and generating sets of diverse and informative experiments to perform. This motivated a new probabilistic machine learning framework called GFlowNets, which can be applied in the modeling, hypotheses generation and experimental design stages of the experimental science loop. GFlowNets learn to sample from a distribution given indirectly by a reward function corresponding to an unnormalized probability, which enables sampling diverse, high-reward candidates. GFlowNets can also be used to form efficient and amortized Bayesian posterior estimators for causal models conditioned on the already acquired experimental data. Having such posterior models can then provide estimators of epistemic uncertainty and information gain that can drive an experimental design policy. Altogether, here we will argue that GFlowNets can become a valuable tool for AI-driven scientific discovery, especially in scenarios of very large candidate spaces where we have access to cheap but inaccurate measurements or too expensive but accurate measurements. This is a common setting in the context of drug and material discovery, which we use as examples throughout the paper.</p></div><hr/>
    
      
      <h2 id="sect310"><span class="a_heading">1 Introduction</span></h2>
      <span>The climate crisis, antibiotic resistance and the prospect of new pandemics are some of the biggest threats to humanity, posing immense risks to global health and food security. One important common aspect to all these threats and others is that significant new scientific discoveries are required to mitigate them. According to the 2022 report by the Intergovernmental Panel on Climate Change (IPCC),<a title="Select to navigate to references" href="#cit1"><sup><span class="sup_ref">1</span></sup></a> limiting global warming will require the adoption of alternative fuels, as well as improvements in the efficiency of energy production and material synthesis. The discovery of new materials, such as electrocatalysts that improve the energy efficiency of chemical reactions, can therefore play a crucial role in such a transition. Correspondingly, growing risks of antimicrobial resistance and pandemics make it essential to accelerate the pipeline for discovery of new drugs. Consequently, the well-being of our societies will strongly depend on the pace of our scientific discoveries.</span>
      <p class="otherpara">Historically, scientific discovery has been the outcome of either serendipity—such as penicilin and Teflon<a title="Select to navigate to references" href="#cit2"><sup><span class="sup_ref">2</span></sup></a>—or the rather slow experimental science loop: observations are accumulated from past experiments, which are carefully analyzed by experts who produce new hypotheses and design experiments that will eventually yield new, valuable observations to continue the cycle (see <a title="Select to navigate to figure" href="#imgfig1">Fig. 1</a>). While this model has well served the progress of science for centuries and will continue to do so in certain domains, the fully manual version of this cycle is too slow for the pressing emergencies of our time. A bottleneck in the cycle occurs when the analysis of data, production of hypotheses and experimental specification are manual. This is further exacerbated when the search space of candidates is dauntingly large, as is the case for drug discovery where there exist 10<small><sup>60</sup></small> feasible small molecules, according to estimations.<a title="Select to navigate to references" href="#cit3"><sup><span class="sup_ref">3</span></sup></a></p>
      <br/><div class="image_table"><table><tr><td colspan="3" class="imgHolder" id="imgfig1"><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-f1_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-f1.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-f1.gif"/></a></td></tr><tr><td class="pushTitleRight"> </td><td class="image_title"><b>Fig. 1 </b> <span id="fig1"><span class="graphic_title">The iterative experimental loop of scientific discovery: observations and data accumulated from past experiments are analyzed and used to generate new hypotheses, and in turn new experiments that will yield new data to continue to cycle. Highlighted with a blue frame are the steps for which we discuss how GFlowNets can be used.</span></span></td><td class="pushTitleLeft"> </td></tr></table></div>
      <p class="otherpara">The scale at which scientific experiments can be conducted is rapidly increasing, enabled by advances in robotics, biotechnology and computational capabilities, among others.<a title="Select to navigate to references" href="#cit4"><sup><span class="sup_ref">4</span></sup></a> For example, we can now easily and cheaply collect high-dimensional images and videos, electron microscopy data or the gene expression of millions of cells. Furthermore, we can also conduct thousands or even millions of experiments in parallel to screen new candidate molecules, experiment with a sequence of reactions, <span class="italic">etc.</span> If experimental interventions can be combined, we can sample from a combinatorially large space of possible experiments at each step. The avenues opened by such large-scale availability of data and compute have been identified as the fourth paradigm in scientific discovery.<a title="Select to navigate to references" href="#cit5"><sup><span class="sup_ref">5</span></sup></a> Nonetheless, our current tools are not enough to truly utilize all the information and resources at our disposal.<a title="Select to navigate to references" href="#cit6"><sup><span class="sup_ref">6</span></sup></a> In this context, the maturation of tailored machine learning (ML) methodologies offers the possibility to not only analyze and make sense of the data, but also to improve the generation of hypotheses and design of experiments, accelerating the experimental science loop.</p>
      <p class="otherpara">ML techniques have been employed in all of the main steps of the experimental science loop illustrated in <a title="Select to navigate to figure" href="#imgfig1">Fig. 1</a>: (a) analyzing and modeling the data accumulated from experiments, (b) characterizing and generating hypotheses compatible with the data, (c) designing the next experiments, and (d) performing the experiments. Analysis and modeling of data is a naturally appealing scenario for ML methods, which are typically designed for extracting predictive patterns from large data sets. For instance, machine learning methods have been quite successful in modeling the quantum mechanical properties of small molecules.<a title="Select to navigate to references" href="#cit7"><sup><span class="sup_ref">7</span></sup></a> ML approaches have also been studied in the context of designing candidate experiments.<a title="Select to navigate to references" href="#cit8"><sup><span class="sup_ref">8</span></sup></a> A standard example of this is leveraging tools from reinforcement learning (RL) and Bayesian optimization (BO) for searching candidates that optimize (as a reward) some property of the candidate.<a title="Select to navigate to reference" href="#cit9"><sup><span class="sup_ref">9,10</span></sup></a> However, as we discuss in detail in Section 2, existing approaches often lack a principled treatment of the challenges introduced by limited data, uncertainty and underspecification of the objectives in scientific domains.</p>
      <p class="otherpara">In this paper, we discuss how a novel machine learning (ML) framework, called Generative Flow Networks<a title="Select to navigate to reference" href="#cit11"><sup><span class="sup_ref">11,12</span></sup></a>—or GFlowNets for short—can help in addressing the shortcomings of existing ML approaches in scientific domains. GFlowNets are general purpose inference machines, which enable generating samples with a probability proportional to some reward function. As a consequence, GFlowNets have emerged as a potentially transformative tool for scientific discovery, as they can be used to generate hypotheses, design experiments and model the experimental observations, key steps of the experimental science loop (<a title="Select to navigate to figure" href="#imgfig1">Fig. 1</a>)—note that ML-augmented robotics can also be useful in the experimental step, but we do not discuss this here.</p>
      <p class="otherpara">Throughout the paper, we consider the following motivating examples to make the discussion more concrete.</p>
      <p class="otherpara">Example 1.1: An important part of fighting growing antimicrobial resistance and emergent infectious diseases is speeding up the discovery of novel small organic molecules (and peptides) that inhibit the action of target bacteria or one to several target proteins. The primary goal is to search the space of molecules (including peptides) for candidates that bind to the target of interest and inhibit or activate its function. The space of molecules is combinatorially large, and the accurate evaluation of the desired activity (<span class="italic">e.g.</span> binding affinity) <span class="italic">in vitro</span> or even <span class="italic">in silico</span> is expensive. Additionally, aside from binding to a target, there are several other pharmacological criteria which a molecule needs to satisfy for use as a therapeutic, such as low toxicity to humans, good Absorption, Distribution, Metabolism, and Excretion (“ADME”), and ease of synthesis.</p>
      <p class="otherpara">Example 1.2: Discovery of novel materials for applications in the generation, storage, and use of clean energy that have better efficiency and rely on sustainable raw materials are critical in aiding efforts to reduce rising global temperatures. The goal here is discovering novel inorganic as well as organic materials, and there are often several specific metrics to optimize simultaneously. A representative example is the development of storage materials for lithium/sodium ions in lithium/sodium ion batteries, where the class of metal oxides (<span class="italic">e.g.</span><a title="Select to navigate to figure" href="#imgfig2">Fig. 2</a>) alone already represents a combinatorially large search space. Inside a lithium/sodium ion battery, a good candidate metal oxide for energy storage should show high energy density, together with other metrics such as high capacity retention, low irreversible capacity, and low cost of synthesis.</p>
      <br/><div class="image_table"><table><tr><td colspan="3" class="imgHolder" id="imgfig2"><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-f2_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-f2.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-f2.gif"/></a></td></tr><tr><td class="pushTitleRight"> </td><td class="image_title"><b>Fig. 2 </b> <span id="fig2"><span class="graphic_title">Example schematics of a GFlowNet. (a) The objects whose distribution is modeled by a GFlowNet should be compositional, like graphs or sequences, built through a sequence of actions; (b) representation of the sequences of actions by which a GFlowNet can construct a molecule by composing smaller fragments, as a directed acyclic graph (DAG) whose nodes represent partially constructed molecules, and a reward is provided when the molecule is completed.</span></span></td><td class="pushTitleLeft"> </td></tr></table></div>
      <p class="otherpara">Example 1.3: Modeling the genetic pathways through which diseases progress within humans plays a critical role in our understanding of human biology. These causal models can help us understand the behavior of various interventions such as therapeutics within the complex environment of the human body. The goal is to learn such causal models with the help of targeted interventions. Even the causal structure of a single cell is a major challenge and raises difficult questions to appropriately scale algorithms and combine learning from data with prior knowledge from biology.</p>
      
        
        <h3 id="sect346"><span class="b_heading">1.1 Organization</span></h3>
        <span>In Section 3 we discuss existing ML methodology, highlighting the distinctive features of GFlowNets. Next in Section 4 we introduce ideas around amortized inference, and discuss how GFlowNets emerge from these ideas. In Section 4.2, we highlight scientific discovery problems where GFlowNets have been applied successfully. In Section 4.3, we discuss how GFlowNets can also be used to represent a distribution over causal models linking multiple random variables of interest and to estimate the posterior distributions of interest along with the marginalized quantities, such as Bayesian posterior densities, that are important to evaluate the information gain from an experiment. To conclude, in Section 5 we chart a potential path towards a unified framework for scientific discovery driven by GFlowNets.</span>
      
    
    
      
      <h2 id="sect350"><span class="a_heading">2 Challenges for AI in scientific discovery</span></h2>
      <span>In the last few decades, ML has enabled remarkable technological advances ranging from agents that can surpass humans at the game of Go<a title="Select to navigate to references" href="#cit13"><sup><span class="sup_ref">13</span></sup></a> to breakthrough advances in protein folding prediction.<a title="Select to navigate to references" href="#cit14"><sup><span class="sup_ref">14</span></sup></a> These advances have been enabled, in part, by the availability of extremely large datasets and often of a well-specified objective to be optimized. In many scientific discovery applications, however, the limited available data, the uncertainty intrinsic to measurements and the underspecification of objectives pose serious challenges for leveraging ML approaches. In this section, we discuss the relevance of these challenges and argue how GFlowNets can circumvent them.</span>
      
        
        <h3 id="sect356"><span class="b_heading">2.1 Limited data and uncertainty</span></h3>
        <span>One critical challenge in leveraging learning-based approaches for scientific discovery is the limited availability of data and the associated uncertainty. Part of the uncertainty is due to unreliable measurements, called aleatoric uncertainty, and part is due to having a limited amount of training data, called epistemic uncertainty, which is the uncertainty associated with theories or models and their parameters,<a title="Select to navigate to references" href="#cit15"><sup><span class="sup_ref">15</span></sup></a> due to the finite size of datasets. Epistemic uncertainty emerges because multiple theories or models or settings of parameters can be compatible with the given data, and Bayesian posteriors on these can capture the epistemic uncertainty. By design, current state-of-the-art ML approaches rely on access to large data sets to extract useful patterns. But owing to experimental limitations, it can be extremely expensive or impossible to obtain large amounts of accurate and precise data at the scale required my modern ML approaches in many applications of interest. In drug discovery, for example, obtaining experimental binding affinities for ligands with a target protein, at the scale required for ML methods, is often very challenging. Furthermore, the differences in experimental techniques and measurement noise can lead to different binding affinities for the same ligand by orders of magnitude. The same is true in materials science: as an example, in the research for new battery materials, a few thousands of data points are already considered high-throughput,<a title="Select to navigate to references" href="#cit16"><sup><span class="sup_ref">16</span></sup></a> and the measurement metrics such as energy density can vary significantly based on minute details of the experimental setup. Thus, it is essential for models to account for the aleatoric and epistemic uncertainty within the context of scientific discovery.</span>
        <p class="otherpara">Additionally, scientific phenomena occurring in nature tend to be complex and often a product of complicated processes. Standard machine learning models that learn a function mapping an input to an output from data can fail to generalize to unseen scenarios where the phenomenon occurs. Incorporating the causal structure of the phenomenon can introduce effective inductive biases that can allow models to generalize to novel scenarios.<a title="Select to navigate to references" href="#cit17"><sup><span class="sup_ref">17</span></sup></a> Whereas a given model will account for uncertainty in outcomes, <span class="italic">i.e.</span>, aleatoric uncertainty, by modeling Bayesian posteriors we can account for all the models that fit well the data, thus also capturing the epistemic uncertainty, which is what we want to reduce through experiments. As we discuss in Section 4.3, GFlowNets can be employed to model the posterior distribution of causal models that fit the data well.</p>
      
      
        
        <h3 id="sect365"><span class="b_heading">2.2 Underspecification and diversity</span></h3>
        <span>ML approaches often assume access to some reward signal or scoring function to evaluate the quality and utility of experimental designs. For instance, to design drug-like molecules, the true objective is to find ligands that specifically inhibit the target protein within the human body. However, this objective can hardly be specified and conveniently quantified as a simple scalar reward. In practice, an estimate of the binding affinity of the molecule with the target protein is used instead as the reward signal to search for candidate molecules. This comes with two caveats: first, the estimation of binding affinity is not immune to systematic and random errors; second, the binding energy alone cannot account for many of the factors that can influence the effect of the ligand within the human body. For instance, a molecule (or a series of similar molecules) that only optimizes this binding energy may be potentially useless or even harmful <span class="italic">in vivo</span> because it could bind to many other proteins and thus be toxic (more broadly, the molecule could have poor ADME). These aspects make it critical to find diverse hypotheses—in this case, diverse motifs of molecules—to account for the underspecification and uncertainty in the reward signal. Nonetheless, popular approaches to ML-aided scientific discovery, like RL<a title="Select to navigate to references" href="#cit9"><sup><span class="sup_ref">9</span></sup></a> and Bayesian optimization<a title="Select to navigate to references" href="#cit10"><sup><span class="sup_ref">10</span></sup></a> aim to discover a single maximizer of the reward signal, not accounting for underspecification of the reward signal itself. Diversity of candidate solutions is also particularly relevant in the evolution of new generations of technologies. For example, before the use of perovskites (or other new materials) in solar cells, optimization of power conversion efficiency and manufacturing in silicon-based solar cells was yielding diminishing returns, and only the use of radically different materials was able to change this situation. By sampling proportional to the reward, GFlowNets, can mitigate the problem of missing out potentially interesting findings due to underspecification in the target reward, generating a diverse set of high-reward candidate solutions to the discovery problem at hand.</span>
      
    
    
      
      <h2 id="sect372"><span class="a_heading">3 Background</span></h2>
      <span>In this section, we review the relevant fundamental areas in machine learning and set the stage for Section 4 where we discuss how GFlowNets can address the challenges presented in Section 2.</span>
      
        
        <h3 id="sect376"><span class="b_heading">3.1 Preliminaries</span></h3>
        <span>To establish notation, consider an example problem from organic synthesis where chemists want to find new and/or efficient synthetic pathways to obtain a desired molecule (<span class="italic">e.g.</span> a drug candidate).</span>
        <p class="otherpara">• Design: Let <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t1_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t1.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t1.gif"/></a> be the design for an experiment, where <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t2_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t2.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t2.gif"/></a> denotes the design space of all possible experiments. For Example 1.1 and Example 1.2, each experimental design, <span class="italic">x</span>, specifies a candidate molecule, antibody or metal oxide material. <span class="italic">x</span> can also represent interventions on specific genes for Example 1.3, or experimental parameters for a specific procedure (<span class="italic">e.g.</span> synthesis conditions). If an experiment is modeled <span class="italic">in silico</span>, it can also include the fidelity of the approximations used, with the associated computational cost.</p>
        <p class="otherpara">• Parameters: We use <span class="italic">θ</span> to represent the parameters of our mathematical model of the underlying phenomenon of interest. Like the experimental design <span class="italic">x</span>, <span class="italic">θ</span> can parameterize a wide range of objects. For instance, <span class="italic">θ</span> could represent the parameters of the physical process of supramolecular interactions/protein binding in Example 1.1, or a set of parameters describing the model of energy capacity and mechanisms of capacity loss in a battery for Example 1.2, or a structural causal model describing the causal interaction genetic pathways in Example 1.3, or more general cases such as parameters of a neural network.</p>
        <p class="otherpara">• Outcome: We use <span class="italic">y</span> to denote the experimental outcome, for example the yield of a chemical reaction. The outcome, <span class="italic">y</span>, may also be multi-dimensional, and may include all measurements recorded during the experiment. <span class="italic">y</span> can represent the binding affinity to a target, toxicity to humans and synthetic accessibility in Example 1.1. For Example 1.2, <span class="italic">y</span> can represent energy capacity and retention loss, as well as materials purity and X-ray diffraction patterns. In Example 1.3, <span class="italic">y</span> can even include images and videos of specific interventions on a population of cells. The experimental outcomes are often structurally rich but might lack the abstractions necessary for effective modeling.</p>
        <p class="otherpara">• Dataset: Finally, we denote the data collected from previous experiments as <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t3_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t3.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t3.gif"/></a>.</p>
        <p class="otherpara">We model the outcome <span class="italic">y</span> as a consequence of the design <span class="italic">x</span>. The likelihood—denoted <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">θ</span>, <span class="italic">x</span>)—is parameterized by <span class="italic">θ</span>, and is a measure of how likely each experimental outcome, <span class="italic">y</span>, is to occur, given a particular design, <span class="italic">x</span>, and model parameters, <span class="italic">θ</span>. This likelihood acts as our abstract model of the underlying phenomenon. If the likelihood is known analytically or can be computed efficiently it is called an explicit model. For example, we might model the outcome of an experiment with a Gaussian distribution, with mean as some function <span class="italic">f</span><small><sub><span class="italic">θ</span></sub></small>(<span class="italic">x</span>), such that <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t4_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t4.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t4.gif"/></a>. Alternatively, if the likelihood is intractable, it is called an implicit model. Implicit models are common in the context of scientific discovery because we often model processes <span class="italic">via</span> simulators that allow us to sample from <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">θ</span>, <span class="italic">x</span>), without being able to evaluate the likelihood.</p>
        <p class="otherpara">We assume that the data set of observed variables <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t5_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t5.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t5.gif"/></a>, is drawn from the joint distribution <span class="italic">p</span>(<span class="italic">x</span>, <span class="italic">θ</span>) for some <span class="italic">θ</span>. In order to use that data to update our model of likely outcomes, we need an approach to solving the inference problem: estimating the posterior probability distribution <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t6_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t6.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t6.gif"/></a> over the latent variable given the observed data. This problem appears in various contexts across domains. For instance, given observations of the experimental outcomes, say the binding affinities of several ligands to a particular target, we might be interested in estimating the distributions over parameters in the model that describe the process of binding. In principle this distribution can be estimated using Bayes' rule,<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn1"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t7_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t7.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t7.gif"/></a></td><td class="rightEqn">(1)</td></tr></table></p>
        <p class="otherpara">In practice, however, computing the posterior exactly is intractable for high-dimensional <span class="italic">θ</span> and <span class="italic">x</span>. Thus, approximate inference methods have been studied extensively. We briefly summarize two broad classes of methods: Markov Chain Monte Carlo (MCMC) and Variational Inference (VI).</p>
      
      
        
        <h3 id="sect435"><span class="b_heading">3.2 Approximate inference</span></h3>
        <span>MCMC methods<a title="Select to navigate to references" href="#cit18"><sup><span class="sup_ref">18</span></sup></a> are designed to generate samples from a target distribution, where a correct sampling procedure is not known but the density of the desired distribution is known up to a normalizing constant. They approximate sampling from the desired distribution by constructing a sequence of samples whose asymptotic distribution (as the sequence becomes longer) matches the desired target distribution. At each step of the sequence a new sample is generated by performing a small random perturbation from the previous sample. When trying to sample from a Bayesian posterior <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t8_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t8.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t8.gif"/></a>, we can compute the unnormalized form of the posterior as the product of the prior and the likelihood, <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t9_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t9.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t9.gif"/></a>. Unfortunately, in high-dimensional problems and problems where the modes of the distribution occupy a tiny relative volume and can be far from each other, MCMC methods can take exponentially more time to properly sample from all the modes (or even just move from one mode to another). Methods to improve the performance of MCMC for sampling from high-dimensional distributions<a title="Select to navigate to reference" href="#cit19"><sup><span class="sup_ref">19–21</span></sup></a> are limited to certain classes of distributions and do not apply to sampling complex objects such as graphs and sequences which are important in a number of applications in scientific discovery.</span>
        <p class="otherpara">Variational Inference methods<a title="Select to navigate to references" href="#cit22"><sup><span class="sup_ref">22</span></sup></a> approach the problem of sampling from the posterior using instead an optimization-based approach, finding a member of family of distributions that is closest to the posterior distribution that we seek. In particular, they search for a distribution <span class="italic">q</span>(<span class="italic">θ</span>)—by optimizing the values of <span class="italic">q</span> or parameters that define it—so as to minimize the reverse Kullback–Liebler (KL) divergence <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t10_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t10.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t10.gif"/></a>. Because this measure of “closeness” is a reverse KL, VI methods tend to drop most modes of the true posterior or even focus on just one of them.<a title="Select to navigate to reference" href="#cit23"><sup><span class="sup_ref">23,24</span></sup></a></p>
        <p class="otherpara">GFlowNets address this issue of mode dropping that plagues both MCMC and typical VI methods. They are similar to amortized variational methods (<span class="italic">i.e.</span>, they learn a parameterization for <span class="italic">q</span>) but use a different training objective which favors a greater diversity of samples by allowing the use of exploration in the space of samples<a title="Select to navigate to references" href="#cit25"><sup><span class="sup_ref">25</span></sup></a> as we discuss in Section 4.1.</p>
      
      
        
        <h3 id="sect454"><span class="b_heading">3.3 Experimental design</span></h3>
        <span>Experiments are the primary interface for interaction between our abstract models and the complexities of the real world. A key element of scientific methodology has been the careful design of experiments that allow the acquisition of knowledge corresponding to a reliable understanding of the underlying phenomena. However, experiments are expensive—either computationally, financially or in time. Therefore, we need methods to design experiments that maximize the amount of information our models learn from each experiment. This task of automated experimental design has been extensively studied in statistics and machine learning.</span>
        <p class="otherpara">The field of experimental design studies the problem of designing “useful” experiments effectively. The usefulness of an experiment is defined by a utility function (or reward) <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t11_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t11.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t11.gif"/></a>, which may change as a function of the data, <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t12_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t12.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t12.gif"/></a>, that we have observed from previous experiments. Given this utility function, we are typically interested in selecting the most useful designs, <span class="italic">x</span>*,<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn2"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t13_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t13.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t13.gif"/></a></td><td class="rightEqn">(2)</td></tr></table></p>
        <p class="otherpara">The process of experimental science is often iterative, as illustrated in <a title="Select to navigate to figure" href="#imgfig1">Fig. 1</a>. We design an experiment, perform the experiment and observe the experimental outcome, update our model based on the observations and then design the next experiment guided by the updated model. This is referred to as sequential experimental design. The sequential experimental design setting is thus formalized at any iteration <span class="italic">k</span> as follows, in terms of the estimated utility of the experiment <span class="italic">x</span> considered and the past data <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t14_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t14.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t14.gif"/></a>:<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn3"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t15_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t15.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t15.gif"/></a></td><td class="rightEqn">(3)</td></tr></table>where <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t16_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t16.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t16.gif"/></a> consists of the designs and outcomes of the experiments performed till iteration <span class="italic">k</span>.</p>
        <p class="otherpara">Designing utility functions that accurately reflect the value of an experiment while being efficient to compute has been a problem of interest in various communities. Classical work on experimental design relied on the Fisher information matrix to quantify the information about parameters <span class="italic">θ</span> contained in the experimental outcome <span class="italic">y</span>.<a title="Select to navigate to reference" href="#cit26"><sup><span class="sup_ref">26,27</span></sup></a> This measure of information can be efficiently computed in linear models, where the outcome depends linearly on the design.<a title="Select to navigate to references" href="#cit8"><sup><span class="sup_ref">8</span></sup></a> When this relationship is nonlinear, a variety of methods exist to select among a version space of nonlinear functions that are consistent with what we have observed; see Settles<a title="Select to navigate to references" href="#cit28"><sup><span class="sup_ref">28</span></sup></a> for a survey. In scientific discovery, we are not agnostic to the set of functions that could explain our observations: we typically have significant prior knowledge from the literature and previous experiments that what we can use to weigh the relative likelihood of potential experimental outcomes. Bayesian experimental design, introduced below, provides a principled approach to incorporating these priors into our choice of future experiments.</p>
      
      
        
        <h3 id="sect481"><span class="b_heading">3.4 Bayesian experimental design</span></h3>
        <span>Bayesian Experimental Design (BED) or Bayesian Optimal Experimental Design (BOED)<a title="Select to navigate to reference" href="#cit8"><sup><span class="sup_ref">8,29</span></sup></a> approaches experimental design by modeling a rational agent that aims to maximize their expected utility of new experiments with respect to prior beliefs. The utility function provides a real-valued score for each potential outcome, <span class="italic">y</span>, of any potential experimental design, <span class="italic">x</span>. At each round of experimentation, the agent selects an experimental design,<a title="Select to navigate to footnote" href="#fn1">†</a><span class="italic">x</span>, that gives the highest expected utility weighted by how likely each outcome is to occur under the agent's prior beliefs (parameterized by <span class="italic">θ</span>). By specifying the agent's prior belief, we can encode scientific knowledge of known relationships and uncertainties in the observed outcomes, thereby making the procedure more efficient at exploring unknown parts of the experimental design space.</span>
        <p class="otherpara">A common choice for the agent's utility function is the mutual information [MI; ref. <a title="Select to navigate to references" href="#cit30">30</a>] between the experimental parameters <span class="italic">θ</span> and the outcome <span class="italic">y</span> observed upon performing an experiment <span class="italic">y</span>, given the dataset <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t17_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t17.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t17.gif"/></a> of previous experiments.<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn4"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t18_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t18.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t18.gif"/></a></td><td class="rightEqn">(4)</td></tr></table><table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn5"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t19_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t19.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t19.gif"/></a></td><td class="rightEqn">(5)</td></tr></table><table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn6"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t20_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t20.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t20.gif"/></a></td><td class="rightEqn">(6)</td></tr></table></p>
        <p class="otherpara">MI can be interpreted as how much information can we expect to gather—or equivalently how much we reduce our uncertainty—about some random variable of interest (say the model parameters <span class="italic">θ</span>) thanks to the experimental outcome. <a title="" href="#eqn5">Eqn (5)</a> and <a title="" href="#eqn6">(6)</a> give two equivalent definitions of MI, but both are intractable in general so we will need to rely on approximations.</p>
        <p class="otherpara">Assuming access to the likelihood function, <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">θ</span>, <span class="italic">x</span>), we first need to estimate the various posterior distributions, depending on which of the above formulations of the MI we choose. To sample one of the sums, we need to estimate or at least sample from either the unknown and generally intractable posterior over parameters <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t21_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t21.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t21.gif"/></a>, or the marginal likelihood <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">x</span>) (where <span class="italic">θ</span> has been summed out). Estimating high-dimensional posteriors can be challenging and marginalizing out <span class="italic">θ</span> in <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">θ</span>, <span class="italic">x</span>) can also be intractable. Additionally, the MI itself involves a high dimensional integral which can be intractable. Consequently, developing efficient estimators to approximate the MI has been one of the central challenges in BED. Estimators of MI have been developed for both implicit and explicit models. The estimators typically leverage tools from approximate inference, including MCMC and VI discussed in Section 3.1, to approximate the posterior over parameters or the marginal likelihood,<a title="Select to navigate to reference" href="#cit31"><sup><span class="sup_ref">31–36</span></sup></a> and the likelihood in the case of implicit models.<a title="Select to navigate to references" href="#cit37"><sup><span class="sup_ref">37</span></sup></a></p>
        <div>
          
          <span id="sect528"/><span class="c_heading_indent">3.4.1 Towards amortization. </span>
          <span>Conventional approaches discussed above consist of two distinct steps: estimating or approximating the posterior over parameters or marginal likelihood to estimate the MI and then maximizing this estimator of MI to find the optimal experiment. Despite being applied in various contexts in scientific discovery,<a title="Select to navigate to reference" href="#cit37"><sup><span class="sup_ref">37,38</span></sup></a> each of these steps alone can be computationally expensive.<a title="Select to navigate to references" href="#cit39"><sup><span class="sup_ref">39</span></sup></a> introduced a unified stochastic gradient method to combine estimation of MI and the selection of the optimal experiment. They propose jointly optimizing the parameters <span class="italic">ϕ</span> of the MI estimator and the experiment design <span class="italic">x</span> using gradient based methods.</span>
          <p class="otherpara">Ref. <a title="Select to navigate to references" href="#cit40">40</a> formalizes the conventional BED approach in terms of a design policy π, which directly maps a history of experimental data <span class="italic">h</span><small><sub><span class="italic">t</span></sub></small> = [(<span class="italic">x</span><small><sub>1</sub></small>, <span class="italic">y</span><small><sub>1</sub></small>), …(<span class="italic">x</span><small><sub><span class="italic">t</span></sub></small>, <span class="italic">y</span><small><sub><span class="italic">t</span></sub></small>)] to the next experiment design <span class="italic">x</span><small><sub><span class="italic">t</span>+1</sub></small>. Once this policy is trained, the next experiment can be selected directly using the policy, instead of the usual MI estimation and optimization. In essence, the training of the policy amortizes the cost of estimating and optimizing the MI.<a title="Select to navigate to references" href="#cit41"><sup><span class="sup_ref">41</span></sup></a> extends this to implicit models.</p>
          <p class="otherpara">These are examples of amortized inference: instead of expensive Monte Carlo sampling to estimate or maximizes some expected value at run-time, we pre-train a function that directly produces an approximation of the desired quantities. We elaborate on learned amortized inference in Section 4, with a focus on GFlowNets and a discussion of its advantages over MCMC methods.</p>
          <p class="otherpara">Current BED methods have been limited to continuous design spaces. While recent work has considered extensions to incorporate discrete designs,<a title="Select to navigate to references" href="#cit42"><sup><span class="sup_ref">42</span></sup></a> they are limited to small problem domains. BED methods in general are hard to scale to larger problem settings.</p>
        </div>
      
      
        
        <h3 id="sect558"><span class="b_heading">3.5 Bayesian optimization</span></h3>
        <span>A typical problem encountered in various domains of scientific interest is that of optimizing the value of some expensive to compute black-box function <span class="italic">f</span>. For instance, consider the task of designing novel molecules to inhibit the activity of a particular target protein. We are interested in searching for a molecule <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t22_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t22.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t22.gif"/></a> which minimizes the binding energy of the molecule with the target protein, <span class="italic">f</span>:<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn7"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t23_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t23.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t23.gif"/></a></td><td class="rightEqn">(7)</td></tr></table></span>
        <p class="otherpara">Further, we only observe noisy measurements <span class="italic">y</span> on evaluating <span class="italic">f</span>, as described by <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">f</span>(<span class="italic">x</span>)). In the context of the binding energy, each experimental evaluation can be expensive and take weeks to perform in the lab and the observed results are noisy. Consequently the goal here is to discover <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t24_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t24.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t24.gif"/></a> with the fewest possible evaluations of <span class="italic">f</span>. This problem is studied broadly within the framework of global optimization.<a title="Select to navigate to references" href="#cit43"><sup><span class="sup_ref">43</span></sup></a> Solving the global optimization problem for any general function <span class="italic">f</span> is NP-hard in discrete spaces, and intractable without special structural constraints (<span class="italic">e.g.</span> convexity) on <span class="italic">f</span> in the continuous case. Methods for finding approximate solutions to this problem have received significant attention in the literature due to the broad applicability. Among the wide variety of techniques studied, Bayesian Optimization (BO)<a title="Select to navigate to reference" href="#cit44"><sup><span class="sup_ref">44–46</span></sup></a> is a popular and widely used approach. Bayesian optimization has been applied extensively to a wide variety of scientific problems.<a title="Select to navigate to reference" href="#cit47"><sup><span class="sup_ref">47–50</span></sup></a> Broadly, Bayesian optimization consists of an iterative process to search for the global optimum in a sample-efficient manner, relying on tools from Bayesian Inference. Algorithm 1 provides a general overview of the Bayesian optimization approach.<br/><div class="image_table"><table><tr><td colspan="3" class="imgHolder" id="imgugr1"><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-u1_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-u1.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-u1.gif"/></a></td></tr><tr><td class="pushTitleRight"> </td><td><a id="ugr1"/><span id="ugr1"/></td><td class="pushTitleLeft"> </td></tr></table></div></p>
        <p class="otherpara">The two key ingredients of a Bayesian optimization algorithm are the surrogate model <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t25_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t25.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t25.gif"/></a> which approximates <span class="italic">f</span> (and its epistemic uncertainty) and the acquisition function <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t26_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t26.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t26.gif"/></a> which quantifies the utility of acquiring a point. Gaussian Processes [GPs; ref. <a title="Select to navigate to references" href="#cit51">51</a>] are an appealing choice for the surrogate model owing to simple analytical form for the posterior. Consequently, GPs are the default choice in modern BO methods.<a title="Select to navigate to references" href="#cit52"><sup><span class="sup_ref">52</span></sup></a></p>
        <p class="otherpara">From an information theoretic perspective, in each round we are interested in acquiring candidates that maximize the mutual information between the observed value and the global optimum of the function:<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn8"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t27_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t27.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t27.gif"/></a></td><td class="rightEqn">(8)</td></tr></table></p>
        <p class="otherpara">This objective resembles the information gain from Section 3.3, where the parameter of interest is <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t28_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t28.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t28.gif"/></a>. Indeed, BO can be viewed as an instantiation of experimental design with an implicit model <span class="italic">f</span>, where we are interested in a particular random variable, the location of the maximum value of <span class="italic">f</span>, rather than all the parameters.</p>
        <div>
          
          <span id="sect598"/><span class="c_heading_indent">3.5.1 Acquisition functions. </span>
          <span>The acquisition function plays a critical role in Bayesian optimization and over the years various acquisition functions have been proposed. Expected improvement<a title="Select to navigate to references" href="#cit53"><sup><span class="sup_ref">53</span></sup></a> was one of the earliest acquisition functions. Upper-Confidence Bound [UCB; ref. <a title="Select to navigate to references" href="#cit54">54</a>] and Thompson Sampling [TS; ref. <a title="Select to navigate to references" href="#cit55">55</a> and <a title="Select to navigate to references" href="#cit56">56</a>] were inspired by the bandit learning literature. More recently, there have been significant developments in entropy search methods which adopt the information theoretic perspective introduced in <a title="" href="#eqn8">eqn (8)</a>.<a title="Select to navigate to references" href="#cit57"><sup><span class="sup_ref">57</span></sup></a> and<a title="Select to navigate to references" href="#cit58"><sup><span class="sup_ref">58</span></sup></a> introduced Entropy Search (ES) and Predictive Entropy Search (PES) as acquisition functions based on <a title="" href="#eqn8">eqn (8)</a>.<a title="Select to navigate to reference" href="#cit59"><sup><span class="sup_ref">59,60</span></sup></a> instead considered the mutual information between the outcome and the max value of <span class="italic">f</span> rather than the arg max, resulting in the Max Value Entropy Search (MES) acquisition function:<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn9"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t29_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t29.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t29.gif"/></a></td><td class="rightEqn">(9)</td></tr></table></span>
          <p class="otherpara">Ref. <a title="Select to navigate to references" href="#cit61">61</a> further proposed considering a lower-bound on the mutual information resulting in a general purpose information-theoretic acquisition function GIBBON, which is also applicable to various extensions we discuss below.</p>
        </div>
        <div>
          
          <span id="sect617"/><span class="c_heading_indent">3.5.2 Extensions. </span>
          <span>Inspired by various practical applications, several extensions to the standard Bayesian optimization setting have been studied. A common scenario is where <span class="italic">f</span> can be evaluated on multiple different candidates in parallel. In practice, we can often evaluate multiple candidates with nearly the same cost as a single candidate. For example, phage display can produce libraries of millions of antibodies in one batch. Batch Bayesian optimization<a title="Select to navigate to reference" href="#cit62"><sup><span class="sup_ref">62,63</span></sup></a> is an extension of BO where in each round we acquire a batch of candidates instead of a single candidate. Additionally, we might have access to oracles with different costs and fidelities to evaluate <span class="italic">f</span>; for example, to obtain the simulated binding affinity of a molecule to a protein, oracles can include free energy perturbation and molecular docking, where the former is substantially more accurate but the computational cost is orders of magnitude higher. This setting is studied in multi-fidelity Bayesian optimization.<a title="Select to navigate to reference" href="#cit64"><sup><span class="sup_ref">64–66</span></sup></a> Another important aspect in practical applications is multiple objectives. For example, we are interested in multiple properties such as the drug-likeness, toxicity to humans, and synthesizability in addition to binding energy in the drug discovery setting. Multi-objective Bayesian optimization<a title="Select to navigate to reference" href="#cit58"><sup><span class="sup_ref">58,67,68</span></sup></a> methods study this problem setup. Recent work has also incorporated physical inductive biases as priors for efficient Bayesian optimization.<a title="Select to navigate to reference" href="#cit69"><sup><span class="sup_ref">69,70</span></sup></a> Finally, while traditional BO methods mainly consider continuous <span class="italic">x</span>, recent work has enabled BO on discrete spaces.<a title="Select to navigate to reference" href="#cit71"><sup><span class="sup_ref">71,72</span></sup></a> Despite recent progress, BO methods have typically been limited to small problems due to challenges in scaling surrogate models to larger domains. Additionally, as mentioned in Section 2, as BO is concerned with maximizing or minimizing a function, it can miss out on diversity which is critical for many scientific applications.</span>
        </div>
      
      
        
        <h3 id="sect629"><span class="b_heading">3.6 Causal discovery</span></h3>
        <span>An important goal of the scientific methodology is understanding the causes and effects of certain phenomena based on prior observations and experiments. Causal discovery studies the problem of learning the causal structure from data.</span>
        <p class="otherpara">A Bayesian Network<a title="Select to navigate to references" href="#cit73"><sup><span class="sup_ref">73</span></sup></a> is a representation of the joint distribution over <span class="italic">d</span> random variables {<span class="italic">Y</span><small><sub>1</sub></small>, …, <span class="italic">Y</span><small><sub><span class="italic">d</span></sub></small>}, whose conditional independencies are encoded in a compact graphical way. These random variables correspond to the nodes of a directed acyclic graph (DAG) <span class="italic">G</span> that determines the factorization of the joint distribution as<br/><div class="image_table"><table><tr><td colspan="3" class="imgHolder" id="imgugt30"><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t30_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t30.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t30.gif"/></a></td></tr><tr><td class="pushTitleRight"> </td><td><a id="ugt30"/><span id="ugt30"/></td><td class="pushTitleLeft"> </td></tr></table></div>where Pa<small><sub><span class="italic">G</span></sub></small>(<span class="italic">Y</span><small><sub><span class="italic">i</span></sub></small>) is the set of parent nodes of <span class="italic">Y</span><small><sub><span class="italic">i</span></sub></small> in the graph <span class="italic">G</span>, and <span class="italic">θ</span><small><sub><span class="italic">i</span></sub></small> are the parameters of the conditional distribution associated with the random variable <span class="italic">Y</span><small><sub><span class="italic">i</span></sub></small>.</p>
        <p class="otherpara">Although in a Bayesian Network the edges connecting the nodes in <span class="italic">G</span> only encode associations between random variables, a causal graphical model enhances this framework with notions of causality. In a causal graphical model, again represented by a DAG, <span class="italic">G</span>, over the random variables, any directed edge <span class="italic">Y</span><small><sub><span class="italic">i</span></sub></small> → <span class="italic">Y</span><small><sub><span class="italic">j</span></sub></small> represents a direct causal influence of <span class="italic">Y</span><small><sub><span class="italic">i</span></sub></small> on <span class="italic">Y</span><small><sub><span class="italic">j</span></sub></small>. This allows the model to not only represent the joint distribution of the system (<span class="italic">i.e.</span>, passively observing the system), but also the effects of actively experimenting on it. A causal model specifies the distribution that would be obtained under any intervention. For example, a “DO-intervention” sets the value of a variable, ignoring its usual causes. However, because the same causal mechanisms (the conditionals <span class="italic">P</span>(<span class="italic">Y</span><small><sub><span class="italic">i</span></sub></small>|Pa<small><sub><span class="italic">G</span></sub></small>(<span class="italic">Y</span><small><sub><span class="italic">i</span></sub></small>); <span class="italic">θ</span><small><sub><span class="italic">i</span></sub></small>)) are shared across all interventions, if the causal mechanisms (<span class="italic">i.e. θ</span>) and the graph <span class="italic">G</span> have been inferred correctly, a causal model can generalize to distributions never seen during training (<span class="italic">i.e.</span>, out-of-distribution), corresponding to new interventions.</p>
        <div>
          
          <span id="sect689"/><span class="c_heading_indent">3.6.1 Causal structure learning. </span>
          <span>The structure <span class="italic">G</span> of a causal graphical model is often assumed to be known, where for example the causal relationships are determined using expert knowledge. This allows us to perform a number of tasks using these models, such as inference (either probabilistic, or causal), or learning the parameters <span class="italic">θ</span> of the causal model from observations of the system.</span>
          <p class="otherpara">However in the context of scientific discovery, the objective is precisely to discover causal relationships that may have eluded experts thus far. For example, in the development of a disease, we want to find what factors (<span class="italic">e.g.</span> social factors, proteomes, pathogens) are involved. In this situation, we would like to learn the structure of the causal graphical model (or at least part of it) using data, stored in a dataset <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t31_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t31.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t31.gif"/></a>. This data could either come from passive observations of the system (called observational data, <span class="italic">e.g.</span> the statistics of protein expressions in patients), or from active experiments (called interventional data, <span class="italic">e.g.</span> genome-wide gene perturbation). This problem is known as causal structure learning, or causal discovery.<a title="Select to navigate to reference" href="#cit74"><sup><span class="sup_ref">74–78</span></sup></a></p>
        </div>
        <div>
          
          <span id="sect701"/><span class="c_heading_indent">3.6.2 Bayesian causal discovery. </span>
          <span>Similar to how there may be multiple theories explaining the same phenomenon, there may also be multiple models that could explain our observations equally well, even in the limit where we have a very large amount of data. Concretely, this means that many standard structure learning methods would typically choose an arbitrary model, which could lead to undesirable (and potentially harmful) outcomes. For example, if we had a system with only two (correlated) random variables <span class="italic">A</span> and <span class="italic">B</span>, there would be no way in general to distinguish between the two causal models <span class="italic">A</span> → <span class="italic">B</span> and <span class="italic">B</span> → <span class="italic">A</span> using observational data only, even though both models have significantly different causal conclusions. Moreover, in practice, the amount of data available in <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t32_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t32.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t32.gif"/></a> to identify the causal model may be scarce, and this introduces another source of variability: since causal discovery methods only return a single candidate, some theory may be favored only due to the limited evidence. Ideally, we would like to quantify our epistemic uncertainty to avoid model misspecification. This can be done using the Bayesian posterior over the causal structures <span class="italic">G</span>, given a dataset <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t33_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t33.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t33.gif"/></a>, similar to the description in Section. 4.1.6. Using Bayes' rule, the posterior is given by<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn10"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t34_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t34.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t34.gif"/></a></td><td class="rightEqn">(10)</td></tr></table></span>
          <p class="otherpara">In the expression above, <span class="italic">P</span>(<span class="italic">G</span>) represents our prior belief, and may encode some <span class="italic">a priori</span> knowledge about the structure <span class="italic">G</span>. For example, we may encourage causal graphs to be sparse, <span class="italic">i.e.</span> to limit the number of parents for any node in the graph. While this prior may be designed based on expert knowledge, this usually encodes only soft beliefs about the causal model, and does not represent a single graph <span class="italic">G</span> unlike when the structure is assumed to be known. The term <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t35_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t35.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t35.gif"/></a> is called the marginal likelihood, and is defined by integrating over all possible values of the causal mechanisms<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn11"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t36_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t36.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t36.gif"/></a></td><td class="rightEqn">(11)</td></tr></table>where <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t37_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t37.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t37.gif"/></a> is the likelihood of the data under a specific choice of causal structure and mechanisms, and <span class="italic">P</span>(<span class="italic">θ</span>|<span class="italic">G</span>) is a prior distribution over causal mechanisms. The marginal likelihood represents how well the data <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t38_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t38.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t38.gif"/></a> fits a certain hypothesis, given by the causal model <span class="italic">G</span>, regardless of the choice of the causal mechanisms themselves.</p>
          <p class="otherpara">As is typically the case in Bayesian statistics, the difficulty in evaluating <a title="" href="#eqn10">eqn (10)</a> arises from the marginal evidence <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t39_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t39.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t39.gif"/></a>, which is almost always intractable. To circumvent this issue, approximations of the Bayesian posterior are often necessary, for example based on MCMC,<a title="Select to navigate to reference" href="#cit79"><sup><span class="sup_ref">79–83</span></sup></a> bootstrapping,<a title="Select to navigate to reference" href="#cit84"><sup><span class="sup_ref">84,85</span></sup></a> or more recently variational inference.<a title="Select to navigate to reference" href="#cit86"><sup><span class="sup_ref">86–90</span></sup></a></p>
        </div>
        <div>
          
          <span id="sect740"/><span class="c_heading_indent">3.6.3 Active learning of causal structures. </span>
          <span>With an approximation of the Bayesian posterior over causal graphs, we can also leverage the tools from Bayesian experimental design in Section 3.3 in order to design interventions on the system that would refine our beliefs about its causal structure.<a title="Select to navigate to references" href="#cit91"><sup><span class="sup_ref">91</span></sup></a> This creates a feedback loop between the estimation of our uncertainty about the causal graph based on data, the decisions about which experiments to perform, and the acquisition of new experimental data (see <a title="Select to navigate to figure" href="#imgfig1">Fig. 1</a>). Active causal discovery can be used to learn the causal structure of either the whole system,<a title="Select to navigate to reference" href="#cit92"><sup><span class="sup_ref">92–95</span></sup></a> or part of it.<a title="Select to navigate to references" href="#cit85"><sup><span class="sup_ref">85</span></sup></a> Recently, Toth <span class="italic">et al.</span><a title="Select to navigate to references" href="#cit96"><sup><span class="sup_ref">96</span></sup></a> proposed a novel framework called Active Bayesian Causal Inference (ABCI) to infer not only the causal graph, but also jointly learning the posterior over causal queries of interest.</span>
        </div>
      
    
    
      
      <h2 id="sect750"><span class="a_heading">4 Generative Flow Networks</span></h2>
      <span>We begin by introducing the broader ideas around using neural networks to efficiently learn a mapping from sampled observations to proposed high-dimensional probability distributions and intractable sums, as a general substitute for the popular MCMC-based inference. These ideas lead into GFlowNets, which provide a general framework for amortized inference with neural networks.</span>
      
        
        <h3 id="sect754"><span class="b_heading">4.1 Learning to perform amortized inference</span></h3>
        <span>Let us first look at how neural nets can be used to amortize the inference problem introduced in Section 3.1, <span class="italic">i.e.</span>, by being trained to approximately perform the sampling or summing task that is otherwise intractable. Specifically, we consider how an intractable expectation or sum can be transformed into a tractable training task to approximate the desired sum. This is the fundamental principle underlying GFlowNets.</span>
        <div>
          
          <span id="sect759"/><span class="c_heading_indent">4.1.1 Simple mean squared error criterion to amortize an intractable expectation. </span>
          <span>Consider a set of intractable expectations that we would like to approximate, for a pair of random variables <span class="italic">x</span> and <span class="italic">y</span> that can both take an exponential number of values or live in a high-dimensional space:<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn12"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t40_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t40.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t40.gif"/></a></td><td class="rightEqn">(12)</td></tr></table>which is then intractable because of the exponential number of terms in the sum.</span>
          <p class="otherpara">If we know how to sample from <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">x</span>), we could, however, train a neural net <span class="italic">Ŝ</span> with input <span class="italic">x</span>, stochastic target output <span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>) and Mean Squared Error (MSE) loss<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn13"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t41_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t41.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t41.gif"/></a></td><td class="rightEqn">(13)</td></tr></table>where <span class="italic">y</span> ∼ <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">x</span>), to train the estimator <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t42_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t42.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t42.gif"/></a> with parameters <span class="italic">θ</span>. When we sample training examples (<span class="italic">x</span>, <span class="italic">y</span>), the stochastic gradients <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t43_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t43.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t43.gif"/></a> would make <span class="italic">Ŝ</span> converge to <span class="italic">S</span> if it has enough capacity and is trained long enough.<a title="Select to navigate to references" href="#cit97"><sup><span class="sup_ref">97</span></sup></a></p>
          <p class="otherpara">For any new <span class="italic">x</span>, we would then have an amortized estimator <span class="italic">Ŝ</span>(<span class="italic">x</span>) which in one pass through the network would give us an approximation of the intractable sum <span class="italic">S</span>(<span class="italic">x</span>). We can consider this an efficient alternative to doing a Monte Carlo approximation<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn14"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t44_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t44.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t44.gif"/></a></td><td class="rightEqn">(14)</td></tr></table>which would require a potentially large number of samples and computations of <span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>) for each <span class="italic">x</span> at run-time, especially if <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">x</span>)<span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>) is a rich multimodal function (for which averaging just a few samples of <span class="italic">y</span> does not give us a good estimator of the expectation).</p>
          <p class="otherpara">Besides the advantage of faster run-time, a crucial potential advantage of the amortized version is that it could benefit from generalizable structure in the product <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">x</span>)<span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>): if observing a training set of (<span class="italic">x</span>, <span class="italic">y</span>, <span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>)) triplets can allow us to generalize to new (<span class="italic">x</span>, <span class="italic">y</span>) pairs, then we may not need to train <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t45_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t45.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t45.gif"/></a> with an exponential number of examples before it captures the generalizable structure and provides good answers (<span class="italic">i.e.</span>, approximates <span class="italic">E</span><small><sub><span class="italic">Y</span></sub></small>|<small><sub><span class="italic">x</span></sub></small>[<span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">Y</span>)] well) on new <span class="italic">x</span>'s. This ability to generalize from structure in the data is actually what explains the remarkable success of ML (and in particular of deep learning) in the vast set of modern AI applications.</p>
          <p class="otherpara">When we do not have a <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">x</span>) that we can sample from easily, we can, in principle, use MCMC methods that form chains of samples of <span class="italic">y</span>'s whose distribution converge to the desired <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">x</span>), and where the next sample is generally obtained from the previous one by a small stochastic change that favors increases in <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">x</span>). Unfortunately, when the modes of the summand, <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">x</span>)<span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>), occupy a small volume in the search space (<span class="italic">i.e.</span> throwing darts does not find them) and these modes are well-separated (by low-probability regions), especially in high dimension, it tends to take exponential time to mix from one mode to another. However, such an MCMC approach leaves money on the table: the attempts (<span class="italic">x</span>, <span class="italic">y</span>, <span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>)) contain information that one could use to train an ML model. To the extent that the space is sufficiently structured, such a model could guess where the yet unseen modes might be given the location of the already observed modes, as illustrated in <a title="Select to navigate to figure" href="#imgfig3">Fig. 3</a>.</p>
          <br/><div class="image_table"><table><tr><td colspan="3" class="imgHolder" id="imgfig3"><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-f3_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-f3.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-f3.gif"/></a></td></tr><tr><td class="pushTitleRight"> </td><td class="image_title"><b>Fig. 3 </b> <span id="fig3"><span class="graphic_title">An illustration of the feasibility of systematic generalization enabled by ML methods: if we have already discovered the three modes shown of a reward function, a learner that can generalize may guess the presence of a 4th mode, because the first three modes seem to align on a grid. The existence of such generalization structure is why amortized ML samplers can potentially do much better than MCMC samplers.</span></span></td><td class="pushTitleLeft"> </td></tr></table></div>
        </div>
        <div>
          
          <span id="sect863"/><span class="c_heading_indent">4.1.2 GFlowNet criterion to obtain a sampler and estimate intractable sums. </span>
          <span>Let us consider the situation where we do not have a handy <span class="italic">p</span>(<span class="italic">y</span>|<span class="italic">x</span>) and our objective is just to approximate a set of intractable sums (for any <span class="italic">x</span>)<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn15"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t46_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t46.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t46.gif"/></a></td><td class="rightEqn">(15)</td></tr></table>where we have the constraint that <span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>) ≥ 0 and <span class="italic">S</span>(<span class="italic">x</span>) &gt; 0. This may be useful to estimate a normalization constant for energy-based models or Bayesian posteriors (where <span class="italic">y</span> corresponds to learnable parameters and <span class="italic">x</span> to observed data). Hence we may also be interested in the sampling policy<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn16"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t47_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t47.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t47.gif"/></a></td><td class="rightEqn">(16)</td></tr></table></span>
          <p class="otherpara">Now, GFlowNet losses are derived from a set of constraints that we would like to be true:<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn17"/><span id="eqn17">∀(<span class="italic">x</span>, <span class="italic">y</span>): π(<span class="italic">y</span>|<span class="italic">x</span>)<span class="italic">S</span>(<span class="italic">x</span>) = <span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>)</span></td><td class="rightEqn">(17)</td></tr></table></p>
          <p class="otherpara">We can define estimators <img class="charmap" src="https://www.rsc.org/images/entities/char_e1de.gif" alt="[small pi, Greek, circumflex]"/> and <span class="italic">Ŝ</span> and train them with a loss such as<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn18"/><span id="eqn18"><span class="italic">L</span>(<span class="italic">x</span>,<span class="italic">y</span>) = (<img class="charmap" src="https://www.rsc.org/images/entities/char_e1de.gif" alt="[small pi, Greek, circumflex]"/>(<span class="italic">y</span>|<span class="italic">x</span>)<span class="italic">Ŝ</span>(<span class="italic">x</span>) − <span class="italic">R</span>(<span class="italic">x</span>,<span class="italic">y</span>))<small><sup>2</sup></small></span></td><td class="rightEqn">(18)</td></tr></table>or with an interpretation of <span class="italic">R</span> as unnormalized probabilities that we want well calibrated in the log-domain,<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn19"/><span id="eqn19"><span class="italic">L</span>(<span class="italic">x</span>,<span class="italic">y</span>) = (log(<img class="charmap" src="https://www.rsc.org/images/entities/char_e1de.gif" alt="[small pi, Greek, circumflex]"/>(<span class="italic">y</span>|<span class="italic">x</span>)<span class="italic">Ŝ</span>(<span class="italic">x</span>)) − log<img class="charmap" src="https://www.rsc.org/images/entities/char_2009.gif" alt="[thin space (1/6-em)]"/><span class="italic">R</span>(<span class="italic">x</span>,<span class="italic">y</span>))<small><sup>2</sup></small></span></td><td class="rightEqn">(19)</td></tr></table>where (<span class="italic">x</span>, <span class="italic">y</span>) are sampled from a training distribution <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t48_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t48.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t48.gif"/></a> that has full support. It can then be shown<a title="Select to navigate to reference" href="#cit11"><sup><span class="sup_ref">11,12</span></sup></a> that with <img class="charmap" src="https://www.rsc.org/images/entities/char_e1de.gif" alt="[small pi, Greek, circumflex]"/> and <span class="italic">Ŝ</span> with enough capacity and trained for long enough they both converge to their desired value:<br/><div class="image_table"><table><tr><td colspan="3" class="imgHolder" id="imgugt49"><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t49_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t49.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t49.gif"/></a></td></tr><tr><td class="pushTitleRight"> </td><td><a id="ugt49"/><span id="ugt49"/></td><td class="pushTitleLeft"> </td></tr></table></div></p>
          <p class="otherpara">This is a crucial property of GFlowNets: they are trained to sample objects <span class="italic">y</span> (given <span class="italic">x</span>) with probability proportional to a given reward function <span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>).</p>
        </div>
        <div>
          
          <span id="sect940"/><span class="c_heading_indent">4.1.3 Marginalizing over compositional random variables. </span>
          <span>To make the notion of intractable sum more concrete, it is good to think of <span class="italic">y</span> (and potentially <span class="italic">x</span> as well) as a compositional object, like a subset of variable-value pairs or a graph. For example, we can construct compositional objects sequentially through a series of steps where a new piece of the compositional object is inserted at each step, such as the molecular fragments composed to form a larger molecule in <a title="Select to navigate to figure" href="#imgfig2">Fig. 2b</a>. The sampling policy π then sequentially and stochastically chooses a constructive action at each step, and after each step we get a partially constructed object <span class="italic">s</span> which we call a GFlowNet state. A sequence of such states and actions forms a GFlowNet trajectory <span class="italic">τ</span>. In the basic GFlowNet framework, the actions are stochastic, but the next state is deterministically obtained from the previous state and the action, because they are not happening in an external environment but are part of the internal computation of a sampler. In addition, the GFlowNet mathematical results, as they currently stand, assume that each step is constructive, <span class="italic">i.e.</span>, we cannot return to the same partially constructed object <span class="italic">s</span> twice. This means that the set of all possible trajectories forms a directed acyclic graph (DAG), illustrated in <a title="Select to navigate to figure" href="#imgfig2">Fig. 2</a>. Because the transitions are deterministic, we can specify a trajectory <span class="italic">τ</span> with a sequence of states (or, equivalently, an initial state and a sequence of actions). A special “exit” action is also defined to declare the construction of the object <span class="italic">y</span> is completed. The policy π(<span class="italic">y</span>|<span class="italic">x</span>) is now specified by a forward transition distribution <span class="italic">P</span><small><sub>F</sub></small>(<span class="italic">s</span>|<span class="italic">s</span>′) which specifies how to generate each constructive step given the previous state, and we are interested in parameterizing and learning this <span class="italic">P</span><small><sub>F</sub></small>.</span>
          <p class="otherpara">For instance, consider the molecule graph example illustrated in <a title="Select to navigate to figure" href="#imgfig2">Fig. 2</a>. We can construct a molecule graph sequentially using nodes representing atoms as building blocks. Starting from a special empty state, which we denote as <span class="italic">s</span><small><sub>0</sub></small> (this can be an empty graph, null set or empty sequence or chosen based on the value of a conditioning variable <span class="italic">x</span>, maybe specifying some desired characteristics of the molecule), the object <span class="italic">y</span> can be constructed through a sequence of steps, each consisting of adding a single block <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t50_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t50.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t50.gif"/></a>. We assume that the actions are limited to be constructive, and deletion of blocks is not allowed. At each step, we have a partially-constructed object <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t51_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t51.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t51.gif"/></a>, where <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t52_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t52.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t52.gif"/></a> denoted the space of all possible partially-constructed objects and <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t53_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t53.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t53.gif"/></a>. Another assumption we make throughout is that these states are Markovian, that is, they incorporate all the information from their history. This results in a directed acyclic graph (DAG) <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t54_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t54.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t54.gif"/></a> which is defined by a tuple <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t55_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t55.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t55.gif"/></a>, where the set of nodes corresponds to <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t56_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t56.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t56.gif"/></a>, and an edge <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t57_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t57.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t57.gif"/></a> indicates that object <span class="italic">s</span>′ can be constructed by adding a block <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t58_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t58.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t58.gif"/></a> to <span class="italic">s</span>, <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t59_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t59.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t59.gif"/></a>. We can define a trajectory as a sequence of steps describing the construction of an object <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t60_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t60.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t60.gif"/></a>.<a title="Select to navigate to footnote" href="#fn2">‡</a> Let <span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>) denote the utility (reward) for a given object <span class="italic">y</span> in context <span class="italic">x</span>. For instance, it can be the binding energy for the ligand molecule <span class="italic">y</span> with a given target protein <span class="italic">x</span>.</p>
          <p class="otherpara">Formally, the training objective is to learn a stochastic policy π which sequentially generates an object <span class="italic">y</span> with a probability proportional to its reward, <span class="italic">i.e.</span>, π(<span class="italic">y</span>|<span class="italic">x</span>) ∝ <span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>).</p>
        </div>
        <div>
          
          <span id="sect998"/><span class="c_heading_indent">4.1.4 Multiple parent states. </span>
          <span>Besides the sequential nature of the generative process for <span class="italic">y</span>, an interesting complication is that there may be many ways (in fact exponentially many trajectories) to construct <span class="italic">y</span> from some starting point and context <span class="italic">x</span>. This means that a partially constructed object, <span class="italic">i.e.</span>, a state <span class="italic">s</span>, may have multiple parents <span class="italic">s</span>′ for which an action <span class="italic">a</span> exists that leads to <span class="italic">s</span>. Otherwise (when each state only has one parent), the DAG is a tree, which makes the computation much simpler. But when it is not a tree, it turns out to be convenient to consider and parameterize a backward transition probability function <span class="italic">P</span><small><sub>B</sub></small>(<span class="italic">s</span>′|<span class="italic">s</span>) which is consistent with that DAG and the associated forward transition probabilities <span class="italic">P</span><small><sub>F</sub></small>. The constraint in <a title="" href="#eqn17">eqn (17)</a> can be reformulated in several ways, in particular what is called the detailed balance constraint:<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn20"/><span id="eqn20">∀(<span class="italic">s</span>, <span class="italic">s</span>′): <span class="italic">P</span><small><sub>F</sub></small>(<span class="italic">s</span>|<span class="italic">s</span>′)<span class="italic">F</span>(<span class="italic">s</span>′) = <span class="italic">P</span><small><sub>B</sub></small>(<span class="italic">s</span>′|<span class="italic">s</span>)<span class="italic">F</span>(<span class="italic">s</span>)</span></td><td class="rightEqn">(20)</td></tr></table>where <span class="italic">F</span>(<span class="italic">s</span>) is called the flow at state <span class="italic">s</span> and plays a role similar to <span class="italic">S</span>(<span class="italic">x</span>) above, <span class="italic">i.e.</span>, it is an intractable sum, and there is a starting state <span class="italic">s</span><small><sub>0</sub></small> = <span class="italic">x</span> from which a trajectory is initiated, as well as a constraint that the flow into a terminal state <span class="italic">s</span> = <span class="italic">y</span> equals <span class="italic">R</span>(<span class="italic">x</span>, <span class="italic">y</span>). Similarly to the simpler case above, this can be turned into a training loss that we want to minimize, but now over all (<span class="italic">x</span>, <span class="italic">τ</span>) pairs or over all (<span class="italic">s</span>, <span class="italic">s</span>′) pairs. As a consequence of satisfying the detailed balance constraint at all (<span class="italic">s</span>, <span class="italic">s</span>′) pairs, the initial flow becomes equal to the normalizing constant:<a title="Select to navigate to references" href="#cit11"><sup><span class="sup_ref">11</span></sup></a><table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn21"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t61_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t61.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t61.gif"/></a></td><td class="rightEqn">(21)</td></tr></table></span>
        </div>
        <div>
          
          <span id="sect1058"/><span class="c_heading_indent">4.1.5 Learning objectives. </span>
          <span>In practice, we would like to approximate <span class="italic">P</span><small><sub>F</sub></small>(·|·; <span class="italic">θ</span>), <span class="italic">P</span><small><sub>B</sub></small>(·|·; <span class="italic">θ</span>), and <span class="italic">F</span>(·; <span class="italic">θ</span>) with learnable parameters <span class="italic">θ</span>, and we want to choose those parameters to satisfy as well as possible the detailed balance constraint <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t62_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t62.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t62.gif"/></a>. The detailed balance constraint can be converted to the following loss to learn the parameters <span class="italic">θ</span>:<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn22"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t63_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t63.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t63.gif"/></a></td><td class="rightEqn">(22)</td></tr></table></span>
          <p class="otherpara">Several alternative learning objectives for GFlowNets have been proposed, especially for longer trajectories to sample the object <span class="italic">y</span>.<a title="Select to navigate to reference" href="#cit98"><sup><span class="sup_ref">98,99</span></sup></a> Trajectory balance [ref. <a title="Select to navigate to references" href="#cit98">98</a>, TB] is a prominent learning objective for training GFlowNets. Contrary to the detailed balance objective, which considers constraints on pairs of states, trajectory balance jointly applies the detailed balance constraint over entire trajectories. A learnable parameter <span class="italic">Z</span> is introduced which at convergence is equal to the desired sum. The trajectory balance loss over a trajectory <span class="italic">τ</span> is defined as follows:<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn23"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t64_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t64.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t64.gif"/></a></td><td class="rightEqn">(23)</td></tr></table></p>
          <p class="otherpara">Algorithm 2 illustrates the typical approach for training GFlowNets, by sampling trajectories from a sampling policy <span class="italic"><img class="charmap" src="https://www.rsc.org/images/entities/i_char_0050_0302.gif" alt="[P with combining circumflex]"/></span><small><sub>F</sub></small> which is typically a tempered <span class="italic">P</span><small><sub>F</sub></small> or a mixture of <span class="italic">P</span><small><sub>F</sub></small> with a uniform policy to enable exploration, and optimizing the loss induced by the learning objective with respect to <span class="italic">θ</span>, with stochastic gradient descent.<a title="Select to navigate to footnote" href="#fn3">§</a> As a result of this procedure, we learn a <span class="italic">P</span><small><sub>F</sub></small> with the objective that the marginal likelihood of a trajectory terminating at a terminal state <span class="italic">x</span>, denoted as π(<span class="italic">x</span>) become proportional to the reward <span class="italic">R</span>(<span class="italic">x</span>). The learnable objects <span class="italic">P</span><small><sub>F</sub></small>, <span class="italic">P</span><small><sub>B</sub></small>, <span class="italic">F</span> are typically parameterized by neural networks. These neural networks must have appropriate inductive biases depending upon the type of objects we are constructing. These neural networks must also have enough capacity to model the underlying distribution. In Section 4.2 and Section 4.3 we discuss specific cases of leveraging GFlowNets for problems of molecule generation and causal modeling respectively.<br/><div class="image_table"><table><tr><td colspan="3" class="imgHolder" id="imgugr2"><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-u2_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-u2.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-u2.gif"/></a></td></tr><tr><td class="pushTitleRight"> </td><td><a id="ugr2"/><span id="ugr2"/></td><td class="pushTitleLeft"> </td></tr></table></div></p>
        </div>
        <div>
          
          <span id="sect1107"/><span class="c_heading_indent">4.1.6 Implications for Bayesian ML. </span>
          <span>Let us consider the special case where <span class="italic">y</span> = <span class="italic">θ</span> is a latent parameter, <span class="italic">i.e.</span>, in a Bayesian setting, and <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t65_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t65.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t65.gif"/></a> is the available data. Then we can define the reward function<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn24"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t66_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t66.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t66.gif"/></a></td><td class="rightEqn">(24)</td></tr></table>from the parameter prior <span class="italic">P</span>(<span class="italic">θ</span>) (how plausible are these parameters <span class="italic">a priori</span>) and the data likelihood <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t67_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t67.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t67.gif"/></a> (how well does this choice of parameters fit the data). Training a GFlowNet provides us with an approximate sampler for the posterior over parameters (the policy <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t68_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t68.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t68.gif"/></a>) given data as well as an estimator of the normalizing constant of the Bayesian posterior, through the learned initial flow <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t69_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t69.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t69.gif"/></a>. Hence, we have used amortization to turn a tractable function (prior times likelihood, as a function of <span class="italic">θ</span>) into estimators of these generally intractable quantities. We get a fast sampler for the posterior with no need for a Markov chain going through a large number of candidate samples. With that sampler, we can generate many independent samples <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t70_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t70.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t70.gif"/></a> (possibly in parallel) that are likely to visit the larger modes of the posterior (where the reward is larger).</span>
          <p class="otherpara">To make computations more ML-friendly (especially for large datasets) while training the GFlowNet, we can note that the GFlowNet squared loss objectives naturally lend themselves to the case where the reward or log-reward is stochastic and is an unbiased estimator of the true reward. For example, we can typically decompose the overall dataset log-likelihood <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t71_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t71.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t71.gif"/></a> into a sum of per-example or per-minibatch terms, and we can introduce a multiplicative correction to account for the prior <span class="italic">P</span>(<span class="italic">θ</span>):<br/><div class="image_table"><table><tr><td colspan="3" class="imgHolder" id="imgugt72"><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t72_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t72.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t72.gif"/></a></td></tr><tr><td class="pushTitleRight"> </td><td><a id="ugt72"/><span id="ugt72"/></td><td class="pushTitleLeft"> </td></tr></table></div>where the expectation over <span class="italic">Z</span> is just a sum over the <span class="italic">Z</span>'s in <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t73_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t73.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t73.gif"/></a>. This makes it possible to train the GFlowNet posterior estimator using stochastic gradient descent on single examples or minibatches, which is the state-of-the-art to train deep nets.</p>
        </div>
        <div>
          
          <span id="sect1134"/><span class="c_heading_indent">4.1.7 Why GFlowNets?. </span>
          <span>Let us look at how GFlowNets differ from other related conceptual frameworks:</span>
          <p class="otherpara">• Markov Chain Monte Carlo: GFlowNets do not construct Markov chains with semantics like those in MCMC methods. GFlowNets and MCMC approaches differ fundamentally: with MCMC approaches, the chain is irreducible (every state is reachable from every other state), and the stationary distribution of this chain is of interest. In order to generate samples from this stationary distribution, we need to run long chains (ideally infinitely long ones). In GFlowNets, however, the chains only need every state to be accessible from the initial state, and what we have is a bounded sequence of stochastic transitions. The expensive stochastic “search” (to reach low energy configurations) normally performed by MCMC is replaced by the training phase of the GFlowNet, using the principle of amortized inference, so that during inference a sample can be generated in a single short trajectory by the policy. To exemplify, if we were to run an MCMC to generate samples of desirable molecules, we would probably have a molecule at every state, and we would have actions that can stochastically transform one molecule into a nearby one,<a title="Select to navigate to references" href="#cit100"><sup><span class="sup_ref">100</span></sup></a> whereas a typical way to sample a desirable molecule with GFlowNets is constructive, where we start from an empty object (which is not really a molecule) and we sequentially and stochastically add molecular fragments: the state corresponds to these intermediate objects, which may or may not correspond to a well-formed molecule.<a title="Select to navigate to references" href="#cit11"><sup><span class="sup_ref">11</span></sup></a> That being said, the overall objective is the same: turn a given energy function (or unnormalized distribution) into a generative procedure for obtaining samples from that distribution. Both MCMC and GFlowNets can also be used to marginalize, <span class="italic">i.e.</span>, compute intractable sums, although again in different ways. MCMC turn the exact sum into a Monte Carlo approximation of it while GFlowNets perform amortized inference, <span class="italic">i.e.</span>, they train a neural net whose output will, after training, approximate the sum. This becomes useful when we have more than one marginalization to do, say given a context, and thus the neural net can take that context as input and rapidly produce an estimator of the intractable sum as output.</p>
          <p class="otherpara">• Reinforcement learning: GFlowNets learn policies to sample trajectories that land in a terminal state with probability proportional to the reward of the terminal state rather than trajectories that maximize the expected reward, as in standard deep reinforcement learning. As shown by Bengio <span class="italic">et al.</span>,<a title="Select to navigate to references" href="#cit11"><sup><span class="sup_ref">11</span></sup></a> Jain <span class="italic">et al.</span>,<a title="Select to navigate to references" href="#cit101"><sup><span class="sup_ref">101</span></sup></a> this results in a diversity of samples which is important when the reward function is an imperfect proxy for the property that we actually care about: it avoids putting all our eggs in the wrong basket.</p>
          <p class="otherpara">• Deep generative models: traditional generative models in deep learning such as variational auto-encoders or VAEs<a title="Select to navigate to reference" href="#cit102"><sup><span class="sup_ref">102,103</span></sup></a> or GANs<a title="Select to navigate to references" href="#cit104"><sup><span class="sup_ref">104</span></sup></a> require positive samples to model the distribution of interest, whereas GFlowNets are trained from a reward function.</p>
          <p class="otherpara">• Variational inference: variational inference trains an approximate sampler (and the corresponding density) so as to reduce the forward KL-divergence (the evidence lower bound or ELBO) with a given distribution function (playing the same role as the reward). This requires on-policy training (sampling from the learned sampler), which has a tendency for focusing on a single mode rather than find a diversity of modes. Instead (see Malkin <span class="italic">et al.</span><a title="Select to navigate to references" href="#cit25"><sup><span class="sup_ref">25</span></sup></a> for details), GFlowNet objectives enable off-policy training without requiring the high-variance importance sampling correction necessary with the ELBO.</p>
          <p class="otherpara">To summarize, GFlowNets shine in problems with the following properties:</p>
          <p class="otherpara">• It is possible to define or learn a non-negative reward function which will specify from what distribution the GFlowNet should sample.</p>
          <p class="otherpara">• The reward function of interest is highly multimodal. This emphasizes the advantage of GFlowNets in terms of diversity of samples. If the reward function was unimodal, existing RL or variational inference methods (which tend to focus on a single mode) could be used instead.</p>
          <p class="otherpara">• It is advantageous to sample sequentially, <span class="italic">e.g.</span>, there is compositional structure that can be exploited by sequential generation.</p>
          
            
            <span id="sect1159"/><br/><span class="d_heading_indent">4.1.7.1 Current limitations. </span>
            <span>Until recently, GFlowNets have been limited to sampling from distributions over discrete objects (<span class="italic">e.g.</span> graphs). Recent work by Lahlou <span class="italic">et al.</span><a title="Select to navigate to references" href="#cit105"><sup><span class="sup_ref">105</span></sup></a> presents a theoretical framework for extending GFlowNets to sample from distributions over continuous spaces. Leveraging this framework for sampling from distributions over high-dimensional continuous or mixed (discrete and continuous) spaces remains an open problem. Another potential limitation, shared with other reinforcement learning methods, is that effective credit assignment over very long trajectories (for generating large objects, such as proteins) is more difficult. Pan <span class="italic">et al.</span><a title="Select to navigate to references" href="#cit106"><sup><span class="sup_ref">106</span></sup></a> take initial steps to tackle this problem, proposing a way to assign partial rewards earlier in the generated trajectory which results in more effective credit assignment. Another open question is that of the best policy for sampling training trajectories for a GFlowNet. Existing theoretical results from Bengio <span class="italic">et al.</span><a title="Select to navigate to references" href="#cit12"><sup><span class="sup_ref">12</span></sup></a> assume that the policy sampling trajectories should have full support over the space of trajectories, but designing this policy (beyond the heuristics discussed in Section 4.1.5) for sample-efficient learning is an open problem.</span>
          
        </div>
      
      
        
        <h3 id="sect1170"><span class="b_heading">4.2 Diverse candidate generation</span></h3>
        <span>A fundamental problem in chemistry is the synthesis of novel chemical structures (<span class="italic">e.g.</span> molecules) that satisfy some criteria. As alluded to in Section 4.1, generation of molecules to optimize for a particular chemical property is an appealing use case for GFlowNets, because GFlowNets will tend to generate a diverse set of molecules optimizing that property. An important problem in the context of drug discovery, which we introduced in Example 1.1 is to discover molecules that bind to a particular target, potentially inhibiting the target in the process. From the computational design perspective, molecular docking simulations can give scoring functions to approximately evaluate proposed molecules. More recently, graph neural networks which approximate the binding energy<a title="Select to navigate to references" href="#cit107"><sup><span class="sup_ref">107</span></sup></a> are used to approximate docking as they are much faster. As discussed in Section 2 as these scoring functions serve as approximations to the underlying process, it is important to generate diverse candidates for downstream applications, to avoid putting all our eggs in the same basket.</span>
        <p class="otherpara">Ref. <a title="Select to navigate to references" href="#cit11">11</a> leverage GFlowNets for the problem of diverse molecule generation.<a title="Select to navigate to footnote" href="#fn4">¶</a> Soluble epoxide hydrolase (sEH) in the 4JNC configuration is studied as a target in the paper. It is a useful target as it plays a role in certain respiratory and heart diseases.<a title="Select to navigate to reference" href="#cit108"><sup><span class="sup_ref">108,109</span></sup></a> Autodock Vina<a title="Select to navigate to references" href="#cit110"><sup><span class="sup_ref">110</span></sup></a> was used for docking the generated molecules to evaluate the binding energy. Docking each molecule with Autodock Vina can be quite slow and takes several minutes to run, making it prohibitively expensive to train a policy directly using it as a reward. Instead, the authors rely on a graph neural network, trained using a data set of docking scores for 300<img class="charmap" src="https://www.rsc.org/images/entities/char_2009.gif" alt="[thin space (1/6-em)]"/>000 molecules, as the reward for training the policy. The molecules are generated using fragments, as illustrated in <a title="Select to navigate to figure" href="#imgfig2">Fig. 2</a>. At each step, the policy picks a fragment from a library to add to the partially constructed molecule, and choose where to place that fragment. The library of fragments is derived from the Zinc database.<a title="Select to navigate to references" href="#cit111"><sup><span class="sup_ref">111</span></sup></a></p>
        <p class="otherpara">The molecule design problem possesses all the key properties discussed in Section 4.1.7 for GFlowNets to be effective − (a) there is compositional structure in generation as molecules are built using subgraphs with unique chemical properties (b) the reward function is an approximation of what we really care about, as the docking score and its approximation by a neural network (which has epistemic uncertainty associated with it due to finite training) are approximations of the underlying phenomenon of a molecule binding to a target and inhibiting it, and (c) the reward is multi-modal since there can be multiple motifs of molecules that bind well to a given target.</p>
        <p class="otherpara">Ref. <a title="Select to navigate to references" href="#cit11">11</a> showed that GFlowNets result in substantial improvements over existing methods on this molecule generation task. In particular, as shown in <a title="Select to navigate to figure" href="#imgfig4">Fig. 4a</a>, GFlowNets discover significantly more modes of the reward function (<span class="italic">i.e.</span> many different molecules that have high predicted docking score) relative to other reinforcement learning (PPO) and MCMC (MARS) approaches. Sampling proportional to the reward results in high reward and diverse samples. Though it is important to note that while using GFlowNets results in significant improvements in the diversity of generated samples, they do not always lead to the highest scoring candidates, because there is a natural trade-off between diversity and reward.<a title="Select to navigate to references" href="#cit112"><sup><span class="sup_ref">112</span></sup></a> introduce metrics to study the ability of GFlowNets to explore novel regions in molecular space.</p>
        <br/><div class="image_table"><table><tr><td colspan="3" class="imgHolder" id="imgfig4"><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-f4_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-f4.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-f4.gif"/></a></td></tr><tr><td class="pushTitleRight"> </td><td class="image_title"><b>Fig. 4 </b> <span id="fig4"><span class="graphic_title">(a) Molecules generated with GFlowNets cover significantly more modes of the reward distribution, resulting in diverse high reward molecules. (b) Acquiring molecules generated with GFlowNets results in significant improvements over the starting pool of molecules. Figures taken from <a title="Select to navigate to references" href="#cit11"><sup><span class="sup_ref">11</span></sup></a> with permission.</span></span></td><td class="pushTitleLeft"> </td></tr></table></div>
        <p class="otherpara">Further,<a title="Select to navigate to references" href="#cit11"><sup><span class="sup_ref">11</span></sup></a> also consider an active learning setup, starting with a data set of 2000 molecules. In each round, a surrogate model is trained on the data set. This surrogate model is used as the reward for the GFlowNet. Next, molecules are generated with the GFlowNet policy, evaluated with docking, and added to the data set for the next round. Using GFlowNet to acquire the batches of molecules results in significant improvements in the reward over the initial data set, shown in <a title="Select to navigate to figure" href="#imgfig4">Fig. 4b</a>, demonstrating the potential of GFlowNets to accelerate large-scale virtual screenings.</p>
        <p class="otherpara">From a practical perspective, we are often interested in multiple objectives rather than a single one. For instance, in the context of drug discovery, an ideal drug candidate should specifically inhibit the target but also be synthesizable in large quantities, soluble, and harmless to humans; alternatively, in material science, to have an efficient solar cell means the optimization of current, voltage, and fill factor. Typically, there are very few candidates which simultaneously satisfy all the objectives, which might even be conflicting with each other (<span class="italic">e.g.</span> in solar cells, photocurrent can increase with a photoactive material with lower bandgap, but the voltage decreases). Instead, there exists a set of candidates with the optimal trade-offs between the objectives where further optimizing an objective is impossible without compromising another, <span class="italic">i.e.</span> the Pareto front. Moreover, as with the single objective case, diversity is still critical in the multi-objective case. Multi-Objective GFlowNets [ref. <a title="Select to navigate to references" href="#cit113">113</a>, MOGFNs;] extend GFlowNets to tackle multi-objective optimization problems. Building upon scalarization approaches in multi-objective optimization,<a title="Select to navigate to references" href="#cit114"><sup><span class="sup_ref">114</span></sup></a> MOGFNs decompose the multi-objective optimization problem into a family of sub-problems which can solved simultaneously. This family of sub-problems is modeled simultaneously with a reward conditional GFlowNet.<a title="Select to navigate to references" href="#cit12"><sup><span class="sup_ref">12</span></sup></a> MOGFNs demonstrate state-of-the-art performance on a variety of small molecule generation and protein design tasks. MOGFNs consistently generate diverse pareto-optimal candidates. For instance, MOGFNs are able to generate molecules that bind to the sEH target, while achieving a high synthesizability and QED score.</p>
        <p class="otherpara">The active learning setting is further explored by.<a title="Select to navigate to references" href="#cit101"><sup><span class="sup_ref">101</span></sup></a><a title="Select to navigate to footnote" href="#fn5">||</a> Incorporating ideas from Bayesian optimization discussed in Section 3.4, GFlowNet-AL<a title="Select to navigate to references" href="#cit101"><sup><span class="sup_ref">101</span></sup></a> incorporates information about the epistemic uncertainty of the surrogate model in the reward for the GFlowNet with an acquisition function. This epistemic uncertainty helps in guiding the GFlowNet to optimize the promising less explored regions in the state space. As such, instead of maximizing the acquisition function in Algorithm 1,<a title="Select to navigate to references" href="#cit101"><sup><span class="sup_ref">101</span></sup></a> propose sampling proportional to the acquisition function. Equipped with information about the epistemic uncertainty in the reward and other improvements, GFlowNet-AL outperforms various existing methods on a variety of biological sequence design tasks, including generation of peptide sequences with antimicrobial properties. The state space <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t74_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t74.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t74.gif"/></a> consists of partially constructed sequences with each action being the addition of a token from a vocabulary (<span class="italic">e.g.</span> a residue from a set of amino acids) to the end of the current partial sequence. Candidate sequences generated by GFlowNets are significantly more diverse and have high rewards. The diversity of generated candidates demonstrates the potential of GFlowNets to accelerate the process of discovering novel antibiotics to tackle the growing and highly concerning phenomenon of antimicrobial resistance.<a title="Select to navigate to references" href="#cit115"><sup><span class="sup_ref">115</span></sup></a></p>
        <p class="otherpara">These initial empirical successes demonstrate the potential of GFlowNets to make a significant impact in improving experimental design for a wide variety of scientific problems.</p>
      
      
        
        <h3 id="sect1212"><span class="b_heading">4.3 Modeling posteriors over causal models</span></h3>
        <div>
          
          <span id="sect1215"/><span class="c_heading_indent">4.3.1 Bayesian causal discovery with GFlowNets. </span>
          <span>As we have seen in Section 4.1.6, GFlowNets offer a general solution to approximate Bayesian posteriors, like the one in <a title="" href="#eqn10">eqn (10)</a>. GFlowNets are all the more adapted to the problem of Bayesian causal discovery that causal structures <span class="italic">G</span>, represented as a DAG, are compositional objects. Deleu <span class="italic">et al.</span><a title="Select to navigate to references" href="#cit116"><sup><span class="sup_ref">116</span></sup></a><a title="Select to navigate to footnote" href="#fn6">**</a> used this observation to introduce a GFlowNet whose states are DAGs, and where some graph <span class="italic">G</span> is created sequentially by adding one edge at a time, starting from the completely disconnected graph over <span class="italic">d</span> nodes; the structure of this GFlowNet is shown in <a title="Select to navigate to figure" href="#imgfig5">Fig. 5</a> (left). Similar to <a title="" href="#eqn24">eqn (24)</a>, for a fixed dataset <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t75_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t75.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t75.gif"/></a>, the reward function of the GFlowNet is defined as <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t76_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t76.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t76.gif"/></a>. By constraining the set of valid actions at every state, the edges are added in such a way that they will never introduce a cycle, which guarantees that graphs remain acyclic at every stage of the construction. Therefore, all the states of the GFlowNet are valid causal structures. Deleu <span class="italic">et al.</span><a title="Select to navigate to references" href="#cit116"><sup><span class="sup_ref">116</span></sup></a> leveraged this property and showed that such a GFlowNet may be trained using a modification of the detailed balance loss [ref. <a title="Select to navigate to references" href="#cit12">12</a>, see also <a title="" href="#eqn20">eqn (20)</a>], specifically adapted to the case where all the states are terminating.</span>
          <br/><div class="image_table"><table><tr><td colspan="3" class="imgHolder" id="imgfig5"><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-f5_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-f5.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-f5.gif"/></a></td></tr><tr><td class="pushTitleRight"> </td><td class="image_title"><b>Fig. 5 </b> <span id="fig5"><span class="graphic_title">GFlowNet for Bayesian causal discovery. (Left) The structure of the GFlowNet introduced in ref. <a title="Select to navigate to references" href="#cit116">116</a>, where directed acyclic graphs (DAGs) are constructed one edge at a time. Each DAG is associated with a reward <span class="italic">R</span>(<span class="italic">G</span>). (Right) Comparison between the edge marginals computed using the exact posterior distribution, and approximated using the GFlowNet; the GFlowNet is capable of accurately approximating the exact posterior <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t77_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t77.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t77.gif"/></a>. Used with permission from Tristan Deleu.<a title="Select to navigate to references" href="#cit116"><sup><span class="sup_ref">116</span></sup></a></span></span></td><td class="pushTitleLeft"> </td></tr></table></div>
          <p class="otherpara">To evaluate the reward function <span class="italic">R</span>(<span class="italic">G</span>) though, one needs to evaluate the marginal likelihood <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t78_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t78.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t78.gif"/></a> in <a title="" href="#eqn11">eqn (11)</a>, which is in general intractable.<a title="Select to navigate to references" href="#cit117"><sup><span class="sup_ref">117</span></sup></a> Deleu <span class="italic">et al.</span><a title="Select to navigate to references" href="#cit116"><sup><span class="sup_ref">116</span></sup></a> experimented only with models such as multinomial-Dirichlet (for discrete data) and linear-Gaussian (for continuous data), for which the marginal likelihood may be computed efficiently in closed form. Alternatively though, instead of approximating the (marginal) Bayesian posterior <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t79_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t79.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t79.gif"/></a> over structures only, we could approximate the posterior <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t80_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t80.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t80.gif"/></a> over both the causal structures <span class="italic">G</span> and the causal mechanisms <span class="italic">θ</span>,<a title="Select to navigate to references" href="#cit118"><sup><span class="sup_ref">118</span></sup></a> to avoid the intractable integration in <a title="" href="#eqn11">eqn (11)</a>.</p>
          
            
            <span id="sect1256"/><br/><span class="d_heading_indent">4.3.1.1 Beyond DAGs. </span>
            <span>Work on causal discovery focuses primarily on the causal graphical model framework introduced in Section 3.5 that assumes a DAG structure, but acyclicity is indeed an assumption that may not hold in certain domains. For instance, in gene regulatory networks, there are feedback loops between multiple genes interacting with one another.<a title="Select to navigate to references" href="#cit119"><sup><span class="sup_ref">119</span></sup></a> Nevertheless, when we consider the temporally unfolded cyclic graph, <span class="italic">i.e.</span>, the dynamics, we are back to a DAG. Some recent work has studied the problem of learning the structure of non-acyclic causal models.<a title="Select to navigate to reference" href="#cit120"><sup><span class="sup_ref">120–122</span></sup></a> The GFlowNet approach discussed above naturally extends to cases where the causal graph might be cyclic. The masking mechanism introduced by Deleu <span class="italic">et al.</span><a title="Select to navigate to references" href="#cit116"><sup><span class="sup_ref">116</span></sup></a> prevents cycles from being introduced at every step where an edge is being added, ensuring the generated graphs are DAGs. If we remove this additional constraint and allow the GFlowNet to introduce cycles in the generated graph, then it would approximate the posterior distribution over cyclic causal models which fit the given observations.</span>
          
        </div>
        <div>
          
          <span id="sect1265"/><span class="c_heading_indent">4.3.2 Bayesian posteriors for scientific discovery. </span>
          
            
            <span id="sect1268"/><br/><span class="d_heading_indent">4.3.2.1 Posterior predictive. </span>
            <span>Once the structure of the causal graphical model is known, we can use the model to perform inference, <span class="italic">i.e.</span> answering (possibly causal) questions about the system of interest, in the context of different interventions (which we can interpret as setting some variables, <span class="italic">i.e.</span>, designing an experiment). If we have information about the epistemic uncertainty, through the Bayesian posterior <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t81_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t81.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t81.gif"/></a>, we can even go one step further and average out the predictions made with all possible causal models, weighted using the posterior distribution. Concretely, given a new observation <span class="italic">y</span> in the context of an intervention <span class="italic">x</span> this corresponds to evaluating<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn25"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t82_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t82.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t82.gif"/></a></td><td class="rightEqn">(25)</td></tr></table></span>
            <p class="otherpara">This is called the posterior predictive, or Bayesian model averaging.<a title="Select to navigate to reference" href="#cit123"><sup><span class="sup_ref">123,124</span></sup></a> The advantage of <a title="" href="#eqn25">eqn (25)</a> over making predictions using a single causal model is that multiple concurrent theories may now participate in those predictions. In this way, we avoid using only theory, which may be incorrect, and we obtain a more conservative answer, thus avoiding catastrophic outcomes due to a single theory (say a particular causal graph <span class="italic">G</span>) being confidently wrong.</p>
          
          
            
            <span id="sect1284"/><br/><span class="d_heading_indent">4.3.2.2 Amortized posterior predictive. </span>
            <span>Instead of performing a Monte Carlo average to estimate <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t83_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t83.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t83.gif"/></a> for each candidate <span class="italic">x</span> as per <a title="" href="#eqn25">eqn (25)</a> (which may be fairly expensive if we want to train a policy that is trained by considering a large number of possible <span class="italic">x</span>'s), we can use a neural network <span class="italic">g</span><small><sub><span class="italic">ϕ</span></sub></small>(<span class="italic">x</span>, <span class="italic">y</span>) to amortize that calculation. This can be done by training <span class="italic">g</span> over (<span class="italic">x</span>, <span class="italic">y</span>, <span class="italic">G</span>) triplets with squared loss<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn26"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t84_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t84.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t84.gif"/></a></td><td class="rightEqn">(26)</td></tr></table></span>
            <p class="otherpara">Other amortization approaches are possible. For example, using the GFlowNet framework, a policy <span class="italic">Q</span>(<span class="italic">y</span><small><sub><span class="italic">i</span></sub></small>|<span class="italic">x</span><small><sub><span class="italic">i</span></sub></small>,<span class="italic">y</span><small><sup><span class="italic">i</span>−1</sup></small><small><sub>1</sub></small>,<span class="italic">x</span><small><sup><span class="italic">i</span>−1</sup></small><small><sub>1</sub></small>) can be trained to first sample one outcome <span class="italic">y</span><small><sub><span class="italic">i</span></sub></small> at a time, given the input experiment specification <span class="italic">x</span><small><sub><span class="italic">i</span></sub></small> and the previous experimental results <span class="italic">y</span><small><sup><span class="italic">i</span>−1</sup></small><small><sub>1</sub></small> of the previous experiments <span class="italic">x</span><small><sup><span class="italic">i</span>−1</sup></small><small><sub>1</sub></small>. The GFlowNet constraint to satisfy is that<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn27"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t85_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t85.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t85.gif"/></a></td><td class="rightEqn">(27)</td></tr></table><table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn28"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t86_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t86.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t86.gif"/></a></td><td class="rightEqn">(28)</td></tr></table><table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn29"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t87_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t87.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t87.gif"/></a></td><td class="rightEqn">(29)</td></tr></table>where the trained posterior predictive takes explicitly a partial dataset (<span class="italic">x</span><small><sup><span class="italic">i</span>−1</sup></small><small><sub>1</sub></small>, <span class="italic">y</span><small><sup><span class="italic">i</span>−1</sup></small><small><sub>1</sub></small>) as input, similarly to neural processes<a title="Select to navigate to references" href="#cit125"><sup><span class="sup_ref">125</span></sup></a> and <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t88_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t88.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t88.gif"/></a> is the GFlowNet causal graph sampler as described above, except that we allow interventions (different choices of <span class="italic">x</span>) in the data.</p>
          
          
            
            <span id="sect1360"/><br/><span class="d_heading_indent">4.3.2.3 Interpretability. </span>
            <span>Bayesian posteriors over causal models also provide a natural tool for interpretability, since they encode the belief that a causal structure fits the observed data. By inspecting which causal structures contain a certain edge, we can obtain a belief that certain causal relationships between two random variables exist.<a title="Select to navigate to references" href="#cit126"><sup><span class="sup_ref">126</span></sup></a> This is called the edge marginal distribution:<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn30"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-u3_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-u3.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-u3.gif"/></a></td><td class="rightEqn">(30)</td></tr></table></span>
            <p class="otherpara">
              <a title="Select to navigate to figure" href="#imgfig5">Fig. 5</a> (right) shows a comparison of the edge marginals computed with the posterior approximation returned by DAG-GFlowNet<a title="Select to navigate to references" href="#cit116"><sup><span class="sup_ref">116</span></sup></a> against the exact edge marginals, highlighting the capacity of GFlowNets to accurately approximate the posterior over graphs <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t89_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t89.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t89.gif"/></a>. Note that this kind of comparison is typically limited to small problems where the true posterior <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t90_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t90.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t90.gif"/></a> may be computed efficiently in closed-form, and in general one may be concerned with the calibration of these estimated marginals.<a title="Select to navigate to references" href="#cit90"><sup><span class="sup_ref">90</span></sup></a></p>
          
        </div>
      
    
    
      
      <h2 id="sect1374"><span class="a_heading">5 Towards a unified framework for scientific discovery with GFlowNets</span></h2>
      <span>In this paper, we have introduced GFlowNets as a tool for modeling and for experimental design in the context of the scientific discovery loop (<a title="Select to navigate to figure" href="#imgfig1">Fig. 1</a>). We have summarized how they have been used and could be further used on both fronts. In this concluding section, we outline research directions based on this early work and aimed at providing scientists with a powerful ML-based framework applicable when it is possible to iteratively generate informative experimental data.</span>
      
        
        <h3 id="sect1379"><span class="b_heading">5.1 Exploiting amortized causal Bayesian modeling for defining the utility of an experiment</span></h3>
        <span>An appealing theoretical framework for defining the objective of an experiment is that of information gain introduced in Section 3.2: “how much information about a random variable of interest can we expect to gain through the experiment?” A good policy for experimental design should propose experiments with a high value of this information gain as a reward. Note that this framework is broadly applicable to a wide range of interactive learning domains, such as reinforcement learning and active learning, encapsulating the fundamental problem of exploration. In general, the decision to perform an experiment may not simply be based on the number of bits of information gained but also on the risks and costs involved.<a title="Select to navigate to references" href="#cit127"><sup><span class="sup_ref">127</span></sup></a> We can however incorporate the notion of a cost or budget by considering the information gain per unit of cost incurred as the reward.</span>
        <p class="otherpara">Information gain can be measured in principle by the mutual information between the outcome of an experiment (a random variable since the experiment has not taken place yet) and the variable of interest (about which we seek to gain information), given the experimental specification and any other knowledge (including data) we may already have. In the simplest and purely unsupervised knowledge-seeking scenario, the variable of interest may be the causal model explaining the outcomes of experiments. In a more targeted scenario, for example in drug discovery, it would be the set of molecules that have certain desirable characteristics (<span class="italic">e.g.</span>, affinity with a target protein is above a threshold and toxicity is below a threshold and synthesis cost is below a threshold). Let <span class="italic">Y</span> be the experimental outcome, <span class="italic">x</span> be the experiment specification, and <span class="italic">V</span> the variable of interest about which we seek to gain information. The information-theoretic utility for our experimental design would then be defined as<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn31"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t91_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t91.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t91.gif"/></a></td><td class="rightEqn">(31)</td></tr></table><table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn32"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t92_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t92.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t92.gif"/></a></td><td class="rightEqn">(32)</td></tr></table>where <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t93_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t93.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t93.gif"/></a> is our dataset of prior experimental results {(<span class="italic">x</span>, <span class="italic">y</span>)} and any other constraint we want to exploit to condition the probabilities. With <span class="italic">V</span> typically being a much higher-dimensional object than <span class="italic">Y</span>, <a title="" href="#eqn32">eqn (32)</a> tends to be more practical numerically. To evaluate the expression in <a title="" href="#eqn32">eqn (32)</a> we can leverage the ideas of amortization and GFlowNets to estimate (a) the numerator and denominator probabilities <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t94_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t94.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t94.gif"/></a> (b) a sampler for the joint <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t95_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t95.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t95.gif"/></a>, and (c) an estimator <span class="italic">Î</span> of the MI itself, as a function of <span class="italic">x</span>. In the case where the variable of interest are the parameters of some underlying process <span class="italic">v</span> = <span class="italic">θ</span> (as introduced in Section 3.2), we can follow the amortization approach outlined in Section 4.3.2 to estimate the posterior predictive <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t96_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t96.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t96.gif"/></a> in the denominator. On the other hand, the likelihood in the numerator <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t97_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t97.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t97.gif"/></a> is available in the case of explicit models, and can be approximated in the case of implicit models as discussed in Section 3.3. Next to learn a sampler for the joint <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t98_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t98.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t98.gif"/></a> we first approximate samples from the posterior over parameters <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t99_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t99.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t99.gif"/></a> following Section 4.1.6. By combining the samples from the posterior <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t100_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t100.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t100.gif"/></a> and the likelihood <span class="italic">P</span>(<span class="italic">y</span>|<span class="italic">x</span>, <span class="italic">θ</span>) we can learn a sampler <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t101_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t101.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t101.gif"/></a> to approximate the joint <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t102_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t102.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t102.gif"/></a>.</p>
        <p class="otherpara">As for the estimator of MI itself, one possibility is to train a neural network <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t103_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t103.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t103.gif"/></a> to amortize the expected value over (<span class="italic">θ</span>, <span class="italic">y</span>) given <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t104_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t104.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t104.gif"/></a> using the samples from the joint <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t105_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t105.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t105.gif"/></a> and the estimators for the probabilities in the log-prob ratio from with a squared loss<table><td class="leftEqn"> </td><tr><td class="eqn"><span id="eqn33"/><a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t106_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t106.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t106.gif"/></a></td><td class="rightEqn">(33)</td></tr></table>where <span class="italic">x</span> is sampled from a dataset or a generative model of inputs, <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t107_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t107.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t107.gif"/></a> and <span class="italic">y</span> ∼ <span class="italic">P</span>(<span class="italic">y</span>|<span class="italic">x</span>, <span class="italic">θ</span>). With enough capacity and training time, <span class="italic">Q</span> converges to <span class="italic">P</span> and <span class="italic">Î</span>(<span class="italic">x</span>) converges to <a href="/image/article/2023/DD/d3dd00002h/d3dd00002h-t108_hi-res.gif" title="Select to open image in new window" onclick="open(this.href, &#34;_blank&#34;, &#34;toolbar=1,scrollbars=yes,resizable=1&#34;); return false;"><img alt="image file: d3dd00002h-t108.tif" src="/image/article/2023/DD/d3dd00002h/d3dd00002h-t108.gif"/></a>. What is particularly interesting if <span class="italic">x</span> is in a high-dimensional space is that it generally won't be necessary to see more than one value of <span class="italic">y</span> and <span class="italic">θ</span> for each value of <span class="italic">x</span> in order to train <span class="italic">Î</span>, as usual in supervised learning. This can work if it is possible for the learning procedure for <span class="italic">Î</span> to generalize from the (<span class="italic">θ</span>, <span class="italic">x</span>, <span class="italic">y</span>) triplets used to train it.</p>
      
      
        
        <h3 id="sect1449"><span class="b_heading">5.2 Additional open challenges</span></h3>
        <div>
          
          <span id="sect1452"/><span class="c_heading_indent">5.2.1 Modeling and causality. </span>
          <span>One open challenge on the modeling side is to leverage GFlowNets to model Bayesian posteriors beyond causal models.<a title="Select to navigate to references" href="#cit128"><sup><span class="sup_ref">128</span></sup></a> take an initial step in this direction, using GFlowNets to model the posterior over dropout masks in a neural network. Moreover, in the context of causal models, many challenges remain to extend the work done by.<a title="Select to navigate to references" href="#cit116"><sup><span class="sup_ref">116</span></sup></a> This includes (a) accommodating larger causal graphs efficiently (b) making it possible to handle unobserved causal variables by also learning how the raw inputs (<span class="italic">e.g.</span>, images) may be related to the causal variables (c) learning how experimental choices relate to interventions on the causal variable when this is not known perfectly <span class="italic">a priori</span>.</span>
        </div>
        <div>
          
          <span id="sect1460"/><span class="c_heading_indent">5.2.2 Experimental design. </span>
          <span>Our discussion has focused primarily on the case where we are interested in information gain about the parameter <span class="italic">θ</span> to drive knowledge acquisition in the experimental design loop. As we discussed in the previous section, it is possible to incorporate any random variable <span class="italic">V</span> (<a title="" href="#eqn31">eqn (31)</a>) that we can learn to model and sample. An interesting case is one where the random variable <span class="italic">V</span> is an extremum, <span class="italic">e.g.</span>, the top molecular candidates, for some task, as in <a title="" href="#eqn9">eqn (9)</a>. Furthermore, in many practical experimental settings, we have access to measurements of varying fidelities as the outcome of our experiments (<span class="italic">e.g.</span>, computer simulations with varying accuracy-computational cost trade-offs). Such a multi-fidelity setting is discussed above (Section. 3.4) but needs to be incorporated within the GFlowNet framework. Another important practical scenario also introduced in the same section is the existence of multiple objectives, with early work to incorporate that in the GFlowNet framework by Jain <span class="italic">et al</span>.<a title="Select to navigate to references" href="#cit113"><sup><span class="sup_ref">113</span></sup></a></span>
          <p class="otherpara">Finally, as introduced in Section 3.5 these experimental design tools could be integrated within the causal discovery framework, by focusing the knowledge acquisition on the causal graph itself, an object of great value to scientists from an interpretability point of view. This could be achieved by using the graph itself as the target variable <span class="italic">V</span> (or a part of it), to drive the experimental design to accelerate the discovery of the causal structure.</p>
        </div>
      
    
    
      <h2 id="sect1475"><span class="a_heading">Data availability</span></h2>
      <span>No new data are provided in this article.</span>
    
    
      <h2 id="sect1478"><span class="a_heading">Conflicts of interest</span></h2>
      <span>Yoshua Bengio is an advisor to Recursion and Dreamfold. Jason Hartford's postdoctoral position was partly funded by Recursion.</span>
    
  
    <h2 id="sect1482"><span class="a_heading">Acknowledgements</span></h2>
      <span>The authors thank DreamFold and Maksym Korablyov for important help, suggestions and feedback, as well as acknowledge funding from CIFAR, Recursion, IVADO, NSERC, and the Quebec government.</span>
    
    <span id="sect1484"><h2 id="sect1481"><span class="a_heading">References</span></h2></span><ol type="1">
      <li><span id="cit1">
          C. Adler, P. Wester, I. Bhatt, C. Huggel, G. E. Insarov, M. D. Morecroft, V. Muccione, and A. Prakash, <span class="italic">Cross-Chapter Paper 5: Mountains</span>, Cambridge University Press, Cambridge, UK and New York, USA,  2022, pp. 2273–2318, ISBN 9781009325844, <small> DOI:<a class="DOILink" href="https://doi.org/10.1017/9781009325844.022.2273" TARGET="_BLANK" title="DOI Link to 10.1017/9781009325844.022.2273">10.1017/9781009325844.022.2273</a></small>.</span></li>
      <li><span id="cit2">T. A. Ban, The role of serendipity in drug discovery, <span class="italic">Dialogues Clin. Neurosci.</span>, 2022, <span class="bold">8</span>(3), 335–344 <a target="_blank" class="DOILink" href="https://doi.org/10.31887/DCNS.2006.8.3/tban" title="DOI Link to resource 10.31887/DCNS.2006.8.3/tban">CrossRef</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=17117615%5Buid%5D" title="PubMed Link to resource 17117615">PubMed</a>.</span></li>
      <li><span id="cit3">R. S. Bohacek, C. McMartin and W. C. Guida, The art and practice of structure-based drug design: A molecular modeling perspective, <span class="italic">Med. Res. Rev.</span>, 1996, <span class="bold">16</span>(1), 3–50, <small> DOI:<a class="DOILink" href="https://doi.org/10.1002/(SICI)1098-1128(199601)16:1&lt;3::AID-MED1&gt;3.0.CO;2-6" TARGET="_BLANK" title="DOI Link to 10.1002/(SICI)1098-1128(199601)16:1&lt;3::AID-MED1&gt;3.0.CO;2-6">10.1002/(SICI)1098-1128(199601)16:1&lt;3::AID-MED1&gt;3.0.CO;2-6</a></small> , https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291098-1128%28199601%2916%3A1%3C3%3A%3AAID-MED1%3E3.0.CO%3B2-6.</span></li>
      <li><span id="cit4">B. P. MacLeod, F. G. L. Parlane, T. D Morrissey, F. Häse, L. M. Roch, K. E. Dettelbach, R. Moreira, L. P. E. Yunker, M. B. Rooney and J. R. Deeth, 
            <span class="italic">et al.</span>, Self-driving laboratory for accelerated discovery of thin-film materials, <span class="italic">Sci. Adv.</span>, 2020, <span class="bold">6</span>(20), eaaz8867 <a target="_blank" class="DOILink" href="https://doi.org/10.1126/sciadv.aaz8867" title="DOI Link to resource 10.1126/sciadv.aaz8867">CrossRef</a> <a target="_blank" class="COILink" href="/en/content/coiresolver?coi=1%3ACAS%3A528%3ADC%252BB3cXitFGhsL3J" title="Link to resource in CAS">CAS</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=32426501%5Buid%5D" title="PubMed Link to resource 32426501">PubMed</a>.</span></li>
      <li><span id="cit5">
          J. G. H. Anthony, T. Stewart, K. M. Tolle, <span class="italic">et al.</span>, <span class="italic">The fourth paradigm: data-intensive scientific discovery</span>, Microsoft research Redmond, WA,  2009, vol. 1 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=The%20fourth%20paradigm:%20data-intensive%20scientific%20discovery%5BJour%5D%20AND%20vol. 1%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202009%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit6">A. Agrawal and A. Choudhary, Perspective: Materials informatics and big data: Realization of the “fourth paradigm” of science in materials science, <span class="italic">Apl Materials</span>, 2016, <span class="bold">4</span>(5), 053208 <a target="_blank" class="DOILink" href="https://doi.org/10.1063/1.4946894" title="DOI Link to resource 10.1063/1.4946894">CrossRef</a>.</span></li>
      <li><span id="cit7">
          H. Stärk, D. Beaini, G. Corso, P. Tossou, C. Dallago, S. Günnemann, and L. Pietro, 3d infomax improves gnns for molecular property prediction, in <span class="italic">International Conference on Machine Learning</span>, PMLR,  2022, pp. 20479–20502 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit8">E. G. Ryan, C. C. Drovandi, J. M. McGree and A. N. Pettitt, A review of modern computational algorithms for bayesian optimal design, <span class="italic">Int. Stat. Rev.</span>, 2016, <span class="bold">84</span>(1), 128–154 <a target="_blank" class="DOILink" href="https://doi.org/10.1111/insr.12107" title="DOI Link to resource 10.1111/insr.12107">CrossRef</a>.</span></li>
      <li><span id="cit9">
          C. Angermueller, D. Dohan, D. Belanger, R. Deshpande, K. Murphy, and L. Colwell, Model-based reinforcement learning for biological sequence design, in <span class="italic">International conference on learning representations</span>,  2019 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20conference%20on%20learning%20representations%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202019%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit10">
          S. Kim, P. Y. Lu, C. Loh, J. Smith, J. Snoek, and M. Soljacic, <span class="italic">Deep learning for bayesian optimization of scientific problems with high-dimensional structure</span>, Transactions of Machine Learning Research,  2022 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Deep%20learning%20for%20bayesian%20optimization%20of%20scientific%20problems%20with%20high-dimensional%20structure%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit11">
          E. Bengio, M. Jain, M. Korablyov, D. Precup, and Y. Bengio, Flow network based generative models for non-iterative diverse candidate generation, in <span class="italic">Advances in Neural Information Processing Systems</span>, ed. A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan,  2021, https://openreview.net/forum?id=Arn2E4IRjEB <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Advances%20in%20Neural%20Information%20Processing%20Systems%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202021%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit12">
          Y. Bengio, T. Deleu, E. J. Hu, S. Lahlou, M. Tiwari, and E. Bengio, <span class="italic">Gflownet foundations</span>,  2021 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Gflownet%20foundations%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202021%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit13">D. Silver, A. Huang, C. J. Maddison, A. Guez, S. Laurent, G. V. D. Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam and M. Lanctot, 
            <span class="italic">et al.</span>, Mastering the game of go with deep neural networks and tree search, <span class="italic">Nature</span>, 2016, <span class="bold">529</span>(7587), 484–489 <a target="_blank" class="DOILink" href="https://doi.org/10.1038/nature16961" title="DOI Link to resource 10.1038/nature16961">CrossRef</a> <a target="_blank" class="COILink" href="/en/content/coiresolver?coi=1%3ACAS%3A528%3ADC%252BC28Xhs12is7w%253D" title="Link to resource in CAS">CAS</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=26819042%5Buid%5D" title="PubMed Link to resource 26819042">PubMed</a>.</span></li>
      <li><span id="cit14">J. Jumper, R. Evans, P. Alexander, T. Green, M. Figurnov, O. Ronneberger, K. Tunyasuvunakool, R. Bates, Ž. Augustin and P. Anna, 
            <span class="italic">et al.</span>, Highly accurate protein structure prediction with alphafold, <span class="italic">Nature</span>, 2021, <span class="bold">596</span>(7873), 583–589 <a target="_blank" class="DOILink" href="https://doi.org/10.1038/s41586-021-03819-2" title="DOI Link to resource 10.1038/s41586-021-03819-2">CrossRef</a> <a target="_blank" class="COILink" href="/en/content/coiresolver?coi=1%3ACAS%3A528%3ADC%252BB3MXhvVaktrrL" title="Link to resource in CAS">CAS</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=34265844%5Buid%5D" title="PubMed Link to resource 34265844">PubMed</a>.</span></li>
      <li><span id="cit15">A. Der Kiureghian and O. Ditlevsen, Aleatory or epistemic? does it matter?, <span class="italic">Structural Safety</span>, 2009, <span class="bold">31</span>(2), 105–112, <small> DOI:<a class="DOILink" href="https://doi.org/10.1016/j.strusafe.2008.06.020" TARGET="_BLANK" title="DOI Link to 10.1016/j.strusafe.2008.06.020">10.1016/j.strusafe.2008.06.020</a></small> , ISSN 0167-4730..</span></li>
      <li><span id="cit16">S. J. Honrao, X. Yang, B. Radhakrishnan, S. Kuwata, H. Komatsu, A. Ohma, M. Sierhuis and J. W. Lawson, Discovery of novel li sse and anode coatings using interpretable machine learning and high-throughput multi-property screening, <span class="italic">Sci. Rep.</span>, 2021, <span class="bold">11</span>(1), 1–14 <a target="_blank" class="DOILink" href="https://doi.org/10.1038/s41598-020-79139-8" title="DOI Link to resource 10.1038/s41598-020-79139-8">CrossRef</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=33414495%5Buid%5D" title="PubMed Link to resource 33414495">PubMed</a>.</span></li>
      <li><span id="cit17">B. Schölkopf, F. Locatello, S. Bauer, N. R. Ke, N. Kalchbrenner, A. Goyal and Y. Bengio, Toward causal representation learning, <span class="italic">Proc. IEEE</span>, 2021, <span class="bold">109</span>(5), 612–634 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Proc.%20IEEE%5BJour%5D%20AND%20109%5Bvolume%5D%20AND%20612%5Bpage%5D%20and%202021%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit18">C. Andrieu, N. De Freitas, A. Doucet and M. I. Jordan, An introduction to mcmc for machine learning, <span class="italic">Mach. Learn.</span>, 2003, <span class="bold">50</span>(1), 5–43 <a target="_blank" class="DOILink" href="https://doi.org/10.1023/A:1020281327116" title="DOI Link to resource 10.1023/A:1020281327116">CrossRef</a>.</span></li>
      <li><span id="cit19">G. M. Torrie and J. P. Valleau, Nonphysical sampling distributions in monte carlo free-energy estimation: Umbrella sampling, <span class="italic">J. Comput. Phys.</span>, 1977, <span class="bold">23</span>(2), 187–199 <a target="_blank" class="DOILink" href="https://doi.org/10.1016/0021-9991(77)90121-8" title="DOI Link to resource 10.1016/0021-9991(77)90121-8">CrossRef</a>.</span></li>
      <li><span id="cit20">D. J. Earl and M. W. Deem, Parallel tempering: Theory, applications, and new perspectives, <span class="italic">Phys. Chem. Chem. Phys.</span>, 2005, <span class="bold">7</span>(23), 3910–3916 <a target="_blank" class="RSCLink" href="http://xlink.rsc.org/?doi=B509983H&amp;newsite=1" title="Link to RSC resource DOI:10.1039/B509983H">RSC</a>.</span></li>
      <li><span id="cit21">A. Beskos, F. J. Pinski, J. Marıa Sanz-Serna and A. M. Stuart, Hybrid monte carlo on hilbert spaces, <span class="italic">Stoch. Process. Their Appl.</span>, 2011, <span class="bold">121</span>(10), 2201–2230 <a target="_blank" class="DOILink" href="https://doi.org/10.1016/j.spa.2011.06.003" title="DOI Link to resource 10.1016/j.spa.2011.06.003">CrossRef</a>.</span></li>
      <li><span id="cit22">D. M. Blei, A. Kucukelbir and J. D. McAuliffe, Variational inference: A review for statisticians, <span class="italic">J. Am. Stat. Assoc.</span>, 2017, <span class="bold">112</span>(518), 859–877 <a target="_blank" class="DOILink" href="https://doi.org/10.1080/01621459.2017.1285773" title="DOI Link to resource 10.1080/01621459.2017.1285773">CrossRef</a> <a target="_blank" class="COILink" href="/en/content/coiresolver?coi=1%3ACAS%3A528%3ADC%252BC2sXhtFKrtrzM" title="Link to resource in CAS">CAS</a>.</span></li>
      <li><span id="cit23">
          M. Tom, <span class="italic">et al.</span>, <span class="italic">Divergence measures and message passing</span>, Technical report, Microsoft Research,  2005 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Divergence%20measures%20and%20message%20passing%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202005%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit24">
          R. E. Turner and M. Sahani, <span class="italic">Two problems with variational expectation maximisation for time series models</span>, Cambridge University Press,  2011, pp. 104–124, <small> DOI:<a class="DOILink" href="https://doi.org/10.1017/CBO9780511984679.006" TARGET="_BLANK" title="DOI Link to 10.1017/CBO9780511984679.006">10.1017/CBO9780511984679.006</a></small>.</span></li>
      <li><span id="cit25">
          N. Malkin, S. Lahlou, T. Deleu, X. Ji, E. Hu, K. Everett, D. Zhang, and Y. Bengio. Gflownets and variational inference, in <span class="italic">International Conference on Learning Representations</span>, ICLR,  2023 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Learning%20Representations%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202023%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit26">
          V. V. Fedorov, <span class="italic">Theory of optimal experiments</span>, Elsevier,  1972 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Theory%20of%20optimal%20experiments%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%201972%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit27">
          A. C. Atkinson and A. N. Donev, <span class="italic">Optimum experimental designs</span>, Clarendon Press,  1992, vol. 5 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Optimum%20experimental%20designs%5BJour%5D%20AND%20vol. 5%5Bvolume%5D%20AND%20%5Bpage%5D%20and%201992%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit28">S. Burr, Active learning, <span class="italic">Synth. Lect. Artif. Intell. Mach. Learn.</span>, 2012, <span class="bold">6</span>(1), 1–114 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Synth.%20Lect.%20Artif.%20Intell.%20Mach.%20Learn.%5BJour%5D%20AND%206%5Bvolume%5D%20AND%201%5Bpage%5D%20and%202012%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit29">
          K. Chaloner and I. Verdinelli, <span class="italic">Bayesian experimental design: A review</span>, Statistical Science,  1995, pp. 273–304 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Bayesian%20experimental%20design:%20A%20review%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%201995%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit30">D. V. Lindley, On a measure of the information provided by an experiment, <span class="italic">Ann. Math. Stat.</span>, 1956, <span class="bold">27</span>(4), 986–1005 <a target="_blank" class="DOILink" href="https://doi.org/10.1214/aoms/1177728069" title="DOI Link to resource 10.1214/aoms/1177728069">CrossRef</a>.</span></li>
      <li><span id="cit31">D. R. C. Jay I Myung and M. A. Pitt, A tutorial on adaptive design optimization, <span class="italic">J. Math. Psychol.</span>, 2013, <span class="bold">57</span>(3–4), 53–67 <a target="_blank" class="DOILink" href="https://doi.org/10.1016/j.jmp.2013.05.005" title="DOI Link to resource 10.1016/j.jmp.2013.05.005">CrossRef</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=23997275%5Buid%5D" title="PubMed Link to resource 23997275">PubMed</a>.</span></li>
      <li><span id="cit32">
          T. Rainforth, R. Cornish, H. Yang, A. Warrington, and F. Wood, On nesting monte carlo estimators, in <span class="italic">International Conference on Machine Learning</span>, PMLR,  2018, pp. 4267–4276 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202018%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit33">A. Foster, J. Martin, E. Bingham, H. Paul, Y. W. Teh, T. Rainforth and N. Goodman, Variational bayesian optimal experimental design, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2019, <span class="bold">32</span> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%2032%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202019%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a> , https://papers.nips.cc/paper_files/paper/2019/file/d55cbf210f175f4a37916eafe6c04f0d-Bibtex.bib.</span></li>
      <li><span id="cit34">
          S. Kleinegesse and M. U. Gutmann, Efficient bayesian experimental design for implicit models, in <span class="italic">The 22nd International Conference on Artificial Intelligence and Statistics</span>, PMLR,  2019, pp. 476–485 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=The%2022nd%20International%20Conference%20on%20Artificial%20Intelligence%20and%20Statistics%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202019%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit35">
          S. Kleinegesse and M. U. Gutmann, Bayesian experimental design for implicit models by mutual information neural estimation, in <span class="italic">International Conference on Machine Learning</span>, PMLR,  2020, pp. 5316–5326 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202020%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit36">F. Heinrich, P. A. Kienzle, D. P. Hoogerheide and M. Lösche, Information gain from isotopic contrast variation in neutron reflectometry on protein–membrane complex structures, <span class="italic">J. Appl. Crystallogr.</span>, 2020, <span class="bold">53</span>(3), 800–810 <a target="_blank" class="DOILink" href="https://doi.org/10.1107/S1600576720005634" title="DOI Link to resource 10.1107/S1600576720005634">CrossRef</a> <a target="_blank" class="COILink" href="/en/content/coiresolver?coi=1%3ACAS%3A528%3ADC%252BB3cXhtV2rtr%252FI" title="Link to resource in CAS">CAS</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=32684895%5Buid%5D" title="PubMed Link to resource 32684895">PubMed</a>.</span></li>
      <li><span id="cit37">O. Antony and J. McGree, Bayesian design of experiments for intractable likelihood models using coupled auxiliary models and multivariate emulation, <span class="italic">Bayesian Anal.</span>, 2020, <span class="bold">15</span>(1), 103–131 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Bayesian%20Anal.%5BJour%5D%20AND%2015%5Bvolume%5D%20AND%20103%5Bpage%5D%20and%202020%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit38">C. C. Drovandi, J. M. McGree and A. N. Pettitt, Sequential monte carlo for bayesian sequentially designed experiments for discrete data, <span class="italic">Comput. Stat. Data Anal.</span>, 2013, <span class="bold">57</span>(1), 320–335 <a target="_blank" class="DOILink" href="https://doi.org/10.1016/j.csda.2012.05.014" title="DOI Link to resource 10.1016/j.csda.2012.05.014">CrossRef</a>.</span></li>
      <li><span id="cit39">
          A. Foster, J. Martin, M. O'Meara, Y. W. Teh, and T. Rainforth. A unified stochastic gradient approach to designing bayesian-optimal experiments, in <span class="italic">International Conference on Artificial Intelligence and Statistics</span>, PMLR,  2020, pp. 2959–2969 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Artificial%20Intelligence%20and%20Statistics%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202020%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit40">
          A. Foster, D. R. Ivanova, I. Malik, and T. Rainforth. Deep adaptive design: Amortizing sequential bayesian experimental design, in <span class="italic">International Conference on Machine Learning</span>, PMLR,  2021, pp. 3384–3395 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202021%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit41">D. R. Ivanova, A. Foster, S. Kleinegesse, M. U. Gutmann and T. Rainforth, Implicit deep adaptive design: policy-based experimental design without likelihoods, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2021, <span class="bold">34</span>, 25785–25798 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%2034%5Bvolume%5D%20AND%2025785%5Bpage%5D%20and%202021%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit42">
          T. Blau, E. V Bonilla, I. Chades, and A. Dezfouli. Optimizing sequential experimental design with deep reinforcement learning, in <span class="italic">International Conference on Machine Learning</span>, PMLR,  2022, pp. 2107–2128 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit43">
          R. Horst, P. M. Pardalos, and N. V. Thoai, <span class="italic">Introduction to global optimization</span>, Springer Science &amp; Business Media,  2000 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Introduction%20to%20global%20optimization%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202000%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit44">
          J. Mockus, V. Tiesis, and A. Zilinskas, The application of bayesian methods for seeking the extremum, <span class="italic">Towards global optimization</span>, vol. 2, 2,  1978, pp. 117–129 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Towards%20global%20optimization%5BJour%5D%20AND%20vol. 2%5Bvolume%5D%20AND%20%5Bpage%5D%20and%201978%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit45">D. R. Jones, M. Schonlau and W. J. Welch, Efficient global optimization of expensive black-box functions, <span class="italic">J. Glob. Optim.</span>, 1998, <span class="bold">13</span>(4), 455–492 <a target="_blank" class="DOILink" href="https://doi.org/10.1023/A:1008306431147" title="DOI Link to resource 10.1023/A:1008306431147">CrossRef</a>.</span></li>
      <li><span id="cit46">
          R. Garnett, <span class="italic">Bayesian Optimization</span>, Cambridge University Press,  2022 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Bayesian%20Optimization%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit47">
          J. Gonzalez, L. Joseph, D. C. James, and N. D. Lawrence, Bayesian optimization for synthetic gene design, <span class="italic">arXiv</span>,  2015, preprint, arXiv:1505.01627, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/arXiv.1505.01627" TARGET="_BLANK" title="DOI Link to 10.48550/arXiv.1505.01627">10.48550/arXiv.1505.01627</a></small>.</span></li>
      <li><span id="cit48">R.-R. Griffiths and J. M. Hernández-Lobato, Constrained bayesian optimization for automatic chemical design using variational autoencoders, <span class="italic">Chem. Sci.</span>, 2020, <span class="bold">11</span>(2), 577–586 <a target="_blank" class="RSCLink" href="http://xlink.rsc.org/?doi=C9SC04026A&amp;newsite=1" title="Link to RSC resource DOI:10.1039/C9SC04026A">RSC</a>.</span></li>
      <li><span id="cit49">
          H. B. Moss and R.-R. Griffiths, Gaussian process molecule property prediction with flowmo, <span class="italic">arXiv</span>,  2020, preprint, arXiv:2010.01118, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/arXiv.2010.01118" TARGET="_BLANK" title="DOI Link to 10.48550/arXiv.2010.01118">10.48550/arXiv.2010.01118</a></small>.</span></li>
      <li><span id="cit50">B. J. Shields, J. Stevens, J. Li, M. Parasram, F. Damani, J. I. Martinez Alvarado, M. J. Jacob, R. P. Adams and A. G. Doyle, Bayesian reaction optimization as a tool for chemical synthesis, <span class="italic">Nature</span>, 2021, <span class="bold">590</span>(7844), 89–96 <a target="_blank" class="DOILink" href="https://doi.org/10.1038/s41586-021-03213-y" title="DOI Link to resource 10.1038/s41586-021-03213-y">CrossRef</a> <a target="_blank" class="COILink" href="/en/content/coiresolver?coi=1%3ACAS%3A528%3ADC%252BB3MXjt1SjtLg%253D" title="Link to resource in CAS">CAS</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=33536653%5Buid%5D" title="PubMed Link to resource 33536653">PubMed</a>.</span></li>
      <li><span id="cit51">
          C. E. Rasmussen and C. K. I. Williams, <span class="italic">Gaussian Processes for Machine Learning. Adaptive Computation and Machine Learning series</span>, MIT Press,  2005, ISBN 9780262182539, https://books.google.ca/books?id=GhoSngEACAAJ <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Gaussian%20Processes%20for%20Machine%20Learning.%20Adaptive%20Computation%20and%20Machine%20Learning%20series%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202005%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit52">M. Balandat, B. Karrer, D. Jiang, S. Daulton, B. Letham, A. G. Wilson and E. Bakshy, Botorch: a framework for efficient monte-carlo bayesian optimization, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2020, <span class="bold">33</span>, 21524–21538 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%2033%5Bvolume%5D%20AND%2021524%5Bpage%5D%20and%202020%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit53">J. B. Mockus and L. J. Mockus, Bayesian approach to global optimization and application to multiobjective and constrained problems, <span class="italic">J. Optim. Theory Appl.</span>, 1991, <span class="bold">70</span>(1), 157–172 <a target="_blank" class="DOILink" href="https://doi.org/10.1007/BF00940509" title="DOI Link to resource 10.1007/BF00940509">CrossRef</a>.</span></li>
      <li><span id="cit54">
          N. Srinivas, A. Krause, K. Sham, and M. Seeger, Gaussian process optimization in the bandit setting: no regret and experimental design, in <span class="italic">Proceedings of the 27th International Conference on International Conference on Machine Learning</span>,  2010, pp. 1015–1022 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Proceedings%20of%20the%2027th%20International%20Conference%20on%20International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202010%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit55">W. R. Thompson, On the likelihood that one unknown probability exceeds another in view of the evidence of two samples, <span class="italic">Biometrika</span>, 1933, <span class="bold">25</span>(3–4), 285–294 <a target="_blank" class="DOILink" href="https://doi.org/10.1093/biomet/25.3-4.285" title="DOI Link to resource 10.1093/biomet/25.3-4.285">CrossRef</a>.</span></li>
      <li><span id="cit56">S. Vakili, H. Moss, A. Artemev, D. Vincent and V. Picheny, Scalable thompson sampling using sparse Gaussian process models, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2021, <span class="bold">34</span>, 5631–5643 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%2034%5Bvolume%5D%20AND%205631%5Bpage%5D%20and%202021%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit57">P. Hennig and C. J. Schuler, Entropy search for information-efficient global optimization, <span class="italic">J. Mach. Learn. Res.</span>, 2012, <span class="bold">13</span>(6), 1809–1837 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=J.%20Mach.%20Learn.%20Res.%5BJour%5D%20AND%2013%5Bvolume%5D%20AND%201809%5Bpage%5D%20and%202012%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit58">J. M. Hernández-Lobato, M. W. Hoffman and Z. Ghahramani, Predictive entropy search for efficient global optimization of black-box functions, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2014, <span class="bold">27</span> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%2027%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202014%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a> , https://papers.nips.cc/paper_files/paper/2014/file/069d3bb002acd8d7dd095917f9efe4cb-Bibtex.bib.</span></li>
      <li><span id="cit59">
          M. W. Hoffman and Z. Ghahramani, Output-space predictive entropy search for flexible global optimization, in <span class="italic">NIPS workshop on Bayesian Optimization</span>,  2015, pp. 1–5 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=NIPS%20workshop%20on%20Bayesian%20Optimization%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202015%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit60">
          Z. Wang and S. Jegelka, Max-value entropy search for efficient bayesian optimization, in <span class="italic">International Conference on Machine Learning</span>, PMLR,  2017, pp. 3627–3635 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202017%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit61">H. B. Moss, D. S. Leslie, J. Gonzalez and R. Paul, Gibbon: General-purpose information-based bayesian optimisation, <span class="italic">J. Mach. Learn. Res.</span>, 2021, <span class="bold">22</span>(235), 1–49 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=J.%20Mach.%20Learn.%20Res.%5BJour%5D%20AND%2022%5Bvolume%5D%20AND%201%5Bpage%5D%20and%202021%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit62">
          J. González, Z. Dai, P. Hennig, and N. Lawrence, Batch bayesian optimization <span class="italic">via</span> local penalization, in <span class="italic">Artificial intelligence and statistics</span>, PMLR,  2016, pp. 648–657 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Artificial%20intelligence%20and%20statistics%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202016%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit63">
          K. Kandasamy, A. Krishnamurthy, J. Schneider, and B. Póczos, Parallelised bayesian optimisation <span class="italic">via</span> thompson sampling, in <span class="italic">International Conference on Artificial Intelligence and Statistics</span>, PMLR,  2018, pp. 133–142 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Artificial%20Intelligence%20and%20Statistics%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202018%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit64">
          V. Picheny, D. Ginsbourger, and Y. Richet. <span class="italic">Noisy expected improvement and on-line computation time allocation for the optimization of simulators with tunable fidelity</span>,  2010 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Noisy%20expected%20improvement%20and%20on-line%20computation%20time%20allocation%20for%20the%20optimization%20of%20simulators%20with%20tunable%20fidelity%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202010%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit65">
          K. Kandasamy, G. Dasarathy, J. Schneider, and B. Póczos, Multi-fidelity bayesian optimisation with continuous approximations, in <span class="italic">International Conference on Machine Learning</span>, PMLR,  2017, pp. 1799–1808 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202017%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit66">
          S. Takeno, H. Fukuoka, Y. Tsukada, T. Koyama, M. Shiga, I. Takeuchi, and M. Karasuyama, Multi-fidelity bayesian optimization with max-value entropy search and its parallelization, in <span class="italic">International Conference on Machine Learning</span>, PMLR,  2020, pp. 9334–9345 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202020%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit67">S. Belakaria, A. Deshwal and J. Rao Doppa, Max-value entropy search for multi-objective bayesian optimization, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2019, <span class="bold">32</span> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%2032%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202019%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a> , https://proceedings.neurips.cc/paper_files/paper/2019/file/82edc5c9e21035674d481640448049f3-Bibtex.bib.</span></li>
      <li><span id="cit68">
          S. Daulton, D. Eriksson, M. Balandat, and E. Bakshy, Multi-objective bayesian optimization over high-dimensional search spaces, in <span class="italic">Uncertainty in Artificial Intelligence</span>, PMLR,  2022, pp. 507–517 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Uncertainty%20in%20Artificial%20Intelligence%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit69">M. A. Ziatdinov, Y. Liu, A. N. Morozovska, E. A. Eliseev, X. Zhang, I. Takeuchi and S. V. Kalinin, Hypothesis learning in automated experiment: application to combinatorial materials libraries, <span class="italic">Adv. Mater.</span>, 2022, <span class="bold">34</span>(20), 2201345 <a target="_blank" class="DOILink" href="https://doi.org/10.1002/adma.202201345" title="DOI Link to resource 10.1002/adma.202201345">CrossRef</a> <a target="_blank" class="COILink" href="/en/content/coiresolver?coi=1%3ACAS%3A528%3ADC%252BB38XpvFKktro%253D" title="Link to resource in CAS">CAS</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=35279893%5Buid%5D" title="PubMed Link to resource 35279893">PubMed</a>.</span></li>
      <li><span id="cit70">M. Austin, M. Frontzek, A. T. Savici, M. Doucet, E. E. Rodriguez, K. Meuse, J. Opsahl-Ong, D. Samarov, I. Takeuchi and W. Ratcliff, 
            <span class="italic">et al.</span>, On-the-fly autonomous control of neutron diffraction <span class="italic">via</span> physics-informed bayesian active learning, <span class="italic">Appl. Phys. Rev.</span>, 2022, <span class="bold">9</span>(2), 021408 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Appl.%20Phys.%20Rev.%5BJour%5D%20AND%209%5Bvolume%5D%20AND%20021408%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit71">H. Moss, D. Leslie, D. Beck, J. Gonzalez and R. Paul, Boss: Bayesian optimization over string spaces, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2020, <span class="bold">33</span>, 15476–15486 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%2033%5Bvolume%5D%20AND%2015476%5Bpage%5D%20and%202020%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit72">
          S. Kevin, Y. Rubanova, D. Dohan, and K. Murphy, Amortized bayesian optimization over discrete spaces, in <span class="italic">Conference on Uncertainty in Artificial Intelligence</span>, PMLR,  2020, pp. 769–778 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Conference%20on%20Uncertainty%20in%20Artificial%20Intelligence%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202020%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit73">
          J. Pearl, <span class="italic">Probabilistic Reasoning in Intelligent Systems</span>, Morgan Kaufmann,  1988 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Probabilistic%20Reasoning%20in%20Intelligent%20Systems%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%201988%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit74">
          P. Spirtes, C. N. Glymour, R. Scheines, and D. Heckerman, <span class="italic">Causation, Prediction, and Search</span>, MIT press,  2000 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Causation,%20Prediction,%20and%20Search%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202000%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit75">D. Maxwell Chickering, Optimal Structure Identification With Greedy Search, <span class="italic">J. Mach. Learn. Res.</span>, 2002, 507–554 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=J.%20Mach.%20Learn.%20Res.%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20507%5Bpage%5D%20and%202002%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit76">
          X. Zheng, B. Aragam, P. Ravikumar, and E. P. Xing, DAGs with NO TEARS: Continuous Optimization for Structure Learning, in <span class="italic">Advances in Neural Information Processing Systems</span>,  2018 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Advances%20in%20Neural%20Information%20Processing%20Systems%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202018%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit77">
          N. R. Ke, O. Bilaniuk, A. Goyal, S. Bauer, H. Larochelle, B. Schölkopf, M. C. Mozer, C. Pal, and Y. Bengio, Learning neural causal models from unknown interventions, <span class="italic">arXiv</span>,  2019, arXiv:1910.01075, preprint, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/arXiv.1910.01075" TARGET="_BLANK" title="DOI Link to 10.48550/arXiv.1910.01075">10.48550/arXiv.1910.01075</a></small>.</span></li>
      <li><span id="cit78">P. Brouillard, S. Lachapelle, A. Lacoste, S. Lacoste-Julien and D. Alexandre, Differentiable Causal Discovery from Interventional Data, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2020, 21865–21877 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%20%5Bvolume%5D%20AND%2021865%5Bpage%5D%20and%202020%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit79">D. Madigan, J. York and D. Allard, Bayesian Graphical Models for Discrete Data, <span class="italic">Int. Stat. Rev.</span>, 1995, <span class="bold">63</span>(2), 215–232 <a target="_blank" class="DOILink" href="https://doi.org/10.2307/1403615" title="DOI Link to resource 10.2307/1403615">CrossRef</a>.</span></li>
      <li><span id="cit80">N. Friedman and D. Koller, Being Bayesian About Network Structure. A Bayesian Approach to Structure Discovery in Bayesian Networks, <span class="italic">Mach. Learn.</span>, 2003, <span class="bold">50</span>, 95–125 <a target="_blank" class="DOILink" href="https://doi.org/10.1023/A:1020249912095" title="DOI Link to resource 10.1023/A:1020249912095">CrossRef</a>.</span></li>
      <li><span id="cit81">P. Giudici and R. Castelo, Improving Markov chain Monte Carlo model search for data mining, <span class="italic">Mach. Learn.</span>, 2003, <span class="bold">50</span>, 127–158 <a target="_blank" class="DOILink" href="https://doi.org/10.1023/A:1020202028934" title="DOI Link to resource 10.1023/A:1020202028934">CrossRef</a>.</span></li>
      <li><span id="cit82">T. Niinimäki, P. Parviainen and M. Koivisto, Structure Discovery in Bayesian Networks by Sampling Partial Orders, <span class="italic">J. Mach. Learn. Res.</span>, 2016, 1–47 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=J.%20Mach.%20Learn.%20Res.%5BJour%5D%20AND%20%5Bvolume%5D%20AND%201%5Bpage%5D%20and%202016%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit83">J. Viinikka, A. Hyttinen, J. Pensar and M. Koivisto, Towards Scalable Bayesian Learning of Causal DAGs, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2020, 6584–6594 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%20%5Bvolume%5D%20AND%206584%5Bpage%5D%20and%202020%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit84">
          N. Friedman, M. Goldszmidt, and W. Abraham, Data Analysis with Bayesian Networks: A Bootstrap Approach, <span class="italic">Proceedings of the Fifteenth conference on Uncertainty in Artificial Intelligence</span>,  1999 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Proceedings%20of%20the%20Fifteenth%20conference%20on%20Uncertainty%20in%20Artificial%20Intelligence%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%201999%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit85">
          R. Agrawal, C. Squires, K. Yang, K. Shanmugam, and C. Uhler, Abcd-strategy: Budgeted experimental design for targeted causal structure discovery, in <span class="italic">The 22nd International Conference on Artificial Intelligence and Statistics</span>, PMLR,  2019 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=The%2022nd%20International%20Conference%20on%20Artificial%20Intelligence%20and%20Statistics%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202019%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit86">
          Y. Annadani, J. Rothfuss, A. Lacoste, N. Scherrer, A. Goyal, Y. Bengio, and S. Bauer, Variational Causal Networks: Approximate Bayesian Inference over Causal Structures, <span class="italic">arXiv</span>,  2021, preprint, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/arXiv.2106.07635" TARGET="_BLANK" title="DOI Link to 10.48550/arXiv.2106.07635">10.48550/arXiv.2106.07635</a></small>.</span></li>
      <li><span id="cit87">C. Cundy, A. Grover and S. Ermon, BCD Nets: Scalable Variational Approaches for Bayesian Causal Discovery, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2021, 7095–7110 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%20%5Bvolume%5D%20AND%207095%5Bpage%5D%20and%202021%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit88">
          B. Wang, M. R. Wicker, and M. Kwiatkowska, Tractable Uncertainty for Structure Learning, <span class="italic">International Conference on Machine Learning</span>,  2022 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit89">L. Lorch, J. Rothfuss, B. Schölkopf and A. Krause, DiBS: Differentiable Bayesian Structure Learning, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2021, 24111–24123 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%20%5Bvolume%5D%20AND%2024111%5Bpage%5D%20and%202021%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit90">L. Lorch, S. Scott, J. Rothfuss, A. Krause and B. Schölkopf, Amortized Inference for Causal Structure Learning, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2022, 13104–13118 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%20%5Bvolume%5D%20AND%2013104%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit91">
          W. BUNTINE, Theory refinement on bayesian networks, in <span class="italic">Proc. 7th Conf. Uncertainty in Artificial Intelligence</span>,  1991, vol. 1991, pp. 52–60 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Proc.%207th%20Conf.%20Uncertainty%20in%20Artificial%20Intelligence%5BJour%5D%20AND%20vol. 1991%5Bvolume%5D%20AND%20%5Bpage%5D%20and%201991%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit92">
          S. Tong and D. Koller. Active learning for structure in Bayesian networks. <span class="italic">International Joint Conference on Artificial Intelligence</span>,  2001 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Joint%20Conference%20on%20Artificial%20Intelligence%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202001%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit93">
          K. Murphy. <span class="italic">Active Learning of Causal Bayes Net Structure</span>,  2001 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Active%20Learning%20of%20Causal%20Bayes%20Net%20Structure%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202001%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit94">
          N. Scherrer, O. Bilaniuk, Y. Annadani, A. Goyal, P. Schwab, B. Schölkopf, M. C. Mozer, Y. Bengio, S. Bauer, and N. R. Ke, Learning Neural Causal Models with Active Interventions, <span class="italic">arXiv</span>,  2021, arXiv:2109.02429, preprint, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/2109.02429" TARGET="_BLANK" title="DOI Link to 10.48550/2109.02429">10.48550/2109.02429</a></small>.</span></li>
      <li><span id="cit95">
          P. Tigas, Y. Annadani, A. Jesson, B. Schölkopf, Y. Gal, and S. Bauer, <span class="italic">Interventions, Where and How? Experimental Design for Causal Models at Scale</span>, Neural Information Processing Systems,  2022 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Interventions,%20Where%20and%20How?%20Experimental%20Design%20for%20Causal%20Models%20at%20Scale%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit96">
          C. Toth, L. Lorch, C. Knoll, A. Krause, F. Pernkopf, R. Peharz, and J. von Kügelgen, <span class="italic">Active Bayesian Causal Inference</span>, Neural Information Processing Systems,  2022 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Active%20Bayesian%20Causal%20Inference%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit97">
          C. M. Bishop, <span class="italic">et al.</span>, <span class="italic">Neural networks for pattern recognition</span>, Oxford university press,  1995 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Neural%20networks%20for%20pattern%20recognition%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%201995%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit98">
          N. Malkin, M. Jain, E. Bengio, C. Sun and Y. Bengio, Trajectory balance: Improved credit assignment in gflownets, <span class="italic">Advances in Neural Information Processing Systems</span>,  2022, pp. 5955–5967 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Advances%20in%20Neural%20Information%20Processing%20Systems%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit99">
          K. Madan, J. Rector-Brooks, M. Korablyov, E. Bengio, M. Jain, A. Nica, T. Bosc, Y. Bengio, and N. Malkin, Learning gflownets from partial episodes for improved convergence and stability, <span class="italic">arXiv</span>,  2022, arXiv:2209.12782, preprint, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/arXiv.2209.12782" TARGET="_BLANK" title="DOI Link to 10.48550/arXiv.2209.12782">10.48550/arXiv.2209.12782</a></small>.</span></li>
      <li><span id="cit100">
          Y. Xie, C. Shi, H. Zhou, Y. Yang, W. Zhang, Y. Yu, and L. Li, {MARS}: Markov molecular sampling for multi-objective drug discovery, in <span class="italic">International Conference on Learning Representations</span>,  2021, https://openreview.net/forum?id=kHSu4ebxFXY <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Learning%20Representations%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202021%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit101">
          M. Jain, E. Bengio, A. Hernandez-Garcia, J. Rector-Brooks, B. F. P. Dossou, C. A. Ekbote, J. Fu, T. Zhang, M. Kilgour, D. Zhang, <span class="italic">et al.</span>, Biological sequence design with gflownets, in <span class="italic">International Conference on Machine Learning</span>, PMLR,  2022, pp. 9786–9801 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit102">
          P. Diederik, Kingma and Max Welling. Auto-encoding variational Bayes, <span class="italic">International Conference on Learning Representations</span>, ICLR,  2014 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Learning%20Representations%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202014%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit103">
          D. Jimenez Rezende, S. Mohamed, and D. Wierstra, Stochastic backpropagation and approximate inference in deep generative models, <span class="italic">International Conference on Machine Learning (ICML)</span>,  2014 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%20(ICML)%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202014%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit104">
          I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. C Courville, and Y. Bengio, in <span class="italic">Generative adversarial nets</span>, NIPS,  2014 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Generative%20adversarial%20nets%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202014%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit105">
          S. Lahlou, T. Deleu, P. Lemos, D. Zhang, A. Volokhova, A. Hernández-García, L. N. Ezzine, Y. Bengio, and N. Malkin, <span class="italic">A theory of continuous generative flow networks</span>,  2023, https://arxiv.org/abs/2301.12594 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=A%20theory%20of%20continuous%20generative%20flow%20networks%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202023%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit106">
          L. Pan, N. Malkin, D. Zhang, and Y. Bengio, <span class="italic">Better training of gflownets with local credit and incomplete trajectories</span>,  2023, https://arxiv.org/abs/2302.01687 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Better%20training%20of%20gflownets%20with%20local%20credit%20and%20incomplete%20trajectories%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202023%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit107">
          S. Zhang, Y. Liu, and L. Xie, Molecular mechanics-driven graph neural network with multiplex graph for molecular structures, <span class="italic">arXiv</span>,  2020, arXiv:2011.07457, preprint, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/arXiv.2011.07457" TARGET="_BLANK" title="DOI Link to 10.48550/arXiv.2011.07457">10.48550/arXiv.2011.07457</a></small>.</span></li>
      <li><span id="cit108">N. Chiamvimonvat, C.-M. Ho, H.-J. Tsai and B. D. Hammock, The soluble epoxide hydrolase as a pharmaceutical target for hypertension, <span class="italic">J. Cardiovasc. Pharmacol.</span>, 2007, <span class="bold">50</span>(3), 225–237 <a target="_blank" class="DOILink" href="https://doi.org/10.1097/FJC.0b013e3181506445" title="DOI Link to resource 10.1097/FJC.0b013e3181506445">CrossRef</a> <a target="_blank" class="COILink" href="/en/content/coiresolver?coi=1%3ACAS%3A528%3ADC%252BD2sXhtVCktbjJ" title="Link to resource in CAS">CAS</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=17878749%5Buid%5D" title="PubMed Link to resource 17878749">PubMed</a>.</span></li>
      <li><span id="cit109">D. I. John and B. D. Hammock, Soluble epoxide hydrolase as a therapeutic target for cardiovascular diseases, <span class="italic">Nat. Rev. Drug Discovery</span>, 2009, <span class="bold">8</span>(10), 794–805 <a target="_blank" class="DOILink" href="https://doi.org/10.1038/nrd2875" title="DOI Link to resource 10.1038/nrd2875">CrossRef</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=19794443%5Buid%5D" title="PubMed Link to resource 19794443">PubMed</a>.</span></li>
      <li><span id="cit110">O. Trott and A. J. Olson, Autodock vina: improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading, <span class="italic">J. Comput. Chem.</span>, 2010, <span class="bold">31</span>(2), 455–461 <a target="_blank" class="COILink" href="/en/content/coiresolver?coi=1%3ACAS%3A528%3ADC%252BD1MXhsFGnur3O" title="Link to resource in CAS">CAS</a>.</span></li>
      <li><span id="cit111">J. J. Irwin and B. K. Shoichet, Zinc- a free database of commercially available compounds for virtual screening, <span class="italic">J. Chem. Inf. Model.</span>, 2005, <span class="bold">45</span>(1), 177–182 <a target="_blank" class="DOILink" href="https://doi.org/10.1021/ci049714+" title="DOI Link to resource 10.1021/ci049714+">CrossRef</a> <a target="_blank" class="COILink" href="/en/content/coiresolver?coi=1%3ACAS%3A528%3ADC%252BD2cXhtVOjt77J" title="Link to resource in CAS">CAS</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=15667143%5Buid%5D" title="PubMed Link to resource 15667143">PubMed</a>.</span></li>
      <li><span id="cit112">
          A. C. Nica, M. Jain, E. Bengio, C.-H. Liu, M. Korablyov, M. M. Bronstein, and Y. Bengio, Evaluating generalization in GFlownets for molecule design, in <span class="italic">ICLR2022 Machine Learning for Drug Discovery</span>,  2022, https://openreview.net/forum?id=JFSaHKNZ35b <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=ICLR2022%20Machine%20Learning%20for%20Drug%20Discovery%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit113">
          M. Jain, S. Chandra Raparthy, A. Hernandez-Garcia, J. Rector-Brooks, Y. Bengio, S. Miret, and E. Bengio, Multi-objective gflownets, <span class="italic">arXiv</span>,  2022, arXiv:2210.12765, preprint, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/arXiv.2210.12765" TARGET="_BLANK" title="DOI Link to 10.48550/arXiv.2210.12765">10.48550/arXiv.2210.12765</a></small>.</span></li>
      <li><span id="cit114">
          M. Ehrgott, <span class="italic">Multicriteria optimization</span>, Springer Science &amp; Business Media,  2005, vol. 491 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Multicriteria%20optimization%5BJour%5D%20AND%20vol. 491%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202005%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit115">
          O'Neill UK government study, <span class="italic">Antimicrobial resistance: Tackling a crisis for the health and wealth of nations</span>,  2014 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Antimicrobial%20resistance:%20Tackling%20a%20crisis%20for%20the%20health%20and%20wealth%20of%20nations%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202014%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit116">
          T. Deleu, A. Góis, C. C. Emezue, M. Rankawat, S. Lacoste-Julien, S. Bauer, and Y. Bengio, Bayesian structure learning with generative flow networks, in <span class="italic">The 38th Conference on Uncertainty in Artificial Intelligence</span>,  2022 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=The%2038th%20Conference%20on%20Uncertainty%20in%20Artificial%20Intelligence%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202022%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit117">
          D. Heckerman, D. Geiger, and D. M. Chickering, <span class="italic">Learning bayesian networks: The combination of knowledge and statistical data</span>, Machine learning,  1995 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Learning%20bayesian%20networks:%20The%20combination%20of%20knowledge%20and%20statistical%20data%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%201995%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit118">
          M. Nishikawa-Toomey, T. Deleu, J. Subramanian, Y. Bengio and L. Charlin, Bayesian learning of causal structure and mechanisms with gflownets and variational bayes, <span class="italic">arXiv</span>,  2022, arXiv:2211.02763, preprint, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/arXiv.2211.02763" TARGET="_BLANK" title="DOI Link to 10.48550/arXiv.2211.02763">10.48550/arXiv.2211.02763</a></small>.</span></li>
      <li><span id="cit119">J. W. Freimer, O. Shaked, S. Naqvi, N. Sinnott-Armstrong, A. Kathiria, C. M. Garrido, A. F. Chen, T. Jessica, W. J. G. Cortez and J. K. Pritchard, 
            <span class="italic">et al.</span>, Systematic discovery and perturbation of regulatory genes in human t cells reveals the architecture of immune networks, <span class="italic">Nat. Genet.</span>, 2022, <span class="bold">54</span>(8), 1133–1144 <a target="_blank" class="DOILink" href="https://doi.org/10.1038/s41588-022-01106-y" title="DOI Link to resource 10.1038/s41588-022-01106-y">CrossRef</a> <a target="_blank" class="COILink" href="/en/content/coiresolver?coi=1%3ACAS%3A528%3ADC%252BB38XhslOgu77K" title="Link to resource in CAS">CAS</a> <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/pubmed/?term=35817986%5Buid%5D" title="PubMed Link to resource 35817986">PubMed</a>.</span></li>
      <li><span id="cit120">A. Hyttinen, F. Eberhardt and P. O. Hoyer, Learning linear cyclic causal models with latent variables, <span class="italic">J. Mach. Learn. Res.</span>, 2012, <span class="bold">13</span>(1), 3387–3439 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=J.%20Mach.%20Learn.%20Res.%5BJour%5D%20AND%2013%5Bvolume%5D%20AND%203387%5Bpage%5D%20and%202012%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit121">
          L. Lorch, S. Scott, J. Rothfuss, A. Krause and B. Schölkopf, Amortized inference for causal structure learning, <span class="italic">arXiv</span>,  2022, arXiv:2205.12934, preprint, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/arXiv.2205.12934" TARGET="_BLANK" title="DOI Link to 10.48550/arXiv.2205.12934">10.48550/arXiv.2205.12934</a></small>.</span></li>
      <li><span id="cit122">
          M. G. Sethuraman, R. Lopez, R. Mohan, F. Fekri, T. Biancalani and J.-C. Hütter, Nodags-flow: Nonlinear cyclic causal structure learning, <span class="italic">arXiv</span>,  2023, arXiv:2301.01849, preprint, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/arXiv.2301.01849" TARGET="_BLANK" title="DOI Link to 10.48550/arXiv.2301.01849">10.48550/arXiv.2301.01849</a></small>.</span></li>
      <li><span id="cit123">
          D. Madigan, A. E. Raftery, C. Volinsky, and J. Hoeting, Bayesian Model Averaging, in <span class="italic">Proceedings of the AAAI Workshop on Integrating Multiple Learned Models</span>,  1996 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Proceedings%20of%20the%20AAAI%20Workshop%20on%20Integrating%20Multiple%20Learned%20Models%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%201996%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit124">
          A. H. Jennifer, D. Madigan, A. E. Raftery, and C. T. Volinsky, <span class="italic">Bayesian model averaging: a tutorial with comments by M. Clyde, David Draper and EI George, and a rejoinder by the authors</span>, Statistical science,  1999 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Bayesian%20model%20averaging:%20a%20tutorial%20with%20comments%20by%20M.%20Clyde,%20David%20Draper%20and%20EI%20George,%20and%20a%20rejoinder%20by%20the%20authors%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%201999%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit125">
          M. Garnelo, D. Rosenbaum, C. Maddison, T. Ramalho, D. Saxton, S. Murray, Y. W. Teh, D. Rezende, and S. M. A. Eslami, Conditional neural processes, in <span class="italic">International Conference on Machine Learning</span>, PMLR,  2018, pp. 1704–1713 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=International%20Conference%20on%20Machine%20Learning%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202018%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit126">
          D. Eaton and K. Murphy, <span class="italic">Bayesian structure learning using dynamic programming and MCMC</span>, Uncertainty in Artificial Intelligence,  2007 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Bayesian%20structure%20learning%20using%20dynamic%20programming%20and%20MCMC%5BJour%5D%20AND%20%5Bvolume%5D%20AND%20%5Bpage%5D%20and%202007%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit127">S. Zheng, D. Hayden, J. Pacheco and J. W. Fisher III, Sequential bayesian experimental design with variable cost structure, <span class="italic">Adv. Neural Inf. Process. Syst.</span>, 2020, <span class="bold">33</span>, 4127–4137 <a target="_blank" class="PMedLink" href="http://www.ncbi.nlm.nih.gov/sites/entrez?orig_db=PubMed&amp;db=pubmed&amp;cmd=Search&amp;term=Adv.%20Neural%20Inf.%20Process.%20Syst.%5BJour%5D%20AND%2033%5Bvolume%5D%20AND%204127%5Bpage%5D%20and%202020%5Bpdat%5D" title="Search PubMed for this citation">Search PubMed</a>.</span></li>
      <li><span id="cit128">
          D. Liu, M. Jain, B. Dossou, Q. Shen, S. Lahlou, A. Goyal, N. Malkin, C. Emezue, D. Zhang, N. Hassen, <span class="italic">et al.</span>, Gflowout: Dropout with generative flow networks, arXiv,  2022, preprint, <small> DOI:<a class="DOILink" href="https://doi.org/10.48550/arXiv.2210.12928" TARGET="_BLANK" title="DOI Link to 10.48550/arXiv.2210.12928">10.48550/arXiv.2210.12928</a></small>.</span></li>
    </ol>
    
    
    
    
    
  <hr/><table><tr><td><h3>Footnotes</h3></td></tr><tr><td><span class="sup_ref">† <span id="fn1">Sequences of experiments are also possible, but even more computationally involved.</span></span></td></tr><tr><td><span class="sup_ref">‡ <span id="fn2">Note that there can be multiple trajectories resulting in the same object at the end.</span></span></td></tr><tr><td><span class="sup_ref">§ <span id="fn3">Code implementing various GFlowNet learning objectives on simple synthetic domains: saleml/gfn.</span></span></td></tr><tr><td><span class="sup_ref">¶ <span id="fn4">Code for molecule generation recursionpharma/gflownet.</span></span></td></tr><tr><td><span class="sup_ref">|| <span id="fn5">Code for active learning with biological sequences: mj10/BioSeq-GFN-AL and alexhernandezgarcia/gflownet.</span></span></td></tr><tr><td><span class="sup_ref">** <span id="fn6">Code for modeling posterior over causal models: tristandeleu/jax-dag-gflownet.</span></span></td></tr></table><table><tr><td><hr/></td></tr><tr><td><b>This journal is © The Royal Society of Chemistry 2023</b></td></tr></table></div></div></div></body><script src="/content/scripts/CrossMarkIE.js"> </script><SaxonLicenceTest result="pass" message="Licenced Enterprise Edition [ EE 9.3.0.4 ]"/></html>