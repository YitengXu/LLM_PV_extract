<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1038/s41467-022-28526-y</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="research-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">41467</journal-id><journal-id journal-id-type="doi">10.1038/41467.2041-1723</journal-id><journal-title-group><journal-title>Nature Communications</journal-title><abbrev-journal-title abbrev-type="publisher">Nat Commun</abbrev-journal-title></journal-title-group><issn pub-type="epub">2041-1723</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s41467-022-28526-y</article-id><article-id pub-id-type="manuscript">28526</article-id><article-id pub-id-type="doi">10.1038/s41467-022-28526-y</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/638/440/94</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/705/117</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/705/531</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/638/563/606</subject></subj-group><subj-group subj-group-type="NatureArticleTypeID"><subject>article</subject></subj-group></article-categories><title-group><article-title xml:lang="en">Inverse design of 3d molecular structures with conditional generative neural networks</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="Au1"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9149-7424</contrib-id><name><surname>Gebauer</surname><given-names>Niklas W. A.</given-names></name><address><email>n.gebauer@tu-berlin.de</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="corresp" rid="IDs4146702228526y_cor1">a</xref></contrib><contrib contrib-type="author" id="Au2"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7954-3275</contrib-id><name><surname>Gastegger</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au3"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8399-2193</contrib-id><name><surname>Hessmann</surname><given-names>Stefaan S. P.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au4"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3861-7685</contrib-id><name><surname>Müller</surname><given-names>Klaus-Robert</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff4">4</xref><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au5"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8342-0964</contrib-id><name><surname>Schütt</surname><given-names>Kristof T.</given-names></name><address><email>kristof.schuett@tu-berlin.de</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="corresp" rid="IDs4146702228526y_cor5">e</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.6734.6</institution-id><institution-id institution-id-type="ISNI">0000 0001 2292 8254</institution-id><institution content-type="org-division">Machine Learning Group</institution><institution content-type="org-name">Technische Universität Berlin</institution></institution-wrap><addr-line content-type="postcode">10587</addr-line><addr-line content-type="city">Berlin</addr-line><country country="DE">Germany</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution content-type="org-name">Berlin Institute for the Foundations of Learning and Data</institution></institution-wrap><addr-line content-type="postcode">10587</addr-line><addr-line content-type="city">Berlin</addr-line><country country="DE">Germany</country></aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.6734.6</institution-id><institution-id institution-id-type="ISNI">0000 0001 2292 8254</institution-id><institution content-type="org-division">BASLEARN—TU Berlin/BASF Joint Lab for Machine Learning</institution><institution content-type="org-name">Technische Universität Berlin</institution></institution-wrap><addr-line content-type="postcode">10587</addr-line><addr-line content-type="city">Berlin</addr-line><country country="DE">Germany</country></aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.222754.4</institution-id><institution-id institution-id-type="ISNI">0000 0001 0840 2678</institution-id><institution content-type="org-division">Department of Artificial Intelligence</institution><institution content-type="org-name">Korea University, Anam-dong, Seongbuk-gu</institution></institution-wrap><addr-line content-type="postcode">02841</addr-line><addr-line content-type="city">Seoul</addr-line><country country="KR">Korea</country></aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.419528.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 0491 9823</institution-id><institution content-type="org-name">Max-Planck-Institut für Informatik</institution></institution-wrap><addr-line content-type="postcode">66123</addr-line><addr-line content-type="city">Saarbrücken</addr-line><country country="DE">Germany</country></aff></contrib-group><author-notes><corresp id="IDs4146702228526y_cor1"><label>a</label><email>n.gebauer@tu-berlin.de</email></corresp><corresp id="IDs4146702228526y_cor5"><label>e</label><email>kristof.schuett@tu-berlin.de</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>21</day><month>2</month><year>2022</year></pub-date><pub-date date-type="collection" publication-format="electronic"><month>12</month><year>2022</year></pub-date><volume>13</volume><issue seq="973">1</issue><elocation-id>973</elocation-id><history><date date-type="registration"><day>1</day><month>2</month><year>2022</year></date><date date-type="received"><day>10</day><month>9</month><year>2021</year></date><date date-type="accepted"><day>28</day><month>1</month><year>2022</year></date><date date-type="online"><day>21</day><month>2</month><year>2022</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2022</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">The rational design of molecules with desired properties is a long-standing challenge in chemistry. Generative neural networks have emerged as a powerful approach to sample novel molecules from a learned distribution. Here, we propose a conditional generative neural network for 3d molecular structures with specified chemical and structural properties. This approach is agnostic to chemical bonding and enables targeted sampling of novel molecules from conditional distributions, even in domains where reference calculations are sparse. We demonstrate the utility of our method for inverse design by generating molecules with specified motifs or composition, discovering particularly stable molecules, and jointly targeting multiple electronic properties beyond the training regime.</p></abstract><abstract xml:lang="en" id="Abs2" abstract-type="ShortSummary"><p id="Par2">The targeted discovery of molecules with specific structural and chemical properties is an open challenge in computational chemistry. Here, the authors propose a conditional generative neural network for the inverse design of 3d molecular structures.</p></abstract><funding-group><award-group><funding-source><institution-wrap><institution>Bundesministerium für Bildung, Wissenschaft, Forschung und Technologie (Federal Ministry for Education, Science, Research and Technology)</institution><institution-id institution-id-type="doi" vocab="open-funder-registry">https://doi.org/10.13039/501100010571</institution-id></institution-wrap></funding-source><award-id award-type="FundRef grant">1IS18037A, 01IS14013A-E, 01GQ1115, 01GQ0850</award-id><principal-award-recipient><name><surname>Schütt</surname><given-names>Kristof T.</given-names></name></principal-award-recipient></award-group><award-group><funding-source><institution-wrap><institution>Deutsche Forschungsgemeinschaft (German Research Foundation)</institution><institution-id institution-id-type="doi" vocab="open-funder-registry">https://doi.org/10.13039/501100001659</institution-id></institution-wrap></funding-source><award-id award-type="FundRef grant">90685689</award-id><principal-award-recipient><name><surname>Schütt</surname><given-names>Kristof T.</given-names></name></principal-award-recipient></award-group><award-group><funding-source><institution-wrap><institution>BASF</institution><institution-id institution-id-type="doi" vocab="open-funder-registry">https://doi.org/10.13039/100004349</institution-id></institution-wrap></funding-source></award-group><award-group><funding-source><institution-wrap><institution>Institute of Information &amp; Communications Technology Planning &amp; Evaluation (IITP) by the Korea Government (No. 2019-0-0007)</institution></institution-wrap></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Nature Portfolio</meta-value></custom-meta><custom-meta><meta-name>volume-issue-count</meta-name><meta-value>1</meta-value></custom-meta><custom-meta><meta-name>issue-article-count</meta-name><meta-value>972</meta-value></custom-meta><custom-meta><meta-name>issue-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>issue-pricelist-year</meta-name><meta-value>2022</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-holder</meta-name><meta-value>The Author(s)</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-year</meta-name><meta-value>2022</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>Yes</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2022</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>2</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>1</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>volume-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>NonStandardArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>false</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/41467_2022_Article_28526.pdf</meta-value></custom-meta><custom-meta><meta-name>pdf-type</meta-name><meta-value>Typeset</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>issue-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>OriginalPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Science, Humanities and Social Sciences, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Science, Humanities and Social Sciences, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Science, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Science (multidisciplinary)</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par3">Identifying chemical compounds with particular properties is a critical task in many applications, ranging from drug design<sup><xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR3">3</xref></sup> over catalysis<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> to energy materials<sup><xref ref-type="bibr" rid="CR5">5</xref>–<xref ref-type="bibr" rid="CR8">8</xref></sup>. As an exhaustive exploration of the vast chemical compound space is infeasible, progress in these areas can benefit substantially from inverse design methods. In recent years, machine learning (ML) has been used to accelerate the exploration of chemical compound space<sup><xref ref-type="bibr" rid="CR9">9</xref>–<xref ref-type="bibr" rid="CR15">15</xref></sup>. A plethora of methods accurately predicts chemical properties and potential energy surfaces of 3d structures at low computational cost<sup><xref ref-type="bibr" rid="CR16">16</xref>–<xref ref-type="bibr" rid="CR27">27</xref></sup>. Here, the number of reference calculations required for training ML models depends on the size of the domain to be explored. Thus, naive exploration schemes may still require a prohibitive number of electronic structure calculations. Instead, chemical space has to be navigated in a guided way with fast and accurate methods to distill promising molecules.</p><p id="Par4">This gives rise to the idea of inverse molecular design<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, where the structure-property relationship is reversed. Here, the challenge is to directly construct molecular structures corresponding to a given set of properties. Generative ML models have recently gained traction as a powerful, data-driven approach to inverse design as they enable sampling from a learned distribution of molecular configurations<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. By appropriately restricting the distributions, they allow obtaining sets of candidate structures with desirable characteristics for further evaluation. These methods typically represent molecules as graphs or SMILES strings<sup><xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup>, which lack information about the three-dimensional structure of a molecule. Therefore, the same molecular graph can represent various spatial conformations that differ in their respective properties, e.g., due to intramolecular interactions (hydrogen bonds, long-range interactions) or different orientations of structural motifs (rotamers, stereoisomers). Beyond that, connectivity-based representations are problematic in chemical systems where bonding is ambiguous, e.g., in transition metal complexes, conjugated systems or metals. Relying on these abstract representations is ultimately a limiting factor when exploring chemical space.</p><p id="Par5">Recently, generative models that enable sampling of 3d molecular configurations have been proposed. This includes specifically designed approaches to translate given molecular graphs to 3d conformations<sup><xref ref-type="bibr" rid="CR32">32</xref>–<xref ref-type="bibr" rid="CR38">38</xref></sup>, map from coarse-grained to fine-grained structures<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>, sample unbiased equilibrium configurations of a given system<sup><xref ref-type="bibr" rid="CR40">40</xref>,<xref ref-type="bibr" rid="CR41">41</xref></sup>, or focus on protein folding<sup><xref ref-type="bibr" rid="CR42">42</xref>–<xref ref-type="bibr" rid="CR46">46</xref></sup>. In contrast, other models aim at sampling directly from distributions of 3d molecules with arbitrary composition<sup><xref ref-type="bibr" rid="CR47">47</xref>–<xref ref-type="bibr" rid="CR56">56</xref></sup>, making them suitable for general inverse design settings. These models need to be biased towards structures with properties of interest, e.g., using reinforcement learning<sup><xref ref-type="bibr" rid="CR51">51</xref>,<xref ref-type="bibr" rid="CR52">52</xref>,<xref ref-type="bibr" rid="CR56">56</xref></sup>, fine-tuning on a biased dataset<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>, or other heuristics<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>.</p><p id="Par6">Some of us have previously proposed G-SchNet<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>, an autoregressive deep neural network that generates diverse, small organic molecules by placing atom after atom in Euclidean space. It has been applied in the 3D-Scaffold framework to build molecules around a functional group associated with properties of interest in order to discover novel drug candidates<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>. Such an approach requires prior knowledge about the relationship between functional groups and target properties and might prevent the model from unfolding its potential by limiting sampling to very specific molecules. G-SchNet has been biased by fine-tuning on a fraction of the training dataset containing all molecules with a small HOMO-LUMO gap<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>. For this, a sufficient amount of training examples in the target space is required. However, the most interesting regions for exploration are often those where reference calculations are sparse.</p><p id="Par7">In this work, we propose conditional G-SchNet (cG-SchNet), a conditional generative neural network for the inverse design of molecules. Building on G-SchNet, the model learns conditional distributions depending on structural or chemical properties allowing us to sample corresponding 3d molecular structures. Our architecture is designed to generate molecules of arbitrary size and does not require the specification of a target composition. Consequently, it learns the relationship between the composition of molecules and their physical properties in order to sample candidates exhibiting given target properties, e.g., preferring smaller structures when targeting small polarizabilities. Previously proposed methods have been biased towards one particular set of target property values at a time by adjusting the training objective or data<sup><xref ref-type="bibr" rid="CR48">48</xref>,<xref ref-type="bibr" rid="CR51">51</xref></sup>. In contrast, our conditional approach permits searching for molecules with any desired set of target property values after training is completed. It is able to jointly target multiple properties without the need to retrain or otherwise indirectly constrain the sampling process. This provides the foundation for the model to leverage the full information of the training data resulting in increased generalization and data efficiency. We demonstrate that cG-SchNet enables the exploration of sparsely populated regions that are hardly accessible with unconditional models. To this end, we conduct extensive experiments with diverse conditioning targets including chemical properties, atomic compositions and molecular fingerprints. In this way, we generate novel molecules with predefined structural motifs, isomers of a given composition that exhibit specific chemical properties, and novel configurations that jointly optimize HOMO-LUMO gap and energy. This demonstrates that our model enables flexible, guided exploration of chemical compound space.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Targeted 3d molecule generation with cG-SchNet</title><p id="Par8">We represent molecules as tuples of atom positions <bold>R</bold><sub>≤<italic>n</italic></sub> = (<bold>r</bold><sub>1</sub>, …, <bold>r</bold><sub><italic>n</italic></sub>) with <inline-formula id="IEq1"><alternatives><mml:math id="IEq1_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math><tex-math id="IEq1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{r}}}}}}}}}_{i}\in {{\mathbb{R}}}^{3}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq1.gif"/></alternatives></inline-formula> and corresponding atom types <bold>Z</bold><sub>≤<italic>n</italic></sub> = (<italic>Z</italic><sub>1</sub>, …, <italic>Z</italic><sub><italic>n</italic></sub>) with <inline-formula id="IEq2"><alternatives><mml:math id="IEq2_Math"><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">N</mml:mi></mml:math><tex-math id="IEq2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Z}_{i}\in {\mathbb{N}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq2.gif"/></alternatives></inline-formula>. cG-SchNet assembles these structures from sequences of atoms that are placed step by step in order to build the molecule in an autoregressive manner, where the placement of the next atom depends on the preceding atoms (Fig. <xref rid="Fig1" ref-type="fig">1</xref>a and c). In contrast to G-SchNet<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>, which learns an unconditional distribution over molecules, cG-SchNet samples from target-dependent conditional probability distributions of 3d molecular structures (Fig. <xref rid="Fig1" ref-type="fig">1</xref>b).<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><title>Molecule generation with cG-SchNet.</title><p><bold>a</bold> Factorization of the conditional joint probability of atom positions and types into a chain of probabilities for placing single atoms one after another. <bold>b</bold> Results of sampling molecules from target-dependent conditional probability distributions. Distributions of the isotropic polarizability of training structures (orange) and five sets of molecules generated by the same cG-SchNet model (blue curves) conditioned on five different isotropic polarizability target values (color-matching dots above the <italic>x</italic>-axis). The generated molecule closest to the corresponding target value and not contained in the training data (unseen) is shown above each curve. <bold>c</bold> Schematic depiction of the atom placement loop. For visualization purposes, we show a planar molecule and a 2d slice of the actual 3d grid distributions in steps 4, 5, and 6.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2022_28526_Fig1_HTML.png"/></fig></p><p id="Par9">Given a tuple of <italic>k</italic> conditions <bold>Λ</bold> = (<italic>λ</italic><sub>1</sub>, …, <italic>λ</italic><sub><italic>k</italic></sub>), cG-SchNet learns a factorization of the conditional distribution of molecules, i.e., the joint distribution of atom positions and atom types conditioned on the target properties:<disp-formula id="Equ1"><label>1</label><alternatives><mml:math id="Equ1_Math"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∏</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math><tex-math id="Equ1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p({{{{{{{{\bf{R}}}}}}}}}_{\le n},{{{{{{{{\bf{Z}}}}}}}}}_{\le n}| {{{{{\mathbf{\Lambda}}}}}})=\mathop{\prod }\limits_{i=1}^{n}p\left({{{{{{{{\bf{r}}}}}}}}}_{i},{Z}_{i}| {{{{{{{{\bf{R}}}}}}}}}_{\le i-1},{{{{{{{{\bf{Z}}}}}}}}}_{\le i-1},{{{{{\mathbf{\Lambda}}}}}}\right).$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ1.gif"/></alternatives></disp-formula></p><p id="Par10">In fact, we can split up the joint probability of the next type and the next position into the probability of the next type and the probability of the next position given the associated next type:<disp-formula id="Equ2"><label>2</label><alternatives><mml:math id="Equ2_Math"><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math><tex-math id="Equ2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p \left({{{{{{{{\bf{r}}}}}}}}}_{i},{Z}_{i}| {{{{{{{{\bf{R}}}}}}}}}_{\le i-1},{{{{{{{{\bf{Z}}}}}}}}}_{\le i-1},{{{{{\mathbf{\Lambda}}}}}}\right)\hfill\\ =p({Z}_{i}| {{{{{{{{\bf{R}}}}}}}}}_{\le i-1},{{{{{{{{\bf{Z}}}}}}}}}_{\le i-1},{{{{{\mathbf{\Lambda}}}}}})\,p({{{{{{{{\bf{r}}}}}}}}}_{i}| {{{{{{{{\bf{R}}}}}}}}}_{\le i-1},{{{{{{{{\bf{Z}}}}}}}}}_{\le i},{{{{{\mathbf{\Lambda}}}}}}).$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ2.gif"/></alternatives></disp-formula></p><p id="Par11">This allows predicting the next type before the next position. We approximate the distribution over the absolute position from distributions over distances to already placed atoms<disp-formula id="Equ3"><label>3</label><alternatives><mml:math id="Equ3_Math"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∏</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">R</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">Z</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><tex-math id="Equ3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p({{{{{{{{\bf{r}}}}}}}}}_{i}| {{{{{{{{\bf{R}}}}}}}}}_{\le i-1},{{{{{{{{\bf{Z}}}}}}}}}_{\le i},{{{{{\mathbf{\Lambda}}}}}})=\frac{1}{\alpha }\mathop{\prod }\limits_{j=1}^{i-1}p({r}_{ij}| {{{{{{{{\bf{R}}}}}}}}}_{\le i-1},{{{{{{{{\bf{Z}}}}}}}}}_{\le i},{{{{{\mathbf{\Lambda}}}}}})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ3.gif"/></alternatives></disp-formula>which guarantees that it is equivariant with respect to translation and rotation of the input. Here <italic>α</italic> is the normalization constant and <italic>r</italic><sub><italic>i</italic><italic>j</italic></sub> = ∣∣<bold>r</bold><sub><italic>i</italic></sub> − <bold>r</bold><sub><italic>j</italic></sub>∣∣ is the distance between the new atom <italic>i</italic> and a previously placed atom <italic>j</italic>. This approximation has previously been shown to accurately reproduce a distribution of molecular structures<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>.</p><p id="Par12">Figure <xref rid="Fig2" ref-type="fig">2</xref> shows a schematic depiction of the cG-SchNet architecture. The conditions <italic>λ</italic><sub>1</sub>, …, <italic>λ</italic><sub><italic>k</italic></sub> are each embedded into a latent vector space and concatenated, followed by a fully connected layer. In principle, any combination of properties can be used as conditions with our architecture with a suitable embedding network. In this work, we use three scalar-valued electronic properties such as isotropic polarizability, vector-valued molecular fingerprints, and the atomic composition of molecules. Vector-valued properties are directly processed by the network while scalar-valued targets are first expanded on a Gaussian basis. To target an atomic composition, learnable atom type embeddings are weighted by occurrence. The embedding procedure is described in detail in the Methods section.<fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><title>Schematic depiction of the cG-SchNet architecture with inputs and outputs.</title><p>“ ⊕ " represents concatenation and “ ⊙ " represents the Hadamard product. Left: Atom-wise feature vectors representing an unfinished molecule are extracted with SchNet<sup><xref ref-type="bibr" rid="CR67">67</xref></sup> and conditions are individually embedded and then concatenated to extract the conditional features vector. The exact embedding depends on the type of the condition (e.g., scalar or vector-valued). Middle: The distribution for the type of the next atom is predicted from the extracted feature vectors. Right: Based on the extracted feature vectors and the sampled type of the next atom, distributions for the pairwise distances between the next atom and every atom/token in the unfinished molecule are predicted. See Methods for details on the building blocks.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2022_28526_Fig2_HTML.png"/></fig></p><p id="Par13">In order to localize the atom placement and stabilize the generation procedure, cG-SchNet makes use of the same two auxiliary tokens as in the unconditional setting, namely the origin and the focus token<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>. Auxiliary tokens are treated like regular atoms by the model, i.e., they possess positions and token types, which are contained in the tuples of atom positions and atom types serving as input at each step. The origin token marks the center of the mass of molecules and allows the architecture to steer the growth from inside to outside. The focus token localizes the prediction of the next position in order to assure scalability and allows to break symmetries of partial structures. This avoids artifacts in the reconstruction of the positional distribution (Eq. (<xref rid="Equ3" ref-type="disp-formula">3</xref>)) as reported by Gebauer et al.<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>. At each step, the focus token is randomly assigned to a previously placed atom. The position of the next atom is required to be close to this focus. In this way, we can use a small grid localized on the focus that does not grow with the number of atoms when predicting the distribution of the next position.</p><p id="Par14">We train cG-SchNet on a set of molecular structures, where the values of properties used as conditions are known for each molecule. Given the conditions and the partial molecular structure at each step, cG-SchNet predicts a discrete distribution for the type of the next atom. As part of this, a stop type may be predicted that allows the model to control the termination of the sampling procedure and therefore generate molecules with variable size and composition. After sampling a type, cG-SchNet predicts distributions for the distance between the atom to be placed and each preceding atom and auxiliary token. The schematic depiction of the atom placement loop in Fig. <xref rid="Fig1" ref-type="fig">1</xref>c includes the auxiliary tokens, the model predictions, and the reconstruction of the localized 3d grid distribution. During training, we minimize the cross-entropy loss between the predicted distributions and the ground-truth distributions known from the reference calculations. For further details on the model architecture and training procedure, refer to the Methods section.</p></sec><sec id="Sec4"><title>Generating molecules with specified motifs</title><p id="Par15">In many applications, it is advantageous for molecules to possess specific functional groups or structural motifs. These can be correlated with desirable chemical properties, e.g., polar groups that increase solubility, or with improved synthetic accessibility. In order to sample molecules with specific motifs, we condition cG-SchNet on a path-based, 1024 bits long fingerprint that checks molecular graphs for all linear segments of up to seven atoms<sup><xref ref-type="bibr" rid="CR57">57</xref></sup> (Supplementary Methods <xref ref-type="supplementary-material" rid="MOESM1">3)</xref>. The model is trained on a randomly selected subset of 55k molecules from the QM9 dataset consisting of ~134k organic molecules with up to nine heavy atoms from carbon, nitrogen, oxygen, and fluorine<sup><xref ref-type="bibr" rid="CR58">58</xref>–<xref ref-type="bibr" rid="CR60">60</xref></sup>. We condition the sampling on fingerprints of unseen molecules, i.e., structures not used during training. Figure <xref rid="Fig3" ref-type="fig">3</xref>a shows results for four examples. We observe that the generated molecules have a higher similarity with the target fingerprints than the training data. Furthermore, structures with high target similarity are also sampled with higher probability, as can be seen from the increased similarity score of generated duplicates. In the last column of Fig. <xref rid="Fig3" ref-type="fig">3</xref>a, we show sampled molecules with high similarity to each target and see that in each case various structures with perfectly matching fingerprints were found. For reference, we also show the most similar molecule in the training set. Overall, we see that the conditional sampling with cG-SchNet is sensitive to the target fingerprint and allows for the generation of molecules with desired structural motifs. Although there are no molecules with the same fingerprint in the training data for three of the four fingerprint targets, the ML model successfully generates perfectly matching molecules, demonstrating its ability to generalize and explore unseen regions of chemical compound space.<fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><title>Targeted exploration of chemical space with cG-SchNet.</title><p><bold>a</bold> Generation of molecules with desired motifs by conditioning cG-SchNet on simple path-based fingerprints. First column: Four different target fingerprints of structures from the test set. For each, we conditionally sample 20k molecules with cG-SchNet. Second column: Average Tanimoto similarity of the respective target to training structures (brown) and to generated molecules without duplicates (blue) and with duplicates (gray). The amount of generated structures is noted next to the dots. Third column: Most similar training molecule. Fourth column: Three generated unseen examples with high similarity to the target. The Tanimoto similarity to the target structure is noted to the bottom-right of depicted molecules. <bold>b</bold> Generation of C<sub>7</sub>N<sub>1</sub>O<sub>1</sub>H<sub>11</sub> isomers with HOMO-LUMO gap targets outside the training data range by conditioning cG-SchNet on atomic composition and HOMO-LUMO gap. The training dataset of 55k QM9 molecules is restricted to not contain any C<sub>7</sub>N<sub>1</sub>O<sub>1</sub>H<sub>11</sub> isomers with gap &lt; 6 eV or gap &gt; 8 eV. The graph shows the distribution of the gap for the C<sub>7</sub>N<sub>1</sub>O<sub>1</sub>H<sub>11</sub> isomers in QM9 (brown), the isomers in the restricted training dataset (orange), and the two sets of isomers generated with cG-SchNet (blue curves) when targeting the composition C<sub>7</sub>N<sub>1</sub>O<sub>1</sub>H<sub>11</sub> and two gap values outside the training data range (color-matching dots on the <italic>x</italic>-axis). For each target value, the two generated isomers closest to it are depicted.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2022_28526_Fig3_HTML.png"/></fig></p></sec><sec id="Sec5"><title>Generalization of condition-structure relationship across compositions</title><p id="Par16">For inverse design tasks, integrating information gained from different structures and properties is vital to obtain previously unknown candidates with desired properties. In this experiment, we target C<sub>7</sub>N<sub>1</sub>O<sub>1</sub>H<sub>11</sub> isomers with HOMO-LUMO gap values outside the range observed during training. To this end, the model has to learn from other compositions how molecules with particularly high or low HOMO-LUMO gaps are structured, and transfer this knowledge to the target composition. There are 5859 C<sub>7</sub>N<sub>1</sub>O<sub>1</sub>H<sub>11</sub> isomers in QM9, where 997 have a HOMO-LUMO gap smaller than 6 eV, 1612 have a HOMO-LUMO gap larger than 8 eV, and 3250 lie in between these two values. We restrict the training data consisting of 55k molecules from QM9 to contain no C<sub>7</sub>N<sub>1</sub>O<sub>1</sub>H<sub>11</sub> isomers with HOMO-LUMO gap values outside the intermediate range (Fig. <xref rid="Fig3" ref-type="fig">3</xref>b). Thus, the model can only learn to generate molecules with gaps outside this range from compositions other than C<sub>7</sub>N<sub>1</sub>O<sub>1</sub>H<sub>11</sub>.</p><p id="Par17">Fig. <xref rid="Fig3" ref-type="fig">3</xref>b shows examples of generated C<sub>7</sub>N<sub>1</sub>O<sub>1</sub>H<sub>11</sub> isomers for two target values as well as the respective HOMO-LUMO gap distributions. In both cases, the majority of generated isomers exhibit gap values close to the respective target (±1 eV), i.e., outside of the range observed for these isomers by the model during training. This demonstrates that cG-SchNet is able to transfer knowledge about the relationship between structural patterns and HOMO-LUMO gaps learned from molecules of other compositions to generate unseen C<sub>7</sub>N<sub>1</sub>O<sub>1</sub>H<sub>11</sub> isomers with outlying gap values upon request.</p></sec><sec id="Sec6"><title>Discovery of low-energy conformations</title><p id="Par18">The ability to sample molecules that exhibit property values that are missing in the training data is a prerequisite for the targeted exploration of chemical space. A generative model needs to fill the sparsely sampled regions of the space, effectively enhancing the available data with novel structures that show property values of interest. We study this by training cG-SchNet on a randomly sampled set of 55k QM9 molecules and query our model to sample low-energy C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers—the most common composition in QM9. We exclude these isomers from the training data, i.e., our model has to generalize beyond the seen compositions. The identification of low-energy conformations is desirable in many practical applications, since they tend to be more stable. However, the energy of molecules is largely determined by their size and composition. Since we are mainly interested in the energy contribution of the spatial arrangement sampled by the model, we require a normalized energy value. To this end, we define the relative atomic energy, which indicates whether the internal energy per atom is relatively high or low compared to other molecules of the same composition in the dataset (see Supplementary Methods <xref ref-type="supplementary-material" rid="MOESM1">2</xref> for details). Negative values indicate comparatively low energy, and thus higher stability than the average structure of this composition. Note that a similarly normalized energy has been defined by Zubatyuk et al.<sup><xref ref-type="bibr" rid="CR61">61</xref></sup> for their neural network potential. Using the relative atomic energy allows cG-SchNet to learn the influence of the spatial arrangement of atoms on the energy and transfer this knowledge to the unseen target composition. Examples of generated C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers with low, intermediate, and high relative atomic energy are shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>a. We observe that conformations with highly strained, small rings exhibit increased relative atomic energy values.<fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><title>Discovery of low-energy isomers for an unseen composition.</title><p>We sample C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers with cG-SchNet conditioned on atomic composition and relative atomic energy (see text for details), where the training dataset was restricted to contain no C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> conformations. <bold>a</bold> The distribution of the relative atomic energy for C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers in the test set (orange) and for three sets of isomers generated with cG-SchNet (blue curves) when targeting the composition C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> and three different relative atomic energy values as marked with color-matching dots on the <italic>x</italic>-axis. The generated isomer closest to the respective target is depicted above each curve. <bold>b</bold> The absolute number of C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers in the test set (red dotted line) for increasing relative atomic energy thresholds. The black solid line shows how many of these were generated by cG-SchNet (target energy −0.1 eV). <bold>c</bold> Bar plot of the absolute number of C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers with relative atomic energy ≤0.05 eV in the test set (orange) and generated by cG-SchNet (target energy −0.1 eV, purple). The bar for generated molecules is divided into isomers that can be found in the test set (unseen isomers), isomers that have different stereochemistry but share the same bonding pattern as test set structures (novel stereoisomers), and novel constitutional isomers that are not in QM9 (novel isomers). <bold>d</bold> Relaxed example low-energy isomers generated by cG-SchNet (target energy −0.1 eV, blue dots) and structures from the test set (orange dots) along with their relative atomic energy.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2022_28526_Fig4_HTML.png"/></fig></p><p id="Par19">Figure <xref rid="Fig4" ref-type="fig">4</xref>a shows that the trained model generalizes from the training data to sample C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers capturing the whole range of relative atomic energies exhibited by the QM9 test structures. We focus on stable, low-energy isomers for our analysis in the following. We sample 100k molecules with the trained cG-SchNet conditioned on the composition C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> and a relative atomic energy value of −0.1 eV, i.e., close to the lowest energies occurring for these isomers in QM9. The generated molecules are filtered for valid and unique C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers, relaxed using density functional theory (DFT), and then matched with the test data structures. 169 of the 200 isomers with the lowest relative atomic energy in the test set have been recovered by the model as well as 67% of the 1k isomers with relative atomic energy lower than −0.05 eV (Fig. <xref rid="Fig4" ref-type="fig">4</xref>b). Beyond that, cG-SchNet has generated 416 novel isomers as well as 243 novel stereoisomers that share the same bonding pattern as a test structure but show different stereochemistry (Fig. <xref rid="Fig4" ref-type="fig">4</xref>c). We found 32% more unique C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers with relative atomic energy lower than −0.05 eV with our model than already contained in QM9. Example isomers are depicted in Fig. <xref rid="Fig4" ref-type="fig">4</xref>d. For reference, we show additional, randomly selected generated novel isomers along with their most similar counterparts from QM9 in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">1</xref> and depict how atoms in these structures moved during relaxation in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">4</xref>. These examples illustrate that cG-SchNet samples molecules that are close to equilibrium configurations and thus require only a few steps of relaxation with DFT or a neural network potential. Furthermore, we examine different conformations found for the five most often generated isomers in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">3</xref>.</p><p id="Par20">The generated molecules include structures and motifs that are sparse or not included in the QM9 benchmark dataset, which has previously been reported to suffer from decreased chemical diversity compared to real-world datasets<sup><xref ref-type="bibr" rid="CR62">62</xref></sup>. For instance, there are no C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers with carboxylic acid groups in QM9, while twelve of the generated novel low-energy isomers possess this functional group (e.g., Fig. <xref rid="Fig4" ref-type="fig">4</xref>d, top right and Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">2)</xref>. Carboxylic acid groups are a common motif of organic compounds and feature prominently in fats and amino acids. While they are only contained in a few hundred molecules in QM9, cG-SchNet has learned to transfer this group to molecules of the targeted composition. Moreover, the model has discovered several acyclic C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers exhibiting a significantly lower relative atomic energy than those in QM9 (examples in Fig. <xref rid="Fig4" ref-type="fig">4</xref>d, bottom row). As cG-SchNet generalizes beyond the chemical diversity of QM9, this demonstrates that it can be employed to systematically enhance a database of molecular structures.</p></sec><sec id="Sec7"><title>Targeting multiple properties: Discovery of low-energy structures with small HOMO-LUMO gap</title><p id="Par21">For most applications, the search for suitable molecules is guided by multiple properties of interest. Therefore, a method for exploration needs to allow for the specification of several conditions at the same time. Here we demonstrate this ability by targeting HOMO-LUMO gap as well as relative atomic energy, i.e., two complex electronic properties at the same time. A particular challenging task is to find molecules with extreme property values, as those are often located at the sparsely populated borders of the training distribution. In previous work, we have biased an unconditioned G-SchNet in order to sample molecules with small HOMO-LUMO gap<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>. The model was fine-tuned with all ~3.8k available molecules from QM9 with HOMO-LUMO gap smaller than 4.5 eV, a small fraction of the whole QM9 dataset with ~130k molecules. In the following, we demonstrate that improved results can be achieved with the cG-SchNet architecture while using fewer training samples from the target region. We further condition the sampling to particularly stable, low-energy conformations. In a fine-tuning approach, this would limit the training data to only a few molecules that are both stable and exhibit small gaps. In contrast, the conditioned model is able to learn also from reference calculations where only one of the desired properties is present.</p><p id="Par22">We condition cG-SchNet on the HOMO-LUMO gap as well as the relative atomic energy and train it on 55k randomly selected QM9 molecules, where only ~1.6k of the ~3.8k molecules with HOMO-LUMO gap smaller than 4.5 eV are contained. Then, we sample the same number of molecules as for the biased model<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> (20k) with the trained cG-SchNet using a HOMO-LUMO gap value of 4.0 eV and relative atomic energy of −0.2 eV as conditions. The generated conformations are filtered for valid and unique molecules, relaxed using DFT, and then matched with the training data structures.</p><p id="Par23">Figure <xref rid="Fig5" ref-type="fig">5</xref> compares the sets of generated, unique, unseen molecules with HOMO-LUMO gap smaller than 4.5 eV obtained for the cG-SchNet and biased G-SchNet. For biased G-SchNet, we use the previously published<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> dataset of generated molecules with a low HOMO-LUMO gap and remove all structures with HOMO-LUMO gap larger than 4.5 eV. Since the energy range has not been restricted for the biased G-SchNet, it samples structures that capture the whole space spanned by the training data, i.e., also less stable molecules with higher relative atomic energy. The molecules generated with cG-SchNet, in contrast, are mostly structures with low relative atomic energy (Fig. <xref rid="Fig5" ref-type="fig">5</xref>a). Considering the total amount of unseen molecules with small gaps found by both models, we observe that cG-SchNet samples a significantly larger number of structures from the low-energy domain than the biased G-SchNet. It similarly surpasses the number of molecules from this domain in the training set, showcasing an excellent generalization performance (see Fig. <xref rid="Fig5" ref-type="fig">5</xref>b). For example, the model has learned to build molecules close to the target conditions that contain more than nine heavy atoms, i.e., larger than the structures from the training data. This can be seen in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">5</xref>, where we depict generated molecules with gap and relative atomic energy values beyond the training regime.<fig id="Fig5"><label>Fig. 5</label><caption xml:lang="en"><title>Discovery of low-energy structures with small HOMO-LUMO gap.</title><p>We compare cG-SchNet to the previous, biased G-SchNet approach<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>. <bold>a</bold> The joint distributions of relative atomic energy and HOMO-LUMO gap for QM9 (left) and for unique, unseen molecules with gap ≤4.5 eV generated with cG-SchNet (middle) and with biased G-SchNet (right). Biased G-SchNet was fine-tuned on all molecules in QM9 below a gap threshold of 4.5 eV (red, dotted line). The conditions used for generation with cG-SchNet are marked with a blue cross. The depicted molecules are generated examples with a gap of 4 eV and different relative atomic energy values (black, dotted lines). More examples as well as the distributions close to the conditioning target for cG-SchNet and the training data can be found in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">5</xref>. <bold>b</bold> The absolute number of unique, unseen molecules with gap ≤4.5 eV generated by cG-SchNet (black) and biased G-SchNet (red) for increasing relative atomic energy thresholds. For reference, we also show the amount of structures with low gap included in the training set of cG-SchNet (blue dotted line). <bold>c</bold> The average number of atoms of different types (left), bonds of different orders (middle), and rings of different sizes (right) in unique, unseen molecules with gap ≤4.5 eV generated by each model.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2022_28526_Fig5_HTML.png"/></fig></p><p id="Par24">The statistics about the average atom, bond, and ring count of generated molecules depicted in Fig. <xref rid="Fig5" ref-type="fig">5</xref>c reveal further insights about the structural traits and differences of molecules with low HOMO-LUMO gap in the two sets. The molecules found with cG-SchNet contain more double bonds and a larger number of rings, mainly consisting of five or six atoms. This indicates a prevalence of aromatic rings and conjugated systems with alternating double and single bonds, which are important motifs in organic semiconductors. The same patterns can be found for molecules from biased G-SchNet, however, there is an increased number of nitrogen and oxygen atoms stemming from less stable motifs such as rings dominated by nitrogen. An example of this is the molecule with the highest energy depicted in Fig. <xref rid="Fig5" ref-type="fig">5</xref>a. Furthermore, the molecules of biased G-SchNet tend to contain highly strained small cycles of three or four atoms. cG-SchNet successfully averts these undesirable motifs when sampling molecules with a low relative atomic energy target.</p><p id="Par25">We conclude that cG-SchNet has learned to build stable molecules with a low HOMO-LUMO gap even though it has seen less than half of the structures that the biased model was fine-tuned on. More importantly, the training data contains only very few (~200) structures close to the target conditions at the border of the QM9 distribution, i.e., with HOMO-LUMO gap smaller than 4.5 eV and relative atomic energy smaller than −0.1 eV. However, our model is able to leverage information even from structures where one of the properties is outside the targeted range. Consequently, it is able to sample a significantly higher number of unseen molecules from the target domain than there are structures in the training data that fulfill both targets. In this way, multiple properties can be targeted at once in order to efficiently explore chemical compound space.</p><p id="Par26">The efficiency of cG-SchNet in finding molecular structures close to the target conditions is particularly evident compared to an exhaustive enumeration of graphs with subsequent relaxation using DFT. In both cases, the relaxation required to obtain equilibrium coordinates and the physical properties is the computational bottleneck and takes more than 15 min per structure for the molecules generated in this experiment. Furthermore, the calculation of the internal energy at zero Kelvin (U0) requires additional 40 min per molecule. In contrast, the generation with cG-SchNet takes only 9 ms per structure on a Nvidia A100 GPU when sampling in batches of 1250. The training time of about 40 hours is negligible, as it corresponds to the relaxation and calculation of U0 of only 44 structures. Thus, the efficiency is determined by the number of molecules that need to be relaxed for each method. The QM9 dataset was assembled by relaxing structures from the GDB enumeration<sup><xref ref-type="bibr" rid="CR60">60</xref></sup> of graphs for small organic compounds. Of the ~78k molecules that we did not use for training, 354 molecules are close to the target region. Relaxing only the 5283 structures proposed by cG-SchNet, i.e., less than 10% of the computations performed by screening all graphs, we can already recover 46% of these structures. Additionally, the model has unveiled valid molecules close to the target that are not contained in the dataset. More than 380 of these are larger than QM9 structures and thus not covered. However, 253 smaller structures were missed by the enumeration method. This is, again, in line with findings by Glavatskikh et al.<sup><xref ref-type="bibr" rid="CR62">62</xref></sup> that even for these small compounds the graph-based sampling does not cover all structures of interest. Consequently, we obtain more than two times the amount of molecules close to the target property values with cG-SchNet than with the exhaustive enumeration method while requiring less than 10% of the computation time.</p><p id="Par27">The conditional model is not restricted to the space of low-energy / low gap molecules, but can also sample low-energy / high gap structures or any other combination of interest. Thus, the efficiency of the generative model becomes even more pronounced when there are multiple sets of desirable target values. Figure <xref rid="Fig1" ref-type="fig">1</xref>b depicts an example where cG-SchNet has been trained on the isotropic polarizability as a condition. Here, the same model is employed to sample molecules for five different target values. Again, cG-SchNet is able to generalize to isotropic polarizabilities beyond the values present in the training data.</p></sec></sec><sec id="Sec8" sec-type="discussion"><title>Discussion</title><p id="Par28">cG-SchNet enables the targeted discovery of 3d molecular structures conditioned on arbitrary combinations of multiple structural and chemical properties. The neural network captures global and local symmetries of molecular structures by design, enabling it to learn complex relationships between chemical properties and 3d structures. This makes it possible to generalize to unseen conditions and structures, as we have thoroughly evaluated in a line of experiments where we target property values not included in the training data. In contrast to previous approaches, the model does not require target-specific biasing procedures. Instead, the explicit conditioning enables cG-SchNet to learn efficiently from all available reference calculations. Desirable values of multiple properties can be targeted simultaneously to sample from specific conditional distributions. In this way, cG-SchNet generates novel 3d candidate molecules that exhibit the target properties with high probability and thus are perfectly suited for further filtering and evaluation using ML force fields.</p><p id="Par29">Further work is required to apply the cG-SchNet architecture to the exploration of significantly larger systems and a more diverse set of atom types. Although an unconditional G-SchNet has been trained on drug-like molecules with 50+ atoms in the 3D-Scaffold framework<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>, adjustments will be necessary to ensure scalability to materials. In the current implementation, we employ all preceding atoms to predict the type and reconstruct the positional distribution of the next atom. Here, a cutoff or other heuristics to limit the number of considered atoms will need to be introduced, together with corrections for long-range interactions. While the small organic compounds considered in this work are well represented by QM9, the model might benefit from enhancing the training data using representative building blocks such as “amons”<sup><xref ref-type="bibr" rid="CR63">63</xref></sup> or other fragmentation methods<sup><xref ref-type="bibr" rid="CR64">64</xref>,<xref ref-type="bibr" rid="CR65">65</xref></sup>. This becomes increasingly important when tackling larger molecules where reference data is hard to obtain. Another direction for future work is the extended comparison of cG-SchNet to established methods in different fields, e.g., for the discovery of drugs or materials, to identify promising applications and possible shortcomings. Furthermore, additional adaptations are necessary to explore systems with periodic boundary conditions. In cases where not all targeted properties can be fulfilled simultaneously, finding suitable molecules becomes harder, if not impossible. Therefore, another important extension is to explicitly define a trade-off between multiple conditions or to sample along a Pareto front.</p><p id="Par30">We have applied cG-SchNet to sample particularly stable, low-energy C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers. In this process, we have discovered molecules and motifs that are absent from the QM9 database, such as isomers with carboxylic acid groups. Furthermore, we have sampled more than 800 low-energy molecules with HOMO-LUMO gaps smaller than 4.5 eV from a domain that is only sparsely represented in the training data. Although the exploration of such small molecules with an exhaustive sampling of molecular graphs and subsequent evaluation with DFT is computationally feasible, our model considerably accelerates the process by providing reasonable candidate structures. cG-SchNet thus also enables the data-efficient, systematic improvement of chemical databases, which is particularly valuable considering the computational cost and unfavourable scaling of electronic structure calculations. This paves the way for ML-driven, targeted exploration of chemical compound space and opens avenues for further development towards generative models for larger and more general atomistic systems.</p></sec><sec id="Sec9" sec-type="methods"><title>Methods</title><sec id="Sec10"><title>Training data</title><p id="Par31">For each training run, 55k reference structures are randomly sampled from the QM9 dataset<sup><xref ref-type="bibr" rid="CR58">58</xref>–<xref ref-type="bibr" rid="CR60">60</xref></sup>, a collection of 133,885 molecules with up to nine heavy atoms from carbon, nitrogen, oxygen, and fluorine. We removed 915 molecules from the training pool which are deemed invalid by our validation procedure that checks the valency and connectedness of generated structures (see Section Checking validity and uniqueness of generated molecules). For some runs, limited subsets of the training data pool are used, as described in the results (e.g., without C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers). We train the neural network using 50k randomly sampled molecules and employ the remaining 5k for validation (see Section Neural network training). All molecules shown in figures have been rendered with the 3d visualization package Mayavi<sup><xref ref-type="bibr" rid="CR66">66</xref></sup>.</p></sec><sec id="Sec11"><title>Details on the neural network architecture</title><p id="Par32">In the following, we describe the cG-SchNet architecture as depicted in Figure <xref rid="Fig2" ref-type="fig">2</xref> in detail. We use the shifted softplus non-linearity<disp-formula id="Equ4"><label>4</label><alternatives><mml:math id="Equ4_Math"><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">ssp</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>ln</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><tex-math id="Equ4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\,{{{{{{\rm{ssp}}}}}}}\,(x)=\ln \left(\frac{1}{2}{e}^{x}+\frac{1}{2}\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ4.gif"/></alternatives></disp-formula>throughout the architecture. Successive linear neural network layers with intermediate shifted softplus activation are written as<disp-formula id="Equ5"><label>5</label><alternatives><mml:math id="Equ5_Math"><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">mlp</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">ssp</mml:mi><mml:mspace width="0.25em"/><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="Equ5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\,{{{{{{\rm{mlp}}}}}}}\,({{{{{{{\bf{x}}}}}}}})={{{{{{{{\bf{W}}}}}}}}}_{2}^{T}\,{{{{{{\rm{ssp}}}}}}}\,\left({{{{{{{{\bf{W}}}}}}}}}_{1}^{T}{{{{{{{\bf{x}}}}}}}}+{{{{{{{{\bf{b}}}}}}}}}_{1}\right)+{{{{{{{{\bf{b}}}}}}}}}_{2}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ5.gif"/></alternatives></disp-formula>with input <inline-formula id="IEq3"><alternatives><mml:math id="IEq3_Math"><mml:mi mathvariant="bold">x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><tex-math id="IEq3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{\bf{x}}}}}}}}\in {{\mathbb{R}}}^{{n}_{i{n}_{1}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq3.gif"/></alternatives></inline-formula>, weights <inline-formula id="IEq4"><alternatives><mml:math id="IEq4_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><tex-math id="IEq4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{W}}}}}}}}}_{1}\in {{\mathbb{R}}}^{{n}_{i{n}_{1}}\times {n}_{i{n}_{2}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq4.gif"/></alternatives></inline-formula>, <inline-formula id="IEq5"><alternatives><mml:math id="IEq5_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><tex-math id="IEq5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{W}}}}}}}}}_{2}\in {{\mathbb{R}}}^{{n}_{i{n}_{2}}\times {n}_{out}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq5.gif"/></alternatives></inline-formula>, and biases <inline-formula id="IEq6"><alternatives><mml:math id="IEq6_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><tex-math id="IEq6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{b}}}}}}}}}_{1}\in {{\mathbb{R}}}^{{n}_{i{n}_{2}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq6.gif"/></alternatives></inline-formula>, <inline-formula id="IEq7"><alternatives><mml:math id="IEq7_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math><tex-math id="IEq7_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{b}}}}}}}}}_{2}\in {{\mathbb{R}}}^{{n}_{out}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq7.gif"/></alternatives></inline-formula>. While this example shows a succession of two linear layers, the notation covers any number of successive linear layers with intermediate shifted softplus activations in the following. The number of layers and neurons as well as all other hyper-parameter choices for our neural network architecture are given in Supplementary Table <xref ref-type="supplementary-material" rid="MOESM1">1</xref>.</p><p id="Par33">The inputs to cG-SchNet when placing atom <italic>i</italic> is a partial molecule consisting of <italic>i</italic> − 1 atoms including two auxiliary tokens (focus and origin) and <italic>k</italic> target properties <bold>Λ</bold> = (<italic>λ</italic><sub>1</sub>, …, <italic>λ</italic><sub><italic>k</italic></sub>). The atoms and tokens are given as tuples of positions <bold>R</bold><sub>≤<italic>i</italic>−1</sub> = (<bold>r</bold><sub>1</sub>, …, <bold>r</bold><sub><italic>i</italic>−1</sub>) with <inline-formula id="IEq8"><alternatives><mml:math id="IEq8_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math><tex-math id="IEq8_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{r}}}}}}}}}_{j}\in {{\mathbb{R}}}^{3}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq8.gif"/></alternatives></inline-formula> and types <bold>Z</bold><sub>≤<italic>i</italic>−1</sub> = (<italic>Z</italic><sub>1</sub>, …, <italic>Z</italic><sub><italic>i</italic>−1</sub>) with <inline-formula id="IEq9"><alternatives><mml:math id="IEq9_Math"><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">N</mml:mi></mml:math><tex-math id="IEq9_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Z}_{j}\in {\mathbb{N}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq9.gif"/></alternatives></inline-formula>. The first two entries correspond to the auxiliary tokens, which are treated like ordinary atoms by the neural network. Thus, whenever we refer to atoms in the following, this also encompasses the tokens. Note that tokens do not influence the sampling probability of a molecule in Eq. (<xref rid="Equ1" ref-type="disp-formula">1</xref>), since they are placed with probability <italic>p</italic>(<bold>R</bold><sub>≤2</sub>, <bold>Z</bold><sub>≤2</sub>∣<bold>Λ</bold>) = 1.</p><p id="Par34">We employ SchNet<sup><xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR67">67</xref></sup> to extract atom-wise features <bold>X</bold><sub>≤<italic>i</italic>−1</sub> = (<bold>x</bold><sub>1</sub>, …, <bold>x</bold><sub><italic>i</italic>−1</sub>) that are invariant to rotation and translation. We use the SchNet representation network as implemented in the SchNetPack software package<sup><xref ref-type="bibr" rid="CR68">68</xref></sup> with <italic>F</italic> = 128 features per atom and 9 interaction blocks.</p><p id="Par35">Additionally, we construct a vector <inline-formula id="IEq10"><alternatives><mml:math id="IEq10_Math"><mml:mi mathvariant="bold">y</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="IEq10_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{\bf{y}}}}}}}}\in {{\mathbb{R}}}^{D}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq10.gif"/></alternatives></inline-formula> of conditional features from the list of target properties. To this end, each target property is first mapped into vector space using an individual embedding network that depends on the form of the specific property. In this work, we employ different embedding networks for scalar-valued properties, vector-valued properties, and atomic composition. Scalar-valued properties are processed by an MLP after applying a Gaussian radial basis function expansion<disp-formula id="Equ6"><label>6</label><alternatives><mml:math id="Equ6_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">scal</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">mlp</mml:mi><mml:mspace width="0.25em"/><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">scal</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>min</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>ω</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>l</mml:mi><mml:mo>≤</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>min</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>ω</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><tex-math id="Equ6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{f}}}}}}}}}_{{{{{{{\rm{scal}}}}}}}}={{{{{{\rm{mlp}}}}}}}\,\left({\left[{e}^{-\frac{{\left({\lambda }_{{{{{{{\rm{scal}}}}}}}}-({\lambda }_{{{{\min}}}}+l{{\Delta }}\omega )\right)}^{2}}{2{{\Delta }}{\omega }^{2}}}\right]}_{0\le l\le \frac{{\lambda }_{{{{\max}}}}-{\lambda }_{{{{\min}}}}}{{{\Delta }}\omega }}\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ6.gif"/></alternatives></disp-formula>where the minimum <italic>λ</italic><sub>min</sub> and maximum <italic>λ</italic><sub>max</sub> property values and the grid spacing Δ<italic>ω</italic> are hyper-parameters chosen per target property. Vector-valued properties such as molecular fingerprints are directly processed by an MLP:<disp-formula id="Equ7"><label>7</label><alternatives><mml:math id="Equ7_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">vec</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">mlp</mml:mi><mml:mspace width="0.25em"/><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">vec</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math><tex-math id="Equ7_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{f}}}}}}}}}_{{{{{{{\rm{vec}}}}}}}}={{{{{{\rm{mlp}}}}}}}\,\left({\lambda }_{{{{{{{\rm{vec}}}}}}}}\right).$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ7.gif"/></alternatives></disp-formula></p><p id="Par36">For the atomic composition, we use two embedding blocks. While the number of atoms is embedded as a scalar property, we map atom types to learnable embeddings <inline-formula id="IEq11"><alternatives><mml:math id="IEq11_Math"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">comp</mml:mi><mml:mspace width="0.25em"/></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="IEq11_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{g}}}}}}}}}_{Z}^{\,{{{{{{\rm{comp}}}}}}}\,}\in {{\mathbb{R}}}^{G}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq11.gif"/></alternatives></inline-formula>. These vectors are weighted by the fraction of the corresponding atom type in the target atomic composition, concatenated, and processed by an MLP. For example, the atomic composition of hydrocarbons would be encoded as:<disp-formula id="Equ8"><label>8</label><alternatives><mml:math id="Equ8_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">comp</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">mlp</mml:mi><mml:mspace width="0.25em"/><mml:mfenced close=")" open="("><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">comp</mml:mi><mml:mspace width="0.25em"/></mml:mrow></mml:msubsup><mml:mo>⊕</mml:mo><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">comp</mml:mi><mml:mspace width="0.25em"/></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math><tex-math id="Equ8_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{f}}}}}}}}}_{{{{{{{\rm{comp}}}}}}}}={{{{{{\rm{mlp}}}}}}}\,\left(\left[{n}_{H}\,{{{{{{{{\bf{g}}}}}}}}}_{H}^{\,{{{{{{\rm{comp}}}}}}}\,}\oplus {n}_{C}\,{{{{{{{{\bf{g}}}}}}}}}_{C}^{\,{{{{{{\rm{comp}}}}}}}\,}\right]\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ8.gif"/></alternatives></disp-formula>where “ ⊕ ” is the concatenation of two vectors and <italic>n</italic><sub><italic>H</italic></sub> and <italic>n</italic><sub><italic>C</italic></sub> is the fraction of hydrogen and carbon atoms in the target atomic composition, respectively. Finally, the property feature vectors <inline-formula id="IEq12"><alternatives><mml:math id="IEq12_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="IEq12_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{f}}}}}}}}}_{{\lambda }_{1}},\ldots ,{{{{{{{{\bf{f}}}}}}}}}_{{\lambda }_{k}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq12.gif"/></alternatives></inline-formula> are aggregated by an MLP<disp-formula id="Equ9"><label>9</label><alternatives><mml:math id="Equ9_Math"><mml:mi mathvariant="bold">y</mml:mi><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">mlp</mml:mi><mml:mspace width="0.25em"/><mml:mfenced close=")" open="("><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>⊕</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>⊕</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><tex-math id="Equ9_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{\bf{y}}}}}}}}=\,{{{{{{\rm{mlp}}}}}}}\,\left(\left[{{{{{{{{\bf{f}}}}}}}}}_{{\lambda }_{1}}\oplus {{{{{{{{\bf{f}}}}}}}}}_{{\lambda }_{2}}\oplus \ldots {{{{{{{{\bf{f}}}}}}}}}_{{\lambda }_{k}}\right]\right),$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ9.gif"/></alternatives></disp-formula>to obtain the combined conditional features <bold>y</bold>.</p><p id="Par37">Given the conditional features <bold>y</bold> representing the target properties and the atom-wise features <bold>X</bold><sub>≤<italic>i</italic>−1</sub> describing the partial molecule, the cG-SchNet architecture predicts distributions for the type of the next atom and its pairwise distances to all preceding atoms with two output networks. Let <inline-formula id="IEq13"><alternatives><mml:math id="IEq13_Math"><mml:msup><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">Z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">all</mml:mi></mml:mrow></mml:msup><mml:mo>⊂</mml:mo><mml:mi mathvariant="double-struck">N</mml:mi></mml:math><tex-math id="IEq13_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\mathcal{Z}}}}}}}}}^{{{{{{{\rm{all}}}}}}}}\subset {\mathbb{N}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq13.gif"/></alternatives></inline-formula> be the set of all atom types in the training data including an additional stop marker type. The type prediction network first computes atom-wise, <inline-formula id="IEq14"><alternatives><mml:math id="IEq14_Math"><mml:mo>∣</mml:mo><mml:msup><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">Z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">all</mml:mi></mml:mrow></mml:msup><mml:mo>∣</mml:mo></mml:math><tex-math id="IEq14_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$| {{{{{{{{\mathcal{Z}}}}}}}}}^{{{{{{{\rm{all}}}}}}}}|$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq14.gif"/></alternatives></inline-formula>-sized vectors<disp-formula id="Equ10"><label>10</label><alternatives><mml:math id="Equ10_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">mlp</mml:mi><mml:mspace width="0.25em"/><mml:mfenced close=")" open="("><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⊕</mml:mo><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mspace width="1.0em"/><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">with</mml:mi><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi>j</mml:mi><mml:mspace width="0.25em"/><mml:mo>&lt;</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi></mml:math><tex-math id="Equ10_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{s}}}}}}}}}_{j}=\,{{{{{{\rm{mlp}}}}}}}\,\left(\left[{{{{{{{{\bf{x}}}}}}}}}_{j}\oplus {{{{{{{\bf{y}}}}}}}}\right]\right)\quad \,{{{{{{\rm{with}}}}}}}\,\,j \, &lt; \, i$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ10.gif"/></alternatives></disp-formula>containing a scalar score for each atom type. Let <inline-formula id="IEq15"><alternatives><mml:math id="IEq15_Math"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math><tex-math id="IEq15_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{s}}}}}}}}}_{j}^{\left[z\right]}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq15.gif"/></alternatives></inline-formula> be the score of type <inline-formula id="IEq16"><alternatives><mml:math id="IEq16_Math"><mml:mi>z</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">Z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">all</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="IEq16_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$z\in {{{{{{{{\mathcal{Z}}}}}}}}}^{{{{{{{\rm{all}}}}}}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq16.gif"/></alternatives></inline-formula> predicted for preceding atom <italic>j</italic>. Then, the probability for the next atom being of type <italic>z</italic> is obtained by taking the softmax over all types and averaging the atom-wise predictions:<disp-formula id="Equ11"><label>11</label><alternatives><mml:math id="Equ11_Math"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>z</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">Z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">all</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:msup><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math><tex-math id="Equ11_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p({Z}_{i}=z| {{{{{{{{\bf{X}}}}}}}}}_{\le i-1},{{{{{{{\bf{y}}}}}}}})=\frac{1}{i-1}\mathop{\sum }\limits_{j=1}^{i-1}\frac{{e}^{{s}_{j}^{\left[z\right]}}}{\mathop{\sum}\limits_{z^{\prime} \in {{{{{{{{\mathcal{Z}}}}}}}}}^{{{{{{{\rm{all}}}}}}}}}{e}^{{s}_{j}^{\left[z^{\prime} \right]}}}.$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ11.gif"/></alternatives></disp-formula></p><p id="Par38">The distance distributions are discretized on a grid with <italic>L</italic> bins, each covering a span of Δ<italic>μ</italic>. The bin of a distance <inline-formula id="IEq17"><alternatives><mml:math id="IEq17_Math"><mml:mi>d</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:math><tex-math id="IEq17_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d\in {{\mathbb{R}}}^{+}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq17.gif"/></alternatives></inline-formula> is given by <inline-formula id="IEq18"><alternatives><mml:math id="IEq18_Math"><mml:mi>b</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>↦</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math><tex-math id="IEq18_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b:{{\mathbb{R}}}^{+}\mapsto \{1,\ldots ,L\}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq18.gif"/></alternatives></inline-formula><disp-formula id="Equ12"><label>12</label><alternatives><mml:math id="Equ12_Math"><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mfenced close="⌉" open="⌈"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mtd><mml:mtd columnalign="left"><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">if</mml:mi><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi>d</mml:mi><mml:mspace width="0.16em"/><mml:mo>≤</mml:mo><mml:mspace width="0.16em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mi>L</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">if</mml:mi><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mi>d</mml:mi><mml:mspace width="0.16em"/><mml:mo>&gt;</mml:mo><mml:mspace width="0.16em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math><tex-math id="Equ12_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b(d)=\left\{\begin{array}{ll}\left\lceil \frac{d+\frac{1}{2}{{\Delta }}\mu }{{{\Delta }}\mu }\right\rceil &amp;\,{{{{{{\rm{if}}}}}}}\,\,\,d \; \le \; (L-1){{\Delta }}\mu \\ L&amp;\,{{{{{{\rm{if}}}}}}}\,\,\,d \; &gt; \; (L-1){{\Delta }}\mu \end{array}\right..$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ12.gif"/></alternatives></disp-formula></p><p id="Par39">Given the type <italic>Z</italic><sub><italic>i</italic></sub> of the next atom, the distance prediction network computes scores for each preceding atom and distance bin<disp-formula id="Equ13"><label>13</label><alternatives><mml:math id="Equ13_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">mlp</mml:mi><mml:mspace width="0.25em"/><mml:mfenced close=")" open="("><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⊙</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">next</mml:mi><mml:mspace width="0.25em"/></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>⊕</mml:mo><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mspace width="1.0em"/><mml:mo>∀</mml:mo><mml:mi>j</mml:mi><mml:mspace width="0.25em"/><mml:mo>&lt;</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi></mml:math><tex-math id="Equ13_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{u}}}}}}}}}_{j}=\,{{{{{{\rm{mlp}}}}}}}\,\left(\left[\left({{{{{{{{\bf{x}}}}}}}}}_{j}\odot {{{{{{{{\bf{g}}}}}}}}}_{{Z}_{i}}^{\,{{{{{{\rm{next}}}}}}}\,}\right)\oplus {{{{{{{\bf{y}}}}}}}}\right]\right)\quad \forall j \, &lt; \, i$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ13.gif"/></alternatives></disp-formula>where “ ⊙ ” is the Hadamard product and <inline-formula id="IEq19"><alternatives><mml:math id="IEq19_Math"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">next</mml:mi><mml:mspace width="0.25em"/></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="IEq19_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{g}}}}}}}}}_{Z}^{\,{{{{{{\rm{next}}}}}}}\,}\in {{\mathbb{R}}}^{F}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq19.gif"/></alternatives></inline-formula> is a learnable atom type embedding. The probability of any distance between the new atom and a preceding atom is obtained by applying a softmax over all bins<disp-formula id="Equ14"><label>14</label><alternatives><mml:math id="Equ14_Math"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mspace width="1.0em"/><mml:mo>∀</mml:mo><mml:mi>j</mml:mi><mml:mspace width="0.25em"/><mml:mo>&lt;</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi></mml:math><tex-math id="Equ14_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p({r}_{ij}=d| {{{{{{{{\bf{x}}}}}}}}}_{j},{{{{{{{\bf{y}}}}}}}},{Z}_{i})=\frac{{e}^{{{{{{{{{\bf{u}}}}}}}}}_{j}^{[b(d)]}}}{\mathop{\sum }\nolimits_{l=1}^{L}{e}^{{{{{{{{{\bf{u}}}}}}}}}_{j}^{[l]}}}\quad \forall j \, &lt; \, i$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ14.gif"/></alternatives></disp-formula>where <inline-formula id="IEq20"><alternatives><mml:math id="IEq20_Math"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math><tex-math id="IEq20_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{u}}}}}}}}}_{j}^{[b(d)]}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq20.gif"/></alternatives></inline-formula> is the score of bin <italic>b</italic>(<italic>d</italic>) predicted for preceding atom <italic>j</italic>.</p></sec><sec id="Sec12"><title>Sampling atom placement sequences for training</title><p id="Par40">The number of sequences in which a molecule can be built by placing <italic>n</italic> atoms grows factorially with <italic>n</italic>. During training, we randomly sample a new atom placement sequence for every training molecule in each epoch. However, we use the focus and origin tokens to constrain how molecules are built by cG-SchNet and thus significantly reduce the number of possible sequences. Our approach ensures that molecules tend to grow outwards starting from the center of mass and that each new atom is placed close to one of the already placed atoms. For the first atom placement step, we set the positions of the focus and origin tokens to the center of mass of the training molecule and choose the atom closest to it as the first atom to be placed. If multiple atoms are equally close, one of them is randomly chosen as the first atom.</p><p id="Par41">Afterwards, each atom placement step follows the same procedure. One of the already placed atoms (excluding tokens) is chosen as focus, i.e., the position of the focus token is set to the position of the chosen atom. Then, from all unplaced atoms, we select the neighbor of the focus that is closest to the center of mass as the next atom. If there are no neighbors of the focus among the unplaced atoms, we insert a step where the type prediction network shall predict the stop marker type. In this way, the focus atom is marked as finished before randomly choosing a new focus and proceeding with the next atom placement step. Marked atoms cannot be chosen as focus anymore and the atom placement sequence is complete when all placed atoms are marked as finished. Thus, the sequence ends up with 2<italic>n</italic> steps, as each atom needs to be placed and furthermore marked as finished.</p><p id="Par42">For our experiments, we consider atoms sharing a bond as neighbors. However, note that bonding information is not necessarily required as neighborhood can also be defined by a radial cutoff of, e.g., 3 Å centered on the focus atom.</p></sec><sec id="Sec13"><title>Neural network training</title><p id="Par43">We use mini-batches with <italic>M</italic> molecules for training. Each mini-batch contains one atom placement sequence per molecule, randomly sampled in each epoch as explained in Section Sampling atom placement sequences for training. Each step of the atom placement sequence <inline-formula id="IEq21"><alternatives><mml:math id="IEq21_Math"><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq21_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a\in {{{{{{{{\mathcal{A}}}}}}}}}_{m}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq21.gif"/></alternatives></inline-formula> consists of types <bold>Z</bold><sub>≤<italic>i</italic>−1</sub> and positions <bold>R</bold><sub>≤<italic>i</italic>−1</sub> of already placed atoms and the two auxiliary tokens, of the values <bold>Λ</bold> of molecule <italic>m</italic> for the target properties of the model, and of the type <italic>Z</italic><sub>next</sub> and position <bold>r</bold><sub>next</sub> of the next atom.</p><p id="Par44">For each atom placement, we minimize the cross-entropy between the distributions predicted by the model given <bold>Z</bold><sub>≤<italic>i</italic>−1</sub>, <bold>R</bold><sub>≤<italic>i</italic>−1</sub>, and <bold>Λ</bold> and the distributions obtained from the ground-truth next type <italic>Z</italic><sub>next</sub> and position <bold>r</bold><sub>next</sub>. The ground-truth distribution of the next type is a one-hot encoding of <italic>Z</italic><sub>next</sub>, thus the cross-entropy loss for the type distributions is<disp-formula id="Equ15"><label>15</label><alternatives><mml:math id="Equ15_Math"><mml:msup><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">type</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">next</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math><tex-math id="Equ15_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\ell }^{{{{{{{\rm{type}}}}}}}}(a)=-\log \left(p\left({Z}_{i}={Z}_{{{{{{{\rm{next}}}}}}}}| {{{{{{{{\bf{X}}}}}}}}}_{\le i-1},{{{{{{{\bf{y}}}}}}}}\right)\right).$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ15.gif"/></alternatives></disp-formula></p><p id="Par45">The average cross-entropy loss for the distance distributions is<disp-formula id="Equ16"><label>16</label><alternatives><mml:math id="Equ16_Math"><mml:msup><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">dist</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">next</mml:mi><mml:mspace width="0.25em"/></mml:mrow></mml:msubsup><mml:mi>log</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">next</mml:mi><mml:mspace width="0.25em"/></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math><tex-math id="Equ16_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\ell }^{{{{{{{\rm{dist}}}}}}}}(a)=-\frac{1}{i-1}\mathop{\sum }\limits_{j=1}^{i-1}\mathop{\sum }\limits_{l=0}^{L-1}{{{{{{{{\bf{q}}}}}}}}}_{jl}^{\,{{{{{{\rm{next}}}}}}}\,}\log \left({{{{{{{{\bf{p}}}}}}}}}_{jl}^{\,{{{{{{\rm{next}}}}}}}\,}\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ16.gif"/></alternatives></disp-formula>with model predictions<disp-formula id="Equ17"><label>17</label><alternatives><mml:math id="Equ17_Math"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">next</mml:mi><mml:mspace width="0.25em"/></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><tex-math id="Equ17_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{p}}}}}}}}}_{jl}^{\,{{{{{{\rm{next}}}}}}}\,}=p\left({r}_{ij}=l{{\Delta }}\mu | {{{{{{{{\bf{x}}}}}}}}}_{j},{{{{{{{\bf{y}}}}}}}},{Z}_{i}\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ17.gif"/></alternatives></disp-formula>and Gaussian expanded ground-truth distance<disp-formula id="Equ18"><label>18</label><alternatives><mml:math id="Equ18_Math"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">q</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">next</mml:mi><mml:mspace width="0.25em"/></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mo>∣</mml:mo><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">next</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mo>∣</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>l</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mo>∣</mml:mo><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">next</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mo>∣</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math><tex-math id="Equ18_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{q}}}}}}}}}_{jl}^{\,{{{{{{\rm{next}}}}}}}\,}=\frac{{e}^{-\gamma {\left(| | {{{{{{{{\bf{r}}}}}}}}}_{{{{{{{\rm{next}}}}}}}}-{{{{{{{{\bf{r}}}}}}}}}_{j}| {| }_{2}-l{{\Delta }}\mu \right)}^{2}}}{\mathop{\sum }\nolimits_{l^{\prime} =0}^{L-1}{e}^{-\gamma {\left(| | {{{{{{{{\bf{r}}}}}}}}}_{{{{{{{\rm{next}}}}}}}}-{{{{{{{{\bf{r}}}}}}}}}_{j}| {| }_{2}-l^{\prime} {{\Delta }}\mu \right)}^{2}}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ18.gif"/></alternatives></disp-formula>where <italic>L</italic> is the number of bins of the distance probability grid with spacing Δ<italic>μ</italic>. The width of the Gaussian expansion can be tuned with <italic>γ</italic>, which we set to <inline-formula id="IEq22"><alternatives><mml:math id="IEq22_Math"><mml:mfrac><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="IEq22_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{10}{{{\Delta }}\mu }$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq22.gif"/></alternatives></inline-formula> in our experiments.</p><p id="Par46">The loss for a mini-batch <italic>C</italic> is the average type and distance loss of all atom placement steps of all <italic>M</italic> molecules in the mini-batch:<disp-formula id="Equ19"><label>19</label><alternatives><mml:math id="Equ19_Math"><mml:mi>ℓ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">type</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">dist</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>0.5</mml:mn><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math><tex-math id="Equ19_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\ell (C)=\frac{1}{M}\mathop{\sum }\limits_{m=1}^{M}\mathop{\sum}\limits_{a\in {{{{{{{{\mathcal{A}}}}}}}}}_{m}}\left(\frac{{\ell }^{{{{{{{\rm{type}}}}}}}}(a)}{| {{{{{{{{\mathcal{A}}}}}}}}}_{m}| }+\frac{\delta (a){\ell }^{{{{{{{\rm{dist}}}}}}}}(a)}{0.5| {{{{{{{{\mathcal{A}}}}}}}}}_{m}| }\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ19.gif"/></alternatives></disp-formula>where <inline-formula id="IEq23"><alternatives><mml:math id="IEq23_Math"><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo></mml:math><tex-math id="IEq23_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$| {{{{{{{{\mathcal{A}}}}}}}}}_{m}|$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq23.gif"/></alternatives></inline-formula> is the number of steps in sequence <inline-formula id="IEq24"><alternatives><mml:math id="IEq24_Math"><mml:msub><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">A</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq24_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\mathcal{A}}}}}}}}}_{m}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq24.gif"/></alternatives></inline-formula> and<disp-formula id="Equ20"><label>20</label><alternatives><mml:math id="Equ20_Math"><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn><mml:mspace width="1.0em"/></mml:mtd><mml:mtd columnalign="left"><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">if</mml:mi><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">next</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">STOP</mml:mi><mml:mspace width="0.25em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mn>1</mml:mn><mml:mspace width="1.0em"/></mml:mtd><mml:mtd columnalign="left"><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">else</mml:mi><mml:mspace width="0.25em"/><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math><tex-math id="Equ20_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta (a)=\left\{\begin{array}{ll}0\quad &amp;\,{{{{{{\rm{if}}}}}}}\,\,\,{Z}_{{{{{{{\rm{next}}}}}}}}={{{{{{\rm{STOP}}}}}}}\,\\ 1\quad &amp;\,{{{{{{\rm{else}}}}}}}\,.\hfill\end{array}\right.$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ20.gif"/></alternatives></disp-formula>The indicator function <italic>δ</italic> is zero for steps where the type to predict is the stop marker, since no position is predicted in these steps.</p><p id="Par47">The neural networks were trained with stochastic gradient descent using the ADAM optimizer<sup><xref ref-type="bibr" rid="CR69">69</xref></sup>. We start with a learning rate <italic>η</italic> = 10<sup>−4</sup> which is reduced using a decay factor of 0.5 after 10 epochs without improvement of the validation loss. The training is stopped at <italic>η</italic> ≤ 10<sup>−6</sup>. We use mini-batches of 5 molecules and the model with the lowest validation error is selected for generation.</p></sec><sec id="Sec14"><title>Conditional generation of molecules</title><p id="Par48">For the generation of molecules, conditions need to be specified covering all target properties the model was trained on, e.g., the atomic composition and the relative atomic energy. The generation is an iterative process where the type and position of each atom are sampled sequentially using the distributions predicted by cG-SchNet. Generating a molecule with <italic>n</italic> atoms takes 2<italic>n</italic> steps, as each atom needs to be placed and furthermore marked as finished in order to terminate the generation process.</p><p id="Par49">At each step, we want to sample the type <inline-formula id="IEq25"><alternatives><mml:math id="IEq25_Math"><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">next</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">Z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">all</mml:mi></mml:mrow></mml:msup><mml:mo>⊂</mml:mo><mml:mi mathvariant="double-struck">N</mml:mi></mml:math><tex-math id="IEq25_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Z}_{{{{{{{\rm{next}}}}}}}}\in {{{{{{{{\mathcal{Z}}}}}}}}}^{{{{{{{\rm{all}}}}}}}}\subset {\mathbb{N}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq25.gif"/></alternatives></inline-formula> and position <inline-formula id="IEq26"><alternatives><mml:math id="IEq26_Math"><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">next</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="bold">G</mml:mi><mml:mo>⊂</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math><tex-math id="IEq26_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{r}}}}}}}}}_{{{{{{{\rm{next}}}}}}}}\in {{{{{{{\bf{G}}}}}}}}\subset {{\mathbb{R}}}^{3}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq26.gif"/></alternatives></inline-formula> of the next atom given the types and positions of already placed atoms (including the two tokens) and the conditions. Here, <inline-formula id="IEq27"><alternatives><mml:math id="IEq27_Math"><mml:msup><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">Z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">all</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="IEq27_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\mathcal{Z}}}}}}}}}^{{{{{{{\rm{all}}}}}}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_IEq27.gif"/></alternatives></inline-formula> is the set of all atom types in the training data including an additional stop marker type and <bold>G</bold> is a grid of candidate positions in 3d space (see Supplementary Methods <xref ref-type="supplementary-material" rid="MOESM1">1)</xref>. An unfinished atom is randomly chosen as focus at the start of each step, i.e., the position of the focus token is aligned with the position of the chosen atom. Then, we predict the distribution of the type of the next atom with the model (see Eq. (<xref rid="Equ11" ref-type="disp-formula">11</xref>)) to sample the next type<disp-formula id="Equ21"><label>21</label><alternatives><mml:math id="Equ21_Math"><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">next</mml:mi></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">next</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math><tex-math id="Equ21_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Z}_{{{{{{{\rm{next}}}}}}}} \sim p\left({Z}_{i}={Z}_{{{{{{{\rm{next}}}}}}}}| {{{{{{{{\bf{X}}}}}}}}}_{\le i-1},{{{{{{{\bf{y}}}}}}}}\right).$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ21.gif"/></alternatives></disp-formula></p><p id="Par50">If the next type is the stop marker, we mark the currently focused atom as finished and proceed with the next step by choosing a new focus without sampling a position. Otherwise, we proceed to predict the distance distributions between placed atoms and the next atom with the model (see Eq. (<xref rid="Equ14" ref-type="disp-formula">14</xref>)). Since cG-SchNet is trained to place atoms in close proximity to the focused atom, we align the local grid of candidate positions with the focus at each step regardless of the number of atoms in the unfinished molecule. Then, the distance probabilities are aggregated to compute the distribution over 3d candidate positions in the proximity of the focus. The position of the next atom is drawn accordingly<disp-formula id="Equ22"><label>22</label><alternatives><mml:math id="Equ22_Math"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">next</mml:mi><mml:mspace width="0.25em"/></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>~</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∏</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>∣</mml:mo><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">next</mml:mi><mml:mspace width="0.25em"/></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mo>∣</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold">y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><tex-math id="Equ22_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{r}}}}}}}}}_{\,{{{{{{\rm{next}}}}}}}\,}^{\prime} \sim \frac{1}{\alpha }\mathop{\prod }\limits_{j=1}^{i-1}p\left({r}_{ij}=| | {{{{{{{{\bf{r}}}}}}}}}_{j}-{{{{{{{{\bf{r}}}}}}}}}_{\,{{{{{{\rm{next}}}}}}}\,}^{\prime}| {| }_{2}| {{{{{{{{\bf{x}}}}}}}}}_{j},{{{{{{{\bf{y}}}}}}}},{Z}_{i}\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ22.gif"/></alternatives></disp-formula>with<disp-formula id="Equ23"><label>23</label><alternatives><mml:math id="Equ23_Math"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">next</mml:mi><mml:mspace width="0.25em"/></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">next</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">focus</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="Equ23_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{{{{\bf{r}}}}}}}}}_{\,{{{{{{\rm{next}}}}}}}\,}^{\prime}={{{{{{{{\bf{r}}}}}}}}}_{{{{{{{\rm{next}}}}}}}}+{{{{{{{{\bf{r}}}}}}}}}_{{{{{{{\rm{focus}}}}}}}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_28526_Article_Equ23.gif"/></alternatives></disp-formula>where <italic>α</italic> is the normalization constant and <bold>r</bold><sub>focus</sub> is the position of the focus token. At the very first atom placement step, we center the focus and grid on the origin token, while for the remaining steps, only atoms will be focused.</p><p id="Par51">The generation process terminates when all regular atoms have been marked as finished. In this work, we limit the model to a maximum number of 35 atoms. If the model attempts to place more atoms, the generation terminates and the molecule is marked as invalid.</p></sec><sec id="Sec15"><title>Checking validity and uniqueness of generated molecules</title><p id="Par52">We use Open Babel<sup><xref ref-type="bibr" rid="CR57">57</xref></sup> to assess the validity of generated molecules. Open Babel assigns bonds and bond orders between atoms to translate the generated 3d representation of atom positions and types into a molecular graph. We check if the valence constraints hold for all atoms in the molecular graph and mark the molecule as invalid if not. Furthermore, the generated structure is considered invalid if it consists of multiple disconnected graphs. We found that Open Babel may struggle to assign correct bond orders even for training molecules if they contain aromatic sub-structures made of nitrogen and carbon. Thus, we use the same custom heuristic as in previous G-SchNet work<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> that catches these cases and checks whether a correct bond order can be found. The corresponding code is publicly available (see Code availability).</p><p id="Par53">The uniqueness of generated molecules is checked using their canonical SMILES<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> string representation obtained from the molecular graph with Open Babel. If two molecules share the same string, they are considered to be equal, i.e., non-unique. Furthermore, we check the canonical SMILES string of mirror images of generated structures, which means that mirror-image stereoisomers (enantiomers) are considered to be the same molecule in our statistics. In case of duplicates, we keep the molecule sampled first, with the exception of the search for C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers, where we keep the structure with the lowest predicted relative atomic energy. Molecules from the training and test data are matched with generated structures in the same way, using their canonical SMILES representations obtained with Open Babel and the custom heuristic for bond order assignment. In general, we use isomeric SMILES strings that encode information about the stereochemistry of 3d structures. Only in the search for C<sub>7</sub>O<sub>2</sub>H<sub>10</sub> isomers, we also compare non-isomeric canonical SMILES obtained with RDKit<sup><xref ref-type="bibr" rid="CR70">70</xref></sup> in order to identify novel stereoisomers, i.e., structures that share the same non-isomeric SMILES representation but differ in the isomeric variant.</p></sec><sec id="Sec16"><title>Prediction of property values of generated molecules</title><p id="Par54">We use pretrained SchNet<sup><xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR67">67</xref></sup> models from SchNetPack<sup><xref ref-type="bibr" rid="CR68">68</xref></sup> to predict the HOMO-LUMO gap, isotropic polarizability, and internal energy at zero Kelvin of generated molecules. The reported mean absolute error (MAE) of these models is 0.074 eV, 0.124 Bohr<sup>3</sup>, and 0.012 eV, respectively. The predicted values are used to plot the distributions of the respective property in Fig. <xref rid="Fig1" ref-type="fig">1</xref>b, Fig. <xref rid="Fig3" ref-type="fig">3</xref>b, and Fig. <xref rid="Fig4" ref-type="fig">4</xref>a. We relax generated molecules for every experiment in order to assess how close they are to equilibrium configurations and to calculate the MAE between predictions for generated, unrelaxed structures and the computed ground-truth property value of the relaxed structure. The relaxation procedure is described in Supplementary Methods <xref ref-type="supplementary-material" rid="MOESM1">4</xref>, where furthermore a table with the results can be found (Supplementary Table <xref ref-type="supplementary-material" rid="MOESM1">2)</xref>. For the statistics depicted in Fig. <xref rid="Fig4" ref-type="fig">4</xref>b-d and Fig. <xref rid="Fig5" ref-type="fig">5</xref>, we use the property values computed during relaxation instead of predictions from SchNet models.</p></sec></sec></body><back><ack><title>Acknowledgements</title><p>N.W.A.G. and M.G. work at the BASLEARN—TU Berlin/BASF Joint Lab for Machine Learning, co-financed by TU Berlin and BASF SE. N.W.A.G., K.T.S., S.S.P.H., and K.R.M. acknowledge support by the Federal Ministry of Education and Research (BMBF) for the Berlin Institute for the Foundations of Learning and Data (BIFOLD) (01IS18037A). K.R.M. acknowledges financial support under the Grants 01IS14013A-E, 01GQ1115, and 01GQ0850; Deutsche Forschungsgemeinschaft (DFG) under Grant Math+, EXC 2046/1, Project ID 390685689 and K.R.M. was partly supported by the Institute of Information &amp; Communications Technology Planning &amp; Evaluation (IITP) grants funded by the Korea Government (No. 2019-0-00079, Artificial Intelligence Graduate School Program, Korea University).</p></ack><sec sec-type="author-contribution"><title>Author contributions</title><p>N.W.A.G. developed the method and carried out the experiments. M.G. carried out the reference computations and simulations. S.S.P.H. trained the neural networks for predictions of molecular properties. N.W.A.G., M.G., K.R.M., and K.T.S. designed the experiments and analyses. N.W.A.G., M.G., and K.T.S. wrote the paper. All authors discussed results and contributed to the final version of the manuscript.</p></sec><sec sec-type="peer-review"><title>Peer review</title><sec id="FPar1"><title>Peer review information</title><p id="Par55"><italic>Nature Communications</italic> thanks the anonymous reviewers for their contribution to the peer review of this work. Peer reviewer reports are available.</p></sec></sec><sec><title>Funding</title><p>Open Access funding enabled and organized by Projekt DEAL.</p></sec><sec sec-type="data-availability"><title>Data availability</title><p>The molecules generated with cG-SchNet are available at <ext-link xlink:href="http://www.github.com/atomistic-machine-learning/cG-SchNet" ext-link-type="uri">www.github.com/atomistic-machine-learning/cG-SchNet</ext-link>(DOI 10.5281/zenodo.5907027<sup><xref ref-type="bibr" rid="CR71">71</xref></sup>). The QM9 dataset is available under DOI 10.6084/m9.figshare.978904. The set of molecules with small HOMO-LUMO gap generated by biased G-SchNet is available at <ext-link xlink:href="http://quantum-machine.org/datasets" ext-link-type="uri">http://quantum-machine.org/datasets</ext-link>.</p></sec><sec sec-type="data-availability"><title>Code availability</title><p>The code for cG-SchNet is available at <ext-link xlink:href="http://www.github.com/atomistic-machine-learning/cG-SchNet" ext-link-type="uri">www.github.com/atomistic-machine-learning/cG-SchNet</ext-link>(DOI 10.5281/zenodo.5907027<sup><xref ref-type="bibr" rid="CR71">71</xref></sup>). This includes the routines for training and deploying the model, for filtering generated structures, all hyper-parameter settings used in our experiments, and the splits of the data employed to train the reported models.</p></sec><sec sec-type="ethics-statement"><sec id="FPar2" sec-type="COI-statement"><title>Competing interests</title><p id="Par56">The authors declare no competing interests.</p></sec></sec><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hajduk</surname><given-names>PJ</given-names></name><name><surname>Greer</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">A decade of fragment-based drug design: Strategic advances and lessons learned</article-title><source>Nat. Rev. Drug Discov.</source><year>2007</year><volume>6</volume><fpage>211</fpage><lpage>219</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD2sXit12rtr4%3D</pub-id><pub-id pub-id-type="pmid">17290284</pub-id><pub-id pub-id-type="doi">10.1038/nrd2220</pub-id></mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mandal</surname><given-names>S</given-names></name><name><surname>Moudgil</surname><given-names>M</given-names></name><name><surname>Mandal</surname><given-names>SK</given-names></name></person-group><article-title xml:lang="en">Rational drug design</article-title><source>Eur. J. Pharmacol</source><year>2009</year><volume>625</volume><fpage>90</fpage><lpage>100</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD1MXhsVGmtb%2FF</pub-id><pub-id pub-id-type="pmid">19835861</pub-id><pub-id pub-id-type="doi">10.1016/j.ejphar.2009.06.065</pub-id></mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gantzer</surname><given-names>P</given-names></name><name><surname>Creton</surname><given-names>B</given-names></name><name><surname>Nieto-Draghi</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Inverse-QSPR for de novo design: A review</article-title><source>Mol. Inf.</source><year>2020</year><volume>39</volume><fpage>1900087</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXit1aisL7O</pub-id><pub-id pub-id-type="doi">10.1002/minf.201900087</pub-id></mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeze</surname><given-names>JG</given-names></name><name><surname>Kelly</surname><given-names>HR</given-names></name><name><surname>Batista</surname><given-names>VS</given-names></name></person-group><article-title xml:lang="en">Search for catalysts by inverse design: Artificial intelligence, mountain climbers, and alchemists</article-title><source>Chem. Rev.</source><year>2019</year><volume>119</volume><fpage>6595</fpage><lpage>6612</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXosl2rt7w%3D</pub-id><pub-id pub-id-type="pmid">31059236</pub-id><pub-id pub-id-type="doi">10.1021/acs.chemrev.8b00759</pub-id></mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>K</given-names></name><name><surname>Meng</surname><given-names>YS</given-names></name><name><surname>Breger</surname><given-names>J</given-names></name><name><surname>Grey</surname><given-names>CP</given-names></name><name><surname>Ceder</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Electrodes with high power and high capacity for rechargeable lithium batteries</article-title><source>Science</source><year>2006</year><volume>311</volume><fpage>977</fpage><lpage>980</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2006Sci...311..977K</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD28XhsFSmsLo%3D</pub-id><pub-id pub-id-type="pmid">16484487</pub-id><pub-id pub-id-type="doi">10.1126/science.1122152</pub-id></mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hautier</surname><given-names>G</given-names></name><etal/></person-group><article-title xml:lang="en">Novel mixed polyanions lithium-ion battery cathode materials predicted by high-throughput ab initio computations</article-title><source>J. Mater. Chem.</source><year>2011</year><volume>21</volume><fpage>17147</fpage><lpage>17153</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3MXhtlKgtLrI</pub-id><pub-id pub-id-type="doi">10.1039/c1jm12216a</pub-id></mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scharber</surname><given-names>MC</given-names></name><etal/></person-group><article-title xml:lang="en">Design rules for donors in bulk-heterojunction solar cells–towards 10% energy-conversion efficiency</article-title><source>Adv. Mater.</source><year>2006</year><volume>18</volume><fpage>789</fpage><lpage>794</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD28XjsV2isrw%3D</pub-id><pub-id pub-id-type="doi">10.1002/adma.200501717</pub-id></mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>L</given-names></name><name><surname>Kokenyesi</surname><given-names>RS</given-names></name><name><surname>Keszler</surname><given-names>DA</given-names></name><name><surname>Zunger</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Inverse design of high absorption thin-film photovoltaic materials</article-title><source>Adv. Energy Mater.</source><year>2013</year><volume>3</volume><fpage>43</fpage><lpage>48</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3sXhsFKhsb4%3D</pub-id><pub-id pub-id-type="doi">10.1002/aenm.201200538</pub-id></mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butler</surname><given-names>KT</given-names></name><name><surname>Davies</surname><given-names>DW</given-names></name><name><surname>Cartwright</surname><given-names>H</given-names></name><name><surname>Isayev</surname><given-names>O</given-names></name><name><surname>Walsh</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Machine learning for molecular and materials science</article-title><source>Nature</source><year>2018</year><volume>559</volume><fpage>547</fpage><lpage>555</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018Natur.559..547B</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXhtl2jt7vL</pub-id><pub-id pub-id-type="pmid">30046072</pub-id><pub-id pub-id-type="doi">10.1038/s41586-018-0337-2</pub-id></mixed-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>von Lilienfeld</surname><given-names>OA</given-names></name><name><surname>Müller</surname><given-names>K-R</given-names></name><name><surname>Tkatchenko</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Exploring chemical compound space with quantum-based machine learning</article-title><source>Nat. Rev. Chem.</source><year>2020</year><volume>4</volume><fpage>347</fpage><lpage>358</lpage><pub-id pub-id-type="doi">10.1038/s41570-020-0189-9</pub-id></mixed-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="other">Schüttet, K. et al. <italic>Machine Learning Meets Quantum Physics</italic>, volume 968 of Lecture Notes in Physics (Springer International Publishing, 2020).</mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Unke</surname><given-names>OT</given-names></name><etal/></person-group><article-title xml:lang="en">Machine learning force fields</article-title><source>Chem. Rev.</source><year>2021</year><volume>121</volume><fpage>10142</fpage><lpage>10186</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXmtVOksL0%3D</pub-id><pub-id pub-id-type="pmid">33705118</pub-id><pub-id pub-id-type="pmcid">8391964</pub-id><pub-id pub-id-type="doi">10.1021/acs.chemrev.0c01111</pub-id></mixed-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westermayr</surname><given-names>J</given-names></name><name><surname>Gastegger</surname><given-names>M</given-names></name><name><surname>Schütt</surname><given-names>KT</given-names></name><name><surname>Maurer</surname><given-names>RJ</given-names></name></person-group><article-title xml:lang="en">Perspective on integrating machine learning into computational chemistry and materials science</article-title><source>J. Chem. Phys.</source><year>2021</year><volume>154</volume><fpage>230903</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2021JChPh.154w0903W</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXhtl2jsb%2FJ</pub-id><pub-id pub-id-type="pmid">34241249</pub-id><pub-id pub-id-type="doi">10.1063/5.0047760</pub-id></mixed-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ceriotti</surname><given-names>M</given-names></name><name><surname>Clementi</surname><given-names>C</given-names></name><name><surname>Anatole von Lilienfeld</surname><given-names>O</given-names></name></person-group><article-title xml:lang="en">Machine learning meets chemical physics</article-title><source>J. Chem. Phys.</source><year>2021</year><volume>154</volume><fpage>160401</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2021JChPh.154p0401C</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXps1Grtb8%3D</pub-id><pub-id pub-id-type="pmid">33940847</pub-id><pub-id pub-id-type="doi">10.1063/5.0051418</pub-id></mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keith</surname><given-names>JA</given-names></name><etal/></person-group><article-title xml:lang="en">Combining machine learning and computational chemistry for predictive insights into chemical systems</article-title><source>Chem. Rev.</source><year>2021</year><volume>121</volume><fpage>9816</fpage><lpage>9872</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXhsVOrtr3J</pub-id><pub-id pub-id-type="pmid">34232033</pub-id><pub-id pub-id-type="pmcid">8391798</pub-id><pub-id pub-id-type="doi">10.1021/acs.chemrev.1c00107</pub-id></mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behler</surname><given-names>J</given-names></name><name><surname>Parrinello</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Generalized neural-network representation of high-dimensional potential-energy surfaces</article-title><source>Phys. Rev. Lett.</source><year>2007</year><volume>98</volume><fpage>146401</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2007PhRvL..98n6401B</pub-id><pub-id pub-id-type="pmid">17501293</pub-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.98.146401</pub-id></mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rupp</surname><given-names>M</given-names></name><name><surname>Tkatchenko</surname><given-names>A</given-names></name><name><surname>Müller</surname><given-names>K-R</given-names></name><name><surname>Von Lilienfeld</surname><given-names>OA</given-names></name></person-group><article-title xml:lang="en">Fast and accurate modeling of molecular atomization energies with machine learning</article-title><source>Phys. Rev. Lett.</source><year>2012</year><volume>108</volume><fpage>058301</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2012PhRvL.108e8301R</pub-id><pub-id pub-id-type="pmid">22400967</pub-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.108.058301</pub-id></mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schütt</surname><given-names>KT</given-names></name><name><surname>Arbabzadah</surname><given-names>F</given-names></name><name><surname>Chmiela</surname><given-names>S</given-names></name><name><surname>Müller</surname><given-names>KR</given-names></name><name><surname>Tkatchenko</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Quantum-chemical insights from deep tensor neural networks</article-title><source>Nat. Commun.</source><year>2017</year><volume>8</volume><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2017NatCo...813890S</pub-id><pub-id pub-id-type="pmid">28067221</pub-id><pub-id pub-id-type="pmcid">5228054</pub-id><pub-id pub-id-type="doi">10.1038/ncomms13890</pub-id></mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O. &amp; Dahl, G. E. Neural message passing for quantum chemistry. In <italic>Proc. 34th International Conference on Machine Learning</italic>, volume 70 of <italic>Proceedings of Machine Learning Research</italic>, pages 1263–1272 (PMLR, 2017).</mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>JS</given-names></name><name><surname>Isayev</surname><given-names>O</given-names></name><name><surname>Roitberg</surname><given-names>AE</given-names></name></person-group><article-title xml:lang="en">ANI-1: An extensible neural network potential with DFT accuracy at force field computational cost</article-title><source>Chem. Sci.</source><year>2017</year><volume>8</volume><fpage>3192</fpage><lpage>3203</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXitlGnsrs%3D</pub-id><pub-id pub-id-type="pmid">28507695</pub-id><pub-id pub-id-type="pmcid">5414547</pub-id><pub-id pub-id-type="doi">10.1039/C6SC05720A</pub-id></mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schütt</surname><given-names>KT</given-names></name><name><surname>Sauceda</surname><given-names>HE</given-names></name><name><surname>Kindermans</surname><given-names>P-J</given-names></name><name><surname>Tkatchenko</surname><given-names>A</given-names></name><name><surname>Müller</surname><given-names>K-R</given-names></name></person-group><article-title xml:lang="en">SchNet—A deep learning architecture for molecules and materials</article-title><source>J. Chem. Phys.</source><year>2018</year><volume>148</volume><fpage>241722</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018JChPh.148x1722S</pub-id><pub-id pub-id-type="pmid">29960322</pub-id><pub-id pub-id-type="doi">10.1063/1.5019779</pub-id></mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chmiela</surname><given-names>S</given-names></name><name><surname>Sauceda</surname><given-names>HE</given-names></name><name><surname>Müller</surname><given-names>K-R</given-names></name><name><surname>Tkatchenko</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Towards exact molecular dynamics simulations with machinelearned force fields</article-title><source>Nat. Commun.</source><year>2018</year><volume>9</volume><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018NatCo...9.3887C</pub-id><pub-id pub-id-type="pmid">30250077</pub-id><pub-id pub-id-type="pmcid">6155327</pub-id><pub-id pub-id-type="doi">10.1038/s41467-018-06169-2</pub-id></mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Unke</surname><given-names>OT</given-names></name><name><surname>Meuwly</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">PhysNet: A neural network for predicting energies, forces, dipole moments, and partial charges</article-title><source>J. Chem. Theory Comput.</source><year>2019</year><volume>15</volume><fpage>3678</fpage><lpage>3693</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXosF2ms7g%3D</pub-id><pub-id pub-id-type="pmid">31042390</pub-id><pub-id pub-id-type="doi">10.1021/acs.jctc.9b00181</pub-id></mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Klicpera, J., Groß, J. &amp; Günnemann, S. Directional message passing for molecular graphs. In <italic>International Conference on Learning Representations (ICLR)</italic><ext-link xlink:href="https://openreview.net/forum?id=B1eWbxStPH" ext-link-type="uri">https://openreview.net/forum?id=B1eWbxStPH</ext-link> (2020).</mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christensen</surname><given-names>AS</given-names></name><name><surname>Bratholm</surname><given-names>LA</given-names></name><name><surname>Faber</surname><given-names>FA</given-names></name><name><surname>Anatole von Lilienfeld</surname><given-names>O</given-names></name></person-group><article-title xml:lang="en">FCHL revisited: Faster and more accurate quantum machine learning</article-title><source>J. Chem. Phys.</source><year>2020</year><volume>152</volume><fpage>044107</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2020JChPh.152d4107C</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXitVOlsLY%3D</pub-id><pub-id pub-id-type="pmid">32007071</pub-id><pub-id pub-id-type="doi">10.1063/1.5126701</pub-id></mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Batzner</surname><given-names>S</given-names></name><etal/></person-group><article-title xml:lang="en">E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials</article-title><source>arXiv preprint arXiv</source><year>2021</year><volume>2101</volume><fpage>03164</fpage></mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Schütt, K., Unke, O. &amp; Gastegger, M. Equivariant message passing for the prediction of tensorial properties and molecular spectra. In <italic>Proc. 38th International Conference on Machine Learning</italic>, volume 139 of <italic>Proceedings of Machine Learning Research</italic>, pages 9377–9388 (PMLR, 2021).</mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zunger</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Inverse design in search of materials with target functionalities</article-title><source>Nat. Rev. Chem.</source><year>2018</year><volume>2</volume><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1038/s41570-018-0121</pub-id></mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanchez-Lengeling</surname><given-names>B</given-names></name><name><surname>Aspuru-Guzik</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Inverse molecular design using machine learning: Generative models for matter engineering</article-title><source>Science</source><year>2018</year><volume>361</volume><fpage>360</fpage><lpage>365</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018Sci...361..360S</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXhtlyitr3L</pub-id><pub-id pub-id-type="pmid">30049875</pub-id><pub-id pub-id-type="doi">10.1126/science.aat2663</pub-id></mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weininger</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules</article-title><source>J. Chem. Inf. Comput. Sci.</source><year>1988</year><volume>28</volume><fpage>31</fpage><lpage>36</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DyaL1cXnsVeqsA%3D%3D</pub-id><pub-id pub-id-type="doi">10.1021/ci00057a005</pub-id></mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elton</surname><given-names>DC</given-names></name><name><surname>Boukouvalas</surname><given-names>Z</given-names></name><name><surname>Fuge</surname><given-names>MD</given-names></name><name><surname>Chung</surname><given-names>PW</given-names></name></person-group><article-title xml:lang="en">Deep learning for molecular design–a review of the state of the art</article-title><source>Mol. Syst. Des. Eng</source><year>2019</year><volume>4</volume><fpage>828</fpage><lpage>849</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXhtVWktLjN</pub-id><pub-id pub-id-type="doi">10.1039/C9ME00039A</pub-id></mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mansimov</surname><given-names>E</given-names></name><name><surname>Mahmood</surname><given-names>O</given-names></name><name><surname>Kang</surname><given-names>S</given-names></name><name><surname>Cho</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Molecular geometry prediction using a deep generative graph neural network</article-title><source>Sci. Rep.</source><year>2019</year><volume>9</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41598-019-56773-5</pub-id></mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Simm, G. &amp; Hernandez-Lobato, J. M. A generative model for molecular distance geometry. In <italic>Proc. 37th International Conference on Machine Learning</italic>, volume 119 of <italic>Proceedings of Machine Learning Research</italic>, pages 8949–8958 (PMLR, 2020).</mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gogineni</surname><given-names>T</given-names></name><etal/></person-group><article-title xml:lang="en">Torsionnet: A reinforcement learning approach to sequential conformer search</article-title><source>Adv. Neur</source><year>2020</year><volume>33</volume><fpage>20142</fpage><lpage>20153</lpage></mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="other">Xu, M., Luo, S., Bengio, Y., Peng, J. &amp; Tang, J. Learning neural generative dynamics for molecular conformation generation. In <italic>International Conference on Learning Representations</italic>, <ext-link xlink:href="https://openreview.net/forum?id=pAbm1qfheGk" ext-link-type="uri">https://openreview.net/forum?id=pAbm1qfheGk</ext-link> (2021a).</mixed-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="other">Xu, M. et al. An end-to-end framework for molecular conformation generation via bilevel programming. In <italic>Proc. 38</italic><sup><italic>th</italic></sup><italic>International Conference on Machine Learning</italic>, volume 139 of <italic>Proceedings of Machine Learning Research</italic>, pages 11537–11547 (PMLR, 2021)</mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Ganea, O.-E. et al. GeoMol: Torsional geometric generation of molecular 3d conformer ensembles. <italic>arXiv preprint arXiv</italic>:<italic>2106.07802</italic> (2021).</mixed-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lemm</surname><given-names>D</given-names></name><name><surname>von Rudorff</surname><given-names>GF</given-names></name><name><surname>von Lilienfeld</surname><given-names>OA</given-names></name></person-group><article-title xml:lang="en">Machine learning based energy-free structure predictions of molecules, transition states, and solids</article-title><source>Nat. Commun.</source><year>2021</year><volume>12</volume><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2021NatCo..12.4468L</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXhsleru7jN</pub-id><pub-id pub-id-type="pmid">34294693</pub-id><pub-id pub-id-type="pmcid">8298673</pub-id><pub-id pub-id-type="doi">10.1038/s41467-021-24525-7</pub-id></mixed-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stieffenhofer</surname><given-names>M</given-names></name><name><surname>Bereau</surname><given-names>T</given-names></name><name><surname>Wand</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Adversarial reverse mapping of condensed-phase molecular structures: Chemical transferability</article-title><source>APL Mater</source><year>2021</year><volume>9</volume><fpage>031107</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2021APLM....9c1107S</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXms1Knt74%3D</pub-id><pub-id pub-id-type="doi">10.1063/5.0039102</pub-id></mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noé</surname><given-names>F</given-names></name><name><surname>Olsson</surname><given-names>S</given-names></name><name><surname>Köhler</surname><given-names>J</given-names></name><name><surname>Wu</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Boltzmann generators: Sampling equilibrium states of many-body systems with deep learning</article-title><source>Science</source><year>2019</year><volume>365</volume><fpage>eaaw1147</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2019Sci...365.1147N</pub-id><pub-id pub-id-type="pmid">31488660</pub-id><pub-id pub-id-type="doi">10.1126/science.aaw1147</pub-id></mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="other">Köhler, J., Klein, L. &amp; Noe, F. Equivariant flows: Exact likelihood generative learning for symmetric densities. In <italic>Proc. 37</italic><sup><italic>th</italic></sup><italic>International Conference on Machine Learning</italic>, volume 119 of <italic>Proceedings of Machine Learning Research</italic>, pages 5361–5370 (PMLR, 2020).</mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="other">Ingraham, J., Riesselman, A., Sander, C. &amp; Marks, D. Learning protein structure with a differentiable simulator. In <italic>International Conference on Learning Representations</italic>, <ext-link xlink:href="https://openreview.net/forum?id=Byg3y3C9Km" ext-link-type="uri">https://openreview.net/forum?id=Byg3y3C9Km</ext-link> (2018).</mixed-citation></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lemke</surname><given-names>T</given-names></name><name><surname>Peter</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Encodermap: Dimensionality reduction and generation of molecule conformations</article-title><source>J. Chem. Theory Comput.</source><year>2019</year><volume>15</volume><fpage>1209</fpage><lpage>1215</lpage><pub-id pub-id-type="pmid">30632745</pub-id><pub-id pub-id-type="doi">10.1021/acs.jctc.8b00975</pub-id></mixed-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>AlQuraishi</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">End-to-end differentiable learning of protein structure</article-title><source>Cell Syst</source><year>2019</year><volume>8</volume><fpage>292</fpage><lpage>301</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXosVyhtb0%3D</pub-id><pub-id pub-id-type="pmid">31005579</pub-id><pub-id pub-id-type="pmcid">6513320</pub-id><pub-id pub-id-type="doi">10.1016/j.cels.2019.03.006</pub-id></mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Senior</surname><given-names>AW</given-names></name><etal/></person-group><article-title xml:lang="en">Improved protein structure prediction using potentials from deep learning</article-title><source>Nature</source><year>2020</year><volume>577</volume><fpage>706</fpage><lpage>710</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2020Natur.577..706S</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXis1SisL0%3D</pub-id><pub-id pub-id-type="pmid">31942072</pub-id><pub-id pub-id-type="doi">10.1038/s41586-019-1923-7</pub-id></mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jumperet</surname><given-names>J</given-names></name><etal/></person-group><article-title xml:lang="en">Highly accurate protein structure prediction with AlphaFold</article-title><source>Nature</source><year>2021</year><volume>596</volume><fpage>583</fpage><lpage>589</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2021Natur.596..583J</pub-id><pub-id pub-id-type="doi">10.1038/s41586-021-03819-2</pub-id></mixed-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="other">Gebauer, N. W. A., Gastegger, M. and Schütt, K. T. Generating equilibrium molecules with deep neural networks. <italic>NeurIPS Workshop on Machine Learning for Molecules and Materials, arXiv:1810.11347</italic> (2018).</mixed-citation></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="other">Gebauer, N., Gastegger, M. &amp; Schütt, K. Symmetry-adapted generation of 3d point sets for the targeted discovery of molecules. In <italic>Advances in Neural Information Processing Systems 32</italic>, pages 7566–7578 (Curran Associates, Inc., 2019).</mixed-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="other">Hoffmann, M. &amp; Noé, F. Generating valid euclidean distance matrices. <italic>arXiv preprint arXiv:1910.03131</italic> (2019).</mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="other">Nesterov, V., Wieser, M. &amp; Roth, V. 3DMolNet: A generative network for molecular structures. <italic>arXiv preprint arXiv:2010.06477</italic> (2020).</mixed-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="other">Simm, G., Pinsler, R. &amp; Hernandez-Lobato, J. M. Reinforcement learning for molecular design guided by quantum mechanics. In <italic>Proc. 37th International Conference on Machine Learning</italic>, volume 119 of <italic>Proceedings of Machine Learning Research</italic>, pages 8959–8969 (PMLR, 2020).</mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="other">Simm, G. N. C., Pinsler, R. Csányi, G. &amp; Hernández-Lobato, J. M. Symmetry-aware actor-critic for 3d molecular design. In <italic>International Conference on Learning Representations</italic>, <ext-link xlink:href="https://openreview.net/forum?id=jEYKjPE1xYN" ext-link-type="uri">https://openreview.net/forum?id=jEYKjPE1xYN</ext-link> (2021).</mixed-citation></ref><ref id="CR53"><label>53.</label><mixed-citation publication-type="other">Li, Y., Pei, J. &amp; Lai, L. Learning to design drug-like molecules in three-dimensional space using deep generative models. <italic>arXiv preprint arXiv:2104.08474</italic> (2021).</mixed-citation></ref><ref id="CR54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>RP</given-names></name><etal/></person-group><article-title xml:lang="en">3D-Scaffold: A deep learning framework to generate 3d coordinates of drug-like molecules with desired scaffolds</article-title><source>J. Phys. Chem. B</source><year>2021</year><volume>125</volume><fpage>12166</fpage><lpage>12176</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXit1CqsbvI</pub-id><pub-id pub-id-type="pmid">34662142</pub-id><pub-id pub-id-type="doi">10.1021/acs.jpcb.1c06437</pub-id></mixed-citation></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="other">Satorras, V. G., Hoogeboom, E., Fuchs, F. B., Posner, I. &amp; Welling, M. E(n) equivariant normalizing flows. <italic>arXiv preprint arXiv</italic><italic>:</italic><italic>2105</italic>.<italic>09016</italic> (2021).</mixed-citation></ref><ref id="CR56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meldgaard</surname><given-names>SA</given-names></name><etal/></person-group><article-title xml:lang="en">Generating stable molecules using imitation and reinforcement learning</article-title><source>Mach. Learn. Sci. Technol</source><year>2022</year><volume>3</volume><fpage>015008</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2022MLS&amp;T...3a5008A</pub-id><pub-id pub-id-type="doi">10.1088/2632-2153/ac3eb4</pub-id></mixed-citation></ref><ref id="CR57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Boyle</surname><given-names>NM</given-names></name><etal/></person-group><article-title xml:lang="en">Open Babel: An open chemical toolbox</article-title><source>J. Cheminf.</source><year>2011</year><volume>3</volume><fpage>33</fpage><pub-id pub-id-type="doi">10.1186/1758-2946-3-33</pub-id></mixed-citation></ref><ref id="CR58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramakrishnan</surname><given-names>R</given-names></name><name><surname>Dral</surname><given-names>PO</given-names></name><name><surname>Rupp</surname><given-names>M</given-names></name><name><surname>von Lilienfeld</surname><given-names>OA</given-names></name></person-group><article-title xml:lang="en">Quantum chemistry structures and properties of 134 kilo molecules</article-title><source>Sci. Data</source><year>2014</year><volume>1</volume><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXks1aisLo%3D</pub-id><pub-id pub-id-type="pmid">25977779</pub-id><pub-id pub-id-type="pmcid">4322582</pub-id><pub-id pub-id-type="doi">10.1038/sdata.2014.22</pub-id></mixed-citation></ref><ref id="CR59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reymond</surname><given-names>J-L</given-names></name></person-group><article-title xml:lang="en">The chemical space project</article-title><source>Acc. Chem. Res.</source><year>2015</year><volume>48</volume><fpage>722</fpage><lpage>730</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXivFWisb4%3D</pub-id><pub-id pub-id-type="pmid">25687211</pub-id><pub-id pub-id-type="doi">10.1021/ar500432k</pub-id></mixed-citation></ref><ref id="CR60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruddigkeit</surname><given-names>L</given-names></name><name><surname>Van Deursen</surname><given-names>R</given-names></name><name><surname>Blum</surname><given-names>LC</given-names></name><name><surname>Reymond</surname><given-names>J-L</given-names></name></person-group><article-title xml:lang="en">Enumeration of 166 billion organic small molecules in the chemical universe database GDB-17</article-title><source>J. Chem. Inf. Model.</source><year>2012</year><volume>52</volume><fpage>2864</fpage><lpage>2875</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XhsFClsL3J</pub-id><pub-id pub-id-type="pmid">23088335</pub-id><pub-id pub-id-type="doi">10.1021/ci300415d</pub-id></mixed-citation></ref><ref id="CR61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zubatyuk</surname><given-names>R</given-names></name><name><surname>Smith</surname><given-names>JS</given-names></name><name><surname>Leszczynski</surname><given-names>J</given-names></name><name><surname>Isayev</surname><given-names>O</given-names></name></person-group><article-title xml:lang="en">Accurate and transferable multitask prediction of chemical properties with an atoms-in-molecules neural network</article-title><source>Sci. Adv.</source><year>2019</year><volume>5</volume><fpage>eaav6490</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2019SciA....5.6490Z</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXhtlaku7fI</pub-id><pub-id pub-id-type="pmid">31448325</pub-id><pub-id pub-id-type="pmcid">6688864</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.aav6490</pub-id></mixed-citation></ref><ref id="CR62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glavatskikh</surname><given-names>M</given-names></name><name><surname>Leguy</surname><given-names>J</given-names></name><name><surname>Hunault</surname><given-names>G</given-names></name><name><surname>Cauchy</surname><given-names>T</given-names></name><name><surname>Da Mota</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Dataset’s chemical diversity limits the generalizability of machine learning predictions</article-title><source>J. Cheminf.</source><year>2019</year><volume>11</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1186/s13321-019-0391-2</pub-id></mixed-citation></ref><ref id="CR63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>B</given-names></name><name><surname>von Lilienfeld</surname><given-names>OA</given-names></name></person-group><article-title xml:lang="en">Quantum machine learning using atom-in-molecule-based fragments selected on the fly</article-title><source>Nat. Chem.</source><year>2020</year><volume>12</volume><fpage>945</fpage><lpage>951</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXhvVCltb7N</pub-id><pub-id pub-id-type="pmid">32929248</pub-id><pub-id pub-id-type="doi">10.1038/s41557-020-0527-z</pub-id></mixed-citation></ref><ref id="CR64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gastegger</surname><given-names>M</given-names></name><name><surname>Kauffmann</surname><given-names>C</given-names></name><name><surname>Behler</surname><given-names>J</given-names></name><name><surname>Marquetand</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Comparing the accuracy of high-dimensional neural network potentials and the systematic molecular fragmentation method: A benchmark study for all-trans alkanes</article-title><source>J. Chem. Phys.</source><year>2016</year><volume>144</volume><fpage>194110</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2016JChPh.144s4110G</pub-id><pub-id pub-id-type="pmid">27208939</pub-id><pub-id pub-id-type="doi">10.1063/1.4950815</pub-id></mixed-citation></ref><ref id="CR65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gastegger</surname><given-names>M</given-names></name><name><surname>Behler</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Machine learning molecular dynamics for the simulation of infrared spectra</article-title><source>Chem. Sci.</source><year>2017</year><volume>8</volume><fpage>6924</fpage><lpage>6935</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXhtlSrtL7J</pub-id><pub-id pub-id-type="pmid">29147518</pub-id><pub-id pub-id-type="pmcid">5636952</pub-id><pub-id pub-id-type="doi">10.1039/C7SC02267K</pub-id></mixed-citation></ref><ref id="CR66"><label>66.</label><mixed-citation publication-type="other">Ramachandran, P. &amp; Varoquaux, G. Mayavi: 3D visualization of scientific data. <italic>Comput Sci. Eng</italic>. <bold>13</bold>, 40–51 (2011). ISSN 1521-9615.</mixed-citation></ref><ref id="CR67"><label>67.</label><mixed-citation publication-type="other">Schütt, K. et al. SchNet: A continuous-filter convolutional neural network for modeling quantum interactions. In <italic>Advances in Neural Information Processing Systems 30</italic>, pages 992–1002 (Curran Associates, Inc., 2017b).</mixed-citation></ref><ref id="CR68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schütt</surname><given-names>KT</given-names></name><etal/></person-group><article-title xml:lang="en">SchNetPack: A deep learning toolbox for atomistic systems</article-title><source>J. Chem. Theory Comput.</source><year>2019</year><volume>15</volume><fpage>448</fpage><lpage>455</lpage><pub-id pub-id-type="pmid">30481453</pub-id><pub-id pub-id-type="doi">10.1021/acs.jctc.8b00908</pub-id></mixed-citation></ref><ref id="CR69"><label>69.</label><mixed-citation publication-type="other">Kingma, D. P. &amp; Ba, J. Adam: A method for stochastic optimization. <italic>International Conference for Learning Representations, arXiv:1412.6980</italic>, 2014.</mixed-citation></ref><ref id="CR70"><label>70.</label><mixed-citation publication-type="other">RDKit, online. <italic>RDKit: Open-source cheminformatics</italic>. <ext-link xlink:href="http://www.rdkit.org" ext-link-type="uri">http://www.rdkit.org</ext-link> (2021).</mixed-citation></ref><ref id="CR71"><label>71.</label><mixed-citation publication-type="other">Gebauer, N. W. A., Gastegger, M., Hessmann, S. S. P., Müller, K.-R. &amp; Schütt, K. T. atomistic-machine-learning/cG-SchNet: Inverse design of 3d molecular structures with conditional generative neural networks. <italic>Zenodo</italic><ext-link xlink:href="10.5281/zenodo.5907027" ext-link-type="doi">https://doi.org/10.5281/zenodo.5907027</ext-link> (2022).</mixed-citation></ref></ref-list></ref-list><app-group><app id="App1" specific-use="web-only"><sec id="Sec17"><title>Supplementary information</title><p id="Par57"><supplementary-material content-type="local-data" id="MOESM1" xlink:title="Supplementary information"><media mimetype="application" mime-subtype="pdf" xlink:href="MediaObjects/41467_2022_28526_MOESM1_ESM.pdf" position="anchor"><caption xml:lang="en"><p>Supplementary Information</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM2" xlink:title="Supplementary information"><media mimetype="application" mime-subtype="pdf" xlink:href="MediaObjects/41467_2022_28526_MOESM2_ESM.pdf" position="anchor"><caption xml:lang="en"><p>Peer Review File</p></caption></media></supplementary-material></p></sec></app></app-group><notes notes-type="ESMHint"><title>Supplementary information</title><p>The online version contains supplementary material available at <ext-link xlink:href="10.1038/s41467-022-28526-y" ext-link-type="doi">https://doi.org/10.1038/s41467-022-28526-y</ext-link>.</p></notes><notes notes-type="Misc"><p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Science, Humanities and Social Sciences, multidisciplinary</facet-value><facet-value count="1">Science, multidisciplinary</facet-value></facet><facet name="keyword"/><facet name="pub"><facet-value count="1">Nature Communications</facet-value></facet><facet name="year"><facet-value count="1">2022</facet-value></facet><facet name="country"><facet-value count="1">Germany</facet-value><facet-value count="1">South Korea</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
