<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1038/s41467-022-35628-0</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="research-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">41467</journal-id><journal-id journal-id-type="doi">10.1038/41467.2041-1723</journal-id><journal-title-group><journal-title>Nature Communications</journal-title><abbrev-journal-title abbrev-type="publisher">Nat Commun</abbrev-journal-title></journal-title-group><issn pub-type="epub">2041-1723</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s41467-022-35628-0</article-id><article-id pub-id-type="manuscript">35628</article-id><article-id pub-id-type="doi">10.1038/s41467-022-35628-0</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/766/1130/2798</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/766/119/995</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/166/987</subject></subj-group><subj-group subj-group-type="TechniquePath"><subject>/120</subject></subj-group><subj-group subj-group-type="TechniquePath"><subject>/128</subject></subj-group><subj-group subj-group-type="TechniquePath"><subject>/147/135</subject></subj-group><subj-group subj-group-type="TechniquePath"><subject>/139</subject></subj-group><subj-group subj-group-type="NatureArticleTypeID"><subject>article</subject></subj-group></article-categories><title-group><article-title xml:lang="en">Self-powered high-sensitivity all-in-one vertical tribo-transistor device for multi-sensing-memory-computing</article-title></title-group><contrib-group><contrib contrib-type="author" id="Au1"><name><surname>Liu</surname><given-names>Yaqian</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au2"><name><surname>Liu</surname><given-names>Di</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au3"><name><surname>Gao</surname><given-names>Changsong</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au4"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9314-9362</contrib-id><name><surname>Zhang</surname><given-names>Xianghong</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au5"><name><surname>Yu</surname><given-names>Rengjian</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au6"><name><surname>Wang</surname><given-names>Xiumei</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au7"><name><surname>Li</surname><given-names>Enlong</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au8"><name><surname>Hu</surname><given-names>Yuanyuan</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author" id="Au9"><name><surname>Guo</surname><given-names>Tailiang</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au10"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1706-3174</contrib-id><name><surname>Chen</surname><given-names>Huipeng</given-names></name><address><email>hpchen@fzu.edu.cn</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="corresp" rid="IDs41467022356280_cor10">k</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.411604.6</institution-id><institution-id institution-id-type="ISNI">0000 0001 0130 6528</institution-id><institution content-type="org-division">Institute of Optoelectronic Display, National &amp; Local United Engineering Lab of Flat Panel Display Technology</institution><institution content-type="org-name">Fuzhou University</institution></institution-wrap><addr-line content-type="postcode">350002</addr-line><addr-line content-type="city">Fuzhou</addr-line><country country="CN">China</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.207374.5</institution-id><institution-id institution-id-type="ISNI">0000 0001 2189 3846</institution-id><institution content-type="org-division">School of Physics and Electronic Engineering</institution><institution content-type="org-name">Zhengzhou University of Light Industry</institution></institution-wrap><addr-line content-type="postcode">450002</addr-line><addr-line content-type="city">Henan</addr-line><country country="CN">China</country></aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.513073.3</institution-id><institution content-type="org-name">Fujian Science &amp; Technology Innovation Laboratory for Optoelectronic Information of China</institution></institution-wrap><addr-line content-type="postcode">350100</addr-line><addr-line content-type="city">Fuzhou</addr-line><country country="CN">China</country></aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.67293.39</institution-id><institution content-type="org-division">State Key Laboratory for Chemo/Biosensing and Chemometrics</institution><institution content-type="org-name">School of Physics and Electronics, Hunan University</institution></institution-wrap><addr-line content-type="postcode">410082</addr-line><addr-line content-type="city">Changsha</addr-line><country country="CN">China</country></aff></contrib-group><author-notes><corresp id="IDs41467022356280_cor10"><label>k</label><email>hpchen@fzu.edu.cn</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>23</day><month>12</month><year>2022</year></pub-date><pub-date date-type="collection" publication-format="electronic"><month>12</month><year>2022</year></pub-date><volume>13</volume><issue seq="7917">1</issue><elocation-id>7917</elocation-id><history><date date-type="registration"><day>14</day><month>12</month><year>2022</year></date><date date-type="received"><day>17</day><month>8</month><year>2022</year></date><date date-type="accepted"><day>13</day><month>12</month><year>2022</year></date><date date-type="online"><day>23</day><month>12</month><year>2022</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2022</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">Devices with sensing-memory-computing capability for the detection, recognition and memorization of real time sensory information could simplify data conversion, transmission, storage, and operations between different blocks in conventional chips, which are invaluable and sought-after to offer critical benefits of accomplishing diverse functions, simple design, and efficient computing simultaneously in the internet of things (IOT) era. Here, we develop a self-powered vertical tribo-transistor (VTT) based on MXenes for multi-sensing-memory-computing function and multi-task emotion recognition, which integrates triboelectric nanogenerator (TENG) and transistor in a single device with the simple configuration of vertical organic field effect transistor (VOFET). The tribo-potential is found to be able to tune ionic migration in insulating layer and Schottky barrier height at the MXene/semiconductor interface, and thus modulate the conductive channel between MXene and drain electrode. Meanwhile, the sensing sensitivity can be significantly improved by 711 times over the single TENG device, and the VTT exhibits excellent multi-sensing-memory-computing function. Importantly, based on this function, the multi-sensing integration and multi-model emotion recognition are constructed, which improves the emotion recognition accuracy up to 94.05% with reliability. This simple structure and self-powered VTT device exhibits high sensitivity, high efficiency and high accuracy, which provides application prospects in future human-mechanical interaction, IOT and high-level intelligence.</p></abstract><abstract xml:lang="en" id="Abs2" abstract-type="ShortSummary"><p id="Par2">Designing efficient sensing-memory-computing systems remains a challenge. Here, the authors propose a self-powered vertical tribo-transistor based on MXenes to implement the multi-sensing-memory-computing function and the interaction of multisensory integration.</p></abstract><funding-group><award-group><funding-source><institution-wrap><institution>National Natural Science Foundation of China (National Science Foundation of China)</institution><institution-id institution-id-type="doi" vocab="open-funder-registry">https://doi.org/10.13039/501100001809</institution-id></institution-wrap></funding-source><award-id award-type="FundRef grant">61974029</award-id><principal-award-recipient><name><surname>Chen</surname><given-names>Huipeng</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Nature Portfolio</meta-value></custom-meta><custom-meta><meta-name>volume-issue-count</meta-name><meta-value>1</meta-value></custom-meta><custom-meta><meta-name>issue-article-count</meta-name><meta-value>7916</meta-value></custom-meta><custom-meta><meta-name>issue-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>issue-pricelist-year</meta-name><meta-value>2022</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-holder</meta-name><meta-value>The Author(s)</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-year</meta-name><meta-value>2022</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>Yes</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2022</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>12</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>14</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>volume-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>NonStandardArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>false</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/41467_2022_Article_35628.pdf</meta-value></custom-meta><custom-meta><meta-name>pdf-type</meta-name><meta-value>Typeset</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>issue-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>OriginalPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Science, Humanities and Social Sciences, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Science, Humanities and Social Sciences, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Science, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Science (multidisciplinary)</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par3">With the upsurge of artificial intelligence applications and the rapid development of internet of things (IOT), the time-efficient sensing information acquisition, energy-efficient data memorizing and processing capabilities of terminal electronic systems are indispensable<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. However, in conventional chips, the separated sensing, storage, and processing units always need to collect signals by external sensors, convert signals into digital format data subsequently, and then transfer the date to memory units and processors for subsequent processing tasks, which limits the data conversion and movement and results in low computing efficiency and huge power consumption<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. Thus, benefiting from in-memory-computing device<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, which can both store data and compute simultaneously by device physics or other physical laws, an integrated sensing-memory-computing (SMC) system with high-efficiency perception, storage and calculation functions could greatly simplify transmission operations, decrease hardware bulk, and increase efficiency in comparison to the traditional chips<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR4">4</xref>–<xref ref-type="bibr" rid="CR8">8</xref></sup>.</p><p id="Par4">Meanwhile, most creatures possess multiple sensory organs with which they can simultaneously perceive a wide variety of physical changes in the environment<sup><xref ref-type="bibr" rid="CR9">9</xref>–<xref ref-type="bibr" rid="CR16">16</xref></sup>. Thus, SMC systems that can integrate and organize various sensory information (multi-sensing-memory-computing (MSMC)) are fundamental to effective perception and cognitive function<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR17">17</xref>–<xref ref-type="bibr" rid="CR20">20</xref></sup>. Noticeably, MSMC system desires various numbers of sensory receptors and processing nodes (tactile, auditory, and visual, etc) to keep producing multi-sensing raw data and processing different types of sensory information, respectively<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR21">21</xref>–<xref ref-type="bibr" rid="CR28">28</xref></sup>. However, the increased number of receptors slows down the working speed due to the subsequent data transmission and processing, and the separated sensory receptors and processing nodes also lead to transmission speed discrepancy, which would further limit the conversion speed and increase energy consumption<sup><xref ref-type="bibr" rid="CR24">24</xref>–<xref ref-type="bibr" rid="CR26">26</xref></sup>. Therefore, developing a single device integrated with the function of MSMC is of great significance to address the above-mentioned challenges and improve sensory perceptual efficiency in current electronic devices.</p><p id="Par5">Noticeably, triboelectric nanogenerator (TENG) is energy harvesting device that can convert various forms of energy such as human motion, sound vibration, and light energy into electric power<sup><xref ref-type="bibr" rid="CR29">29</xref>–<xref ref-type="bibr" rid="CR36">36</xref></sup>. The native advantages of TENG render it a promising power supply device as well as a multisensory receptor<sup><xref ref-type="bibr" rid="CR33">33</xref>,<xref ref-type="bibr" rid="CR37">37</xref>–<xref ref-type="bibr" rid="CR42">42</xref></sup>. Meanwhile, vertical organic field effect transistors (VOFETs) composed of vertically stacked gate/source/drain electrodes and promising short channel possess small subthreshold swing (SS), high working frequency, and promising mechanical stability, ensuring their great practical applications in memory and computing devices<sup><xref ref-type="bibr" rid="CR43">43</xref>–<xref ref-type="bibr" rid="CR46">46</xref></sup>. Thus, the inherent vertically stacked electrodes of VOFETs are suitable to integrate with TENG, which possibly provides an effective approach for achieving multi-functional all-in-one-device with sensing-memory-computing function.</p><p id="Par6">Hence, in this work, we develop a vertical tribo-transistor (VTT) device based on TENG and VOFET to implement the multi-sensing-memory-computing function and the interaction of multisensory integration. This VTT is based on a simple configuration of VOFET without any redundant layers, and MXenes function as the top electrode of TENG, source electrode of transistor, and the light collection layer of multisensory, simultaneously. The VTT allows electrostatic induction and tribo-potential to tune ionic migration and Schottky barrier, and thus the triboelectrification sensory information can be amplified to the source-drain current in a self-energy transducing manner, which improves the sensitivity by 711 times over a single TENG. Meanwhile, processing functions of different sensory perception and multisensory interaction in brain superior colliculus are achieved based on the individual VTT device. Furthermore, artificial conscious response is generated by the integration of robot hand with VTT device, and the open angle of robot hand is successfully controlled with different sensory stimulation, demonstrating that this system can straightforward enhance the accuracy of relevant event. Finally, a multi-model emotion recognition system is constructed to detect and distinguish typical mood. The self-powered VTT device shows great potential in next-generation high-performance in-sensor-memory-computing artificial intelligent system and human-computer interaction interface applications.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Self-powered vertical tribo-transistor with multi-sensing function</title><p id="Par7">A schematic diagram of biological multisensory integration nervous system is illustrated in Fig. <xref rid="Fig1" ref-type="fig">1a</xref>. The system is composed of several sensing units for perception, transmission pathways for transfer information, and brain for memory and computing. Here, a vertical tribo-transistor (VTT) device based on TENG (Fig. <xref rid="Fig1" ref-type="fig">1b</xref>) and VOFET (Fig. <xref rid="Fig1" ref-type="fig">1c</xref>) is fabricated to implement the multi-sensing-memory-computing function, as illustrated in Fig. <xref rid="Fig1" ref-type="fig">1d</xref>. Clearly, this VTT integrates the function of a TENG and a VOFET. It is based on a VOFET configuration without any redundant layer, which is attributed to the fact that both TENG device and VOFET device share the vertical structure. The VTT composes removable Kapton substrate, removable Au gate electrode, ion-gel insulating layer, MXenes network source electrode, PDVT-10 channel layer, and Au source/drain electrode. Meanwhile, the detailed fabrication process of VTT is shown in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">1</xref>, and the cross-section SEM is depicted in Supplementary Figure <xref ref-type="supplementary-material" rid="MOESM1">2</xref>. Noticeably, MXenes, which possess regulated work function, outstanding mechanical and optical properties, have raises significant interest for optoelectronic, energy storage and Schottky-barrier based devices. Thus, MXenes are promising alternative electrode of TENG and network source electrode of VTT here. The sensing abilities, touch and hearing perception are emulated by moving of gate electrode and vibration of VTT, respectively, and the visual perception is achieved by the light-sensitive Ti<sub>3</sub>C<sub>2</sub>T<sub>x</sub> MXenes electrode.<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><title>Schematic diagram of multi-sensing-memory-computing system, the device structure of VTT and its morphology characteristics.</title><p><bold>a</bold> The biological multi-sensing-memory-computing system. The sensory receptors collect sensory data and transmitted the data to human brain for further memory and computing. <bold>b–d</bold> Schematic illustration the structure of TENG, vertical transistor, and VTT, respectively. <bold>e</bold> SEM images of MXenes network source electrode. <bold>f</bold> SEM images of MXenes network source electrode. <bold>g</bold> High-resolution TEM image of MXenes network source electrode.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2022_35628_Fig1_HTML.png"/></fig></p><p id="Par8">The scanning electron microscope (SEM) image of MXenes network is presented in Fig. <xref rid="Fig1" ref-type="fig">1e</xref>, which clearly shows that the MXenes are interconnected with each other and form a network structure. Meanwhile, the transmission electron microscope (TEM) of MXenes is shown in Fig. <xref rid="Fig1" ref-type="fig">1f</xref>, where Mxenes exhibit nanosheets structure, and the thickness of MXenes network source electrode is about 1 nm. Fig <xref rid="Fig1" ref-type="fig">1g</xref> shows the high-resolution TEM image, and the corresponding lattice spacing in this layer is 0.3 nm<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>. The electrostatic induction and triboelectrification between gate electrode and insulating layer would induce the electrode-double-layer effects, which manifests in a transient channel current, thus realizing the multi-sensing-memory-computing function.</p><p id="Par9">We first investigated the sensing function of this VTT device, and the equivalent circuit of VTT is demonstrated in Fig. <xref rid="Fig2" ref-type="fig">2a</xref>. The gate electrode in Fig. <xref rid="Fig2" ref-type="fig">2a</xref> can be moved, and the distance between gate electrode and insulating layer is defined as d. Compared with traditional plane transistor integrated with TENG (Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">3</xref>a, <xref ref-type="supplementary-material" rid="MOESM1">3b</xref>), this VTT not only enhances the device integration level, but also simplifies the equivalent circuit (Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">3</xref>). Clearly, VTT can achieve the function of TENG by only leading out the gate and source electrode, while if external voltage is applied to the source-drain electrodes, it can function as VOFET. The output performance of individual TENG is shown in Fig. <xref rid="Fig2" ref-type="fig">2b</xref>. With the increase of the distance between gate electrode and insulating layer from 0 to 1000 μm, the open-circuit voltage (V<sub>OC</sub>) increases from 0 to 1.71 V. The working mechanism of TENG is illustrated in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">4</xref>. Here, ion-gel is employed as the triboelectric material in TENG. The Au electrode and MXenes electrode are employed as the bottom electrode and top electrode in TENG, respectively. When the distance between bottom electrode and triboelectric layer changes, and the confined charges in ion-gel attract the counterions. In the original state, the bottom electrode and ion-gel layer are not in contact with each other, and then when bottom electrode is fully contacted with ion-gel layer (IL), electrons flow to the IL because of the triboelectric effect. When bottom electrode is moved away, positive and negative ions in the IL accumulate at the air/ion-gel and ion-gel/top electrode interfaces, respectively, forming an electrical double layer (EDL). Accordingly, an output voltage is recorded with the electrons flowing from top electrode to bottom electrode. It is noteworthy that the high capacitance of EDL can remarkably improve the performance of TENG (as illustrated in Supplementary Note <xref ref-type="supplementary-material" rid="MOESM1">1</xref>)<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR45">45</xref>,<xref ref-type="bibr" rid="CR46">46</xref></sup>.<fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><title>The electrical output and sensing properties of TENG and VTT.</title><p><bold>a</bold> Equivalent circuit of the VTT device. <bold>b</bold> The TENG output voltage versus distance. <bold>c</bold> The SS of VTT with external gate voltage. <bold>d</bold>, <bold>e</bold> Transfer curve and output curve of VTT with TENG. <bold>f</bold>, <bold>g</bold> The tactile sensitivity of single TENG and VTT with different distance. <bold>h</bold>, <bold>i</bold> The auditory sensitivity of single TENG and VTT with different sound pressure level. The error bars in f-i means the values of V/Vmin or I/Imin within 10 cycles.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2022_35628_Fig2_HTML.png"/></fig></p><p id="Par10">Then, we investigated the property of the devices as a VOFET. The typical transfer curve of VOFET is illustrated in Fig. <xref rid="Fig2" ref-type="fig">2c</xref>, where gate voltage is modulated through external voltage, and the gate electrode is contacted with the insulating layer (Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">5</xref>). From the transfer characteristics of VOFET<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>, the subthreshold swing (SS) of 91.8 mV/dec is extracted, while lower SS would result in higher ΔI (I<sub>DS1</sub>-I<sub>DS2</sub>) at same ΔV (V<sub>GS1</sub>-V<sub>GS2</sub>), which shows the great potential of the device in achieving high sensitivity sensory perception. Noticeably, the V<sub>OC</sub> of TENG can be considered as a gate-source voltage and then convert into a transient channel current. Figure <xref rid="Fig2" ref-type="fig">2d</xref> and Fig. <xref rid="Fig2" ref-type="fig">2e</xref> show the transfer and output curve of VTT under different V<sub>OC</sub> from TENG, respectively. When the distance between gate electrode and insulating layer increases from 0 to 1000 μm (Fig. <xref rid="Fig2" ref-type="fig">2d</xref>), the VTT exhibits p-type transistor behavior, and the drain-source current (I<sub>DS</sub>) increases by nearly 4 orders. Moreover, the on-state current density is greater than 5 mA/cm<sup>2</sup> (Fig. <xref rid="Fig2" ref-type="fig">2e</xref>), providing sufficient current density to drive organic electronic devices. This high output current density of VTT is mainly ascribed to its ultrashort channel length. For comparison, the transfer curve of planar transistor is depicted in Fig. <xref rid="Fig2" ref-type="fig">2c</xref> left, which shows a higher SS compared with vertical transistor.</p><p id="Par11">Furthermore, we investigated the sensitivity of these two devices individually when they are used for mimicking different sensory perception. Fig <xref rid="Fig2" ref-type="fig">2</xref>f, <xref rid="Fig2" ref-type="fig">g</xref> show the tactile sensitivity of an individual TENG and VTT, respectively. The tactile sensitivity of TENG is defined as equ. <xref rid="Equ1" ref-type="disp-formula">1</xref>:<disp-formula id="Equ1"><label>1</label><alternatives><mml:math id="Equ1_Math"><mml:mi mathvariant="normal">S</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="normal">V</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi>min</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:math><tex-math id="Equ1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{S}}}}}}=(\Delta {{{{{\rm{V}}}}}}/{{{{{{\rm{V}}}}}}}_{{{\min }}})/\Delta {{{{{\rm{d}}}}}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_35628_Article_Equ1.gif"/></alternatives></disp-formula>where ΔV is the change of open-circuit V<sub>oc</sub> (V-V<sub>0</sub>), V<sub>min</sub> is the minimum V<sub>oc</sub>, and Δd is the changed distance (d) between gate electrode and insulating layer. When d is increased from 0 μm to 450 μm, the sensitivity is calculated to be 0.0334 μm<sup>−</sup><sup>1</sup>, and then a lower sensitivity of 0.0038 μm<sup>−</sup><sup>1</sup> is estimated when the d increases from 450 μm to 1000 μm. In comparison, the tactile sensitivity of VTT is defined as eq. <xref rid="Equ2" ref-type="disp-formula">2</xref>:<disp-formula id="Equ2"><label>2</label><alternatives><mml:math id="Equ2_Math"><mml:mi mathvariant="normal">S</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="normal">I</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mi>min</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:math><tex-math id="Equ2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{S}}}}}}=(\Delta {{{{{\rm{I}}}}}}/{{{{{{\rm{I}}}}}}}_{{{\min }}})/\Delta {{{{{\rm{d}}}}}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_35628_Article_Equ2.gif"/></alternatives></disp-formula>where ΔI is the change of drain-source current ΔI<sub>DS</sub> (I-I<sub>0</sub>), I<sub>min</sub> is the minimum I<sub>sc</sub>, and Δd is the changed distance (d) between gate electrode and insulating layer. As depicted in Fig. <xref rid="Fig2" ref-type="fig">2g</xref>, the VTT initially exhibits a sensitivity of 2.2059 μm<sup>−</sup><sup>1</sup>, and then, when the d is increased from 75 μm to 400 μm, the sensitivity (S<sub>2</sub>) is calculated to be 23.7503 μm<sup>−</sup><sup>1</sup>, which is 711 times higher than that of the individual TENG. Finally, with the d exceeding 400 μm, which corresponds with a saturated I<sub>DS</sub> and a lower ΔI, a rapid decrease of the sensitivity to 1.1648 μm<sup>−</sup><sup>1</sup> is observed. Thus, different distance between gate electrode and insulating layer would result in different charge distribution, V<sub>oc</sub>, I<sub>DS</sub>, and sensitivity.</p><p id="Par12">Besides, we characterized the auditory and visual stimuli transduction sensitivity of individual TENG and VTT, respectively. For the auditory stimuli transduction sensitivity, a loudspeaker with tunable sound pressure level (SPL) and frequency is used as the acoustic source to trigger the VTT. The auditory sensitivity is defined as eq. <xref rid="Equ3" ref-type="disp-formula">3</xref>:<disp-formula id="Equ3"><label>3</label><alternatives><mml:math id="Equ3_Math"><mml:mi mathvariant="normal">S</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="normal">V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">V</mml:mi></mml:mrow><mml:mrow><mml:mi>min</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mrow><mml:mi>min</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="normal">SPL</mml:mi></mml:math><tex-math id="Equ3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{S}}}}}}=(\Delta {{{{{\rm{V}}}}}}(\Delta {{{{{\rm{I}}}}}})/{{{{{{\rm{V}}}}}}}_{{{\min }}}({{{{{{\rm{I}}}}}}}_{{{\min }}}))/\Delta {{{{{\rm{SPL}}}}}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_35628_Article_Equ3.gif"/></alternatives></disp-formula>where ΔSPL is the changed sound pressure level of the loudspeaker. As the sound pressure level increases from 40 to 90 dB, the individual TENG device exhibits a nearly linear response and a SPL sensitivity of 0.0098 dB<sup>−</sup><sup>1</sup> (Fig. <xref rid="Fig2" ref-type="fig">2h</xref>). Meanwhile, the dependence of sensitivity of VTT on SPL is shown in Fig. <xref rid="Fig2" ref-type="fig">2i</xref>, and the highest sensitivity is 0.6524 dB<sup>−</sup><sup>1</sup> in the range from 60 to 80 dB. Furthermore, the absorbance of MXenes is presented in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">6</xref>, which exhibits particularly high absorption intensity in ultraviolet (UV) region, and the wavelength light source used is 325 nm next. The photosensitive MXenes function as the top electrode of TENG, source electrode of transistor, and the light collection layer of multisensory, simultaneously, and the visual sensitivity of individual TENG and VTT are illustrated in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">7</xref>. Clearly, VTT exhibits higher sensitivity than the individual TENG for each sensory perception, and the higher sensitivity of VTT is attributed to the amplification, low SS and high on/off ratio of VOFET. Moreover, the function of each material/layer in VTT with different sensing is shown in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">8</xref>, which further indicates that this VTT is beneficial to achieve multi-sensing function.</p></sec><sec id="Sec4"><title>The working mechanism of self-powered vertical tribo-transistor (VTT)</title><p id="Par13">Based on the above results, the working mechanism of VTT unit for tactile signal is illustrated in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. In the initial state, the gate electrode is separated with the IL, and then the VTT is set to the original state (the process was depicted Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">9</xref>). As the gate electrode is fully contacted with IL, positive charges and negative charges accumulated on the surface of gate electrode and IL interface because of the electrostatic induction and triboelectrification, respectively, as depict in Fig. <xref rid="Fig3" ref-type="fig">3a</xref>. Noticeably, the identical positive charges and negative charges lead to the off state of VTT, and there is no current recorded when a source-drain voltage is applied. The corresponding band diagram of this state is illustrates in Fig. <xref rid="Fig3" ref-type="fig">3b</xref>. It is clear that energy band bending would occur at MXenes/PDVT-10 interface when MXenes come into contact with PDVT-10 semiconductor. The high Schottky barrier height between the MXenes and PDVT-10 causes small source-drain current. Next, when the gate electrode and IL are separated, the tribo-potential would regulate the ionic migration of ion-gel layer, and positive ions in the IL are induced based on the charge balance effect (Fig. <xref rid="Fig3" ref-type="fig">3c</xref>). Simultaneously, an EDL is gradually generated at the IL, where the number of negative ions balanced the positive charges. Accordingly, temporary holes are accumulated near IL/PDVT-10 interface, which would decrease Schottky barrier height between the IL and PDVT-10, and then a conductive channel from MXene to drain electrode is formed (Fig. <xref rid="Fig3" ref-type="fig">3d</xref>). Finally, when gate electrode and IL are further separated, the EDL is entirely generated at the IL because of the tribo-potential, as shown in Fig. <xref rid="Fig3" ref-type="fig">3e</xref>. At this stage, massive holes accumulate at the IL/PDVT-10 interface, and thus the width of the Schottky barrier between the HOMO energy level of PDVT-10 and MXenes work function is narrowed, as shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>f, which enables the holes to easily flow into the semiconductor layer. Thus, holes are injected into PDVT-10 semiconductor from MXenes-network source electrode under the source/drain voltage and then are vertically transferred from PDVT-10 channel layer to drain electrode, resulting in the formation of drain-source current (on state).<fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><title>The working mechanism of multi-sensing VTT unit.</title><p><bold>a</bold> Charge distribution of the source/channel/drain layers when gate is in contact with the IL layer. <bold>b</bold> Corresponding band diagram of each layer at contact state. <bold>c</bold> Charge distribution of the source/channel/drain layers when gate is separated from the IL layer. <bold>d</bold> Corresponding band diagram of the source/channel/drain layers when gate is separated from the IL layer. <bold>e</bold> Charge distribution of each layer at separation state. <bold>f</bold> Corresponding band diagram of each layer at separation state. <bold>g–i</bold> The electrical field distributions of VTT under three different states. <bold>j–l</bold> Potential distribution at MXenes electrode.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2022_35628_Fig3_HTML.png"/></fig></p><p id="Par14">To further understand the working mechanism and charge transport in VTT, a 2D cross-section simulation model is exploited to demonstrate the electrical field distributions and electrical potential during the aforementioned three states, as depicted in Fig. <xref rid="Fig3" ref-type="fig">3g–l</xref>. Notably, the drain-source current of VTT is dependent on the distance between gate electrode and IL, and different distances would result in different gate voltage. Thus, the structure of VTT in COMSOL Multiphysics is simply considered as a typical VOFET with varied gate voltage, as depicted in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">10</xref>. Figure <xref rid="Fig3" ref-type="fig">3g–i</xref> show the electrical field distributions of VTT under three different states, which indicates that the distance between gate electrode and IL could effectively control the charge behavior at the IL/PDVT-10 interface. Furthermore, Fig. <xref rid="Fig3" ref-type="fig">3j–l</xref> show the 1D potential distribution of MXenes electrode position (Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">10</xref>). It is observed that the potential becomes more negative as the distance increased, indicating stronger band-bending at the Mxene/semiconductor interface, which is favorable for the injection of holes into the PDVT-10 channel. Moreover, the working mechanism of acoustic signal into electrical signal is illustrated in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">S11</xref>.</p></sec><sec id="Sec5"><title>Self-powered vertical tribo-transistor with multi-sensing-memory function</title><p id="Par15">Furthermore, the multi-sensing-memory function of our VTT is demonstrated. Note that EDL effect is generated at ion-gel layer, which is accompanied with retentive effects and the ion transport in EDL, resulting in synaptic behaviors of VTT. In our sensing-memory-computing system, the sensory transduction process can be regarded as the presynaptic process, and the memory-computing process can be regarded as the postsynaptic process, as depicts in Fig. <xref rid="Fig4" ref-type="fig">4a</xref>. We first study the synaptic plasticity of the VTT with different tactile, auditory, and visual input signals. Fig <xref rid="Fig4" ref-type="fig">4</xref>b, <xref rid="Fig4" ref-type="fig">c</xref> show the tactile response of this VTT, where the gate voltage is controlled by the distance between gate electrode and IL, and the drain-source voltage is fixed at a constant value of −0.5 V. With the distance increased from 25 μm to 250 μm, the equivalent gate voltage is increased from 0.5 V to 1.5 V, and the post-synaptic current amplitude of I<sub>DS</sub> is augmented from 0.1 μA to 8 μA, as shown in Fig. <xref rid="Fig4" ref-type="fig">4b</xref>. Meanwhile, the EPSC peak as a function of pulse time with a fixed distance of 25 μm is depicted in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">12</xref>. The EPSC firstly shows a linear enhancement when the pulse time is below 300 ms and then becomes saturated when the pulse time increases from 300 ms to 1000 ms. Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">13</xref> shows the responding time and decay time of the tactile EPSC, and the responding time is increased from 5 ms to 40 ms with the distance increased from 25 μm to 250 μm. Clearly, larger distance will result in longer time of gate electrode and ion-gel insulating layer to contact with each other and then induce more ions and carries. Moreover, paired-pulse facilitation (PPF) is also presented in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">14</xref>. As the interval time of two continuous pluses is shorter than the ion transfer time, an obvious increase of the second EPSC amplitude can be observed. Thus, we further investigated the EPSC amplitude under different pulse frequencies. As illustrated in Fig. <xref rid="Fig4" ref-type="fig">4c</xref>, with the frequency changed from 1 Hz to 10 Hz, I<sub>max</sub>/I<sub>min</sub> (I<sub>max</sub> is the 10th EPSC amplitude, I<sub>min</sub> is the 1st EPSC amplitude) increases from 1.2 to 40, which is critical for future neuromorphic computing such as dynamic high-pass filter.<fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><title>Synapse response of tactile, auditory, and visual.</title><p><bold>a</bold> The sensory transduction and memory-computing process. The tactile response of our VTT: <bold>b</bold> The EPSC with different distance and <bold>c</bold> I<sub>max</sub>/I<sub>min</sub> with different pulse frequencies. The error bar in <bold>c</bold> means the value of I<sub>max</sub>/I<sub>min</sub> within ten cycles. The auditory response of our VTT: <bold>d</bold> EPSCs of VTT with sound pressure level ranging from 40 dB to 80 dB. <bold>e</bold> EPSCs of VTT with different sound frequencies. <bold>f</bold> Recorded TENG output, pre-synaptic voltage and corresponding post-synaptic current. <bold>g</bold> The visual response of our VTT Normalization EPSCs with different light intensity. <bold>h</bold> EPSC amplitudes with two successive light pluses with different interval time.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2022_35628_Fig4_HTML.png"/></fig></p><p id="Par16">Additionally, for the auditory response, the EPSCs of the VTT with a sound pressure level ranging from 40 dB to 80 dB are shown in Fig. <xref rid="Fig4" ref-type="fig">4d</xref>. When the auditory pulse (100 ms) is applied to VTT, the EPSC rapidly reaches a peak value and then gradually decays to resting current. Meanwhile, the magnitude of EPSC increases from 0.5  μA to 3.2 μA when the sound pressure level increases from 40 dB to 80 dB, and the responding time and decay time of EPSC is also increased with the sound pressure level increased (Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">12</xref>). Moreover, the effect of different sound frequencies (100 ms) on the EPSCs of the VTT is depicted in Fig. <xref rid="Fig4" ref-type="fig">4e</xref>. The EPSC amplitudes first increases and then decreases with the frequencies ranging from 500 Hz to 3000 Hz, and the EPSC reaches its peak at the frequency of 1000 Hz. Fig <xref rid="Fig4" ref-type="fig">4f</xref> shows the V<sub>oc</sub> of TENG, transferred pre-synaptic voltage, and corresponding post-synaptic current is driven by two different voice signals. Clearly, different voice signals can be distinguished with different post-synaptic currents.</p><p id="Par17">Furthermore, the visual response of VTT is illustrated in Fig. <xref rid="Fig4" ref-type="fig">4h</xref><xref rid="Fig4" ref-type="fig">g</xref>. The temporal response of normalized EPSCs as function of light intensity is demonstrated in Fig. <xref rid="Fig4" ref-type="fig">4h</xref>, and the inset shows a typical EPSC response with the intensity of 0.1 mW/cm<sup>2</sup>. The amplitudes of EPSC increase almost linearly within a small light intensity range below 0.1 mW/cm<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>, and then a saturated EPSC would be recorded with further increase of the light intensity. Meanwhile, the responding time and decay time are also shown in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">12</xref>. The working mechanism of VTT under light is shown in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">15</xref>. Figure <xref rid="Fig4" ref-type="fig">4g</xref> illustrates the application of two successive light pulses with different interval time (5 s, 1 s, and 0.5 s), where the second EPSC peak increases with the decreases of the interval time. The increased EPSC value after the first light pulse and the second (consecutive) light pulse are denoted as EPSC<sub>1</sub> and EPSC<sub>2</sub>, respectively. Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">16</xref> depicts the ratio of EPSC<sub>2</sub>/ EPSC<sub>1</sub> as a function of interval time, which is an indicator of enhancement of synaptic connections. The increased ratio suggests that the ion transport-mitigating layer contribute notably to maintain synaptic connections. Furthermore, VTT shows high endurance and stability with several cycles and days, respectively, as shows in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">17</xref>. These multi-sensing synaptic functions of our VTT lay foundation for realizing artificial intelligence system with sensing-memory-computing ability.</p></sec><sec id="Sec6"><title>Self-powered vertical tribo-transistor with multi-sensing-memory-computing (MSMC) function</title><p id="Par18">Importantly, the function of MSMC in the human brain can associate and learn crossmodal information. Inspired by this fact, we then investigated the MSMC function of our VTT device. Figure <xref rid="Fig5" ref-type="fig">5a</xref> depicts the traditional digit MSMC system, which contains several components, such as the signal acquisition part (receptors), the power supply part, the preliminary processing parts, and the processing unit. However, the separated analog-digital hybrid circuit, memory, computing, convolution computation and other hardware result in slow processing speed and high power consumption. Our self-powered VTT device is illustrated in Fig. <xref rid="Fig5" ref-type="fig">5b</xref>, the TENG component in VTT is regarded as the sensor of the MSMC system, and VTT is regarded as the preliminary and processing unit. Since the working mechanism of VTT under mechanical and optical stimuli is different, such device is attractive for processing multi-sensing information without an extra preliminary processing unit. Here, the output current (I<sub>DS</sub>) of VTT is depicted as I<sub>DS</sub> = A×I<sub>DS1</sub> + B×I<sub>DS2</sub> + … + N×I<sub>DSn</sub>, where I<sub>DS1</sub>, I<sub>DS2</sub>, and I<sub>DSn</sub> are the EPSC with different external stimuli (visual, auditory, tactile, etc.). Meanwhile, the expression of I<sub>DS</sub> is depicted as eq. (<xref rid="Equ4" ref-type="disp-formula">4</xref>):<disp-formula id="Equ4"><label>4</label><alternatives><mml:math id="Equ4_Math"><mml:mi mathvariant="normal">F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mi mathvariant="normal">z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">A</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">B</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo>…</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="normal">N</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="normal">w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><tex-math id="Equ4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{{{{\rm{F}}}}}}({{{{{\rm{x}}}}}},{{{{{\rm{y}}}}}},\ldots {{{{{\rm{z}}}}}})={{{{{\rm{A}}}}}}\times {{{{{\rm{h}}}}}}({{{{{\rm{x}}}}}})+{{{{{\rm{B}}}}}}\times {{{{{\rm{g}}}}}}({{{{{\rm{y}}}}}})+\ldots+{{{{{\rm{N}}}}}}\times {{{{{\rm{w}}}}}}({{{{{\rm{z}}}}}})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41467_2022_35628_Article_Equ4.gif"/></alternatives></disp-formula>where h (x), g (x), and w (z) are I<sub>DS1</sub>, I<sub>DS2</sub>, and I<sub>DSn</sub> of VTT, respectively, A, B, and N are constants. For example, as shown in Fig. <xref rid="Fig5" ref-type="fig">5c</xref>, the EPSC of VTT under auditory stimuli is fitted as h(x) = −6.5 × exp × (−x/65.9) + 4.9, and the EPSC of VTT under optical stimuli is fitted as g(y) = −6.5 × exp × (−y/32.5) + 5.4. Based on the change of EPSC amplitude, the response under auditory and optical stimuli simultaneously can be fitted as F (x,y) = A × h (x) + B × g (y). Noticeably, with the increases of stimuli pluses, the constant of A decreases, while B increases, as illustrated in Fig. <xref rid="Fig5" ref-type="fig">5d</xref>. We further investigate the MSMC function of VTT with tactile and visual response simultaneously, as illustrated in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">18</xref>. This phenomenon further demonstrates that our artificial multisensory device with the MSMC function could facilitate the parallel processing of large amounts of external stimuli information, which decreases the data exchange between storage and computation, increases working speed, and decreases power consumption compared with traditional CMOS architecture.<fig id="Fig5"><label>Fig. 5</label><caption xml:lang="en"><title>Multi-sensing-memory-computing model and mimicking superior colliculus.</title><p><bold>a</bold> External stimuli of our environment and traditional sensing-memory-computing block, which consists of power supply unit, receptor unit, preliminary processing unit, and processing unit. <bold>b</bold> Equivalent multi-sensing-memory-computing of our VTT and corresponding cross-correlation functions between single sensing-memory-computing and multi-sensing-memory-computing. <bold>c</bold> EPSC with different stimuli, which can be well-fitted by cross-correlation functions. <bold>d</bold> The change of A and B with increased external sensing pulses (single voice pulses, and light pulses; or voice+light pulses). <bold>e</bold> Single sensory stimuli and multisensory stimuli with different sensory strength. The error bar in (<bold>e</bold>) means the stimuli of single sensory and multisensory within ten cycles. <bold>f</bold> The %change from superadditive, additive, to subadditive.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2022_35628_Fig5_HTML.png"/></fig></p><p id="Par19">Furthermore, considering that multisensory integration is a critical and ongoing determinant of human behavior. Noticeably, inputs from different sensory neurons are converged on cells in the superior colliculus, and then result in multisensory integration. Here, we mimicked the response of superior colliculus in the human brain upon the approaching of a dog to demonstrate the multisensory integration (as illustrated in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">19</xref>). As the dog became closer, the individual information (visual and auditory) shows higher impulses, while VA responses became proportionately weaker (Fig. <xref rid="Fig5" ref-type="fig">5e</xref>). In addition, the change between single sensory and multi-sensory is defined as VA/(Vmax, Amax)×100% (%change). Clearly, the %change is enhanced with the dog being closer, as illustrated in Fig. <xref rid="Fig5" ref-type="fig">5f</xref>. The neural computation involved in their integration is changed from superadditive to additive and then to subadditive, and the detailed illustrations are provided in Supplementary Note <xref ref-type="supplementary-material" rid="MOESM1">2</xref>. Moreover, as multisensory integration could enhance the single sensory signal and the behaviors that depend on them, we further constructed an artificial stimulus-response system to further prove the multisensory enhancement concept. The robot hand system supported by our VTT is also illustrated in Supplementary Note <xref ref-type="supplementary-material" rid="MOESM1">3</xref>.</p></sec><sec id="Sec7"><title>Self-powered vertical tribo-transistor with MSMC function for multi-mode emotion recognition</title><p id="Par20">All of the above characterizations and analyses imply that our VTT exhibits excellent MSMC function in a single device. Thus, based on the MSMC function, we construct a multi-model emotion recognition system to further demonstrate the capability of VTT in extending artificial intelligent boundary. Noticeably, the emotion is tightly entangled with behavior of human, while the complete emotion information cannot be obtained only through visual or auditory perception. Thus, combining the characteristic information and extracted feature information from the two perceptions would improve the emotion recognition accuracy and reliability. As depicts in Fig. <xref rid="Fig6" ref-type="fig">6</xref>, through single VTT device, we achieve the multi-model emotion recognition. Noticeably, the effective features are extracted from visual and auditory mode by our devices (the EPSC with different light intensity is been separated into 16 states, and each state corresponds to 16 numerical values of colorful images, as depicted in Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">22</xref>), and then the information is transferred to input layer for further processing, as indicates in Fig. <xref rid="Fig6" ref-type="fig">6a</xref> and Supplementary Fig. <xref ref-type="supplementary-material" rid="MOESM1">23</xref>. Here, the select fusion model is data-level fusion, which directly combines the most original data collect by our devices without special processing to construct a group of new data. Then the several basic discrete emotions, such as sadness, fear, disgust, surprise, excitement and anger can be recognized by operation methods to compute and process data from multiple data sources.<fig id="Fig6"><label>Fig. 6</label><caption xml:lang="en"><title>Multi-model emotion recognition system.</title><p><bold>a</bold> The schematic diagram of multi-model emotion recognition system to recognize the six emotions (anger, fear, disgust, happiness, surprise, and sadness), where the recognition process includes information fusion, feature extract, data classification, emotion recognition. <bold>b</bold> The pictures extract from database without sound information for emotion recognition. <bold>c</bold> The recognition accuracy of different emotion with single visual model. <bold>d</bold> The sound extract from database without visual information for emotion recognition. <bold>e</bold> The recognition accuracy of different emotion with single auditory model. <bold>f</bold> The recognition accuracy of different emotion with multi-model model. <bold>g</bold> The recognition accuracy of our multi-model emotion recognition system at different model.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2022_35628_Fig6_HTML.png"/></fig></p><p id="Par21">We first demonstrate the motion recognition accuracy with visual model, auditory model, and multi-model, respectively, as illustrates in Figs. <xref rid="Fig6" ref-type="fig">6</xref>b–<xref rid="Fig6" ref-type="fig">f</xref>. Several images are selected from a video without sound information, sound wave, or visual information, and the recognition accuracy of six emotions is summarized at Figs. <xref rid="Fig6" ref-type="fig">6</xref>c, e, and <xref rid="Fig6" ref-type="fig">6f</xref>. Note that, the accuracy of multi-model emotion recognition is significantly higher than that of a single model, which further indicates that our multi-model emotion recognition system is suitable for recognizing the complex emotional category through a certain combination mode. Thus, the comparison of recognition accuracy between different models is further shown in Fig. <xref rid="Fig6" ref-type="fig">6g</xref>. Clearly, the visual + auditory model exhibits the highest recognition accuracy of 94.05% after 140 epochs, while the accuracy of other single models is lower than that of the multi-model system. Moreover, the accuracy is higher than the values reported in previous works as illustrates in Table <xref rid="Tab1" ref-type="table">1</xref>. These results apparently demonstrate that MSMC VTT device can well retain the data information on each modal sensor to avoid the loss of information, maintain the integrity of information, and significantly enhance the certainty of emotion.<table-wrap id="Tab1"><label>Table 1</label><caption xml:lang="en"><p>Accuracy of multi-modal recognition with different model</p></caption><table frame="hsides" rules="groups"><thead><tr><th><p>Multi-model</p></th><th><p>Model</p></th><th><p>Mode</p></th><th><p>Device number</p></th><th><p>Accuracy</p></th><th><p>Ref.</p></th></tr></thead><tbody><tr><td><p>Visual+Auditory</p></td><td><p>Emotion</p></td><td><p>Software</p></td><td><p>/</p></td><td><p>90.8%</p></td><td><p><sup><xref ref-type="bibr" rid="CR48">48</xref></sup></p></td></tr><tr><td><p>Visual +Auditory</p></td><td><p>Emotion</p></td><td><p>Software</p></td><td><p>/</p></td><td><p>77.5%</p></td><td><p><sup><xref ref-type="bibr" rid="CR49">49</xref></sup></p></td></tr><tr><td><p>Visual + Auditory</p></td><td><p>Emotion</p></td><td><p>Software</p></td><td><p>/</p></td><td><p>85.9%</p></td><td><p><sup><xref ref-type="bibr" rid="CR50">50</xref></sup></p></td></tr><tr><td><p>Visual+Auditory</p></td><td><p>Emotion</p></td><td><p>Software</p></td><td><p>/</p></td><td><p>82.9%</p></td><td><p><sup><xref ref-type="bibr" rid="CR51">51</xref></sup></p></td></tr><tr><td><p>Visual+Auditory</p></td><td><p>Emotion</p></td><td><p>Software</p></td><td><p>/</p></td><td><p>80.3%</p></td><td><p><sup><xref ref-type="bibr" rid="CR52">52</xref></sup></p></td></tr><tr><td><p>Visual+Tactile</p></td><td><p>Digit</p></td><td><p>Device</p></td><td><p>Two</p></td><td><p>90%</p></td><td><p><sup><xref ref-type="bibr" rid="CR53">53</xref></sup></p></td></tr><tr><td><p>Visual+Tactile</p></td><td><p>Digit</p></td><td><p>Device</p></td><td><p>Two</p></td><td><p>86.8%</p></td><td><p><sup><xref ref-type="bibr" rid="CR19">19</xref></sup></p></td></tr><tr><td><p>Visual+Tactile</p></td><td><p>Alphabet Letters</p></td><td><p>Device</p></td><td><p>/</p></td><td><p>92%</p></td><td><p><sup><xref ref-type="bibr" rid="CR24">24</xref></sup></p></td></tr><tr><td><p>Visual+Auditory</p></td><td><p><italic>Emotion</italic></p></td><td><p><italic>Device</italic></p></td><td><p><italic>Single</italic></p></td><td><p><italic>94.05%</italic></p></td><td><p><italic>This work</italic></p></td></tr></tbody></table></table-wrap></p><p id="Par22">Finally, the superiority of our self-powered multi-sensing-memory-computing device is concluded. (i) simple structure and self-powered device: the receptors and synapses are integrated in a single device based on a simple configuration of VOFET without any redundant layers, which enhances packing density, simplifies fabrication procedures and reduces chip cost, and further decreases power consumption with the self-power function of TENG. (ii) high sensitivity: The amplification, low SS (91.8 mV/dec) and high current density (5 mA/cm<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>) of VTT ensure high sensing sensitivity (the tactile sensitivity improves 711 times over individual TENG). (iii) high efficiency and conversion speed: the multi-sensing-memory-computing function and the interaction of multifunction integration of our VTT increases the conversion speed, which is associated with the decreased physical separation between sensory receptors and processed nodes compared with the traditional CMOS architecture. (iv) high recognition accuracy: the multi-model emotion recognition is successfully achieved based on the multi-sensing-memory-computing ability of our VTT, which significantly improves the computing functionality, recognition variety and accuracy.</p></sec></sec><sec id="Sec8" sec-type="discussion"><title>Discussion</title><p id="Par23">In summary, we experimentally demonstrate a multi-sensing-memory-computing device that integrated a TENG and a transistor in a single device with the configuration of VOFET. Compared with a single TENG device, the sensing sensitivity is significantly enhanced due to the excellent SS and high current density of VTT. Meanwhile, in addition to tactile and auditory perception, the visual perception can be mimicked with the unique advantage and optical-sensitivity performance of MXene electrode. By calculating the cross-correlation functions, the memory-computing between multi-sensing is demonstrated, and the superior colliculus function and artificial stimulus-response system is also mimicked thanks to the multi-sensing integration property of our VTT. Finally, a multi-model emotion recognition system based on our VTT is achieved, which enables 94.05% recognition accuracy of emotion via data-level model fusion. This proof-of-concept work realized tactile/auditory/visual sensing-memory-computing within a single device, which has the potential to decrease the data movement between sensor, memory, and computing units, and paves the way for brain-inspired computing paradigms.</p></sec><sec id="Sec9" sec-type="methods"><title>Methods</title><sec id="Sec10"><title>Device fabrication</title><p id="Par24">The prepared ion–gel solution was spin-coated on Si substrate as the friction layer and insulation layer of TENG and VOFET, respectively. The ion–gel solution was obtained by mixed PAN, [Li<sup>+</sup>TFSI<sup>−</sup>], EC, and PC in a weight ratio of 7:1:1:1 and then the mixture was magnetically stirred at 500 rpm for 6 h. Then, the 2 mg/ml MXenes aqueous solution was selected as the top electrode and source network electrode of TENG and VOFET, respectively. Next, the prepared PDVT-10 solution was spin-coated on the electrode layer as the semiconductor layer, and then the patterned source and drain electrodes were thermally evaporated through a shadow mask. Finally, the fabricated device was transferred to the thermally evaporated gate electrode as VTT device.</p></sec><sec id="Sec11"><title>Device characterization</title><p id="Par25">The output performance of TENG was measured by an oscilloscope. The electrical performance of the synaptic transistor was characterized by Keithley 4200. The surface morphology of MXenes was examined by using scanning electron microscopy (SEM, Verios G4), transmission electron microscopy (TEM, Tecnai G2 F20). The UV-Vis absorption spectra of the films were measured by ultraviolet–visible near infrared spectrophotometer (Shimadzu UV-3600 Plus).</p></sec></sec></body><back><ack><title>Acknowledgements</title><p>The authors are grateful for financial support from National Natural Science Foundation of China (U21A20497) Natural Science Foundation for Distinguished Young Scholars of Fujian Province (2020J06012), Fujian Science &amp; Technology Innovation Laboratory for Optoelectronic Information of China (2021ZZ129).</p></ack><sec sec-type="author-contribution"><title>Author contributions</title><p>H.P.C. T.L.G. and Y.Y.H. conceived the project, Y.Q.L. designed and performed the experiments and collected the data. Y.Q.L., D.L., C.S.G., X.H.Z., R.J.Y., X.M.W. and E.L.L. analyzed and discussed the data. H.P.C. supervised the project. Y.Q.L. and H. P. C. wrote the paper.</p></sec><sec sec-type="peer-review"><title>Peer review</title><sec id="FPar1"><title>Peer review information</title><p id="Par26"><italic>Nature Communications</italic> thanks Sherajul Islam, and the other, anonymous, reviewers for their contribution to the peer review of this work.</p></sec></sec><sec sec-type="data-availability"><title>Data availability</title><p>The data that support the findings of this study are available from the corresponding author upon request.</p></sec><sec sec-type="data-availability"><title>Code availability</title><p>The codes used for the simulations are available in [<ext-link xlink:href="https://github.com/YaqianLiuFZU/NCOMMS-22-33550" ext-link-type="uri">https://github.com/YaqianLiuFZU/NCOMMS-22-33550</ext-link>]<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>.</p></sec><sec sec-type="ethics-statement"><sec id="FPar2" sec-type="COI-statement"><title>Competing interests</title><p id="Par27">The authors declare no competing interests.</p></sec></sec><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>T</given-names></name><etal/></person-group><article-title xml:lang="en">Neuromorphic sensory computing</article-title><source>Sci. China Inform. Sci.</source><year>2022</year><volume>65</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1007/s11432-021-3336-8</pub-id></mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeng</surname><given-names>X</given-names></name><name><surname>Hu</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Sensation and perception of a bioinspired flexible smart sensor system</article-title><source>ACS Nano.</source><year>2021</year><volume>15</volume><fpage>9238</fpage><lpage>9243</lpage><pub-id pub-id-type="doi">10.1021/acsnano.1c03408</pub-id></mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ielmini</surname><given-names>D</given-names></name><name><surname>Wong</surname><given-names>H-SP</given-names></name></person-group><article-title xml:lang="en">In-memory computing with resistive switching devices</article-title><source>Nat. Electron.</source><year>2018</year><volume>1</volume><fpage>333</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1038/s41928-018-0092-2</pub-id></mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>T-Y</given-names></name><etal/></person-group><article-title xml:lang="en">Reconfigurable optoelectronic memristor for in-sensor computing applications</article-title><source>Nano Energy.</source><year>2021</year><volume>89</volume><fpage>106291</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXhsFKnurfO</pub-id><pub-id pub-id-type="doi">10.1016/j.nanoen.2021.106291</pub-id></mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>John</surname><given-names>RA</given-names></name><etal/></person-group><article-title xml:lang="en">Self healable neuromorphic memtransistor elements for decentralized sensory signal processing in robotics</article-title><source>Nat. Commun.</source><year>2020</year><volume>11</volume><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2020NatCo..11.4030J</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXhs1Wrtr3N</pub-id><pub-id pub-id-type="doi">10.1038/s41467-020-17870-6</pub-id></mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>J</given-names></name><etal/></person-group><article-title xml:lang="en">Intrinsic polarization coupling in 2D α‐In<sub>2</sub>Se<sub>3</sub> toward artificial synapse with multimode operations</article-title><source>SmartMat</source><year>2021</year><volume>2</volume><fpage>88</fpage><lpage>98</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB38XisFKqtrbF</pub-id><pub-id pub-id-type="doi">10.1002/smm2.1020</pub-id></mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Pawelzik</surname><given-names>K</given-names></name><name><surname>Markram</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Neural networks with dynamic synapses</article-title><source>Neural Comput.</source><year>1998</year><volume>10</volume><fpage>821</fpage><lpage>835</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DyaK1c3ktFOruw%3D%3D</pub-id><pub-id pub-id-type="doi">10.1162/089976698300017502</pub-id></mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Zeng, M., He, Y., Zhang, C. &amp; Wan, Q. Neuromorphic devices for bionic sensing and perception. <italic>Front. Neurosci.</italic><bold>15</bold>, 690950 (2021).</mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alvarado</surname><given-names>JC</given-names></name><name><surname>Vaughan</surname><given-names>JW</given-names></name><name><surname>Stanford</surname><given-names>TR</given-names></name><name><surname>Stein</surname><given-names>BE</given-names></name></person-group><article-title xml:lang="en">Multisensory versus unisensory integration: contrasting modes in the superior colliculus</article-title><source>J. Neurophysiol.</source><year>2007</year><volume>97</volume><fpage>3193</fpage><lpage>3205</lpage><pub-id pub-id-type="doi">10.1152/jn.00018.2007</pub-id></mixed-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>H</given-names></name><name><surname>Agus</surname><given-names>TR</given-names></name><name><surname>Pressnitzer</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Auditory memory for random time patterns</article-title><source>J. Acoust. Soc. Am.</source><year>2017</year><volume>142</volume><fpage>2219</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2017ASAJ..142.2219K</pub-id><pub-id pub-id-type="doi">10.1121/1.5007730</pub-id></mixed-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stein</surname><given-names>BE</given-names></name><name><surname>Stanford</surname><given-names>TR</given-names></name></person-group><article-title xml:lang="en">Multisensory integration: current issues from the perspective of the single neuron</article-title><source>Nat. Rev. Neurosci.</source><year>2008</year><volume>9</volume><fpage>255</fpage><lpage>266</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2016NatGe...9..255S</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD1cXjsFCks7w%3D</pub-id><pub-id pub-id-type="doi">10.1038/nrn2331</pub-id></mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meredith</surname><given-names>MA</given-names></name><name><surname>Stein</surname><given-names>BE</given-names></name></person-group><article-title xml:lang="en">Visual, auditory, and somatosensory convergence on cells in superior colliculus results in multisensory integration</article-title><source>J. Neurophysiol.</source><year>1986</year><volume>56</volume><fpage>640</fpage><lpage>662</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DyaL2s%2FlvF2rtw%3D%3D</pub-id><pub-id pub-id-type="doi">10.1152/jn.1986.56.3.640</pub-id></mixed-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bu</surname><given-names>X</given-names></name><etal/></person-group><article-title xml:lang="en">Ion‐Gated Transistor: An Enabler for Sensing and Computing Integration</article-title><source>Adv. Intell. Syst.</source><year>2020</year><volume>2</volume><fpage>2000156</fpage><pub-id pub-id-type="doi">10.1002/aisy.202000156</pub-id></mixed-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Liu, Y. et al. Stretchable motion memory devices based on mechanical hybrid materials. <italic>Adv. Mater</italic>. <bold>29,</bold>1701780 (2017).</mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>TY</given-names></name><etal/></person-group><article-title xml:lang="en">Ultralow power wearable heterosynapse with photoelectric synergistic modulation</article-title><source>Adv. Sci.</source><year>2020</year><volume>7</volume><fpage>1903480</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXhsVKmsL7L</pub-id><pub-id pub-id-type="doi">10.1002/advs.201903480</pub-id></mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shim</surname><given-names>H</given-names></name><etal/></person-group><article-title xml:lang="en">Stretchable elastic synaptic transistors and neurologically integrated engineering systems</article-title><source>Sci. Adv.</source><year>2019</year><volume>5</volume><fpage>eaax4691</fpage><pub-id pub-id-type="doi">10.1126/sciadv.aax4961</pub-id></mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>JS</given-names></name><etal/></person-group><article-title xml:lang="en">Sensing and memorising liquids with polarity-interactive ferroelectric sound</article-title><source>Nat. Commun.</source><year>2019</year><volume>10</volume><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2019NatCo..10.3575K</pub-id><pub-id pub-id-type="doi">10.1038/s41467-019-11478-1</pub-id></mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>Y</given-names></name><etal/></person-group><article-title xml:lang="en">Light-Emitting Memristors for Optoelectronic Artificial Efferent Nerve</article-title><source>Nano Lett.</source><year>2021</year><volume>21</volume><fpage>6087</fpage><lpage>6094</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2021NanoL..21.6087Z</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXhsFKhsLjE</pub-id><pub-id pub-id-type="doi">10.1021/acs.nanolett.1c01482</pub-id></mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>X</given-names></name><etal/></person-group><article-title xml:lang="en">Artificial multisensory integration nervous system with haptic and iconic perception behaviors</article-title><source>Nano Energy.</source><year>2021</year><volume>85</volume><fpage>106000</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXnt1Krsrw%3D</pub-id><pub-id pub-id-type="doi">10.1016/j.nanoen.2021.106000</pub-id></mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>ZH</given-names></name><etal/></person-group><article-title xml:lang="en">All-in-one two-dimensional retinomorphic hardware device for motion detection and recognition</article-title><source>Nat. Nanotechnol.</source><year>2021</year><volume>17</volume><fpage>27</fpage><lpage>32</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2022NatNa..17...27Z</pub-id><pub-id pub-id-type="doi">10.1038/s41565-021-01003-1</pub-id></mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>SW</given-names></name><name><surname>Kwon</surname><given-names>SM</given-names></name><name><surname>Kim</surname><given-names>Y-H</given-names></name><name><surname>Park</surname><given-names>SK</given-names></name></person-group><article-title xml:lang="en">Recent progress in transistor‐based optoelectronic synapses: from neuromorphic computing to artificial sensory system</article-title><source>Adv. Intell. Syst.</source><year>2021</year><volume>3</volume><fpage>2000162</fpage><pub-id pub-id-type="doi">10.1002/aisy.202000162</pub-id></mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hou</surname><given-names>YX</given-names></name><etal/></person-group><article-title xml:lang="en">Large-scale and flexible optical synapses for neuromorphic computing and integrated visible information sensing memory processing</article-title><source>ACS Nano.</source><year>2021</year><volume>15</volume><fpage>1497</fpage><lpage>1508</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXis12rtbrJ</pub-id><pub-id pub-id-type="doi">10.1021/acsnano.0c08921</pub-id></mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname><given-names>X</given-names></name><name><surname>Zhao</surname><given-names>X</given-names></name><name><surname>Tan</surname><given-names>MC</given-names></name><name><surname>Zhao</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Artificial perception built on memristive system: visual, auditory, and tactile sensations</article-title><source>Adv. Intell. Syst.</source><year>2020</year><volume>2</volume><fpage>1900118</fpage><pub-id pub-id-type="doi">10.1002/aisy.201900118</pub-id></mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>H</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Tao</surname><given-names>Q</given-names></name><name><surname>Rosen</surname><given-names>J</given-names></name><name><surname>van Dijken</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Bioinspired multisensory neural network with crossmodal integration and recognition</article-title><source>Nat. Commun.</source><year>2021</year><volume>12</volume><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2021NatCo..12.1120T</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXkvFCrsrs%3D</pub-id><pub-id pub-id-type="doi">10.1038/s41467-021-21404-z</pub-id></mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>C</given-names></name><etal/></person-group><article-title xml:lang="en">An artificial sensory neuron with visual-haptic fusion</article-title><source>Nat. Commun.</source><year>2020</year><volume>11</volume><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2020NatCo..11.4602W</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXhvVOntbbM</pub-id><pub-id pub-id-type="doi">10.1038/s41467-020-18375-y</pub-id></mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><etal/></person-group><article-title xml:lang="en">Gesture recognition using a bioinspired learning architecture that integrates visual data with somatosensory data from stretchable sensors</article-title><source>Nat. Electron.</source><year>2020</year><volume>3</volume><fpage>563</fpage><lpage>570</lpage><pub-id pub-id-type="doi">10.1038/s41928-020-0422-z</pub-id></mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>Z</given-names></name><etal/></person-group><article-title xml:lang="en">An artificial olfactory system with sensing, memory and self-protection capabilities-Elsevier Enhanced Reader</article-title><source>Nano Energy.</source><year>2021</year><volume>86</volume><fpage>106078</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXpvVShs7c%3D</pub-id><pub-id pub-id-type="doi">10.1016/j.nanoen.2021.106078</pub-id></mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>C</given-names></name><etal/></person-group><article-title xml:lang="en">An artificial sensory neuron with visual-haptic fusion</article-title><source>Nat. Commun.</source><year>2020</year><volume>11</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2020NatCo..11....2W</pub-id><pub-id pub-id-type="doi">10.1038/s41467-020-18375-y</pub-id></mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cai</surname><given-names>Y-W</given-names></name><etal/></person-group><article-title xml:lang="en">A flexible ultra-sensitive triboelectric tactile sensor of wrinkled PDMS/MXene composite films for E-skin</article-title><source>Nano Energy.</source><year>2021</year><volume>81</volume><fpage>105663</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXis1SgsbzK</pub-id><pub-id pub-id-type="doi">10.1016/j.nanoen.2020.105663</pub-id></mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">Chen, J. et al. Micro-cable structured textile for simultaneously harvesting solar and mechanical energy. <italic>Nature Energy.</italic><bold>1,</bold>16138 (2016).</mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>WT</given-names></name><etal/></person-group><article-title xml:lang="en">A Stretchable Highoutput Triboelectric Nanogenerator Improved by MXene Liquid Electrode with High Electronegativity</article-title><source>Adv. Funct. Mater.</source><year>2020</year><volume>30</volume><fpage>2004181</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXhvVajtr7M</pub-id><pub-id pub-id-type="doi">10.1002/adfm.202004181</pub-id></mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><etal/></person-group><article-title xml:lang="en">A one-structure-layer PDMS/Mxenes based stretchable triboelectric nanogenerator for simultaneously harvesting mechanical and light energy</article-title><source>Nano. Energy.</source><year>2021</year><volume>86</volume><fpage>106118</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXhtFSnsbvM</pub-id><pub-id pub-id-type="doi">10.1016/j.nanoen.2021.106118</pub-id></mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dudem</surname><given-names>B</given-names></name><name><surname>Ko</surname><given-names>YH</given-names></name><name><surname>Leem</surname><given-names>JW</given-names></name><name><surname>Lim</surname><given-names>JH</given-names></name><name><surname>Yu</surname><given-names>JS</given-names></name></person-group><article-title xml:lang="en">Hybrid energy cell with hierarchical nano/micro-architectured polymer film to harvest mechanical, solar, and wind energies individually/simultaneously</article-title><source>ACS Appl. Mater. Interfaces.</source><year>2016</year><volume>8</volume><fpage>30165</fpage><lpage>30175</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28XhslSis7jN</pub-id><pub-id pub-id-type="doi">10.1021/acsami.6b09785</pub-id></mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>Y</given-names></name><etal/></person-group><article-title xml:lang="en">Sustainable hybrid energy harvester based on air stable quantum dot solar cells and triboelectric nanogenerator</article-title><source>J. Mater. Chem. A.</source><year>2018</year><volume>6</volume><fpage>12440</fpage><lpage>12446</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXhtFemtL7J</pub-id><pub-id pub-id-type="doi">10.1039/C8TA03870H</pub-id></mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>C</given-names></name><etal/></person-group><article-title xml:lang="en">All-electrospun flexible triboelectric nanogenerator based on metallic MXene nanosheets</article-title><source>Nano Energy.</source><year>2019</year><volume>59</volume><fpage>268</fpage><lpage>276</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXktVChtr0%3D</pub-id><pub-id pub-id-type="doi">10.1016/j.nanoen.2019.02.052</pub-id></mixed-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>Y</given-names></name><etal/></person-group><article-title xml:lang="en">Stretchable energy‐harvesting tactile interactive interface with liquid‐metal‐nanoparticle‐based electrodes</article-title><source>Adv. Funct. Mater.</source><year>2020</year><volume>30</volume><fpage>1909652</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXitFeks7w%3D</pub-id><pub-id pub-id-type="doi">10.1002/adfm.201909652</pub-id></mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ye</surname><given-names>BU</given-names></name><etal/></person-group><article-title xml:lang="en">Electrospun ion gel nanofibers for flexible triboelectric nanogenerator: electrochemical effect on output power</article-title><source>Nanoscale</source><year>2015</year><volume>7</volume><fpage>16189</fpage><lpage>16194</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2015Nanos...716189Y</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXhsVGju7rL</pub-id><pub-id pub-id-type="doi">10.1039/C5NR02602D</pub-id></mixed-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>J</given-names></name><etal/></person-group><article-title xml:lang="en">Contact-electrification-activated artificial afferents at femtojoule energy</article-title><source>Nat. Commun.</source><year>2021</year><volume>12</volume><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2021NatCo..12.1581Y</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXmslKjs7Y%3D</pub-id><pub-id pub-id-type="doi">10.1038/s41467-021-21890-1</pub-id></mixed-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>D</given-names></name><etal/></person-group><article-title xml:lang="en">Diversiform sensors and sensing systems driven by triboelectric and piezoelectric nanogenerators</article-title><source>Coord. Chem. Rev.</source><year>2021</year><volume>427</volume><fpage>213597</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2021espc.book.....Z</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXitFSntLfN</pub-id><pub-id pub-id-type="doi">10.1016/j.ccr.2020.213597</pub-id></mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shao</surname><given-names>Y</given-names></name><etal/></person-group><article-title xml:lang="en">Nanogenerator-based self-powered sensors for data collection</article-title><source>Beilstein J. Nanotech.</source><year>2021</year><volume>12</volume><fpage>680</fpage><lpage>693</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXhs1Sqs7%2FM</pub-id><pub-id pub-id-type="doi">10.3762/bjnano.12.54</pub-id></mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>W</given-names></name><etal/></person-group><article-title xml:lang="en">Self-powered electrical stimulation for enhancing neural differentiation of mesenchymal stem cells on graphene-Poly(3,4-ethylenedioxythiophene) hybrid microfibers</article-title><source>ACS Nano.</source><year>2016</year><volume>10</volume><fpage>5086</fpage><lpage>5095</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28Xnt12ktrg%3D</pub-id><pub-id pub-id-type="doi">10.1021/acsnano.6b00200</pub-id></mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H</given-names></name><etal/></person-group><article-title xml:lang="en">Ion gel capacitively coupled tribotronic gating for multiparameter distance sensing</article-title><source>ACS Nano.</source><year>2020</year><volume>14</volume><fpage>3461</fpage><lpage>3468</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXjt1ynsLY%3D</pub-id><pub-id pub-id-type="doi">10.1021/acsnano.9b09549</pub-id></mixed-citation></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleemann</surname><given-names>H</given-names></name><name><surname>Krechan</surname><given-names>K</given-names></name><name><surname>Fischer</surname><given-names>A</given-names></name><name><surname>Leo</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">A review of vertical organic transistors</article-title><source>Adv. Funct. Mater.</source><year>2020</year><volume>30</volume><fpage>1907113</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXhsFOgtrY%3D</pub-id><pub-id pub-id-type="doi">10.1002/adfm.201907113</pub-id></mixed-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>D</given-names></name><etal/></person-group><article-title xml:lang="en">High performance flexible nonvolatile memory based on vertical organic thin film transistor</article-title><source>Adv. Funct. Mater.</source><year>2017</year><volume>27</volume><fpage>1703541</fpage><pub-id pub-id-type="doi">10.1002/adfm.201703541</pub-id></mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>E</given-names></name><etal/></person-group><article-title xml:lang="en">MXene based saturation organic vertical photoelectric transistors with low subthreshold swing</article-title><source>Nat. Commun.</source><year>2022</year><volume>13</volume><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2022NatCo..13.2898L</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB38XhsVaqu73F</pub-id><pub-id pub-id-type="doi">10.1038/s41467-022-30527-w</pub-id></mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>X</given-names></name><etal/></person-group><article-title xml:lang="en">Programmable neuronal-synaptic transistors based on 2D MXene for a high-efficiency neuromorphic hardware network</article-title><source>Matter</source><year>2022</year><volume>5</volume><fpage>1</fpage><lpage>18</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB38XhtVWnsL7P</pub-id><pub-id pub-id-type="doi">10.1016/j.matt.2022.06.009</pub-id></mixed-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="other">Liu Y., et al. Self-powered high-sensitivity all-in-one vertical tribo-transistor device for multi-sensing-memory-computing. <italic>Github</italic>, <ext-link xlink:href="10.5281/zenodo.7418909" ext-link-type="doi">https://doi.org/10.5281/zenodo.7418909</ext-link> (2022).</mixed-citation></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nguyen</surname><given-names>D</given-names></name><etal/></person-group><article-title xml:lang="en">Deep spatio-temporal feature fusion with compact bilinear pooling for multimodal emotion recognition</article-title><source>Comput. Vis. Image Und.</source><year>2018</year><volume>174</volume><fpage>33</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1016/j.cviu.2018.06.005</pub-id></mixed-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dobrisek</surname><given-names>S</given-names></name><etal/></person-group><article-title xml:lang="en">Towards efficient multi-modal emotion recognition</article-title><source>Int. J. Adv. Robot. Syst.</source><year>2013</year><volume>10</volume><fpage>53</fpage><pub-id pub-id-type="doi">10.5772/54002</pub-id></mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S</given-names></name><etal/></person-group><article-title xml:lang="en">Learning affective features with a hybrid deep model for audio–visual emotion recognition</article-title><source>IEEE T. Circ. Syst. Vid.</source><year>2017</year><volume>28</volume><fpage>3030</fpage><lpage>3043</lpage><pub-id pub-id-type="doi">10.1109/TCSVT.2017.2719043</pub-id></mixed-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="other">Kansizoglou I., Bampis L., Gasteratos A. An active learning paradigm for online audio-visual emotion recognition. <italic>IEEE Trans. Affect. Comput</italic>. <bold>13</bold>, 756–768 (2019).</mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="other">Raju J., Gaus Y. F. A., Breckon T. P. Continuous Multi-modal Emotion Prediction in Video based on Recurrent Neural Network Variants with Attention. 2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA). IEEE, 688–693 (2021).</mixed-citation></ref><ref id="CR53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>J</given-names></name><etal/></person-group><article-title xml:lang="en">Bioinspired mechano-photonic artificial synapse based on graphene/MoS<sub>2</sub> heterostructure</article-title><source>Sci. Adv.</source><year>2021</year><volume>7</volume><fpage>eabd9117</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2021SciA....7.9117Y</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXpsVaqsr0%3D</pub-id><pub-id pub-id-type="doi">10.1126/sciadv.abd9117</pub-id></mixed-citation></ref></ref-list></ref-list><app-group><app id="App1" specific-use="web-only"><sec id="Sec12"><title>Supplementary information</title><p id="Par28"><supplementary-material content-type="local-data" id="MOESM1" xlink:title="Supplementary information"><media mimetype="application" mime-subtype="pdf" xlink:href="MediaObjects/41467_2022_35628_MOESM1_ESM.pdf" position="anchor"><caption xml:lang="en"><p>Supplementary Information</p></caption></media></supplementary-material></p></sec></app></app-group><notes notes-type="ESMHint"><title>Supplementary information</title><p>The online version contains supplementary material available at <ext-link xlink:href="10.1038/s41467-022-35628-0" ext-link-type="doi">https://doi.org/10.1038/s41467-022-35628-0</ext-link>.</p></notes><notes notes-type="Misc"><p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Science, Humanities and Social Sciences, multidisciplinary</facet-value><facet-value count="1">Science, multidisciplinary</facet-value></facet><facet name="keyword"/><facet name="pub"><facet-value count="1">Nature Communications</facet-value></facet><facet name="year"><facet-value count="1">2022</facet-value></facet><facet name="country"><facet-value count="1">China</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
