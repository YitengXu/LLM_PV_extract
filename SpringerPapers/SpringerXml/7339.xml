<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1007/s12053-020-09879-z</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="research-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">12053</journal-id><journal-id journal-id-type="doi">10.1007/12053.1570-6478</journal-id><journal-title-group><journal-title>Energy Efficiency</journal-title><abbrev-journal-title abbrev-type="publisher">Energy Efficiency</abbrev-journal-title></journal-title-group><issn pub-type="ppub">1570-646X</issn><issn pub-type="epub">1570-6478</issn><publisher><publisher-name>Springer Netherlands</publisher-name><publisher-loc>Dordrecht</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s12053-020-09879-z</article-id><article-id pub-id-type="manuscript">9879</article-id><article-id pub-id-type="doi">10.1007/s12053-020-09879-z</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject></subj-group></article-categories><title-group><article-title xml:lang="en">Modelling energy demand response using long short-term memory neural networks</article-title></title-group><contrib-group><contrib contrib-type="author" id="Au1"><name><surname>Mesa Jiménez</surname><given-names>JoséJoaquìn</given-names></name><address><email>1630060@brunel.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au2"><name><surname>Stokes</surname><given-names>Lee</given-names></name><address><email>Lee.Stokes@mitie.com</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au3"><name><surname>Moss</surname><given-names>Chris</given-names></name><address><email>Chris.Moss@mitie.com</email></address><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au4"><name><surname>Yang</surname><given-names>Qingping</given-names></name><address><email>qingping.yang@brunel.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au5"><name><surname>Livina</surname><given-names>Valerie N.</given-names></name><address><email>valerie.livina@npl.co.uk</email></address><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="corresp" rid="IDs1205302009879z_cor5">e</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.7728.a</institution-id><institution-id institution-id-type="ISNI">0000 0001 0724 6933</institution-id><institution content-type="org-name">Brunel University London</institution></institution-wrap><addr-line content-type="street">Kingston Lane</addr-line><addr-line content-type="postcode">UB8 3PH</addr-line><addr-line content-type="city">London</addr-line><addr-line content-type="state">Uxbridge</addr-line><country country="GB">UK</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.410351.2</institution-id><institution-id institution-id-type="ISNI">0000 0000 8991 6349</institution-id><institution content-type="org-name">National Physical Laboratory</institution></institution-wrap><addr-line content-type="street">Hampton Road</addr-line><addr-line content-type="postcode">TW11 0LW</addr-line><addr-line content-type="city">Teddington</addr-line><country country="GB">UK</country></aff><aff id="Aff3"><label>3</label><institution-wrap><institution content-type="org-name">Mitie, The Shard</institution></institution-wrap><addr-line content-type="street">Level 12, 32 London Bridge Street</addr-line><addr-line content-type="postcode">SE1 9SG</addr-line><addr-line content-type="city">London</addr-line><country country="GB">UK</country></aff></contrib-group><author-notes><corresp id="IDs1205302009879z_cor5"><label>e</label><email>valerie.livina@npl.co.uk</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>24</day><month>7</month><year>2020</year></pub-date><pub-date date-type="pub" publication-format="print"><month>8</month><year>2020</year></pub-date><volume>13</volume><issue seq="15">6</issue><fpage>1263</fpage><lpage>1280</lpage><history><date date-type="registration"><day>26</day><month>6</month><year>2020</year></date><date date-type="received"><day>13</day><month>11</month><year>2018</year></date><date date-type="accepted"><day>26</day><month>6</month><year>2020</year></date><date date-type="online"><day>24</day><month>7</month><year>2020</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2020</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">We propose a method for detecting and forecasting events of high energy demand, which are managed at the national level in demand side response programmes, such as the UK Triads. The methodology consists of two stages: load forecasting with long short-term memory neural network and dynamic filtering of the potential highest electricity demand peaks by using the exponential moving average. The methodology is validated on real data of a UK building management system case study. We demonstrate successful forecasts of Triad events with <italic>R</italic><italic>R</italic><italic>M</italic><italic>S</italic><italic>E</italic> ≈ 2.2<italic>%</italic> and <italic>M</italic><italic>A</italic><italic>P</italic><italic>E</italic> ≈ 1.6<italic>%</italic> and general applicability of the methodology for demand side response programme management, with reduction of energy consumption and indirect carbon emissions.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Load forecasting</kwd><kwd>Demand side response</kwd><kwd>Machine learning</kwd><kwd>Long short-term memory</kwd><kwd>Triad forecasting</kwd><kwd>Electricity demand</kwd><kwd>Neural networks</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Springer</meta-value></custom-meta><custom-meta><meta-name>volume-issue-count</meta-name><meta-value>8</meta-value></custom-meta><custom-meta><meta-name>issue-article-count</meta-name><meta-value>15</meta-value></custom-meta><custom-meta><meta-name>issue-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>issue-pricelist-year</meta-name><meta-value>2020</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-holder</meta-name><meta-value>Springer Nature B.V.</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-year</meta-name><meta-value>2020</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>No</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2020</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>6</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>26</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>volume-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>ArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>false</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/12053_2020_Article_9879.pdf</meta-value></custom-meta><custom-meta><meta-name>pdf-type</meta-name><meta-value>Typeset</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>issue-online-date-year</meta-name><meta-value>2020</meta-value></custom-meta><custom-meta><meta-name>issue-online-date-month</meta-name><meta-value>8</meta-value></custom-meta><custom-meta><meta-name>issue-online-date-day</meta-name><meta-value>18</meta-value></custom-meta><custom-meta><meta-name>issue-print-date-year</meta-name><meta-value>2020</meta-value></custom-meta><custom-meta><meta-name>issue-print-date-month</meta-name><meta-value>8</meta-value></custom-meta><custom-meta><meta-name>issue-print-date-day</meta-name><meta-value>18</meta-value></custom-meta><custom-meta><meta-name>issue-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>OriginalPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Energy</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Energy Policy, Economics and Management</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Renewable and Green Energy</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Environmental Economics</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Environment, general</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Sustainable Development</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Energy Efficiency</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Energy</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><p id="Par2"><bold>Nomenclature</bold><def-list><def-item><term>ANFIS</term><def><p id="Par4">Adaptive Neural Fuzzy Inference System</p></def></def-item><def-item><term>ANN</term><def><p id="Par5">Artificial Neural Network</p></def></def-item><def-item><term>ARIMA</term><def><p id="Par6">Autoregressive Integrated Moving Average</p></def></def-item><def-item><term>CNN</term><def><p id="Par7">Convolutional Neural Network</p></def></def-item><def-item><term>CPP</term><def><p id="Par8">Critical Peak Pricing</p></def></def-item><def-item><term>DNN</term><def><p id="Par9">Deep Neural Network</p></def></def-item><def-item><term>DSR</term><def><p id="Par10">Demand Side Response</p></def></def-item><def-item><term>ELM</term><def><p id="Par11">Extreme Learning Machine</p></def></def-item><def-item><term>EMA</term><def><p id="Par12">Exponential Moving Average</p></def></def-item><def-item><term>FE</term><def><p id="Par13">Forecasted Error</p></def></def-item><def-item><term>GRU</term><def><p id="Par14">Gated Recurrent Unit</p></def></def-item><def-item><term>INDO</term><def><p id="Par15">Initial Demand Out-Turn</p></def></def-item><def-item><term>KNN</term><def><p id="Par16">K-Nearest Neighbors</p></def></def-item><def-item><term>LSSVM</term><def><p id="Par17">Least Square Support Vector Machine</p></def></def-item><def-item><term>LSTM</term><def><p id="Par18">Long-Short-Term Memory</p></def></def-item><def-item><term>MA</term><def><p id="Par19">Moving Average</p></def></def-item><def-item><term>MAE</term><def><p id="Par20">Mean Absolute Error</p></def></def-item><def-item><term>MARS</term><def><p id="Par21">Multivariate Adaptive Regression Spline</p></def></def-item><def-item><term>MLR</term><def><p id="Par22">Multiple Linear Regression</p></def></def-item><def-item><term>NDF</term><def><p id="Par23">National Demand Forecast</p></def></def-item><def-item><term>R1</term><def><p id="Par24">First Reconciliation</p></def></def-item><def-item><term>R2</term><def><p id="Par25">Second Reconciliation</p></def></def-item><def-item><term>RBF</term><def><p id="Par26">Radial Basis Function</p></def></def-item><def-item><term>RMSE</term><def><p id="Par27">Root Mean Square Error</p></def></def-item><def-item><term>RNN</term><def><p id="Par28">Recurrent Neural Network</p></def></def-item><def-item><term>SARIMA</term><def><p id="Par29">Seasonal Autoregressive Integrated Moving Average</p></def></def-item><def-item><term>SD</term><def><p id="Par30">Settled Demand</p></def></def-item><def-item><term>SF</term><def><p id="Par31">Settlement Final</p></def></def-item><def-item><term>SVM</term><def><p id="Par32">Support Vector Machines</p></def></def-item><def-item><term>TNUoS</term><def><p id="Par33">Transmission Network Use of System</p></def></def-item><def-item><term>ToU</term><def><p id="Par34">Time of Use</p></def></def-item><def-item><term>TSDF</term><def><p id="Par35">Transmission Demand Forecast</p></def></def-item></def-list></p><sec id="Sec1"><title>Introduction</title><p id="Par36">The changes in energy policy aim to substantially increase renewable energy generation and reduce carbon emissions. Addressing the growing energy demand, ageing infrastructure and intermittency of renewable energy requires an efficient forecasting methodology to predict periods of peak energy demand. Long-term power load forecasting at national level is an important basis for demand side response planning, which aims to reduce the need for last-minute energy generation from non-renewable sources.</p><p id="Par37">In the energy sector, demand side response (DSR) is meant to substantially reduce the need for investment in peak generation. This is done by minimising consumption at times of high demand. With the goal of adding stability to the system, demand response lowers the need for coal- and gas-fired spinning reserves. This reduces carbon emissions because most power plants burn fuel/coal continuously in order to supply power at short notice and thus reduces climate change impact and decreases the need for local network investments. Demand response refers to “voluntary changes by consumers of their electricity use pattern”, either in response to changes in the price of electricity over time or through incentive payments.</p><p id="Par38">Reducing electricity demand peaks is a key issue for DSR programmes and it is the next step for reduction of carbon emissions, and therefore, less power will have to be generated by coal and gas. In Faruqui and Sergici (<xref ref-type="bibr" rid="CR9">2010</xref>), 15 recent empirical assessments of residential dynamic pricing programmes are surveyed, most conducted in the USA after the year 2000. According to their survey, time-of-use (ToU) tariffs induce a reduction in peak consumption that ranges from 3 to 6% and critical peak pricing (CPP) has the effect of decreasing peak usage by between 13% and 20%. The variety of DSR programmes has been increasing in Europe over the past years; the number of systems specifically oriented to national DSR programmes in the scientific literature is lacking.</p><p id="Par39">There is a rich variety in the literature about methodologies for peak load forecasting, and there have been significant improvements in time series forecasting due to the increase of the computer capacity which has lead to new computational methods such as machine learning and other AI approaches. In Kouroupetroglou and Tsoumakas (<xref ref-type="bibr" rid="CR22">2017</xref>), in the comparison of machine learning models for short-term load forecasting in the Greek electric grid, six machine learning methods are compared: support vector machines (SVM), <italic>K</italic>-nearest neighbours (KNN), random forests, neural networks, xgboost and decision trees. This is very relevant due to its load forecasting methods used at a national level. Four experiments were performed in order to minimise the error of prediction accuracy. The results of these experiments show that, overall, decision trees performed better in terms of prediction error, followed by xgboost and SVM. In another comparative study (Al-Musaylh et al. <xref ref-type="bibr" rid="CR1">2018</xref>), three methodologies are compared for electricity demand forecasting: multivariate adaptive regression spline (MARS), autoregressive integrated moving average (ARIMA) and SVM. The results of this study show that, in terms of statistical metrics, MARS model yielded the most accurate results for 0.5 h and 1.0 h forecasts, whereas the SVR models were better for a 24 h horizon and the ARIMA model’s performance was lower for all forecasting horizons as it generated very high forecast errors.</p><p id="Par40">Another commonly used approach for load forecast is artificial neural networks (ANNs). ANNs are composed of a network of processing nodes (or neurons), which perform numerical transformations and are interconnected in a specific order so different weights are assigned to give importance to different factors through training the network. According to Chen et al. (<xref ref-type="bibr" rid="CR5">1992</xref>), ANNs are well-known for being able to forecast the outputs of nonlinear datasets, to efficiently perform different simultaneous tasks. There are several studies for load forecasting using ANNs, such as the comparative study (Kandananond <xref ref-type="bibr" rid="CR19">2011</xref>), in which three methodologies, ARIMA, ANN and multiple linear regression (MLR) were deployed to forecast the electricity demand in Thailand. The results showed that based on the historical data and on the error measurement the ANN model was superior to the other two. In Filik et al. (<xref ref-type="bibr" rid="CR10">2011</xref>), mathematical models and neural networks to forecast the long-term electricity demand in Turkey are compared. Some short-term load forecasting studies combine ANNs with other methods, such as Saini and Soni (<xref ref-type="bibr" rid="CR30">2002</xref>) which is an ANN-based peak load forecasting using Levenberg-Marquardt and quasi-Newton methods. Also, Gonzalez-Romera et al.’s (<xref ref-type="bibr" rid="CR12">2008</xref>) study focused on the periodic behaviour of consumption for forecasting the Spanish monthly electricity demand, in which the trend of electricity demand was predicted using an ANN combined with Fourier series. There are novel alternative methods that have been compared to more traditional ANN approaches, such as Singh and Dwivedi’s (<xref ref-type="bibr" rid="CR31">2018</xref>), whose study integrates an evolutionary approach with ANNs for short-term load forecast, based on “follow the leader” behaviour of sheep. This hybrid approach is compared with four other variations of ANNs, showing that they are outperformed by the “follow the leader” hybrid approach. The emerging class of ANN, extreme learning machine (ELM), plays an important role for this purpose in Li et al. (<xref ref-type="bibr" rid="CR23">2016</xref>), because it is invoked to predict the hourly load of the next day and it improves its performance significantly.</p><p id="Par41">Deep neural networks (DNNs) are also used for the purpose of load forecasting. DNNs are ANNs with several hidden layers, adding complexity to its structure. He (<xref ref-type="bibr" rid="CR15">2017</xref>) studies one day ahead forecasting of hourly loads based on deep networks. The study of Hamedmoghadam et al. (<xref ref-type="bibr" rid="CR14">2018</xref>) has a more specific goal, the aim is to use DNNs to predict the monthly electricity demand in Australia based on time series of consumption rates as well as socio-economic and environmental factors.</p><p id="Par42">Other methodologies such as radial basis function (RBF) have been used to address the problem of load forecasting (Yun et al. <xref ref-type="bibr" rid="CR35">2008</xref>; Liu and Li <xref ref-type="bibr" rid="CR24">2017</xref>; Khwaja et al. <xref ref-type="bibr" rid="CR20">2017</xref>). The study of Yun et al. (<xref ref-type="bibr" rid="CR35">2008</xref>) combines the RBF neural network with the adaptive neural fuzzy inference system (ANFIS) to adjust the prediction by taking into account the real-time electricity price. Khwaja et al. (<xref ref-type="bibr" rid="CR20">2017</xref>) compared three different versions of RBF to predict electricity load. In the area of short-term load forecasting, Cao et al. (<xref ref-type="bibr" rid="CR4">2015</xref>) addressed this problem by using adopted ARIMA model and similar day method for intraday load forecasting. For very short-term load forecasting, Qingle and Min (<xref ref-type="bibr" rid="CR29">2010</xref>), also proposed an ANN-based predictor and take the load values of the current and previous time steps as the input to predict the load value at the coming step.</p><p id="Par43">SVMs are also very relevant in the literature for load forecasting from earlier years. This is shown in Chen et al. (<xref ref-type="bibr" rid="CR6">2004</xref>) and Hong (<xref ref-type="bibr" rid="CR17">2009</xref>), as well as more recently modified SVM versions, which are combined with other methods in order to achieve a better accuracy. This is the case of Daut et al. (<xref ref-type="bibr" rid="CR7">2017</xref>) for load forecasting method using a combined least square SVM (LSSVM) and modified artificial bee colony (ABCclo-LSSVM), which proved to have a better performance than the standard ABC-LSSVM and LSSVM. Another example of modified SVM for load forecasting is Liu and Li’s (<xref ref-type="bibr" rid="CR24">2017</xref>), which uses the sperm whale algorithm and wavelet least square support vector machine with DWT-IR for feature selection.</p><p id="Par44">Recurrent neural networks (RNNs) are also very popular in the scientific literature as they can work on sequences of arbitrary length. More particularly in Bianchi et al. (<xref ref-type="bibr" rid="CR3">2017</xref>), a comparative study of short-term load forecast is performed by using different classes of RNNs, and although there is not a specific RNN model that outperforms the others in every prediction problem, it shows that LSTM and gated recurrent units (GRUs) achieve outstanding results in many sequence learning problems. As a peculiarity, LSTM, together with GRUs, presents no vanishing/exploding gradient problem. This has been proven in Zheng et al. (<xref ref-type="bibr" rid="CR36">2017</xref>) which shows that LSTM outperforms traditional forecasting methods in the short-term electric load forecasting. They compare its performance with other methods such as seasonal autoregressive integrated moving average model (SARIMA), a nonlinear autoregressive neural network model with exogenous inputs (NARX), SVM and NNETAR, a feed-forward neural network model for univariate time series forecasting with a single hidden layer and lagged inputs. Some other studies combine these methodologies, such as Tian et al.’s (<xref ref-type="bibr" rid="CR32">2018</xref>), which uses a deep neural network model for short-term load forecast based on LSTM and convolutional neural network (CNN), achieving the lowest error in comparison to the other algorithms tested. Kong et al. (<xref ref-type="bibr" rid="CR21">2017</xref>) performs short-term load residential load forecasting using an LSTM recurrent neural network showing a mean absolute percentage error (MAPE) between 1.5% and 35%, depending on the household. There are several other publications about LSTM for speech recognition, sentiment analysis and autonomous driving systems (Graves et al. <xref ref-type="bibr" rid="CR13">2013</xref>; Wang et al. <xref ref-type="bibr" rid="CR33">2016</xref>; Xu et al. <xref ref-type="bibr" rid="CR34">2016</xref>).</p><p id="Par45">This paper proposes a system for detecting events of high energy demand at national level in the context of DSR programmes. The system is designed in two stages: electricity demand forecasting with LSTM model and dynamic filtering of the potential highest electricity demand peaks with an exponential moving average (EMA). The system is validated in a specific case study of UK Triads, which are the three highest electricity demand peaks of the UK energy system from November to February. This application is of high importance for the UK energy market and the EU countries that already use DSR programmes.</p><p id="Par46">The rest of the paper is organised as follows: In “<xref rid="Sec2" ref-type="sec">Methodology</xref>”, the system for peak load forecast is first presented. Beginning with a description of the forecasting method based on a LSTM approach, followed by the peaks extraction method, root mean square error (RMSE), mean absolute error (MAE) and the relative error (%) based on MAE and RMSE (MAPE and RRMSE) as the performance measurement indicators. Next, in “<xref rid="Sec6" ref-type="sec">Case study: UK Triads</xref>”, the system presented in “<xref rid="Sec2" ref-type="sec">Methodology</xref>” is used and adapted for a specific case study: UK Triad forecast. Here, the input data for the algorithm is analysed and the parameters are adjusted through all the forecasting horizon to obtain the results. Last, in the results section, the outputs of the prior system are analysed by comparing the highest daily load peak obtained from the forecast with the actual demand peak of the day after all demand units have been submitted. Then, for this specific case study, another analysis based on the number of successfully forecasted Triads versus the number of warning signals is performed. After this section, the conclusions are presented.</p></sec><sec id="Sec2" sec-type="methods"><title>Methodology</title><p id="Par47">Here, we describe the LSTM, along with the filters performed by the exponential moving averages.</p><sec id="Sec3"><title>LSTM description</title><p id="Par48">Long short-term memory (Hochreiter and Schmidhuber <xref ref-type="bibr" rid="CR16">1997</xref>) has proven to be a useful method for time series analysis of records with several factors correlated with the output. This method can provide a good working system for the purpose of UK national electricity demand forecast, and an effective way to ensure that the system addresses correlations in that data.</p><p id="Par49">LSTM cells manage two state vectors, and for performance reasons, they are separate (Hochreiter and Schmidhuber <xref ref-type="bibr" rid="CR16">1997</xref>). The scheme of a single cell is illustrated below in Fig. <xref rid="Fig1" ref-type="fig">1</xref>.
<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><p>LSTM scheme (following hochreiter and Hochreiter <xref ref-type="bibr" rid="CR16">1997</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig1_HTML.png" id="MO1"/></fig></p><p id="Par50">The state of the cell is split into two vectors: <bold>h</bold><sub>(<italic>t</italic>)</sub> and <bold>c</bold><sub>(<italic>t</italic>)</sub>. Vector <bold>h</bold><sub>(<italic>t</italic>)</sub> can be interpreted as the short-term state and <bold>c</bold><sub>(<italic>t</italic>)</sub> as the long-term state.</p><p id="Par51">The current input vector <bold>x</bold><sub>(<italic>t</italic>)</sub> and the previous short-term state <bold>h</bold><sub>(<italic>t</italic>− 1)</sub> are fed to four different fully connected gates. They serve different purposes:
<list list-type="bullet"><list-item><p id="Par52">The main gate is the one that outputs <bold>c</bold><sub>(<italic>t</italic>)</sub>. It has the usual role of analysing the current inputs <bold>x</bold><sub>(<italic>t</italic>)</sub> and the previous short-term state <bold>h</bold><sub>(<italic>t</italic>− 1)</sub>.</p></list-item><list-item><p id="Par53">The <italic>forget gate</italic> (controlled by <bold>f</bold><sub>(<italic>t</italic>)</sub>) controls which part of the long-term state should be erased.</p></list-item><list-item><p id="Par54">The <italic>input gate</italic> (controlled by <bold>i</bold><sub>(<italic>t</italic>)</sub>) controls which parts of <bold>c</bold><sub>(<italic>t</italic>)</sub> should be added to the long-term state.</p></list-item><list-item><p id="Par55">The <italic>output gate</italic> (controlled by <bold>o</bold><sub>(<italic>t</italic>)</sub>) controls which part of the long-term state should be read and output at this time step (both to <bold>h</bold><sub>(<italic>t</italic>)</sub>) and <bold>c</bold><sub>(<italic>t</italic>)</sub>.</p></list-item></list></p><p id="Par56"><italic>σ</italic> represents the logistic function transformation after a fully connected NN set. The key idea is that the network can learn what to store in the long-term state, what to throw away, and what to read from it. The long-term state transverses the network from left to right, it goes through a <italic>forget gate</italic>, dropping some memories, and it adds new memories through the addition operation. After that, it is copied and processed through the <italic>tanh</italic> function, whose result is filtered by the <italic>output gate</italic>. This produces the short-term state <bold>h</bold><sub>(<italic>t</italic>)</sub>.</p><p id="Par57">Equations <xref rid="Equ1" ref-type="disp-formula">1</xref>–<xref rid="Equ6" ref-type="disp-formula">6</xref> summarise how to compute the cell long-term state, and its output at each time step for a single instance:
<disp-formula id="Equ1"><label>1</label><alternatives><mml:math id="Equ1_Math"><mml:msub><mml:mrow><mml:mtext mathvariant="bold">i</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">h</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">b</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math><tex-math id="Equ1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \textbf{i}_{(t)}=\sigma (\textbf{W}_{xi}\cdot\textbf{x}_{t} +\textbf{W}_{hi}\cdot\textbf{h}_{t-1}+\textbf{b}_{i}), $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_Equ1.gif"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><mml:math id="Equ2_Math"><mml:msub><mml:mrow><mml:mtext mathvariant="bold">f</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">h</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">b</mml:mtext></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math><tex-math id="Equ2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \textbf{f}_{(t)}=\sigma (\textbf{W}_{xf}\cdot\textbf{x}_{t} +\textbf{W}_{hf}\cdot\textbf{h}_{t-1}+\textbf{b}_{f}), $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_Equ2.gif"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><mml:math id="Equ3_Math"><mml:msub><mml:mrow><mml:mtext mathvariant="bold">o</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">h</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">b</mml:mtext></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math><tex-math id="Equ3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \textbf{o}_{(t)}=\sigma (\textbf{W}_{xo}\cdot\textbf{x}_{t} +\textbf{W}_{ho}\cdot\textbf{h}_{t-1}+\textbf{b}_{o}), $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_Equ3.gif"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><mml:math id="Equ4_Math"><mml:msub><mml:mrow><mml:mtext mathvariant="bold">c</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">g</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>tanh</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">W</mml:mtext></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">h</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">b</mml:mtext></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math><tex-math id="Equ4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \textbf{c}_{(t)}=\textbf{g}_{(t)}=\tanh (\textbf{W}_{xg} \cdot\textbf{x}_{t}+\textbf{W}_{hg}\cdot\textbf{h}_{t-1}+\textbf{b}_{g}), $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_Equ4.gif"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><mml:math id="Equ5_Math"><mml:msub><mml:mrow><mml:mtext mathvariant="bold">c</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">f</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>⊗</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">c</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">i</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>⊗</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">g</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math><tex-math id="Equ5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \textbf{c}_{(t)}= \textbf{f}_{(t)} \otimes \textbf{c}_{(t-1)} +\textbf{i}_{(t)} \otimes \textbf{g}_{(t)}, $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_Equ5.gif"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><mml:math id="Equ6_Math"><mml:msub><mml:mrow><mml:mtext mathvariant="bold">y</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">h</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">o</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>⊗</mml:mo><mml:mo>tanh</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mtext mathvariant="bold">c</mml:mtext></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math><tex-math id="Equ6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \textbf{y}_{(t)}=\textbf{h}_{(t)}=\textbf{o}_{(t)} \otimes \tanh(\textbf{c}_{(t)}), $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_Equ6.gif"/></alternatives></disp-formula>where:
<list list-type="bullet"><list-item><p id="Par58"><bold>W</bold><sub><italic>x</italic><italic>i</italic></sub>, <bold>W</bold><sub><italic>x</italic><italic>f</italic></sub>, <bold>W</bold><sub><italic>x</italic><italic>o</italic></sub> and <bold>W</bold><sub><italic>x</italic><italic>g</italic></sub> are the weight matrices of each of the four gates for their connection to the input vector <bold>x</bold><sub><italic>t</italic></sub>.</p></list-item><list-item><p id="Par59"><bold>W</bold><sub><italic>h</italic><italic>i</italic></sub>, <bold>W</bold><sub><italic>h</italic><italic>f</italic></sub>, <bold>W</bold><sub><italic>h</italic><italic>o</italic></sub> and <bold>W</bold><sub><italic>h</italic><italic>g</italic></sub> are the weight matrices of each of the four gates for their connection to the previous shot-term state <bold>h</bold><sub><italic>t</italic>− 1</sub>.</p></list-item><list-item><p id="Par60"><bold>b</bold><sub><italic>i</italic></sub>, <bold>b</bold><sub><italic>f</italic></sub>, <bold>b</bold><sub><italic>o</italic></sub> and <bold>b</bold><sub><italic>g</italic></sub> are the bias terms for each of the four gates.</p></list-item><list-item><p id="Par61">⊗ represents element-wise vector multiplication.</p></list-item></list></p><p id="Par62">In order to achieve a more accurate result, we perform parameter tuning later in “<xref rid="Sec14" ref-type="sec">Results</xref>”. These parameters are the number of years of data used for training, the number of cells and the number of epochs. This will also be discussed later on in “<xref rid="Sec14" ref-type="sec">Results</xref>”.</p></sec><sec id="Sec4"><title>EMA description</title><p id="Par63">Exponential moving average (EMA) is a modified version of the simple moving average (MA), i.e. a type of moving average with more weight given to the latest data. The EMA works as a classifier in this case, generating binary signals, 1 when the peak is over the EMA, 0 when is below it. The formula represents the EMA as follows:
<disp-formula id="Equ7"><label>7</label><alternatives><mml:math id="Equ7_Math"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math><tex-math id="Equ7_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ S_{t}=\alpha y_{t-1} + (1-\alpha)S_{t-1}, $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_Equ7.gif"/></alternatives></disp-formula>where:
<list list-type="bullet"><list-item><p id="Par64"><italic>S</italic><sub><italic>t</italic></sub>: value of the EMA for <italic>t</italic> = <italic>n</italic><italic>o</italic><italic>w</italic></p></list-item><list-item><p id="Par65"><italic>α</italic>: smoothing constant. When <italic>α</italic> is close to 1, dampening is quick, and when <italic>α</italic> is close to 0, dampening is slow.</p></list-item><list-item><p id="Par66"><italic>y</italic><sub><italic>t</italic>− 1</sub>: actual observation for <italic>t</italic> − 1</p></list-item><list-item><p id="Par67"><italic>S</italic><sub><italic>t</italic>− 1</sub>: value of the EMA for <italic>t</italic> − 1</p></list-item></list></p></sec><sec id="Sec5"><title>Model evaluation</title><p id="Par68">This study adopted a range of statistical error criteria in the testing period based on statistical indicators. As accuracy evaluator for this model, the root mean square error (RMSE), mean absolute error (MAE) and the relative error (%) based on MAE and RMSE (MAPE and RRMSE) have been chosen (Mohanad et al. <xref ref-type="bibr" rid="CR26">2018</xref>). The formulas can be seen in Eqs. <xref rid="Equ8" ref-type="disp-formula">8</xref>–<xref rid="Equ11" ref-type="disp-formula">11</xref>.
<disp-formula id="Equ8"><label>8</label><alternatives><mml:math id="Equ8_Math"><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mi>∑</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>ŷ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msqrt><mml:mo>,</mml:mo></mml:math><tex-math id="Equ8_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ RMSE=\sqrt{\frac{1}{N}\sum\limits_{j=1}^{N}(y_{j}-\hat{y}_{j})^{2}}, $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_Equ8.gif"/></alternatives></disp-formula><disp-formula id="Equ9"><label>9</label><alternatives><mml:math id="Equ9_Math"><mml:mi>R</mml:mi><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mi>∑</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>ŷ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msqrt></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>̄</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><tex-math id="Equ9_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ RRMSE=100 * \frac{\sqrt{\frac{1}{N}\sum\limits_{j=1}^{N}(y_{j}-\hat{y}_{j})^{2}}}{\bar{y_{j}}}, $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_Equ9.gif"/></alternatives></disp-formula><disp-formula id="Equ10"><label>10</label><alternatives><mml:math id="Equ10_Math"><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mi>∑</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>ŷ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><tex-math id="Equ10_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ MAE=\frac{1}{N}\sum\limits_{j=1}^{N}\left|y_{j}-\hat{y}_{j}\right|, $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_Equ10.gif"/></alternatives></disp-formula><disp-formula id="Equ11"><label>11</label><alternatives><mml:math id="Equ11_Math"><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mi>∑</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfenced close="|" open="|"><mml:mrow><mml:mfrac class="tfrac"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>ŷ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><tex-math id="Equ11_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ MAPE=100*\frac{1}{N}\sum\limits_{j=1}^{N}\left|\frac{y_{j}-\hat{y}_{j}}{y_{j}}\right|, $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_Equ11.gif"/></alternatives></disp-formula><list list-type="bullet"><list-item><p id="Par69"><italic>N</italic>: Total number of values. In this case, the number of output values which for a single day with HH data would be <italic>N</italic> = 48,</p></list-item><list-item><p id="Par70"><italic>y</italic><sub><italic>j</italic></sub>: Actual (observed) value to compare the forecast with,</p></list-item><list-item><p id="Par71"><inline-formula id="IEq1"><alternatives><mml:math id="IEq1_Math"><mml:msub><mml:mrow><mml:mi>ŷ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\hat {y}_{j}$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_IEq1.gif"/></alternatives></inline-formula>: Forecasted value, output of the LSTM,</p></list-item><list-item><p id="Par72"><inline-formula id="IEq2"><alternatives><mml:math id="IEq2_Math"><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>̄</mml:mo></mml:mover></mml:math><tex-math id="IEq2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\bar {y_{j}}$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="12053_2020_9879_Article_IEq2.gif"/></alternatives></inline-formula>: Average of the array of observed values,</p></list-item></list></p></sec></sec><sec id="Sec6"><title>Case study: UK Triads</title><p id="Par73">Triads are the three 0.5 h periods of peak power demand across the National Grid in a year (from November to February). These three points are used to calibrate the system costs, which are passed on to industry. The aim of the Triad system is to incentivise industry and users to help smooth out peaks in energy demand during the winter, especially in cold snaps (ELEXON <xref ref-type="bibr" rid="CR8">2018</xref>).</p><p id="Par74">According to Newbery (<xref ref-type="bibr" rid="CR27">2011</xref>), the Triad charging system encourages demand reduction at these peak hours and hence signals the need for less generation and transmission (which will be sized to predicted peak loads), as this creates the need for avoiding these peak hours. ELEXON provides a forecast for the UK electricity demand and energy managers, along with businesses rely on this information (publicly available) to know when a Triad is going to happen, but this information is incomplete and inaccurate as the demand values that ELEXON seeks to forecast are not the ones which Triad is calculated against. The model proposed in this paper creates a better decision-making framework because calling Triads implicates switching off equipment. Some companies can not handle the disruption internally, so they need to run fuel generators and this implicates a considerable cost.</p><sec id="Sec7"><title>Triad background</title><p id="Par75">Triad forecasting is a matter of great interest for businesses, as this is an event that costs a significant amount of money, specially to those with higher number of infrastructural objects (banking, retail, telecommunications). TNuoS charges, which cover the costs of operating transmission networks, may represent around 5% of the bill. These fees are revised annually and forecasted for 5 years ahead. The 2017 forecast published by National-Grid (<xref ref-type="bibr" rid="CR28">2018</xref>) shows the value of Triad growing from an average of <italic>£</italic>44 (≈ 57.36$) per kW to <italic>£</italic>59 (≈ 76.90$) per kW used during peak times. This forecast can be seen below in Table <xref rid="Tab1" ref-type="table">1</xref>.
<table-wrap id="Tab1"><label>Table 1</label><caption xml:lang="en"><p>Triad fees (<italic>£</italic>/<italic>k</italic><italic>W</italic>) forecast from 2018/2019 to 2022/2023</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p><inline-graphic xlink:href="MediaObjects/12053_2020_9879_Figa_HTML.gif"/></p></th><th align="left"><p>18/19</p></th><th align="left"><p>19/20</p></th><th align="left"><p>20/21</p></th><th align="left"><p>21/22</p></th><th align="left"><p>22/23</p></th></tr></thead><tbody><tr><td align="left"><p>Northern Scotland</p></td><td align="left"><p>18.35</p></td><td align="left"><p>21.69</p></td><td align="left"><p>27.94</p></td><td align="left"><p>27.19</p></td><td align="left"><p>28.81</p></td></tr><tr><td align="left"><p>Southern Scotland</p></td><td align="left"><p>25.13</p></td><td align="left"><p>29.17</p></td><td align="left"><p>33.99</p></td><td align="left"><p>35.13</p></td><td align="left"><p>37.92</p></td></tr><tr><td align="left"><p>Northern</p></td><td align="left"><p>36.92</p></td><td align="left"><p>41.50</p></td><td align="left"><p>44.31</p></td><td align="left"><p>48.63</p></td><td align="left"><p>51.20</p></td></tr><tr><td align="left"><p>North West</p></td><td align="left"><p>43.87</p></td><td align="left"><p>48.40</p></td><td align="left"><p>51.01</p></td><td align="left"><p>55.79</p></td><td align="left"><p>58.73</p></td></tr><tr><td align="left"><p>Yorkshire</p></td><td align="left"><p>43.83</p></td><td align="left"><p>48.47</p></td><td align="left"><p>51.15</p></td><td align="left"><p>56.25</p></td><td align="left"><p>59.31</p></td></tr><tr><td align="left"><p>Noth Wales and Mersey</p></td><td align="left"><p>45.43</p></td><td align="left"><p>49.97</p></td><td align="left"><p>52.66</p></td><td align="left"><p>57.27</p></td><td align="left"><p>60.70</p></td></tr><tr><td align="left"><p>East Midlands</p></td><td align="left"><p>47.39</p></td><td align="left"><p>52.26</p></td><td align="left"><p>55.59</p></td><td align="left"><p>60.83</p></td><td align="left"><p>64.07</p></td></tr><tr><td align="left"><p>Midlands</p></td><td align="left"><p>48.85</p></td><td align="left"><p>53.50</p></td><td align="left"><p>56.26</p></td><td align="left"><p>61.71</p></td><td align="left"><p>65.19</p></td></tr><tr><td align="left"><p>Eastern</p></td><td align="left"><p>49.37</p></td><td align="left"><p>54.33</p></td><td align="left"><p>57.91</p></td><td align="left"><p>63.17</p></td><td align="left"><p>66.51</p></td></tr><tr><td align="left"><p>South Wales</p></td><td align="left"><p>46.78</p></td><td align="left"><p>50.89</p></td><td align="left"><p>54.18</p></td><td align="left"><p>59.64</p></td><td align="left"><p>64.01</p></td></tr><tr><td align="left"><p>South East</p></td><td align="left"><p>52.52</p></td><td align="left"><p>57.11</p></td><td align="left"><p>60.34</p></td><td align="left"><p>65.51</p></td><td align="left"><p>68.72</p></td></tr><tr><td align="left"><p>London</p></td><td align="left"><p>54.84</p></td><td align="left"><p>60.21</p></td><td align="left"><p>63.92</p></td><td align="left"><p>69.30</p></td><td align="left"><p>72.89</p></td></tr><tr><td align="left"><p>Southern</p></td><td align="left"><p>53.80</p></td><td align="left"><p>58.55</p></td><td align="left"><p>61.67</p></td><td align="left"><p>66.74</p></td><td align="left"><p>69.94</p></td></tr><tr><td align="left"><p>South Western</p></td><td align="left"><p>53.86</p></td><td align="left"><p>57.30</p></td><td align="left"><p>60.08</p></td><td align="left"><p>63.71</p></td><td align="left"><p>67.73</p></td></tr></tbody></table></table-wrap></p><p id="Par76">The charge varies across 14 zones and is set based on user’s average half-hourly demand over three Triad periods taking place every winter season (National-Grid <xref ref-type="bibr" rid="CR28">2018</xref>). Because of economic interests for companies, most of the current Triad forecast systems are not publicly available.</p><p id="Par77">In Marmaras et al. (<xref ref-type="bibr" rid="CR25">2017</xref>), the electricity demand of each building on an actual Triad peak date and time was predicted successfully, and an overall forecasting accuracy of 97.6% was demonstrated for the considered buildings. Marmaras’ model uses data from three different sources at various stages to predict the most probable 0.5 h of the day when the Triad could occur. These are data from National Grid, weather data and historical consumption; and its training set consists of historical data from 1990. This work, however, only validates the effectiveness of Triad forecasting using 1 year of data, not ensuring that the same model will work after periods and therefore not offering a flexible framework when any changes (such as new policies) occur.</p><p id="Par78">As changes happen very often in this field, ideally some parameters should be regulated and a single standalone system that works for every Triad season without having to do any modifications is difficult. Algorithm validation is also not easy to do because of two reasons: data availability and constant changes in the patterns of the training data. This is why we propose to offer a certain degree of flexibility that the user can tune according to the degree of risk that can be afforded. In this work, we use a period of 4 years, as there are policies that change in a relatively short period of time, and it will be validated for four different periods, all of them from November to February, when the Triad season occurs. We apply and train LSTM for this period.</p></sec><sec id="Sec8"><title>Design of experiment</title><p id="Par79">The design of the experiment begins with the analysis of the inputs to the model. We address this by comparing how the aggregated wind and solar generation is related to the load variation from the first to last settlement release. Once we prove these inputs are relevant, we proceed to designing the LSTM model using the previously analysed inputs. The output will be the last settled load forecast, which will be dynamically filtered in order to obtain the peak demands of energy consumption through an exponential moving average. Those values above the filter are considered as potential Triads (for this particular case study) and are finally compared with the total number of signals provided.</p></sec><sec id="Sec9"><title>Triad data analysis</title><p id="Par80">In this section, we analyse the historic data and find the relationship between the settled demand data and the generation with some of the renewable sources. Next, we discuss a plot with the historical Triad, and last, we look for correlations in the data that is going to be used as input for the LSTM, as well as identify seasonality in the training data.</p><sec id="Sec10"><title>Settled data and renewables generation</title><p id="Par81">The data used for selecting Triad days is not the initial demand out-turn (INDO), but the settlement final/ 1st reconciliation/2nd reconciliation (SF/R1/R2), which is the actual load on the grid once the BM units have submitted all the sub-meter data. This data is settled at around 9, 20, and 90 days post the event and is the data that Triad is calculated against. The main difference between INDO and settled is the removal of the station load (the load the power station uses to power itself). This is why, the output forecast first, as previously explained in “<xref rid="Sec2" ref-type="sec">Methodology</xref>”, is the SF/R1/R2.</p><p id="Par82">There are limitations in the models depending on the amount, type and quality of data available. There are forecasts provided for the INDO, however, as there are no forecasts for the SD available, a model needs to be defined based on the available data. The idea is to find parameters that keep a relationship with the difference between the INDO and the SD. Generation renewables (wind and solar generation), and the mentioned difference between actual INDO and the SD keep such relationship. As shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, plotting <italic>I</italic><italic>N</italic><italic>D</italic><italic>O</italic> − <italic>S</italic><italic>D</italic> against the sum of solar and wind generation, the points obtained can be approximated by a linear regression, which makes solar and wind generation possible predictors for the SD forecast system.
<fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><p>Correlation between renewables generation and settled variance</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig2_HTML.png" id="MO2"/></fig></p><p id="Par83">The fact that this data is correlated means that it can be used for a predictive model that forecasts the SD as a first step for Triad forecasting.</p></sec><sec id="Sec11"><title>Historical triads</title><p id="Par84">In order to analyse Triad, it is useful to know when Triad historically happened, so statistical insights can be gained for future decisions.</p><p id="Par85">From the 2008/2009 to the 2015/2016 winter season, 45.8<italic>%</italic> of Triad occurred on Mondays and 29<italic>%</italic> on Thursdays, with other weekdays only accounting for one in four Triad. Out of the total 24 cases, 22 occurred between 17:00 and 17:30 and 2 occurred between 17:30 and 18:00. A reason why a Triad may happen in a latter hour around February may be explained by the number of hours of sunlight, which grows longer after the January period and thus, moving forward the second peak of electricity demand, meaning that users switch on lighting a bit later than usual, generating possible peaks later than in the rest of the Triad season.</p></sec><sec id="Sec12"><title>LSTM inputs analysis</title><p id="Par86">First of all, it is necessary to study the influence factors of the SD. From the modeling point of view, it is also interesting to plot the temperature and observe the close correlation to the INDO.
<list list-type="bullet"><list-item><p id="Par87">NDF (national demand forecast)</p></list-item><list-item><p id="Par88">WIND (wind generation forecasting)</p></list-item><list-item><p id="Par89">TSDF (transmission demand forecast)</p></list-item><list-item><p id="Par90">SOLAR (solar generation forecasting)</p></list-item></list></p><p id="Par91">The four input data variables are forecasts for the next 48 0.5-h intervals predicted by ELEXON, obtained 24 h before the event to be forecasted. Solar and wind data is based on historical out-turn data and detailed local wind and solar forecasts, used by National Grid forecasts likely levels of and solar and wind generation. The system operator NDF is based on historically metered generation output for Great Britain. The values shown here take into account transmission losses and include station transformer load, pump storage demand and interconnector demand (ELEXON <xref ref-type="bibr" rid="CR8">2018</xref>). Given the national demand forecast (NDF) and transmission demand forecast (TSDF) data of several years as shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, it can be seen that the overall trend of both of them is decreasing over the years. This means that the actual demand does decrease and that, for further filtering, this fact needs to be taken into consideration. Historic data for NDF and TSDF can be seen in Fig. <xref rid="Fig3" ref-type="fig">3</xref>.
<fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><p>National demand forecast <bold>a</bold> and transmission demand forecast <bold>b</bold> from January 2008 to October 2017</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig3_HTML.png" id="MO3"/></fig></p><p id="Par92">Also, it is useful to display every quarter of the year for the actual INDO to see the differences in terms of patterns of behaviour between seasons. So, taking the year 2017 as an example, each quarter of the year is plotted in Fig. <xref rid="Fig4" ref-type="fig">4</xref>.
<fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><p>UK electricity demand for the 4 quarters of the year 2017. <bold>a</bold> January–March (months 1–3). <bold>c</bold> April–June (months 1–3). <bold>e</bold> July–September (months 1–3). <bold>g</bold> October–December (months 1–3). Random week taken from each corresponding quarter, Mondays to Sundays, on the right: 16/01/2017 to 22/01/2017 (<bold>b</bold>), 01/05/2017 to 07/05/2017 (<bold>d</bold>), 07/08/2017 to 13/08/2017 (<bold>f</bold>) and 06/11/2017 - 12/11/2017 (<bold>h</bold>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig4_HTML.png" id="MO4"/></fig></p><p id="Par93">As can be seen in Fig. <xref rid="Fig4" ref-type="fig">4</xref>, the patterns of behaviour are different depending on the season and/or day of the week, where the consumer energy use can be visible.</p><p id="Par94">As for wind and solar energy, they depend on weather conditions. For the Triad season 2016/2017, these values are displayed in Figs. <xref rid="Fig5" ref-type="fig">5</xref> and <xref rid="Fig6" ref-type="fig">6</xref>.
<fig id="Fig5"><label>Fig. 5</label><caption xml:lang="en"><p>National total solar generation from November 2016 to February 2017 (<bold>a</bold>) and from 16 January 2017 to 22nd January 2017 (<bold>b</bold>). Data source (ELEXON <xref ref-type="bibr" rid="CR8">2018</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig5_HTML.png" id="MO5"/></fig><fig id="Fig6"><label>Fig. 6</label><caption xml:lang="en"><p>National total wind generation from November 2016 to February 2017 (<bold>a</bold>) and from 16th January 2017 to 22 January 2017 (<bold>b</bold>). Data source (ELEXON <xref ref-type="bibr" rid="CR8">2018</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig6_HTML.png" id="MO6"/></fig></p><p id="Par95">To determine data correlations, the standard correlation coefficient (Pearson’s <italic>r</italic>) can be computed. The result of the four inputs we are using can be seen in Table <xref rid="Tab2" ref-type="table">2</xref>.
<table-wrap id="Tab2"><label>Table 2</label><caption xml:lang="en"><p>Pearson’s <italic>r</italic> coefficients calculated between settled data and other variables</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Variables</p></th><th align="left"><p>Pearson’s <italic>r</italic> with SD</p></th></tr></thead><tbody><tr><td align="left"><p>NDF</p></td><td align="left"><p>0.99</p></td></tr><tr><td align="left"><p>TSDF</p></td><td align="left"><p>0.99</p></td></tr><tr><td align="left"><p>SOLAR</p></td><td align="left"><p>0.18</p></td></tr><tr><td align="left"><p>WIND</p></td><td align="left"><p>− 0.15</p></td></tr></tbody></table></table-wrap></p><p id="Par96">As expected, a strong positive correlation can be found between SD and NDF and TSDF values, so these are going to define the shape of the curve. Also, there are correlations between the wind and solar generation, and SD data. Now that the relationships between variables and the data has been discussed, the model will be built and tested.</p></sec></sec><sec id="Sec13"><title>System configuration</title><p id="Par97">The goal of the system proposed in “<xref rid="Sec2" ref-type="sec">Methodology</xref>” is to produce Triad signals (as few as possible) to determine a DSR intervention.</p><p id="Par98">First of all, the data is rescaled between 0 and 1, this is a beneficial machine learning practice because when feeding the algorithm, the weights are assigned during the training stage of the system, and having different scales of values may lead to a bad fitting and not reaching a global maximum solution. The rest of the system, which is also described in Fig. <xref rid="Fig7" ref-type="fig">7</xref> is divided as follows:
<list list-type="bullet"><list-item><p id="Par99">LSTM forecasting: Provides with the SD forecasted values for the next 48 0.5-h settlement periods. This architecture consists of 40 concatenated cells, with 250 epochs, and a batch size worth of 6 days of data. The output of this system are the next 48 0.5-h settlement periods of SD forecasting.</p></list-item><list-item><p id="Par100">Peak extraction: Next, the maximum demand peak of the day is extracted and added to a vector with the previous forecast peaks. For filtering purposes, weekends and Christmas period (23rd of December to 2nd of February) are excluded from the dataset so the Triad signals will be filtered by using the rest of the days, when Triad happens.</p></list-item><list-item><p id="Par101"><bold>Filters</bold>: Last, after the demand of the next 24 h have been forecast, two different filters have been used based on a simple approach. The idea is to use two exponential moving averages (EMAs) multiplied by a factor. As an example of what the filter values may be, for this paper, we set the percentages to 3.5% and 4% for the soft and hard filters, lower and higher risk respectively.</p></list-item></list><fig id="Fig7"><label>Fig. 7</label><caption xml:lang="en"><p>Triad system architecture</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig7_HTML.png" id="MO7"/></fig></p></sec></sec><sec id="Sec14" sec-type="results"><title>Results</title><p id="Par102">The implementation of the system has been carried using Python, more specifically in the Keras library. The dataset has been divided in the following parts for calibrating the model. The training set includes the data from the four different inputs (WIND, SOLAR, NDF and TSDF) and the output (test set) refers to the final settled data (SF/R1/R2); therefore, all the time ranges mentioned below correspond to these parts of the dataset.
<list list-type="bullet"><list-item><p id="Par103">Training set: 1 November to 28 February (29 when it is Leap year in 2016) years 2015–2018. November to February for each year is the period for which the SF/R1/R1 data is available. This training set is divided and consecutively added behind the test set, so the optimum number of years behind testing can be determined.</p></list-item><list-item><p id="Par104">Test set: next 14 days after the last day of the training set (15 to 28 February 2018). The purpose of this testing set is to measure the variance of the performance when changing the hyperparameters in order to choose an optimum combination of these. This test data must not have been used for training, as it is the consecutive data after the training set, the trained algorithm follows this sample sequence after training and the performance is measured through the different metrics.</p></list-item></list></p><p id="Par105">A summary can be found in Table <xref rid="Tab3" ref-type="table">3</xref>.
<table-wrap id="Tab3"><label>Table 3</label><caption xml:lang="en"><p>Training and testing data information</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left"><p>Training</p></th><th align="left"><p>Testing</p></th></tr></thead><tbody><tr><td align="left"><p>Number of points</p></td><td align="left"><p>11472</p></td><td align="left"><p>672</p></td></tr><tr><td align="left"><p>(%)</p></td><td align="left"><p>94.46%</p></td><td align="left"><p>5.54%</p></td></tr><tr><td align="left"><p>Date range</p></td><td align="left"><p>01.11.2015 to</p></td><td align="left"><p>15.02.2018 to</p></td></tr><tr><td align="left"/><td align="left"><p>14.02.2018</p></td><td align="left"><p>28.02.2018</p></td></tr></tbody></table></table-wrap></p><p id="Par106">We perform long-term forecast; thus, the model is trained from the previous years and serves as outputs for a Triad season after training. The horizon of the forecasting corresponds to four months worth of data.</p><p id="Par107">As our model has four inputs, based on the description in the data analysis section, our LSTM architecture will contain a specific number of these cells concatenated. This number is to be determined through experimentation.</p><p id="Par108">The scheme of the model can be seen in Fig. <xref rid="Fig8" ref-type="fig">8</xref>.
<fig id="Fig8"><label>Fig. 8</label><caption xml:lang="en"><p>LSTM scheme with 4 inputs</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig8_HTML.png" id="MO8"/></fig></p><sec id="Sec15"><title>1st calibration stage: training data size</title><p id="Par109">As previously mentioned in “<xref rid="Sec2" ref-type="sec">Methodology</xref>”, the LSTM parameters need to be tuned in order to achieve a better performance. The hyperparameters of this network are calibrated according to the number of epochs, the number of years worth of data for the training stage and the number of cells constituting the network.</p><p id="Par110">The experiment has been carried out by increasing the number of epochs, as well as the number of years behind the testing period, varying the batch size used for training the LSTM.</p><p id="Par111">Table <xref rid="Tab4" ref-type="table">4</xref> shows the metrics with the best result obtained, that corresponds to 250 epochs and a 48 × 6 batch size (6 days with 48 periods each) with the whole dataset. This means that the earlier the year of testing, the shorter the amount of training data; therefore, for further experiments, the whole dataset behind the testing period is going to be taken because less data is available.
<table-wrap id="Tab4"><label>Table 4</label><caption xml:lang="en"><p>Training and testing accuracy metrics according to the numbers of epochs</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Epochs</p></th><th align="left"><p>50</p></th><th align="left"><p>150</p></th><th align="left"><p>250</p></th><th align="left"><p>300</p></th><th align="left"><p>350</p></th></tr></thead><tbody><tr><td align="left" colspan="6"><p>Training accuracy</p></td></tr><tr><td align="left"><p>RMSE (MW)</p></td><td align="left"><p>740.85</p></td><td align="left"><p>694.44</p></td><td align="left"><p>693.11</p></td><td align="left"><p>699.76</p></td><td align="left"><p>698.65</p></td></tr><tr><td align="left"><p>RRMSE (%)</p></td><td align="left"><p>2.09</p></td><td align="left"><p>1.94</p></td><td align="left"><p>1.94</p></td><td align="left"><p>1.96</p></td><td align="left"><p>1.96</p></td></tr><tr><td align="left"><p>MAE (MW)</p></td><td align="left"><p>574.24</p></td><td align="left"><p>522.95</p></td><td align="left"><p>521.28</p></td><td align="left"><p>527.60</p></td><td align="left"><p>526.56</p></td></tr><tr><td align="left"><p>MAPE (%)</p></td><td align="left"><p>1.66</p></td><td align="left"><p>1.52</p></td><td align="left"><p>1.51</p></td><td align="left"><p>1.53</p></td><td align="left"><p>1.53</p></td></tr><tr><td align="left" colspan="6"><p>Testing accuracy</p></td></tr><tr><td align="left"><p>RMSE (MW)</p></td><td align="left"><p>833.44</p></td><td align="left"><p>799.75</p></td><td align="left"><p>793.53</p></td><td align="left"><p>796.59</p></td><td align="left"><p>798.27</p></td></tr><tr><td align="left"><p>RRMSE (%)</p></td><td align="left"><p>2.35</p></td><td align="left"><p>2.24</p></td><td align="left"><p>2.22</p></td><td align="left"><p>2.23</p></td><td align="left"><p>2.24</p></td></tr><tr><td align="left"><p>MAE (MW)</p></td><td align="left"><p>625.15</p></td><td align="left"><p>578.4</p></td><td align="left"><p>578.15</p></td><td align="left"><p>577.67</p></td><td align="left"><p>578.43</p></td></tr><tr><td align="left"><p>MAPE (%)</p></td><td align="left"><p>1.75</p></td><td align="left"><p>1.60</p></td><td align="left"><p>1.60</p></td><td align="left"><p>1.60</p></td><td align="left"><p>1.60</p></td></tr></tbody></table></table-wrap></p></sec><sec id="Sec16"><title>2nd calibration stage: number of neurons</title><p id="Par112">Next, the number of neurons of the LSTM needs to be determined by using the results obtained in the prior calibration stage. For the experiment in Table <xref rid="Tab4" ref-type="table">4</xref>, 30 concatenated cells have been used by default and the average of five values have been taken for each metric. In Table <xref rid="Tab5" ref-type="table">5</xref>, the results of this experiments can be seen together with a boxplot with the forecasted error (FE) (Al-Musaylh et al. <xref ref-type="bibr" rid="CR1">2018</xref>), which is the difference between observed and predicted values, for each model represented on Fig. <xref rid="Fig9" ref-type="fig">9</xref>.
<fig id="Fig9"><label>Fig. 9</label><caption xml:lang="en"><p>|<italic>F</italic><italic>E</italic>| = |<italic>O</italic><italic>b</italic><italic>s</italic><italic>e</italic><italic>r</italic><italic>v</italic><italic>e</italic><italic>d</italic><italic>v</italic><italic>a</italic><italic>l</italic><italic>u</italic><italic>e</italic> − <italic>P</italic><italic>r</italic><italic>e</italic><italic>d</italic><italic>i</italic><italic>c</italic><italic>t</italic><italic>e</italic><italic>d</italic><italic>v</italic><italic>a</italic><italic>l</italic><italic>u</italic><italic>e</italic>| boxplot for each model from number of cells = 10 to number of cells = 60</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig9_HTML.png" id="MO9"/></fig><table-wrap id="Tab5"><label>Table 5</label><caption xml:lang="en"><p>Metrics for the number of neurons in the LSTM</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Number of neurons</p></th><th align="left"><p>10</p></th><th align="left"><p>20</p></th><th align="left"><p>30</p></th><th align="left"><p>40</p></th><th align="left"><p>50</p></th><th align="left"><p>60</p></th></tr></thead><tbody><tr><td align="left"><p>RMSE (MW)</p></td><td align="left"><p>801.82</p></td><td align="left"><p>798.85</p></td><td align="left"><p>795.54</p></td><td align="left"><p>795.66</p></td><td align="left"><p>794.33</p></td><td align="left"><p>797.97</p></td></tr><tr><td align="left"><p>RRMSE (%)</p></td><td align="left"><p>2.25</p></td><td align="left"><p>2.24</p></td><td align="left"><p>2.23</p></td><td align="left"><p>2.23</p></td><td align="left"><p>2.22</p></td><td align="left"><p>2.23</p></td></tr><tr><td align="left"><p>MAE (MW)</p></td><td align="left"><p>585.26</p></td><td align="left"><p>578.86</p></td><td align="left"><p>576.48</p></td><td align="left"><p>575.99</p></td><td align="left"><p>578.95</p></td><td align="left"><p>581.17</p></td></tr><tr><td align="left"><p>MAPE (%)</p></td><td align="left"><p>1.61</p></td><td align="left"><p>1.60</p></td><td align="left"><p>1.60</p></td><td align="left"><p>1.60</p></td><td align="left"><p>1.61</p></td><td align="left"><p>1.61</p></td></tr></tbody></table></table-wrap></p><p id="Par113">From this experiment, the average of 10 values has been chosen for each experiment, concluding that, for this forecasting horizon, the number of concatenated cells chosen would be 40, as the metrics on Table <xref rid="Tab5" ref-type="table">5</xref> indicates this one is showing one of the best possible results.</p><p id="Par114">The training algorithm used is the Adam optimiser, with a learning rate = 0.001. The total number of parameters, weights and biases, is 7241 and the number of training instances is 11,472.</p><p id="Par115">The modelled demand obtained from the LSTM can be seen in Fig. <xref rid="Fig10" ref-type="fig">10</xref>. For this testing, 14 days (672 points for 48 0.5-h per day) have been taken in February 2018.
<fig id="Fig10"><label>Fig. 10</label><caption xml:lang="en"><p>LSTM prediction points after training</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig10_HTML.png" id="MO10"/></fig></p><p id="Par116">As can be seen in Fig. <xref rid="Fig10" ref-type="fig">10</xref>, 14 days have been taken for demand forecast, from Wednesday to Tuesdays. It is also observed that the patterns of behaviour for the weekends, being lower for these days than for weekdays. The next section will consider the filters and signals for Triad as the last stage of the system.</p></sec><sec id="Sec17"><title>Comparison with other models</title><p id="Par117">In this section, we compare the performance of LSTM with several other popular methodologies mentioned in the Introduction. First, we compare the LSTM with the mean-only model and then with a simpler version of ANN with the same characteristics in terms of the number of cells and learning rate provided for the LSTM. We also compare LSTM with SVM regression, random forests and Bayesian regression. The results of the comparison are shown in Table <xref rid="Tab6" ref-type="table">6</xref> and illustrated in Fig. <xref rid="Fig11" ref-type="fig">11</xref>.
<fig id="Fig11"><label>Fig. 11</label><caption xml:lang="en"><p>Forecast error of the five models</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig11_HTML.png" id="MO11"/></fig><table-wrap id="Tab6"><label>Table 6</label><caption xml:lang="en"><p>Comparison of test accuracy of LSTM with other models</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Model</p></th><th align="left"><p>LSTM</p></th><th align="left"><p>Mean-only</p></th><th align="left"><p>ANN</p></th><th align="left"><p>SVM</p></th><th align="left"><p>Random forests</p></th><th align="left"><p>Bayesian reg.</p></th></tr></thead><tbody><tr><td align="left"><p>RMSE (MW)</p></td><td align="left"><p>795.66</p></td><td align="left"><p>6013.81</p></td><td align="left"><p>850.82</p></td><td align="left"><p>2321.85</p></td><td align="left"><p>1868.25</p></td><td align="left"><p>806.05</p></td></tr><tr><td align="left"><p>RRMSE (%)</p></td><td align="left"><p>2.23</p></td><td align="left"><p>16.91</p></td><td align="left"><p>2.37</p></td><td align="left"><p>6.50</p></td><td align="left"><p>5.27</p></td><td align="left"><p>2.27</p></td></tr><tr><td align="left"><p>MAE (MW)</p></td><td align="left"><p>575.99</p></td><td align="left"><p>5295.46</p></td><td align="left"><p>619.42</p></td><td align="left"><p>2009.95</p></td><td align="left"><p>1588.54</p></td><td align="left"><p>587.68</p></td></tr><tr><td align="left"><p>MAPE (%)</p></td><td align="left"><p>1.60</p></td><td align="left"><p>15.24</p></td><td align="left"><p>1.74</p></td><td align="left"><p>5.78</p></td><td align="left"><p>4.55</p></td><td align="left"><p>1.62</p></td></tr></tbody></table></table-wrap></p><p id="Par118">This shows that LSTM model outperforms other models. It is important to mention that Bayesian regression results are following closely the performance of the LSTM in the second place, which makes this methodology also a good option and worth testing in similar DSR scenarios.</p></sec><sec id="Sec18"><title>Cross-validation</title><p id="Par119">Generalised performance of a learning method and its prediction capability rely on independent test data (Friedman et al. <xref ref-type="bibr" rid="CR11">2001</xref>). Therefore, cross-validation is necessary to ensure that the results are reliable when new data is introduced in the future. As we are forecasting time series data, we need a cross-validation that considers the serial correlation inherent to the problem (Arlot et al. <xref ref-type="bibr" rid="CR2">2010</xref>); therefore, we perform one step ahead cross-validation (Hyndman and Athanasopoulos <xref ref-type="bibr" rid="CR18">2018</xref>) consisting of 1,...,<italic>k</italic> samples, to predict <italic>k</italic> + 1 value (or alternatively <italic>k</italic> + 1,...,<italic>k</italic> + <italic>m</italic> values). We have performed this for the whole period of validation and, following this, we progressively added 24 h of data to the model to obtain the following day’s output.</p></sec><sec id="Sec19"><title>Filters configuration and results</title><p id="Par120">The data filters are the last stage of the data processing. They play the role of data points classification between Triad and no Triad.</p><p id="Par121">For the filters, as mentioned in “<xref rid="Sec2" ref-type="sec">Methodology</xref>”, EMAs have been used. The idea, for this specific case study, is to call Triads as any value above the 3.5<italic>%</italic> and 4<italic>%</italic> of the 40 days EMA, so both EMAs will be multiplied by these factors. For the testing of the system, all the values taken will be the ones predicted by the LSTM.</p><p id="Par122">For filter validity in terms of parameter selection, it must satisfy the following:
<list list-type="bullet"><list-item><p id="Par123">Be valid for all the scope of testing, which means to successfully predict the three Triads at least with one of the two filters</p></list-item><list-item><p id="Par124">Call the minimum number of Triad possible so the energy disruptions in buildings are kept to minimum</p></list-item><list-item><p id="Par125">Be able to successfully call at least two Triads among the signals for both filters</p></list-item></list></p><p id="Par126">The level of financial/energy risk that is to be taken into account depends on the user; this is why two filters are used as an example of how the risk may be managed. In Figs. <xref rid="Fig12" ref-type="fig">12</xref>, <xref rid="Fig13" ref-type="fig">13</xref>, <xref rid="Fig14" ref-type="fig">14</xref> and <xref rid="Fig15" ref-type="fig">15</xref>, we display the peaks for the Triad seasons 2014/2015, 2015/2016, 2016/2017 and 2017/2018 respectively, together with both filters:
<fig id="Fig12"><label>Fig. 12</label><caption xml:lang="en"><p>2014/15 Forecast peaks for each day and EMA</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig12_HTML.png" id="MO12"/></fig><fig id="Fig13"><label>Fig. 13</label><caption xml:lang="en"><p>2015/16 Forecast peaks for each day and EMA</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig13_HTML.png" id="MO13"/></fig><fig id="Fig14"><label>Fig. 14</label><caption xml:lang="en"><p>2016/17 Forecast peaks for each day and EMA</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig14_HTML.png" id="MO14"/></fig><fig id="Fig15"><label>Fig. 15</label><caption xml:lang="en"><p>2017/18 Forecast peaks for each day and EMA</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/12053_2020_9879_Fig15_HTML.png" id="MO15"/></fig></p><p id="Par127">The performance of the filters can be measured by counting the number of signals that our model generates versus the number of Triad predicted in the hindcast. The summary of these results can be seen in Table <xref rid="Tab7" ref-type="table">7</xref>, in which, for each year, the number of signals given by each filter, as well as the number of actual Triad days predicted. It shows the number of positive signals generated and the last two are the number of these signals that predicted the actual Triads.
<table-wrap id="Tab7"><label>Table 7</label><caption xml:lang="en"><p>Number of signals calling Triad for each filter and number of Triads predicted</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Seasons</p></th><th align="left"><p>Soft filter</p></th><th align="left"><p>Hard filter</p></th><th align="left"><p>Triad predicted (soft)</p></th><th align="left"><p>Triad predicted (hard)</p></th></tr></thead><tbody><tr><td align="left"><p>2014/2015</p></td><td align="left"><p>19</p></td><td align="left"><p>14</p></td><td align="left"><p>3</p></td><td align="left"><p>3</p></td></tr><tr><td align="left"><p>2015/2016</p></td><td align="left"><p>21</p></td><td align="left"><p>19</p></td><td align="left"><p>3</p></td><td align="left"><p>3</p></td></tr><tr><td align="left"><p>2016/2017</p></td><td align="left"><p>19</p></td><td align="left"><p>14</p></td><td align="left"><p>3</p></td><td align="left"><p>3</p></td></tr><tr><td align="left"><p>2017/2018</p></td><td align="left"><p>21</p></td><td align="left"><p>16</p></td><td align="left"><p>3</p></td><td align="left"><p>2</p></td></tr></tbody></table></table-wrap></p><p id="Par128">In this case, the goals for at least one of the filters have been met by properly forecasting the three Triads over the first three testing years (2014 to February 2017) and successfully predicting 2 out of 3 over the 2017/2018 period. The idea is to call the minimum number possible of signals, so EMA parameters in this case are valid for all three years of testing, meaning that the three conditions for filters calibration mentioned in “<xref rid="Sec19" ref-type="sec">Filters configuration and results</xref>” have been met.</p><p id="Par129">This system failed to predict only one of the Triads with one of the filters but, for this example certain parameters have been left fixed for all the testing periods. The flexibility of this system permits to re-calculate the values for the filters in future scenarios.</p></sec></sec><sec id="Sec20"><title>Limitations/further work</title><p id="Par130">This paper proposes a methodology for load forecasting by using several key variables of the energy market (NDF, TSDF, solar and wind). The model produces a satisfactory load forecast at the national level. Although this model captures the demand trend, it does not consider indoor physical factors, such as occupancy, internal system’s efficiency, which may require more power from the grid in the case of older infrastructures. The future research may include electric vehicles in the consumption patterns, as well as consider varying electricity prices, as those have a definite impact on the electricity generation patterns. Also, due to the satisfactory results produced by Bayesian regression, further work may include this methodology for comparison with LSTM if similar data is used.</p></sec><sec id="Sec21" sec-type="conclusions"><title>Conclusions</title><p id="Par131">The goal of this paper was to design a system for load forecasting focusing on DSR events, either long or short term, depending on the DSR intervention performed. The system is composed of two steps: load forecasting and the highest peaks extraction with respect to the latest <italic>n</italic> days. In “<xref rid="Sec2" ref-type="sec">Methodology</xref>”, we present the LSTM model for load forecasting, as well as the EMA for peaks extraction. We evaluate accuracy of the model by using different metrics: RMSE, RMSE, MAE and MAPE. Next, we apply this methodology for the specific case of UK Triads forecasting in “<xref rid="Sec6" ref-type="sec">Case study: UK Triads</xref>”, in which the performance of the model is measured in terms of the number of peaks forecast vs number of Triad signals. The goal is to forecast all the three highest peaks with the least possible number of Triads in order to reduce the number of DSR interventions. In “<xref rid="Sec14" ref-type="sec">Results</xref>”, we calibrate the LSTM model and compare its performance with ANN, SVM, random forests, Bayesian regression and the mean-only model. This demonstrates that LSTM outperforms other models, and that its performance is closely followed by Bayesian regression. We show that over the 4 years of testing, 11 peaks are forecasted in total, showing that the number of signals for the soft and hard filters are, respectively, 19 and 14 for the 2014/2015 period, 21 and 19 for the 2015/2016 period, 19 and 14 for the 2016/2017 period and 21 and 16 for the 2017/2018 period.</p><p id="Par132">Once a Triad signal is positive, then as much equipment as possible is switched off and generators are ran, consuming fuel for every action taken against the DSR signal. The factors chosen for the filters are to be defined by the user, in this case, 3.5% and 4% of the value has been chosen for the soft and hard filter respectively, but this defines the level of risk that the company, building manager or DSR manager wants to take. The risk assessment would determine the number of signals that the organisation can afford in terms of fuel/disruption, and the risk of missing the Triad, which is subject to a cost.</p><p id="Par133">There is a possibility that circumstances of the energy system layout may change, such as re-distribution of transmission losses per region according to the P350 amendment approved on the 24 March 2017 (National-Grid <xref ref-type="bibr" rid="CR28">2018</xref>) which could affect the way the forecast behaves, and may lead to a correction factor for a better forecasting, as well as factors re-calibration. The most limiting factor in the system design has been data availability.</p><p id="Par134">Due to recent changes in energy systems, it is necessary to focus on more generalised methodologies that offer a certain degree of flexibility in order to be adapted to DSR interventions. This work may lead to further developments in the area of more flexible forecast for different long-/short-term DSR scenarios.</p><p id="Par135">The future energy systems will require either nonlinear growth of infrastructures, which is not sustainable, or wider-scale, smart interventions which are agile, low-cost, and reduce carbon emissions. The UK energy market presents a set of DSR interventions which are economically grounded and of high potential of implementation in other countries with similar demands for energy, without large investments into infrastructure. This makes modelling and forecasting of DSR programmes of high relevance to international energy markets. The modelling approach we introduce in this paper is concise, accurate, computationally light and flexible for further tuning, according to market and risk management requirements.</p></sec></body><back><sec sec-type="ethics-statement"><title>Compliance with ethical standards</title><sec id="FPar1"><title><bold>Conflict of interests</bold></title><p id="Par136">The authors declare that they have no conflict of interest</p></sec></sec><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Al-Musaylh</surname><given-names>MS</given-names></name><name><surname>Deo</surname><given-names>RC</given-names></name><name><surname>Adamowski</surname><given-names>JF</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Short-term electricity demand forecasting with MARS, SVR and ARIMA models using aggregated demand data in Queensland, Australia</article-title><source>Advanced Engineering Informatics</source><year>2018</year><volume>35</volume><fpage>1</fpage><lpage>16</lpage></mixed-citation></ref><ref id="CR2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arlot</surname><given-names>S</given-names></name><name><surname>Celisse</surname><given-names>A</given-names></name><etal/></person-group><article-title xml:lang="en">A survey of cross-validation procedures for model selection</article-title><source>Statistics Surveys</source><year>2010</year><volume>4</volume><fpage>40</fpage><lpage>79</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">2602303</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1190.62080</pub-id></mixed-citation></ref><ref id="CR3"><mixed-citation publication-type="other">Bianchi, F. M., Maiorino, E., Kampffmeyer, M. C., Rizzi, A., &amp; Jenssen, R. (2017). An overview and comparative analysis of recurrent neural networks for short term load forecasting, arXiv:<ext-link xlink:href="http://arxiv.org/abs/1705.04378" ext-link-type="uri">1705.04378</ext-link>.</mixed-citation></ref><ref id="CR4"><mixed-citation publication-type="other">Cao, X., Dong, S., Wu, Z., &amp; Jing, Y. (2015). A data-driven hybrid optimization model for short-term residential load forecasting. In <italic>2015 IEEE International Conference on Computer and information technology; ubiquitous computing and communications; dependable, autonomic and secure computing; pervasive intelligence and computing (CIT/IUCC/DASC/PICOM)</italic> (pp. 283–287): IEEE.</mixed-citation></ref><ref id="CR5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>S-T</given-names></name><name><surname>Yu</surname><given-names>DC</given-names></name><name><surname>Moghaddamjo</surname><given-names>AR</given-names></name></person-group><article-title xml:lang="en">Weather sensitive short-term load forecasting using nonfully connected artificial neural network</article-title><source>IEEE Transactions on Power Systems</source><year>1992</year><volume>7</volume><issue>3</issue><fpage>1098</fpage><lpage>1105</lpage></mixed-citation></ref><ref id="CR6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>B-J</given-names></name><name><surname>Chang</surname><given-names>M-W</given-names></name><etal/></person-group><article-title xml:lang="en">Load forecasting using support vector machines: a study on EUNITE competition 2001</article-title><source>IEEE Transactions on Power Systems</source><year>2004</year><volume>19</volume><issue>4</issue><fpage>1821</fpage><lpage>1830</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">1431000</pub-id></mixed-citation></ref><ref id="CR7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daut</surname><given-names>MAM</given-names></name><name><surname>Hassan</surname><given-names>MY</given-names></name><name><surname>Abdullah</surname><given-names>H</given-names></name><name><surname>Rahman</surname><given-names>HA</given-names></name><name><surname>Abdullah</surname><given-names>MP</given-names></name><name><surname>Hussin</surname><given-names>F</given-names></name></person-group><article-title xml:lang="en">An improved building load forecasting method using a combined least square support vector machine and modified artificial bee colony</article-title><source>ELEKTRIKA-Journal of Electrical Engineering</source><year>2017</year><volume>16</volume><issue>1</issue><fpage>1</fpage><lpage>5</lpage></mixed-citation></ref><ref id="CR8"><mixed-citation publication-type="other">ELEXON. (2018). Elexon web site, <ext-link xlink:href="https://www.elexon.co.uk/" ext-link-type="uri">https://www.elexon.co.uk/</ext-link>.</mixed-citation></ref><ref id="CR9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faruqui</surname><given-names>A</given-names></name><name><surname>Sergici</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Household response to dynamic pricing of electricity: a survey of 15 experiments</article-title><source>Journal of regulatory Economics</source><year>2010</year><volume>38</volume><issue>2</issue><fpage>193</fpage><lpage>225</lpage></mixed-citation></ref><ref id="CR10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Filik</surname><given-names>ÜB</given-names></name><name><surname>Gerek</surname><given-names>ÖN</given-names></name><name><surname>Kurban</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">A novel modeling approach for hourly forecasting of long-term electric energy demand</article-title><source>Energy Conversion and Management</source><year>2011</year><volume>52</volume><issue>1</issue><fpage>199</fpage><lpage>211</lpage></mixed-citation></ref><ref id="CR11"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>J</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name></person-group><source>The elements of statistical learning, Vol. 1</source><year>2001</year><publisher-loc>New York</publisher-loc><publisher-name>Springer series in statistics</publisher-name><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">0973.62007</pub-id></mixed-citation></ref><ref id="CR12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>González-Romera</surname><given-names>E</given-names></name><name><surname>Jaramillo-Morán</surname><given-names>M</given-names></name><name><surname>Carmona-Fernández</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Monthly electric energy demand forecasting with neural networks and fourier series</article-title><source>Energy Conversion and Management</source><year>2008</year><volume>49</volume><issue>11</issue><fpage>3135</fpage><lpage>3142</lpage></mixed-citation></ref><ref id="CR13"><mixed-citation publication-type="other">Graves, A., Mohamed, A.-R., &amp; Hinton, G. (2013). Speech recognition with deep recurrent neural networks. In <italic>2013 IEEE international conference on Acoustics, speech and signal processing (icassp)</italic> (pp. 6645–6649): IEEE.</mixed-citation></ref><ref id="CR14"><mixed-citation publication-type="other">Hamedmoghadam, H., Joorabloo, N., &amp; Jalili, M. (2018). Australia’s long-term electricity demand forecasting using deep neural networks, arXiv:<ext-link xlink:href="http://arxiv.org/abs/1801.02148" ext-link-type="uri">1801.02148</ext-link>.</mixed-citation></ref><ref id="CR15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>W</given-names></name></person-group><article-title xml:lang="en">Load forecasting via deep neural networks</article-title><source>Procedia Computer Science</source><year>2017</year><volume>122</volume><fpage>308</fpage><lpage>314</lpage></mixed-citation></ref><ref id="CR16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Long short-term memory</article-title><source>Neural Computation</source><year>1997</year><volume>9</volume><issue>8</issue><fpage>1735</fpage><lpage>1780</lpage></mixed-citation></ref><ref id="CR17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>W-C</given-names></name></person-group><article-title xml:lang="en">Electric load forecasting by support vector model</article-title><source>Applied Mathematical Modelling</source><year>2009</year><volume>33</volume><issue>5</issue><fpage>2444</fpage><lpage>2454</lpage><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1185.68530</pub-id></mixed-citation></ref><ref id="CR18"><mixed-citation publication-type="other">Hyndman, R. J., &amp; Athanasopoulos, G. (2018). <italic>Forecasting: principles and practice</italic>. OTexts.</mixed-citation></ref><ref id="CR19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kandananond</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Forecasting electricity demand in Thailand with an artificial neural network approach</article-title><source>Energies</source><year>2011</year><volume>4</volume><issue>8</issue><fpage>1246</fpage><lpage>1257</lpage></mixed-citation></ref><ref id="CR20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khwaja</surname><given-names>A</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Anpalagan</surname><given-names>A</given-names></name><name><surname>Venkatesh</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Boosted neural networks for improved short-term electric load forecasting</article-title><source>Electric Power Systems Research</source><year>2017</year><volume>143</volume><fpage>431</fpage><lpage>437</lpage></mixed-citation></ref><ref id="CR21"><mixed-citation publication-type="other">Kong, W., Dong, Z. Y., Jia, Y., Hill, D. J., Xu, Y., &amp; Zhang, Y. (2017). Short-term residential load forecasting based on LSTM recurrent neural network. <italic>IEEE Transactions on Smart Grid</italic>.</mixed-citation></ref><ref id="CR22"><mixed-citation publication-type="other">Kouroupetroglou, P.-N., &amp; Tsoumakas, G. (2017). Machine learning techniques for short-term electric load forecasting, Thesis.</mixed-citation></ref><ref id="CR23"><mixed-citation publication-type="other">Li, S., Goel, L., &amp; Wang, P. (2016). An ensemble approach for short-term load forecasting by extreme learning machine. <ext-link xlink:href="https://www.sciencedirect.com/science/article/pii/S0306261916302707" ext-link-type="uri">https://www.sciencedirect.com/science/article/pii/S0306261916302707</ext-link>.</mixed-citation></ref><ref id="CR24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>J-P</given-names></name><name><surname>Li</surname><given-names>C-L</given-names></name></person-group><article-title xml:lang="en">The short-term power load forecasting based on sperm whale algorithm and wavelet least square support vector machine with DWT-IR for feature selection</article-title><source>Sustainability</source><year>2017</year><volume>9</volume><issue>7</issue><fpage>1188</fpage></mixed-citation></ref><ref id="CR25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marmaras</surname><given-names>C</given-names></name><name><surname>Javed</surname><given-names>A</given-names></name><name><surname>Cipcigan</surname><given-names>L</given-names></name><name><surname>Rana</surname><given-names>O</given-names></name></person-group><article-title xml:lang="en">Predicting the energy demand of buildings during triad peaks in GB</article-title><source>Energy and Buildings</source><year>2017</year><volume>141</volume><fpage>262</fpage><lpage>273</lpage></mixed-citation></ref><ref id="CR26"><mixed-citation publication-type="other">Mohanad, S. A.-M., Ravinesh, C. D., &amp; Yan, L. (2018). Particle swarm optimized–support vector regression hybrid model for daily horizon electricity demand forecasting using climate dataset. In <italic>E3S Web of Conferences</italic>, (Vol. 64 p. 08001): EDP Sciences.</mixed-citation></ref><ref id="CR27"><mixed-citation publication-type="other">Newbery, D. (2011). High level principles for guiding GB transmission charging and some of the practical problems of transition to an enduring regime, Report Prepared for and Commissioned by Project TransmiT, Great Britain Office of Gas &amp; Electricity Markets.</mixed-citation></ref><ref id="CR28"><mixed-citation publication-type="other">National-Grid. (2018). National Grid UK <ext-link xlink:href="https://www.nationalgrid.com/uk" ext-link-type="uri">https://www.nationalgrid.com/uk</ext-link>.</mixed-citation></ref><ref id="CR29"><mixed-citation publication-type="other">Qingle, P., &amp; Min, Z. (2010). Very short-term load forecasting based on neural network and rough set, (Vol. 3, IEEE.</mixed-citation></ref><ref id="CR30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saini</surname><given-names>L</given-names></name><name><surname>Soni</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Artificial neural network based peak load forecasting using Levenberg-Marquardt and quasi-Newton methods</article-title><source>IEEE Proceedings-Generation Transmission and Distribution</source><year>2002</year><volume>149</volume><issue>5</issue><fpage>578</fpage><lpage>584</lpage></mixed-citation></ref><ref id="CR31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>P</given-names></name><name><surname>Dwivedi</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Integration of new evolutionary approach with artificial neural network for solving short term load forecast problem</article-title><source>Applied energy</source><year>2018</year><volume>217</volume><fpage>537</fpage><lpage>549</lpage></mixed-citation></ref><ref id="CR32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tian</surname><given-names>C</given-names></name><name><surname>Ma</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Zhan</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">A deep neural network model for short-term load forecast based on long short-term memory network and convolutional neural network</article-title><source>Energies</source><year>2018</year><volume>11</volume><issue>12</issue><fpage>3493</fpage></mixed-citation></ref><ref id="CR33"><mixed-citation publication-type="other">Wang, J., Yu, L.-C., Lai, K. R., &amp; Zhang, X. (2016). Dimensional sentiment analysis using a regional CNN-LSTM model. In <italic>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</italic>, (Vol. 2 pp. 225–230).</mixed-citation></ref><ref id="CR34"><mixed-citation publication-type="other">Xu, H., Gao, Y., Yu, F., &amp; Darrell, T. (2016). End-to-end learning of driving models from large-scale video datasets, arXiv preprint.</mixed-citation></ref><ref id="CR35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yun</surname><given-names>Z</given-names></name><name><surname>Quan</surname><given-names>Z</given-names></name><name><surname>Caixin</surname><given-names>S</given-names></name><name><surname>Shaolan</surname><given-names>L</given-names></name><name><surname>Yuming</surname><given-names>L</given-names></name><name><surname>Yang</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">RBF Neural network and ANFIS-based short-term load forecasting approach in real-time price environment</article-title><source>IEEE Transactions on Power Systems</source><year>2008</year><volume>23</volume><issue>3</issue><fpage>853</fpage><lpage>858</lpage></mixed-citation></ref><ref id="CR36"><mixed-citation publication-type="other">Zheng, J., Xu, C., Zhang, Z., &amp; Li, X. (2017). Electric load forecasting in smart grids using long-short-term-memory based recurrent neural network. In <italic>2017 51st Annual Conference on Information Sciences and Systems (CISS)</italic> (pp. 1–6): IEEE.</mixed-citation></ref></ref-list></ref-list><notes notes-type="Misc"><title>Publisher’s note</title><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Energy</facet-value><facet-value count="1">Energy Efficiency</facet-value><facet-value count="1">Energy Policy, Economics and Management</facet-value><facet-value count="1">Environment, general</facet-value><facet-value count="1">Environmental Economics</facet-value><facet-value count="1">Renewable and Green Energy</facet-value><facet-value count="1">Sustainable Development</facet-value></facet><facet name="keyword"><facet-value count="1">Demand side response</facet-value><facet-value count="1">Electricity demand</facet-value><facet-value count="1">Load forecasting</facet-value><facet-value count="1">Long short-term memory</facet-value><facet-value count="1">Machine learning</facet-value><facet-value count="1">Neural networks</facet-value><facet-value count="1">Triad forecasting</facet-value></facet><facet name="pub"><facet-value count="1">Energy Efficiency</facet-value></facet><facet name="year"><facet-value count="1">2020</facet-value></facet><facet name="country"><facet-value count="1">United Kingdom</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
