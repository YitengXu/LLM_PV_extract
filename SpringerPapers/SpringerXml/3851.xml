<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1007/s40747-022-00879-3</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="research-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">40747</journal-id><journal-title-group><journal-title>Complex &amp; Intelligent Systems</journal-title><abbrev-journal-title abbrev-type="publisher">Complex Intell. Syst.</abbrev-journal-title></journal-title-group><issn pub-type="ppub">2199-4536</issn><issn pub-type="epub">2198-6053</issn><publisher><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s40747-022-00879-3</article-id><article-id pub-id-type="manuscript">879</article-id><article-id pub-id-type="doi">10.1007/s40747-022-00879-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Article</subject></subj-group></article-categories><title-group><article-title xml:lang="en">Wind speed and global radiation forecasting based on differential, deep and stochastic machine learning of patterns in 2-level historical meteo-quantity sets</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="Au1"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2881-4319</contrib-id><name><surname>Zjavka</surname><given-names>Ladislav</given-names></name><address><email>ladislav.zjavka@vsb.cz</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="corresp" rid="IDs40747022008793_cor1">a</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.440850.d</institution-id><institution-id institution-id-type="ISNI">0000 0000 9643 2828</institution-id><institution content-type="org-division">Department of Computer Science, Faculty of Electrical Engineering and Computer Science</institution><institution content-type="org-name">VŠB-Technical University of Ostrava</institution></institution-wrap><addr-line content-type="street">17. listopadu 15/2172</addr-line><addr-line content-type="city">Ostrava</addr-line><country country="CZ">Czech Republic</country></aff></contrib-group><author-notes><corresp id="IDs40747022008793_cor1"><label>a</label><email>ladislav.zjavka@vsb.cz</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>15</day><month>10</month><year>2022</year></pub-date><fpage>1</fpage><lpage>15</lpage><history><date date-type="registration"><day>22</day><month>9</month><year>2022</year></date><date date-type="received"><day>28</day><month>2</month><year>2022</year></date><date date-type="accepted"><day>20</day><month>9</month><year>2022</year></date><date date-type="online"><day>15</day><month>10</month><year>2022</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2022</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">Accurate forecasting of wind speed and solar radiation can help operators of wind farms and Photo-Voltaic (PV) plants prepare efficient and practicable production plans to balance the supply with demand in the generation and consumption of Renewable Energy (RE). Reliable Artificial Intelligence (AI) forecast models can minimize the effect of wind and solar power fluctuations, eliminating their intermittent character in system dispatch planning and utilization. Intelligent wind and solar energy management is essential in load scheduling and decision-making processes to meet user requirements. The proposed 24-h prediction schemes involve the beginning detection and secondary similarity re-evaluation of optimal day-data sequences, which is a notable incremental improvement against state-of-the-art in the consequent application of statistical AI learning. 2-level altitude measurements allow the identification of data relationships between two surface layers (hill and lowland) and adequate interpretation of various meteorological situations, whose differentiate information is used by AI models to recognize upcoming changes in the mid-term day horizon. Observations at two professional meteorological stations comprise specific quantities, of which the most valuable are automatically selected as input for the day model. Differential learning is a novel designed unconventional neurocomputing approach that combines derivative components produced in selected network nodes in the weighted modular output. The complexity of the node-stepwise composed model corresponds to the patterns included in the training data. It allows for representation of high uncertain and nonlinear dynamic systems, dependent on local RE production, not substantially reducing the input vector dimensionality leading to model over simplifications as standard AI does. Available angular and frequency time data (e.g., wind direction, humidity, and irradiation cycles) are combined with the amplitudes to solve reduced Partial Differential Equations (PDEs), defined in network nodes, in the periodical complex form. This is a substantial improvement over the previous publication design. The comparative results show better efficiency and reliability of differential learning in representing the modular uncertainty and PDE dynamics of patterns on a day horizon, taking into account recent deep and stochastic learning. A free available C++ parametric software together with the processed meteo-data sets allow additional comparisons with the presented model results.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Statistical modeling</kwd><kwd>Machine learning</kwd><kwd>Operator calculus</kwd><kwd>Partial differential equation</kwd><kwd>Laplace transform</kwd><kwd>PDE polynomial conversion</kwd><kwd>Inverse formulation</kwd><kwd>Angular representation</kwd></kwd-group><kwd-group xml:lang="ar"><title>Arabic keywords</title><kwd><inline-graphic xlink:href="MediaObjects/40747_2022_879_Figa_HTML.gif"/></kwd><kwd><inline-graphic xlink:href="MediaObjects/40747_2022_879_Figb_HTML.gif"/></kwd><kwd><inline-graphic xlink:href="MediaObjects/40747_2022_879_Figc_HTML.gif"/></kwd><kwd><inline-graphic xlink:href="MediaObjects/40747_2022_879_Figd_HTML.gif"/></kwd></kwd-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Springer</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>No</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2022</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>9</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>22</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>ArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>true</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/40747_2022_Article_879.pdf</meta-value></custom-meta><custom-meta><meta-name>pdf-type</meta-name><meta-value>Typeset</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>OriginalPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Engineering</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Computational Intelligence</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Complexity</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Data Structures and Information Theory</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Engineering</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Wind and PV power generation capacity is restricted by local or regional barriers (e.g., building structures or terrain obstacles). RE sources exhibit seasonal and diurnal addiction with stochastic and high-frequency variability. Wind speed and solar radiation are the complex results of global atmospheric convection processes, primarily caused by pressure and temperature differences or anomalies [<xref ref-type="bibr" rid="CR1">1</xref>]. Wind and solar energy are the most important sources in off-grid systems located in mountains or coastal backcountry domains with inadequate conventional electricity supply, grid structure, or other inconsistent power sources. Wind turbine or PV panel arrangements are affected by a set of environmental factors, e.g. contour line, surface complexity, roughness or temperature stratification around the location. Their configuration can be established by modeling the characteristics of individual components or integrating information into the total energy production of a plant or farm [<xref ref-type="bibr" rid="CR2">2</xref>]. The prediction of wind and solar parameters can be broadly divided into two main categories using [<xref ref-type="bibr" rid="CR3">3</xref>]:<list list-type="bullet"><list-item><p id="Par3">Physical approach simulating wind formation processes through complex mathematical physics, such as numerical weather prediction (NWP).</p></list-item><list-item><p id="Par4">Statistical consideration using data-driven models for the related factors supposing the stochastic nature of the processes</p></list-item></list></p><p id="Par5">Physical models are able to solve the equations of fluid mechanics and thermodynamics for the future atmospheric motion state in a certain time-step and resolution to simulate the variation tendency of meteo-factors. NWP systems attempt to model global or local weather patterns, starting with the observed input data [<xref ref-type="bibr" rid="CR4">4</xref>]. They solve the hydrodynamic and thermodynamic equations of atmospheric flow in models initialized with specific starting and boundary constraints. This modeling approach is based on discretized conservation equations of mass, momentum, and energy in several atmospheric layers. This approach is usually efficient at long-term time horizons, but its applications are limited by a large number of multistep iterations and inadequacies in the short-term definitions. Difficulties are usually encountered in solving numerical models with higher resolution due to limitations in the complexity and time-consumption. NWP requires a lot of computing time and variables, which restricts its practicability in short-term forecasting [<xref ref-type="bibr" rid="CR5">5</xref>].</p><p id="Par6">Statistical data-driven techniques refer to the use of mathematical knowledge, such as statistics, chaos, and probability theory. AI forecasting models, formed with iterative learning, generally obtain better results in solving problems that cannot be defined analytically [<xref ref-type="bibr" rid="CR3">3</xref>]. Their adaptability and robustness have higher potential in dealing with non-stationary disturbances. The statistical approach is usually more efficient than the physical simulation in a specific terrain allocation. Hybrid solutions usually include ensemble learning and metaheuristic optimization. Short-term AI prediction mostly outperforms the original NWP forecast accuracy, capturing temporal dynamics of the wind turbine with relationships among the local meteo-quantities [<xref ref-type="bibr" rid="CR6">6</xref>]. However, the loss in causality between wind speed or solar radiation and other meteorological factors results in shortcomings in statistical reliability using only historical data. AI usually considers meteorological factors only from the point of view of correlations, potentially losing a lot of useful physical information [<xref ref-type="bibr" rid="CR7">7</xref>].</p><p id="Par7">The proposed AI hybrid method, based on differential learning, combines numerical mathematics with neural computing to form progressive PDE-modular models. Its component PDE-formularization using evolving dynamic tree structures is supposed to solve some problems in statistical weather forecasting (e.g. model oversimplification, pattern variability and uncertainty, high-dimensionality reduction, feature extraction, data transformation, model composition, structure self-organization, etc.). The experiments start with two different level ground data sets whose differentiated information allows for an early recognition of changeovers in weather patterns in the 24-h prediction horizon. Specific meteo-quantities, recorded in 2 professional automatic meteo-stations (on lowland and peak bases), are examined to what extent they contribute to the overall forecast reliability. Self-detection of the most valuable data inputs from the days and advanced self-optimization reduce the structural complexity and uncertainties in the model initialization. The initial rough detection of applicable day training sequences is enhanced additionally by a reassessment processing of the interval sample records, one by one, according to pattern similarity in the determinate last observational time. No architecture hand design or training/testing initialization is necessary, as is common in deep learning.</p><p id="Par8">The new designed differential learning is used in RE prediction with significant incremental innovations in its model definition, optimization and initialization (pre-processing):<list list-type="bullet"><list-item><p id="Par9">Periodical variables (radiation, temperature, etc.) are modeled using sine and cosine PDE-conversion functions, in combination with wind azimuth or time-stamp radius data (Section “<xref rid="Sec5" ref-type="sec">Differential learning—a novel hybrid neuro-math computing approach</xref>”).</p></list-item><list-item><p id="Par10">A pareto list of the best input combination couples is initially determined in each layer learning cycle (separate model components are tested for the error minima) to be examined by inserting their node PDE modules into the gradually expanded complete model (Section “<xref rid="Sec3" ref-type="sec">Wind &amp; solar day-ahead forecasting—methodology and data acquisition</xref>”).</p></list-item><list-item><p id="Par11">Binary-tree structures (producing model PDE-components) are dynamically evolved and modified in each training cycle.</p></list-item><list-item><p id="Par12">Backpropagation is used in polynomial parameter post-adaptation in binary-tree nets to improve the model development (Section “<xref rid="Sec5" ref-type="sec">Differential learning—a novel hybrid neuro-math computing approach</xref>”).</p></list-item><list-item><p id="Par13">Supplement power functions are used in model definition to refine the final PDE-formulation.</p></list-item><list-item><p id="Par14">Initially estimated record series of applicable daily training intervals are reassessed, one by one, according to pattern similarity in the last observation times (Section “<xref rid="Sec3" ref-type="sec">Wind &amp; solar day-ahead forecasting—methodology and data acquisition</xref>”).</p></list-item><list-item><p id="Par15">The C +  + parametric application software with examined data sets is provided with publication ([C] D-PNN application C +  + parametric software with Solar, Wind &amp; Meteo-data sets: <ext-link xlink:href="https://drive.google.com/drive/folders/1Q9m09bZ6LlQ2Up2_oJ0vDQpceYvXROrN" ext-link-type="uri">https://drive.google.com/drive/folders/1Q9m09bZ6LlQ2Up2_oJ0vDQpceYvXROrN</ext-link>).</p></list-item></list></p><p id="Par16">The PDE-modular tree representation of weather pattern dynamics allows for free-standing RE statistical prediction in an increased mid-term day horizon, which is a significant advancement in comparison of recent AI (the problem solution is analogous to NWP). High-dimensionality data are sequentially processed (without information loss), in step-by-step model expansion and adaptation to the defined constraints. The Laplace transformation is automatically applied in 2-variable node PDE-conversion, which eliminates unexpected wind and solar parameter data fluctuations. The optimal model definition is automatically performed by selection from several types of base approximation function (rational, periodical, power), which allows a high diversity in model combination forms. Composite PDE modules are back-composed in multi-layer tree structures in the products of determined sub-PDE images in previous layers. Redundant components of PDE-transform products (using the same input variables) are automatically detected and removed from the structural model in learning to eliminate their undesirable interference and increase in complexity. Advanced external complement testing prevents the insertion of unacceptable non-generalizing PDE solutions.</p></sec><sec id="Sec2"><title>State-of-the-art in wind and solar prediction</title><p id="Par17">Decomposition techniques usually transform the original non-stationary series into a more applicable sub-series. Data decomposition analysis can be used to distribute the original series into specific frequency signal bands [<xref ref-type="bibr" rid="CR8">8</xref>]. Empirical mode decomposition can recognize specific signal samples in unknown data that are forecasted and restored in an ensemble output of the target wind series using adaptive wavelet models in a particular time horizon [<xref ref-type="bibr" rid="CR9">9</xref>]. Wavelet analysis decomposes the mother functions into several wave levels, which appear as the most critical parameters. A predictor is constructed for each forecasting component, so the training time is multiplied. Causalities between wind &amp; solar and other meteorological factors (e.g., pressure, temperature, etc.) can be recognized to divide data into several equivalent classes: central, chained, ring, tree, and network, according to the topological data structure. The Deep Learning (DL) network is dynamically formed with respect to the recognized causality data categories [<xref ref-type="bibr" rid="CR7">7</xref>]. Meta-heuristics can adaptively estimate the optimal predictor parameters. These techniques can reconstruct missing information for specific data. Heuristics multi-objective optimizer usually begins with one initial estimate solution. The algorithm efficiently searches a defined search space to iteratively update a set of solution states and modify key parameters until the convergence criterion is satisfied. It can be applied to find the optimal weights of the ensemble forecast models or predictor parameters [<xref ref-type="bibr" rid="CR10">10</xref>]. Fuzzy C-mean clustering can assess the difference in wind turbine output from day-ahead wind prediction. The principle of minimum distance allows for the selection of initial rough cluster centers in the data [<xref ref-type="bibr" rid="CR11">11</xref>].</p><p id="Par18">Ensemble learning is applied to integrate multiple parts of predictors in hybrid models and guarantee diversity. Ensemble strategies in forecasting can be used to form two types of AI models:<list list-type="bullet"><list-item><p id="Par19">weighted ensembles,</p></list-item><list-item><p id="Par20">learner-based aggregation,</p></list-item></list></p><p id="Par21">The weighted output is a simple summary of single-model estimates. The learner approach combines multiple sets of forecast series generated by different predictors. The final output learner captures the relationships between the individual forecasts. Diversity-based methods partition data sets into training samples with different statistical distributions to form predictors, using bootstrap aggregation in bagging or boosting models:<list list-type="bullet"><list-item><p id="Par22">Boosting is applied in training base predictors to combine their best parameters, estimated by heuristics, in an aggregated output. It attempts to improve weak learners by building an integrated stronger predictor. It continuously modifies the distribution of data in the training of individual learners to achieve better performance. Data samples with higher prediction errors are assigned higher weights.</p></list-item><list-item><p id="Par23">Bootstrapping searches for a residual distribution function using resampling of the original data to construct Prediction Intervals (PIs). It repetitively draws commensurate samples to replace the original training data and partition them into several groups.</p></list-item></list></p><p id="Par24">Multi-step prediction procedures based on machine learning are mostly applied in increased time horizons. Larger errors can be induced due to the incorrect initialization time of wind or solar models in synoptic processes [<xref ref-type="bibr" rid="CR12">12</xref>]. They are broadly categorized into the following:<list list-type="bullet"><list-item><p id="Par25">Recursive approach (using the iterative learning).</p></list-item><list-item><p id="Par26">Direct strategy (calculating the output series separately).</p></list-item></list></p><p id="Par27">Chaos theory based on methods can capture linear and nonlinear characteristics in structural data. One-dimensional time series can be extended to a multi-dimensional matrix form using phase-space reconstruction to better represent the characteristics used as model inputs in forecasting [<xref ref-type="bibr" rid="CR5">5</xref>]. The atmospheric stability factor is determined by its tendency to encourage or deter vertical air motion or flow. NWP data are grouped into several meaningful sets according to the atmosphere stability class, based on the comparison of observations at the prediction times. Gaussian Process Regression (GPR) is a nonparametric Bayesian modeling approach which attempts to detect complicated nonlinear relations between model inputs and output variables (predictors), based on the standard statistical distribution in data observations. Its models can recognize anomalies in ground wind speed [<xref ref-type="bibr" rid="CR13">13</xref>]. Singular spectrum analysis can detect the periodic, quasi-periodic, and trend components in data series. The base and detail wind components are learned and predicted by separate models to generalize the inherent depth and long-term data relations. The Gray prediction method can solve high-uncertain problems with a significant lack of data or information, based on sample modeling [<xref ref-type="bibr" rid="CR14">14</xref>]. The validity of the forecasting models for different RE generation scenarios can be determined by their testing approach. Decomposition-based models can analyze robustness and performance under different environmental conditions [<xref ref-type="bibr" rid="CR15">15</xref>].</p><p id="Par28">Probabilistic models provide information on the uncertainty of the calculated forecasts. They provide PIs where the point estimations are expected, as compared to the point forecasts produced by deterministic models. The distribution of output data can be estimated from the given training samples. Output errors, resulting from incorrect assumptions of distribution shapes, can be eliminated in this way [<xref ref-type="bibr" rid="CR16">16</xref>]. Lower–upper bound output estimations can be used to construct PIs. Ensemble forecasts integrate several models using the different approaches or initial conditions. They can estimate a probability distribution of data of random weather quantities. Quantile regression forms ‘quantiles’ to estimate the conditional probability distribution of a random variable. Conditional quantiles are functions of independent explanatory variables, used as input to the model. Explanatory variables can be the result of an analysis of the NWP model. The kernel density can be used to estimate a probability distribution for random variables. A kernel is applied to each data point for a given variable to highlight its contribution and relevance in the density probabilistic function. After that, the sum of all kernel functions gives a smooth curve in the final output to determine the kernel density. Probability solutions are easy to transform into a stochastic Markov chain frame [<xref ref-type="bibr" rid="CR3">3</xref>]. Clustering and K-fold cross-validation in ensemble learning are used to generate multiple training subsets with the same distribution for the Bayesian base learner combining strategy to increase the diversity of input–output samples [<xref ref-type="bibr" rid="CR17">17</xref>].</p></sec><sec id="Sec3"><title>Wind &amp; solar day-ahead forecasting—methodology and data acquisition</title><p id="Par29">The available data record series were first examined using tentative initialization models. Their test error minima, obtained in the latest 8–12 h in the step-by-step increasing learning day interval, give the first rough approximate of the practicable init-time range in formation of prediction models. The applicability of predetermined sequence data was then re-evaluated according to Pearson’s Correlation Distance (CD), based on the Correlation Similarity (CS) measure (1), to particularize the most valuable samples, one by one, computed for the time-counterparts of the last day pattern. Generally, similarity is measured in the range 0 to 1, that is, the value of CS is ‘1’ if the vectors are exactly identical <italic>P</italic> =  = <italic>Q</italic> and converges to ‘0’ if the vector P is totally different from <italic>Q</italic>.<disp-formula id="Equ1"><label>1</label><alternatives><mml:math display="block" id="Equ1_Math"><mml:mrow><mml:mi>C</mml:mi><mml:msup><mml:mi>D</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>C</mml:mi><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mtext>cov</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mtext>var</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msqrt><mml:mo>·</mml:mo><mml:msqrt><mml:mrow><mml:mtext>var</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>·</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:mo>·</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ CD^{\prime} = 1 - CS = 1 - \frac{{\text{cov} (P,Q)}}{{\sqrt {\text{var} (P)}  \cdot \sqrt {\text{var} (Q)} }} = 1 - \frac{{\sum\nolimits_{{k = 1}}^{n} {\left( {p_{{ij}}  - \frac{1}{n}\sum\nolimits_{{j = 1}}^{n} {p_{{ij}} } } \right)}  \cdot \sum\nolimits_{{k = 1}}^{n} {\left( {q_{{ij}}  - \frac{1}{n}\sum\nolimits_{{j = 1}}^{n} {q_{{ij}} } } \right)} }}{{\sqrt {\sum\nolimits_{{i = 1}}^{n} {\left( {p_{{ij}}  - \frac{1}{n}\sum\nolimits_{{j = 1}}^{n} {p_{{ij}} } } \right)} ^{2} }  \cdot \sqrt {\sum\nolimits_{{i = 1}}^{n} {\left( {q_{{ij}}  - \frac{1}{n}\sum\nolimits_{{j = 1}}^{n} {q_{{ij}} } } \right)} ^{2} } }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="40747_2022_879_Article_Equ1.gif"/></alternatives></disp-formula><italic>P</italic>(<italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>,…, <italic>p</italic><sub><italic>n</italic></sub>) and <italic>Q</italic>(<italic>q</italic><sub>1</sub>, <italic>q</italic><sub>2</sub>,…,<italic>q</italic><sub>n</sub>) are 2-point data in the space of n-dimensions, cov(<italic>P</italic>,<italic>Q</italic>) and var(<italic>P</italic>/<italic>Q</italic>) are covariance and variance of P, Q data</p><p id="Par30">12 meteorological quantities were selected from the available observational data recorded in 10 min. series in the experimental 2-level automatic stations allocated in the Kopisty plain (240 m above sea level) and Milešovka peak (837 m attitude) points (Meteorological observational stations of Czech Academy of Sciences in Milesovka and Kopisty <ext-link xlink:href="http://www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/meteorological-observatory-milesovka/milesovka-current-weather" ext-link-type="uri">www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/meteorological-observatory-milesovka/milesovka-current-weather</ext-link>, <ext-link xlink:href="http://www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/kopisty-weather-station/actual-weather" ext-link-type="uri">www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/kopisty-weather-station/actual-weather</ext-link>) from 1 to 31 December, 2017:<list list-type="bullet"><list-item><p id="Par31">Global Radiation (GR), Height of the Condensation Output Level.</p></list-item><list-item><p id="Par32">Ground Temperature, Relative Humidity in 2 m, See Level Pressure.</p></list-item><list-item><p id="Par33">Wind Speed (WS) aver., Wind Direction aver., Time of Maximal Wind Speed, Wind Trajectory (integral).</p></list-item><list-item><p id="Par34">Visibility aver., Height of the 1st Cloudiness Base, Height of the 2nd Cloudiness Base.</p></list-item></list></p><p id="Par35">The above variables were selected as input to the model with the highest relevance. Combining data from two-attitude-based stations allows modeling the relations in 2 atmospheric layers, which contributes to the acceptable mid-term forecasting accuracy in 24-h output time horizon using no NWP processing data (‘Aladin’ regional meso-scale NWP-model produced every 6 h (‘Meteograms’ are in Czech language) <ext-link xlink:href="http://www.chmi.cz/files/portal/docs/meteo/ov/aladin/results/public/meteogramy/mhtml/m.html" ext-link-type="uri">www.chmi.cz/files/portal/docs/meteo/ov/aladin/results/public/meteogramy/mhtml/m.html</ext-link>) (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Pattern variations or instabilities in the 2-level pattern zones indicate eventual frontal disturbances or break changeovers, whose evidence can be registered in the next day hours. The two-layer data relations are identified and incorporated by the multilevel forecasting model to reflect the dynamics of global progress [<xref ref-type="bibr" rid="CR18">18</xref>]. The Clear Sky Index (CSI) factor, a fundamental ratio parameter formulated in the relative GR (<xref rid="Equ2" ref-type="disp-formula">2</xref>), was used to norm GR input–output.<disp-formula id="Equ2"><label>2</label><alternatives><mml:math display="block" id="Equ2_Math"><mml:mrow><mml:mtext>CSI</mml:mtext><mml:mo>=</mml:mo><mml:mtext>GR</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">/</mml:mo><mml:msub><mml:mtext>GR</mml:mtext><mml:mtext>cls</mml:mtext></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math><tex-math id="Equ2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\text{CSI}} = {\text{GR}}(t)/{\text{GR}}_{{{\text{cls}}}} (t), $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="40747_2022_879_Article_Equ2.gif"/></alternatives></disp-formula>GR and GR<sub>cls</sub> is the denotes measured and clear sky (peak) irradiance in time <italic>t</italic> series.</p><p id="Par36">Figure <xref rid="Fig1" ref-type="fig">1</xref> illustrates the identification search for the first applicable day-data sequences using the single-time modeling initialization in the gradually increasing starting-day interval in each validation experiment. Data records in the determined time range were after reassessed, one by one, in computing the sufficient pattern similarity with equivalent data points in the last-day hours (antecedent the prediction time). If tentative models cannot get a satisfactory approximation of the last-day test data (in the case of a frontal break), the start and end daytimes can be gradually shifted in searching appropriate learning multi-base records in the available set of data.<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><p>Predetermination of the modeling initialization time and reappraising data samples, one by one</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig1_HTML.png" id="MO2"/></fig></p><p id="Par37">Figure <xref rid="Fig2" ref-type="fig">2</xref> shows the day-ahead forecasting training scheme applicable in wind and solar parameter AI modeling without using NWP data (‘Aladin’ regional meso-scale NWP-model produced every 6 h (‘Meteograms’ are in Czech language) <ext-link xlink:href="http://www.chmi.cz/files/portal/docs/meteo/ov/aladin/results/public/meteogramy/mhtml/m.html" ext-link-type="uri">www.chmi.cz/files/portal/docs/meteo/ov/aladin/results/public/meteogramy/mhtml/m.html</ext-link>). The evolved models are secondary tested in the last hours and applied to unseen data to calculate their approximation of the response times of the target output in the response times of the following day [<xref ref-type="bibr" rid="CR19">19</xref>]. If a prediction model cannot obtain a defined test error threshold, then its statistical prognosis is obviously impracticable and should not be used as a basis in RE planning. Figure <xref rid="Fig3" ref-type="fig">3</xref> shows a visualization of the situation in the 2-level localization area of the two flat and peak professional observation meteorological facilities (Meteorological observational stations of Czech Academy of Sciences in Milesovka and Kopisty <ext-link xlink:href="http://www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/meteorological-observatory-milesovka/milesovka-current-weather" ext-link-type="uri">www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/meteorological-observatory-milesovka/milesovka-current-weather</ext-link>, <ext-link xlink:href="http://www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/kopisty-weather-station/actual-weather" ext-link-type="uri">www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/kopisty-weather-station/actual-weather</ext-link>).<fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><p>Training and testing schemes in a day-ahead prediction horizon for wind and solar pre-assessed data</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig2_HTML.png" id="MO3"/></fig><fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><p>Low- and high-land locations of professional meteo-observational base stations in the west-Bohemian region</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig3_HTML.png" id="MO1"/></fig></p></sec><sec id="Sec4"><title>AI computing methods used in day-ahead statistics model development</title><sec id="Sec5"><title>Differential learning—a novel hybrid neuro-math computing approach</title><p id="Par38">Differential Learning (DfL) is a novel hybrid soft-computing procedure, proposed by the author, which integrates ML with mathematical principles of solving Partial Differential Equations. Differential Polynomial Neural Network (D-PNN) is a DfL-based regression method that decomposes and solves the general linear PDE of the <italic>k</italic>th order into reduced 2-variable PDEs of the determined low order (3) converted in nodes. D-PNN allows modeling of complex high-nonlinear systems, described by a number of variables, which cannot be completely defined by conventional physical equations or represented by AI computing. Its model development is based on the optimal self-selection of applicable 2-inputs, so that it need not use the initial pre-extraction. D-PNN forms step by step multi-layer Polynomial Neural Network (PNN) tree structures, extending it node by node in the layers. Each selected node can produce PDE-model components, which are selected to be involved (or removed) in (or from) the sum output to progressively improve the approximation of target data. The gradual extension modeling procedure usually leads to the best acceptable solution in the use of the theorem defined by Kurt Goedel’s incompleteness. PNN nodes, included in the back-computing extended D-PNN architecture, process the most proper 2-input data to pre-define and re-substitute the particular PDEs in the sum combinatorial model development, according to Operation Calculus (OC). The polynomial processing order evaluated for the component model substitutes for the PDE-transformation order [<xref ref-type="bibr" rid="CR18">18</xref>].<disp-formula id="Equ3"><label>3</label><alternatives><mml:math display="block" id="Equ3_Math"><mml:mrow><mml:mi>A</mml:mi><mml:mfrac><mml:mrow><mml:msup><mml:mi>∂</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mfrac><mml:mrow><mml:msup><mml:mi>∂</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mfrac><mml:mrow><mml:msup><mml:mi>∂</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>E</mml:mi><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:math><tex-math id="Equ3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ A\frac{{\partial^{2} u}}{{\partial x_{1}^{2} }} + B\frac{{\partial^{2} u}}{{\partial x_{1} x_{2} }} + C\frac{{\partial^{2} u}}{{\partial x_{2}^{2} }} + D\frac{\partial u}{{\partial x_{1} }} + E\frac{\partial u}{{\partial x_{2} }} + Fu = G $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="40747_2022_879_Article_Equ3.gif"/></alternatives></disp-formula>, where <italic>A</italic>, <italic>B</italic>,…,<italic>G</italic> is the parametric coefficient of <italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub> independent variables of the unknown <italic>u</italic> function.</p><p id="Par39">OC conversion of <italic>n</italic>th order derivatives for the <italic>f</italic>(<italic>t</italic>) function is founded on the assumption that it can be replaced by the Laplace transformations (L-transforms) supposing defined initial conditions (<xref rid="Equ4" ref-type="disp-formula">4</xref>).<disp-formula id="Equ4"><label>4</label><alternatives><mml:math display="block" id="Equ4_Math"><mml:mrow><mml:mi>L</mml:mi><mml:mfenced open="{"><mml:mfenced close="}"><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfenced></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>+</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mspace width="0.277778em"/><mml:mi>L</mml:mi><mml:mfenced open="{"><mml:mfenced close="}"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfenced></mml:mfenced><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math><tex-math id="Equ4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ L\left\{ {\left. {f^{(n)} (t)} \right\}} \right. = p^{n} F(p) - \sum\limits_{k = 1}^{n} {p^{n - i} f_{0 + }^{(i - 1)} } \;L\left\{ {\left. {f(t)} \right\}} \right. = F(p), $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="40747_2022_879_Article_Equ4.gif"/></alternatives></disp-formula><italic>f</italic>(<italic>t</italic>), <italic>f</italic>´(<italic>t</italic>),…,<italic>f</italic><sup>(<italic>n</italic>)</sup>(<italic>t</italic>) is the continuous originals in &lt;0+, <italic>∞</italic>&gt;<italic>p</italic>, <italic>t</italic> is the complex and real variables, <italic>L</italic> is the transform</p><p id="Par40">The <italic>f</italic>(<italic>t</italic>) derivatives are L-transformed to define a system of linear Eq. (<xref rid="Equ5" ref-type="disp-formula">5</xref>), where the transform <italic>F</italic>(<italic>p</italic>) is expressed with the imaginary conjugate <italic>p</italic> and separated in pure rational form (<xref rid="Equ3" ref-type="disp-formula">3</xref>).<disp-formula id="Equ5"><label>5</label><alternatives><mml:math display="block" id="Equ5_Math"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>B</mml:mi><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mfrac><mml:msub><mml:mi>A</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ F(p) = \frac{P(p)}{{Q(p)}} = \frac{Bp + C}{{p^{2} + ap + b}} = \sum\limits_{k = 1}^{n} {\frac{{A_{k} }}{{p - \alpha_{k} }}} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="40747_2022_879_Article_Equ5.gif"/></alternatives></disp-formula><italic>B</italic>, <italic>C</italic>, <italic>A</italic><sub><italic>k</italic></sub> is the coefficients of elementary fractions, <italic>a</italic>,<italic>b</italic> is the polynom. parameters<italic>α</italic><sub>1,</sub><italic>α</italic><sub>2,</sub>…, <italic>α</italic><sub><italic>k</italic></sub> is the simple real roots.</p><p id="Par41">The resulting ratios correspond to the L-transforms of the original <italic>f(t</italic>)<italic>,</italic> to which can be applied the inverse L-operation of OC (<xref rid="Equ6" ref-type="disp-formula">6</xref>) to calculate the <italic>f(t</italic>) function defined by the initial PDE (3).<disp-formula id="Equ6"><label>6</label><alternatives><mml:math display="block" id="Equ6_Math"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>·</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd><mml:mtd><mml:mrow/></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="Equ6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ F(p) = \frac{P(p)}{{Q(p)}} = \sum\limits_{k = 1}^{n} {\frac{{P(\alpha_{k} )}}{{Q_{k} \left( {\alpha_{k} } \right)}}} \cdot \frac{1}{{p - \alpha_{k} }}\begin{array}{*{20}c} {} &amp; {} &amp; {} \\ \end{array} f(t) = \sum\limits_{k = 1}^{n} {\frac{{P\left( {\alpha_{k} } \right)}}{{Q_{k} \left( {\alpha_{k} } \right)}}} e^{{\alpha_{k} \cdot t}} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="40747_2022_879_Article_Equ6.gif"/></alternatives></disp-formula><italic>P</italic>(<italic>p</italic>), <italic>Q</italic>(<italic>p</italic>) is the multinomials of degree <italic>s</italic>−1, <italic>s</italic>, <italic>α</italic><sub>1</sub>,<italic>α</italic><sub>2</sub>,…, <italic>α</italic><sub><italic>n</italic></sub> is the simple real roots of <italic>Q</italic>(<italic>p</italic>)</p><p id="Par42">If <italic>f</italic>(<italic>t</italic>) is supposed to be a circulator function, its derivatives are converted into the sine and cosine L transform and the original calculated by the reverse inverse L-operation (<xref rid="Equ7" ref-type="disp-formula">7</xref>). This expanded definition can apply the amplitudes and phases of periodical data variables to obtain the node function L-images, i.e. convert sub-PDEs into periodic functions.<disp-formula id="Equ7"><label>7</label><alternatives><mml:math display="block" id="Equ7_Math"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>r</mml:mi></mml:munderover><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mi>Q</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>s</mml:mi></mml:munderover><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:mo>cos</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:mo>sin</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equ7_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ f(t) = \sum\limits_{k = 1}^{r} {\frac{{P(\alpha_{k} )}}{{Q^{\prime}(\alpha_{k} )}}} e^{{\alpha_{k} \cdot t}} + 2\sum\limits_{k = 1}^{s} {e^{{\beta_{k} \cdot t}} } \left( {a_{k} \cdot \cos \gamma_{k} t - b_{k} \cdot \sin \gamma_{k} t} \right) $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="40747_2022_879_Article_Equ7.gif"/></alternatives></disp-formula></p><p id="Par43">The inverse OC L-transform recovery operation is used for the reduced rational (<xref rid="Equ6" ref-type="disp-formula">6</xref>) or periodic Eq. (<xref rid="Equ7" ref-type="disp-formula">7</xref>), obtained by the first PDE-conversion. The sum of 2-variable <italic>u</italic><sub><italic>k</italic></sub> originals, formed in D-PNN nodes (Fig. <xref rid="Fig4" ref-type="fig">4</xref>), represents a final PDE-model of the n-variable <italic>u</italic> function (<xref rid="Equ3" ref-type="disp-formula">3</xref>).<fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><p>D-PNN blocks form and solve sub-PDEs in the nodes to compose the component model</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig4_HTML.png" id="MO4"/></fig></p><p id="Par44">The expression of imaginary Euler conjugate numbers <italic>c</italic> (<xref rid="Equ8" ref-type="disp-formula">8</xref>) is related to the OC definitions for the original <italic>f(t</italic>) (<xref rid="Equ6" ref-type="disp-formula">6</xref>). Radius <italic>r</italic> (amplitude) can replace the rational component while phase (frequency) <italic>φ</italic> = arctg<italic>(x</italic><sub><italic>2</italic></sub><italic>/x</italic><sub><italic>1</italic></sub>) of variables <italic>x</italic><sub>1</sub><italic>,</italic> × 2 can replace the inverse L transform for <italic>F</italic>(<italic>p</italic>).<disp-formula id="Equ8"><label>8</label><alternatives><mml:math display="block" id="Equ8_Math"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:munder accentunder="true"><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⏟</mml:mo></mml:munder><mml:mtext>Re</mml:mtext></mml:munder><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:mo>·</mml:mo><mml:munder><mml:munder accentunder="true"><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⏟</mml:mo></mml:munder><mml:mtext>Im</mml:mtext></mml:munder><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt><mml:mo>·</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>·</mml:mo><mml:mo>arctan</mml:mo><mml:mfenced close=")" open="("><mml:mfrac><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfrac></mml:mfenced></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mo>·</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>·</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mo>·</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mo>cos</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:mo>·</mml:mo><mml:mo>sin</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:mrow></mml:math><tex-math id="Equ8_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ c = \underbrace {{x_{1} }}_{{\text{Re}}} + i \cdot \underbrace {{x_{2} }}_{{\text{Im}}} = \sqrt {x_{1}^{2} + x_{2}^{2} } \cdot e^{{i \cdot \arctan \left( {\frac{{x_{2} }}{{x_{1} }}} \right)}} = r \cdot e^{i \cdot \phi } = r \cdot \left( {\cos \phi + i \cdot \sin \phi } \right). $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="40747_2022_879_Article_Equ8.gif"/></alternatives></disp-formula></p><p id="Par45">D-PNN main characteristics, allowing (D-PNN application C++ parametric software with Solar, Wind &amp; Meteo-data sets: <ext-link xlink:href="https://drive.google.com/drive/folders/1Q9m09bZ6LlQ2Up2_oJ0vDQpceYvXROrN" ext-link-type="uri">https://drive.google.com/drive/folders/1Q9m09bZ6LlQ2Up2_oJ0vDQpceYvXROrN</ext-link>):<list list-type="bullet"><list-item><p id="Par46">Splitting the n-variable general-order PDE into a defined set of reduced PDE converts</p></list-item><list-item><p id="Par47">Developing PNN structures by inserting node by node into the back-computing structure</p></list-item><list-item><p id="Par48">Producing PDE-components in each added PNN node to be involved in the sum model</p></list-item><list-item><p id="Par49">Several types of PDE conversions using OC base functions to define its computing frame</p></list-item><list-item><p id="Par50">Using L-transforms of PDE-derivatives and the inverse OC recovering of node originals</p></list-item><list-item><p id="Par51">(Re)selecting dynamically optimal 2-inputs to expand the parallel PDE-component model</p></list-item><list-item><p id="Par52">Non-downsizing significantly data dimensionality leading to an over-reduction in models</p></list-item><list-item><p id="Par53">A great variety in selecting the optimal combination of model components</p></list-item></list></p></sec><sec id="Sec6"><title>Deep learning—Matlab Toolbox</title><p id="Par54">Deep Learning is a computing method that learns patterns directly from data samples, utilizing its specific architecture designed in several types of structural layers, not relying on a predefined particular modeling approach. The Matlab Deep Learning Toolbox (DLT) provides a framework for the design and implementation of deep neural network algorithms. It uses the Long-Short-Term Memory (LSTM) network in sequence-to-sequence regression (Matlab—Deep Learning Toolbox (DLT) for sequence-to-sequence regression <ext-link xlink:href="http://www.mathworks.com/help/deeplearning/ug/sequence-to-sequence-regression-using-deep-learning.html" ext-link-type="uri">www.mathworks.com/help/deeplearning/ug/sequence-to-sequence-regression-using-deep-learning.html</ext-link>), usually consisting of these multilevel parts:<list list-type="bullet"><list-item><p id="Par55">Sequence layer of inputs.</p></list-item><list-item><p id="Par56">LSTM.</p></list-item><list-item><p id="Par57">Fully-connected layer.</p></list-item><list-item><p id="Par58">Drop-out layer.</p></list-item><list-item><p id="Par59">Fully-connected layer.</p></list-item><list-item><p id="Par60">Regression layer—output.</p></list-item></list></p><p id="Par61">The key part of the LSTM regression is mostly the LSTM layer. The sequence layer feeds a succession of input time series into the LSTM structure. The LSTM layer is used to learn long-term data relations in time steps of sequenced series. The LSTM blocks combine their current state (<italic>c</italic><sub><italic>t</italic>−1</sub><italic>, h</italic><sub><italic>t</italic>−1</sub>) with the next time <italic>X</italic> sequenced data to calculate the <italic>h</italic><sub><italic>t</italic></sub> output (that is, hidden inner state) and an update of the cell <italic>c</italic><sub><italic>t</italic></sub> state in a time <italic>t</italic> (Fig. <xref rid="Fig5" ref-type="fig">5</xref>). Cells contain information from the previous time <italic>t</italic> − 1, before the next update. This means that the information is represented by the hidden <italic>h</italic><sub><italic>t</italic></sub> state (i.e. output) and the cell <italic>c</italic><sub><italic>t</italic></sub> state. The dropout layer can set some random inputs to the zero values using a probability function to prevent model overfitting. The gradient of a function loss is calculated in consideration of the pre-assessed minimal batch length of sub-set data in training to optimize the updating of weights.<fig id="Fig5"><label>Fig. 5</label><caption xml:lang="en"><p>The flow of input time series X with C features (channels) of length S in the LSTM layer</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig5_HTML.png" id="MO5"/></fig></p><p id="Par62">DLT uses LSTM networks to learn useful pattern representations from input–output data. Its networks integrate multiple nonlinear processing layers using simple operating and computing elements with connections inspired by biological nervous systems. DLT architectures consist mainly of a hand-defined many-layer replicate structure, including convolution and other layer types.</p></sec><sec id="Sec7"><title>Statistics and machine learning—Matlab toolbox</title><p id="Par63">The Matlab Statistics and Machine Learning Regression Tool-Box (SMLT) was used in the comparative evaluation of the statistical WS and GR forecasting results. SMLT includes and aggregates several efficient conventional, soft-computing, and stochastic-tree AI methods (Matlab—Statistics and Machine Learning toolbox (SMLT) for regression <ext-link xlink:href="http://www.mathworks.com/help/stats/choose-regression-model-options.html" ext-link-type="uri">www.mathworks.com/help/stats/choose-regression-model-options.html</ext-link>):<list list-type="bullet"><list-item><p id="Par64">Linear regression (interaction, stepwise, robust)—uses linear equations with the parameters, which are easily adaptable to be interpreted in the most simplified processing form.</p></list-item><list-item><p id="Par65">Regression Tree (fine, medium, coarse)—uses the binary 2-branch form, which is easily to interpret, fast in fitting, and adaptation. Input data are processed step by step from the initializing root in a particular way to the terminal leaf considering the recognized states of predictors. Data are checked in all binary nodes to determine which of the two ways is applied as the computed way. The terminal leaf values correspond to the calculated output model response. Fine trees usually include many node leaves. These detail models may be less accurate in testing for an unlearned data validation set and fall into overfitting with essentially higher errors than those obtained in the training. Coarse trees use mostly a small amount of larger leaves, which usually do not yield a higher training accuracy, but they are more robust in applying to unseen data in the testing (forecasting).</p></list-item><list-item><p id="Par66">Support Vector Machine (SVM)—uses the linear, cubic, square, Gaussian, or Radial Basis Function (RBF) of a kernel form to define the specific transformation of data, which is initially applied before starting the learning process. The linear ε-vector training can be applied to eliminate or ignore output errors that are outside the interval defined by ε values (which are assumed to be zero). The support vectors are the computing output intervals whose errors are larger than the defined ε range.</p></list-item><list-item><p id="Par67">Gaussian Process Regression (GPR) uses a probability data distribution in a space of definition to calculate the output where base functions (e.g. linear, constant, zero, etc.) supply the prior mean model. Kernel functions (rational, exponential, squared exponential, quadratic, or matern) are applied to define response relations in the model output, according to a distance space vector for the predictors.</p></list-item><list-item><p id="Par68">Ensemble-Boosted/Bagged Trees (EBT, EBoosT / EBaggT) – aggregate outputs of several week-learner tree-based models. The least squares principles of bagging, boosting, and bootstrapping can be applied to compose the final output ensemble using a probabilistic approach based on training data statistics (see Sec.2).</p></list-item></list></p><p id="Par69">Principal component analysis (PCA), a built-in SMLT tool, did not produce better WS and GR average forecasts by processing the selected data inputs. The final forecast models, applied to the last available data, were detected from the best approximation results obtained in the testing interval hours.</p></sec><sec id="Sec8"><title>Statistics data experiments in day-ahead wind &amp; solar AI forecasting</title><p id="Par70">The 2-level ground station data sets (described in Section “<xref rid="Sec3" ref-type="sec">Wind &amp; solar day-ahead forecasting—methodology and data acquisition</xref>”) were used in the development and verification of 2 different AI forecast models, using the proposed time-initialization and training-evaluation schemes (Figs. <xref rid="Fig1" ref-type="fig">1</xref> and <xref rid="Fig2" ref-type="fig">2</xref>). If the pattern similarity (1) of the data records, included in the initial detection interval (Fig. <xref rid="Fig1" ref-type="fig">1</xref>), to those of the reference last time is lower than a defined correlation limit (0.5), then their samples are excluded from the training process. An extension in the initializing data range may be considered (in searching for other day points) in the event of insufficiency (or impracticability) in the applicable learning samples. D-PNN automatically searches for the best input couples by trying to include initially scored components (predetermined separately in each layer list) in the expansion of PDE-structural models, node by node. No hand-made parameter preset or architecture design (as used by DLT) was needed in the self-organizing and model-composing learning process of D-PNN and SMLT. After model complement testing and verification (in NWP or additional data comparison, if available), it can be applied in a definite 24 h computing of all-day forecast output series. This one-flush processing essentially reduces computational complexity, since the same prediction model is applied sequentially to the last available day input series at each reference time. The optimal model is finally chosen by considering its test error minima (in all applied AI strategies), resulting from random or user-adaptive start-ups.</p><p id="Par71">The demo graphs in Figs. <xref rid="Fig6" ref-type="fig">6</xref> and <xref rid="Fig7" ref-type="fig">7</xref> reflect the desired and prediction series of 0–24 h wind speed and 8–16 h irradiance in the 1st and 2nd examination days, produced by the day-ahead component D-PNN and comparison DLT and SMLT models in the 10-day monitor autumn–winter season.<fig id="Fig6"><label>Fig. 6</label><caption xml:lang="en"><p>17.12.2017, Milešovka, Wind speed day-ahead prediction RMSE: D-PNN = 1.516, DLT = 1.987, SMLT (GPR matern) = 1.490 [m/s]</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig6_HTML.png" id="MO6"/></fig><fig id="Fig7"><label>Fig. 7</label><caption xml:lang="en"><p>16.12.2017, Kopisty, Global radiation day-ahead prediction RMSE: D-PNN = 21.46, DLT = 27.51, SMLT (EBoosT) = 20.42 [W/m<sup>2</sup>]</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig7_HTML.png" id="MO7"/></fig></p><p id="Par72">All the AI compared models mostly properly approximate ramping series of the target GR or WS quantity in unsettled weather (Figs<xref rid="Fig7" ref-type="fig">.7</xref> and <xref rid="Fig6" ref-type="fig">6</xref>), although the PDE modules allow D-PNN to better adapt its combinatorial solutions to sudden variances in pattern dynamic next-time progress. Characteristics of the following-day patterns remain unchanged and similar to those in the day illustrative graphs with a significant exhibit change coming through 21–22 December and the following days (Figs. <xref rid="Fig1" ref-type="fig">1</xref> and <xref rid="Fig2" ref-type="fig">2</xref>) in a gusty and unsettled cloudiness period. The solar radiation series were normalized using the CSI ratio factor to eliminate day-period alterations related to the actual solar sky-horizon. CSI nominal series are calculated with respect to the ideal maximal ‘clear sky’ GR assumption values, allowing forecasting regardless of the day season. The target GR output is recovered from the nominal CSI forecast series [<xref ref-type="bibr" rid="CR20">20</xref>]. Periodical or angular data quantities (such as GR, temperature, humidity, or wind azimuth) are automatically recognized and related to the time or amplitude represented by the L-conversion functions (sine, cosine) of the cycle (7) in the definition of D-PNN models [<xref ref-type="bibr" rid="CR21">21</xref>]. All SMLT-evaluated methods are self-optimizing (as D-PNN) and do not require any hand design in architecture or training settings (as DLT does).</p></sec></sec><sec id="Sec9"><title>Evaluation of day-ahead wind &amp; solar forecasting using AI</title><p id="Par73">Figures <xref rid="Fig8" ref-type="fig">8</xref> and <xref rid="Fig9" ref-type="fig">9</xref> resume avgage daily errors of the compared neuro- and soft-computing models in wind and solar parameter AI statistical day-ahead forecasting in the 10-day evaluating autumn–winter season.<fig id="Fig8"><label>Fig. 8</label><caption xml:lang="en"><p>Milešovka, 10-day Wind speed day-avg. prediction RMSE: D-PNN = 2.038, DLT = 3.158, SMLT (GPR vs. EBT 7:3) = 2.571 [m/s]</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig8_HTML.png" id="MO8"/></fig><fig id="Fig9"><label>Fig. 9</label><caption xml:lang="en"><p>Kopisty, 10-day Global radiation day-avg. prediction RMSE: D-PNN = 37.68, DLT = 40.30, SMLT (GPR vs. EBT 5:5) = 38.59 [W/m<sup>2</sup>]</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig9_HTML.png" id="MO9"/></fig></p><p id="Par74">Notable changes in wind data patterns (a growth in gusts) beginning on 21 December (Fig. <xref rid="Fig1" ref-type="fig">1</xref>) effect an accumulative increase in the model errors (Fig. <xref rid="Fig8" ref-type="fig">8</xref>). An evident drop in GR on 21 and its analogous characteristic turnover on 22 December (Fig. <xref rid="Fig2" ref-type="fig">2</xref>) results in larger prediction errors of the compared AI models in the same and subsequent days (Fig. <xref rid="Fig9" ref-type="fig">9</xref>). Some unexpected forecast errors can be eliminated by an extensive sequence selection search for applicable training records (1) in a larger monthly database (in several years). The results of statistical models are determined primarily by the optimal pre-detection of data samples in training and testing sets [<xref ref-type="bibr" rid="CR18">18</xref>]. Figures <xref rid="Fig10" ref-type="fig">10</xref> and <xref rid="Fig11" ref-type="fig">11</xref> compare the Pearson correlation determination <italic>R</italic><sup>2</sup> coefficient of the single-day D-PNN, DLT and SMLT models applied throughout statistical forecasting in the 10-day experiment period. The significant decrease in the values of the <italic>R</italic><sup>2</sup> coefficients of SMLT implies an undesirable WS output averaging of the probabilistic GPR and distribution EBT models on some days in the 24-h prediction horizon (Fig. <xref rid="Fig6" ref-type="fig">6</xref>). The results of the compared AI models are more or less the same in all 10-day GR and partly avg. WS 24-h forecast, with only slight variations in daily accuracy. More elaborate robust D-PNN modular solutions partly outperform DLT and SMLT in WS and also slightly in GR. Each of the compared computing approaches gets a better day-ahead approximation in the cycle GR alterations than chaotic WS fluctuations. More leveled spatial observational points in data acquisition can naturally contribute to more reliable AI day-ahead forecating in early statistics learning of unexpected change variations in multi-layer data correlations.<fig id="Fig10"><label>Fig. 10</label><caption xml:lang="en"><p>Milešovka, 10-day Wind speed day-avg. prediction Correlation determin. coeff.: D-PNN = 0.145, DLT = 0.120, SMLT = 0.062</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig10_HTML.png" id="MO10"/></fig><fig id="Fig11"><label>Fig. 11</label><caption xml:lang="en"><p>Kopisty, 10-day Global radiation day-avg. prediction Correlation determin. coeff.: D-PNN = 0.537, DLT = 0.432, SMLT = 0.506</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig11_HTML.png" id="MO11"/></fig></p><p id="Par75">Figures <xref rid="Fig12" ref-type="fig">12</xref> and <xref rid="Fig13" ref-type="fig">13</xref> indicate the first identified modeling initial day time used in the starting search for similarity distance reinterpretation of applicable learning record sequences.<fig id="Fig12"><label>Fig. 12</label><caption xml:lang="en"><p>The predetermined initial numbers of learning day-data sequences used in the pattern sample similarity selection for wind speed model development</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig12_HTML.png" id="MO12"/></fig><fig id="Fig13"><label>Fig. 13</label><caption xml:lang="en"><p>The predetermined initial numbers of learning day-data sequences used in the pattern sample similarity selection for solar radiation model development</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40747_2022_879_Fig13_HTML.png" id="MO13"/></fig></p><p id="Par76">The forecast results of all applied AI techniques are mostly correlated, which denotes analogies in the forecasting methodology and model development. The PDE-modular approach of D-PNN obtains better accuracy in each mean error evaluation (Figs. <xref rid="Fig10" ref-type="fig">10</xref> and <xref rid="Fig11" ref-type="fig">11</xref>); however, SMLT and DLT outperform it slightly on some days. All the model-type day-initialization time is more or less analogous (Figs. <xref rid="Fig12" ref-type="fig">12</xref> and <xref rid="Fig13" ref-type="fig">13</xref>) except DLT in some unsettled day patterns, including an overall extension/reduction in the same consequent day interval, which implies a second significant time point in weather over-change characteristics. DLT in general requires more precise estimations in training periods (Sec.3), compared to the more robust and resistant SMLT-probabilistic and PDE-modular form, to supply reliable 24-h forecasts. The D-PNN limits rest in a large search space in the combinatorial component alternatives (explosion), which allows, on the other hand, a great variety in modular component production to represent system uncertainty. The D-PNN error oscillations, resulting from unexpected pattern variances, are lower than the DLT or SMLT ones (Figs. <xref rid="Fig8" ref-type="fig">8</xref> and <xref rid="Fig9" ref-type="fig">9</xref>), as the L-transformed data contribute to its more stable model output. The most successful SMLT methods (reaching test error minima) were found to be GPR and EBT using the probabilistic and distribution statistics approach (Section “<xref rid="Sec2" ref-type="sec">State-of-the-art in wind and solar prediction</xref>”). The ratios of the final models were 7: 3 pro GPR chosen in the WS and 5: 5 in the GR forecasting. The stochastic GPR and EBT ensemble computing bases of SMLT ([E] Matlab—Statistics and Machine Learning toolbox (SMLT) for regression <ext-link xlink:href="http://www.mathworks.com/help/stats/choose-regression-model-options.html" ext-link-type="uri">www.mathworks.com/help/stats/choose-regression-model-options.html</ext-link>) were approved to be very efficient in a fast and detailed approximation to GR real-day cycles in denormalized CSI forecast series (Figs. <xref rid="Fig7" ref-type="fig">7</xref> and <xref rid="Fig9" ref-type="fig">9</xref>). Their WS prediction results are partly debased by undesirable averaging some interval time series in the computed output, evident in the low <italic>R</italic><sup>2</sup> correlation with target data (Fig. <xref rid="Fig10" ref-type="fig">10</xref>).</p></sec><sec id="Sec10" sec-type="discussion"><title>Discussion</title><p id="Par77">Sudden variances in training and prediction data patterns are mainly induced by irregular surface interactions in air flow parameters and chaotic instabilities. These unstable oscillating states can result in uncertain practicability of the training data with respect to the 24 h model input delay (applied in forecasting) [<xref ref-type="bibr" rid="CR4">4</xref>]. The adequate approximation of ramping series is largely related to predetermined learning samples in similar weather patterns. Their unexpected short-term fluctuation (Fig. <xref rid="Fig6" ref-type="fig">6</xref>) inducing rapid abrupt alterations in WS or GR results mainly in prediction troubles and model failures. The optimization extraction of training records (one by one) is determined by the chosen processing strategy in pattern similarity formulated by a correlation distance in the input space of n-dimensionality (1). A more complex or hybrid measure can improve the selective search for applicable training data. Statistical predictions can be wildly flawed on days of overnight frontal breaks in weather. The WS or GR patterns in the forecast time are totally uncorrelated with those in the test hours. A fixed threshold in test accuracy can be estimated in relation to previous misfires in day-ahead computing model forecasts or comparative NWP data. If AI models cannot be statistically validated in a comparative error limit or in an NWP test, a series of transformed NWP cloud cover or wind parameters can provide the forecast [<xref ref-type="bibr" rid="CR22">22</xref>]. Previous break over-changes in patterns can be examined and detected in a large-scale database in a point-by-point assessment in several initialization time ranges, applicable in daily training (Fig. <xref rid="Fig10" ref-type="fig">10</xref>). Additional input data that are delayed throughout the day cycle can be used, analogously to humidity [<xref ref-type="bibr" rid="CR23">23</xref>] or electrical load [<xref ref-type="bibr" rid="CR24">24</xref>].</p></sec><sec id="Sec11"><title>Limitations and future scope of research</title><p id="Par78">A more consistent approach in detection pattern similarity can be applied, involving all the determine time series (6–8 h.) in computing a comparative mean measure for each individual training sample according to CSI and wind data. Additional normalized periodical quantities (temperature, relative humidity, etc.) can be used in this all-time re-evaluation process in future experiments. The initial pre-assessment of applicable data intervals is necessary, as statistical AI modeling is unable to represent (comprise, nowadays) all the weather dynamics in a global (earth) scale. Thus, a precise determination of optimal learning sequences is necessary in larger historical sets, and this procedure would naturally require extra processing time. On the other hand, model development is simplified in a sequential process. Validating pattern similarity between training/testing samples and NWP data can also contribute to optimized sample extraction and model verification, vital in frontal break changeovers. Although NWP tabular data records ([B] ‘Aladin’ regional meso-scale NWP-model produced every 6 h (‘Meteograms’ are in Czech language) <ext-link xlink:href="http://www.chmi.cz/files/portal/docs/meteo/ov/aladin/results/public/meteogramy/mhtml/m.html" ext-link-type="uri">www.chmi.cz/files/portal/docs/meteo/ov/aladin/results/public/meteogramy/mhtml/m.html</ext-link>) are not available, contrary to accessible free observational archives (Meteorological observational stations of Czech Academy of Sciences in Milesovka and Kopisty <ext-link xlink:href="http://www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/meteorological-observatory-milesovka/milesovka-current-weather" ext-link-type="uri">www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/meteorological-observatory-milesovka/milesovka-current-weather</ext-link>, <ext-link xlink:href="http://www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/kopisty-weather-station/actual-weather" ext-link-type="uri">www.ufa.cas.cz/en/institute-structure/department-of-meteorology/observatories/kopisty-weather-station/actual-weather</ext-link>). The D-PNN computing time is naturally higher, comprising a few minutes as compared to the DLT second-order model adaptation (but using its fixed-layer design with the entire input vector). However, D-PNN performs automatic day input/PDE module selection in its stepwise model optimization, which was shown to be efficient in representing weather dynamics and uncertainties. Extension of the D-PNN input vector is limited to dozens of variables (owing to the higher computing costs at this time). Processing and extracting time-lagged series would naturally improve the model performance. Component heuristics and model optimization algorithms can be further improved (in future work) to approach the standard soft-computing time.</p><p id="Par79">Node-by-node development using the D-PNN binary back-selective architecture in the stepwise expanding additive model allows incremental learning. This means inserting new or removing useless PDE-components in the sum model re-adjusting according to an up-dated training set without resetting the present structure and model combination form. New assigned day samples can be additionally learned to readapt the same D-PNN model for each new situation in the next partial training step, to achieve by degrees greater robustness and stability for unknown prediction patterns and parameter uncertain variances. The complexity of PDE models is gradually increased and refined for new knowledge, in addition to retaining previously learned skills [<xref ref-type="bibr" rid="CR25">25</xref>].</p></sec><sec id="Sec12" sec-type="conclusions"><title>Conclusions</title><p id="Par80">The effective all-day schemes in statistics GR and WS forecasting were implemented with the recent neuro- and soft-computing compared approaches. The advantages of all-day one-sequence procedures are apparent in their processing efficiency and computation time reduction, using single autonomous AI models that provide the complete day output series in the same fixed time horizon. This day-ahead iterative approach allows operational on-time forecasting with an acceptable reliability, the results of which are comparable to the intra-hourly or NWP-model results in most of the day-conducted experiments. The early-produced and transformed prognoses of GR or WS in the evening on a day horizon are helpful in planning and using the RE supply. Advantages of the physical NWP simulations are apparent in break changeovers in weather, where AI models with the 24-h input delay can be out-dated; however, their data are usually charged. Single-time AI models can correct the prognoses of more effective all-day forecasting schemes on the reduced horizon of a few hours in these doubtful situations, using an early warning notification based on available NWP pattern analysis. Inconsistent output estimations of AI models in subsequent hours may denote their incompetence in the applicable statistical prediction and alternative usage of NWP. Parametric modeling C++ software, historical solar, wind and weather sets are available free in data repositories to allow further comparative reinterpretation of the forecast procedure and model performance ([C] D-PNN application C++ parametric software with Solar, Wind &amp; Meteo-data sets: <ext-link xlink:href="https://drive.google.com/drive/folders/1ZAw8KcvDEDM-i7ifVe_hDoS35nI64-Fh?usp=sharing" ext-link-type="uri">https://drive.google.com/drive/folders/1ZAw8KcvDEDM-i7ifVe_hDoS35nI64-Fh?usp=sharing</ext-link>).</p></sec></body><back><ack><title>Acknowledgements</title><p>The
work was supported by
SGS, VSB-Technical
University of Ostrava,
Czech Republic, under
the grant `Parallel
processing of Big Data
IX' [No.\ SGS2022/12].
No conflict of interest or
ethical issues. Informed
consent and ethical
approval. Compliance
with Ethical Standards.
100% Authorship sole
contribution.</p></ack><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>W</given-names></name><name><surname>Xia</surname><given-names>X</given-names></name></person-group><article-title xml:lang="en">A concise overview on solar resource assessment and forecasting</article-title><source>Adv Atmos Sci</source><year>2022</year><volume>40</volume><fpage>1</fpage><lpage>12</lpage></mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Zou</surname><given-names>R</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name></person-group><article-title xml:lang="en">A review of wind speed and wind power forecasting with deep neural networks</article-title><source>Appl Energy</source><year>2021</year><volume>304</volume><fpage>1</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1016/j.apenergy.2021.117766</pub-id></mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bazionis</surname><given-names>IK</given-names></name><name><surname>Georgilakis</surname><given-names>PS</given-names></name></person-group><article-title xml:lang="en">Review of deterministic and probabilistic wind power forecasting: models, methods, and future research</article-title><source>Electricity</source><year>2021</year><volume>2</volume><fpage>13</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.3390/electricity2010002</pub-id></mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lorenz</surname><given-names>E</given-names></name><name><surname>Kühnert</surname><given-names>J</given-names></name><name><surname>Heinemann</surname><given-names>D</given-names></name><name><surname>Pagh Nielsen</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Comparison of global horizontal irradiance forecasts based on numerical weather prediction models with different spatio-temporal resolutions</article-title><source>Progress Photovolt</source><year>2016</year><volume>24</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1002/pip.2799</pub-id></mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>P</given-names></name><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Haiyan</surname><given-names>Lu</given-names></name></person-group><article-title xml:lang="en">Modeling for chaotic time series based on linear and nonlinear framework: application to wind speed forecasting</article-title><source>Energy</source><year>2019</year><volume>173</volume><fpage>468</fpage><lpage>482</lpage><pub-id pub-id-type="doi">10.1016/j.energy.2019.02.080</pub-id></mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meka</surname><given-names>R</given-names></name><name><surname>Alaeddini</surname><given-names>A</given-names></name><name><surname>Bhaganagar</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">A robust deep learning framework for short-term wind power forecast of a full-scale wind farm using atmospheric variables</article-title><source>Energy</source><year>2021</year><volume>221</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.energy.2021.119759</pub-id></mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Qin</surname><given-names>H</given-names></name><name><surname>Liua</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Yao</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Long short-term memory network based on neighborhood gates for processing complex causality in wind speed prediction</article-title><source>Energy Convers Manag</source><year>2019</year><volume>192</volume><fpage>37</fpage><lpage>51</lpage><pub-id pub-id-type="doi">10.1016/j.enconman.2019.04.006</pub-id></mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qian</surname><given-names>Z</given-names></name><name><surname>Pei</surname><given-names>Y</given-names></name><name><surname>Zareipour</surname><given-names>H</given-names></name><name><surname>Chene</surname><given-names>N</given-names></name></person-group><article-title xml:lang="en">A review and discussion of decomposition based hybrid models for wind energy forecasting applications</article-title><source>Appl Energy</source><year>2019</year><volume>235</volume><fpage>939</fpage><lpage>953</lpage><pub-id pub-id-type="doi">10.1016/j.apenergy.2018.10.080</pub-id></mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santhosh</surname><given-names>M</given-names></name><name><surname>Venkaiah</surname><given-names>C</given-names></name><name><surname>Vinod Kumar</surname><given-names>DM</given-names></name></person-group><article-title xml:lang="en">Ensemble empirical mode decomposition based adaptive wavelet neural network method for wind speed prediction</article-title><source>Energy Convers Manag</source><year>2018</year><volume>168</volume><fpage>482</fpage><lpage>493</lpage><pub-id pub-id-type="doi">10.1016/j.enconman.2018.04.099</pub-id></mixed-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Lv</surname><given-names>X</given-names></name><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Wu</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Deterministic wind energy forecasting: a review of intelligent predictors and auxiliary methods</article-title><source>Energy Convers Manag</source><year>2019</year><volume>195</volume><fpage>328</fpage><lpage>345</lpage><pub-id pub-id-type="doi">10.1016/j.enconman.2019.05.020</pub-id></mixed-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>M</given-names></name><name><surname>Shi</surname><given-names>C</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Day-ahead wind power forecasting based on the clustering of equivalent power curves</article-title><source>Energy</source><year>2021</year><volume>218</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1016/j.energy.2020.119515</pub-id></mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanifi</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Lin</surname><given-names>Zi</given-names></name><name><surname>Lotfian</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">A critical review of wind power forecasting methods—past, present and future</article-title><source>Energies</source><year>2020</year><volume>13</volume><fpage>1</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.3390/en13153764</pub-id></mixed-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoolohan</surname><given-names>V</given-names></name><name><surname>Tomlin</surname><given-names>AS</given-names></name><name><surname>Cockerill</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">Improved near surface wind speed predictions using gaussian process regression combined with numerical weather predictions and observed meteorological data</article-title><source>Renew Energy</source><year>2018</year><volume>126</volume><fpage>1043</fpage><lpage>1054</lpage><pub-id pub-id-type="doi">10.1016/j.renene.2018.04.019</pub-id></mixed-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Mi</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Duan</surname><given-names>Z</given-names></name><name><surname>Yinan</surname><given-names>Xu</given-names></name></person-group><article-title xml:lang="en">Smart wind speed deep learning based multi-step forecasting model using singular spectrum analysis, convolutional gated recurrent unit network and support vector regression</article-title><source>Renew Energy</source><year>2019</year><volume>143</volume><fpage>842</fpage><lpage>854</lpage><pub-id pub-id-type="doi">10.1016/j.renene.2019.05.039</pub-id></mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez-Sopena</surname><given-names>JM</given-names></name><name><surname>Pakrashib</surname><given-names>V</given-names></name><name><surname>Ghosha</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">An overview of performance evaluation metrics for short-term statistical wind power forecasting</article-title><source>Renew Sustain Energy Rev</source><year>2021</year><volume>138</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1016/j.rser.2020.110515</pub-id></mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Afrasiabi</surname><given-names>M</given-names></name><name><surname>Mohammadi</surname><given-names>M</given-names></name><name><surname>Rastegar</surname><given-names>M</given-names></name><name><surname>Afrasiab</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Advanced deep learning approach for probabilistic wind speed forecasting</article-title><source>IEEE Trans Industr Inf</source><year>2021</year><volume>17</volume><fpage>720</fpage><lpage>727</lpage><pub-id pub-id-type="doi">10.1109/TII.2020.3004436</pub-id></mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gang Wang</surname><given-names>R</given-names></name><name><surname>Jia</surname><given-names>JL</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">A hybrid wind power forecasting approach based on bayesian model averaging and ensemble learning</article-title><source>Renew Energy</source><year>2020</year><volume>145</volume><fpage>2426</fpage><lpage>2434</lpage><pub-id pub-id-type="doi">10.1016/j.renene.2019.07.166</pub-id></mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zjavka</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Photo-voltaic power daily predictions using expanding pde sum models of polynomial networks based on operational calculus</article-title><source>Eng Appl Artif Intell</source><year>2020</year><volume>89</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1016/j.engappai.2019.103409</pub-id></mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zjavka</surname><given-names>L</given-names></name><name><surname>Mišák</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Direct wind power forecasting using a polynomial decomposition of the general differential equation</article-title><source>IEEE Trans Sustain Energy</source><year>2018</year><volume>9</volume><fpage>1529</fpage><lpage>1539</lpage><pub-id pub-id-type="doi">10.1109/TSTE.2018.2794515</pub-id></mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zjavka</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Photo-voltaic power intra-day and daily statistical predictions using sum models composed from l-transformed pde components in nodes of step by step developed polynomial neural networks</article-title><source>Electr Eng</source><year>2021</year><volume>103</volume><fpage>1183</fpage><lpage>1197</lpage><pub-id pub-id-type="doi">10.1007/s00202-020-01153-w</pub-id></mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zjavka</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Photovoltaic energy all-day and intra-day forecasting using node by node developed polynomial networks forming pde models based on the l-transformation</article-title><source>MDPI Energies</source><year>2021</year><volume>14</volume><fpage>1</fpage><lpage>14</lpage></mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zjavka</surname><given-names>L</given-names></name><name><surname>Krömer</surname><given-names>P</given-names></name><name><surname>Mišák</surname><given-names>S</given-names></name><name><surname>Snášel</surname><given-names>V</given-names></name></person-group><article-title xml:lang="en">Modeling the photovoltaic output power using the differential polynomial network and evolutional fuzzy rules</article-title><source>Math Model Anal</source><year>2017</year><volume>22</volume><fpage>78</fpage><lpage>94</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3596063</pub-id><pub-id pub-id-type="doi">10.3846/13926292.2017.1269025</pub-id></mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zjavka</surname><given-names>L</given-names></name><name><surname>Sokol</surname><given-names>Z</given-names></name></person-group><article-title xml:lang="en">Local improvements in numerical forecasts of relative humidity using polynomial solutions of general differential equations</article-title><source>Q J R Meteorol Soc</source><year>2018</year><volume>144</volume><fpage>780</fpage><lpage>791</lpage><pub-id pub-id-type="doi">10.1002/qj.3247</pub-id></mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zjavka</surname><given-names>L</given-names></name><name><surname>Snášel</surname><given-names>V</given-names></name></person-group><article-title xml:lang="en">Short-term power load forecasting with ordinary differential equation substitutions of polynomial networks</article-title><source>Electr Power Syst Res</source><year>2016</year><volume>137</volume><fpage>113</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.1016/j.epsr.2016.04.003</pub-id></mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zjavka</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Power quality multi-step predictions with the gradually increasing selected input parameters using machine-learning and regression</article-title><source>Sustain Energy Grids Netw</source><year>2021</year><volume>26</volume><fpage>2</fpage><lpage>10</lpage></mixed-citation></ref></ref-list></ref-list><notes notes-type="Misc"><title>Publisher's Note</title><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Complexity</facet-value><facet-value count="1">Computational Intelligence</facet-value><facet-value count="1">Data Structures and Information Theory</facet-value><facet-value count="1">Engineering</facet-value></facet><facet name="keyword"><facet-value count="1">
                     
              
            
                  </facet-value><facet-value count="1">Angular representation</facet-value><facet-value count="1">Inverse formulation</facet-value><facet-value count="1">Laplace transform</facet-value><facet-value count="1">Machine learning</facet-value><facet-value count="1">Operator calculus</facet-value><facet-value count="1">Partial differential equation</facet-value><facet-value count="1">PDE polynomial conversion</facet-value><facet-value count="1">Statistical modeling</facet-value></facet><facet name="pub"><facet-value count="1">Complex &amp; Intelligent Systems</facet-value></facet><facet name="year"><facet-value count="1">2022</facet-value></facet><facet name="country"><facet-value count="1">Czech Republic</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
