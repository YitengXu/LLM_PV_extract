<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1007/s00521-023-08459-3</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="review-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">521</journal-id><journal-id journal-id-type="doi">10.1007/521.1433-3058</journal-id><journal-title-group><journal-title>Neural Computing and Applications</journal-title><abbrev-journal-title abbrev-type="publisher">Neural Comput &amp; Applic</abbrev-journal-title></journal-title-group><issn pub-type="ppub">0941-0643</issn><issn pub-type="epub">1433-3058</issn><publisher><publisher-name>Springer London</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s00521-023-08459-3</article-id><article-id pub-id-type="manuscript">8459</article-id><article-id pub-id-type="doi">10.1007/s00521-023-08459-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Review</subject></subj-group></article-categories><title-group><article-title xml:lang="en">Data Augmentation techniques in time series domain: a survey and taxonomy</article-title></title-group><contrib-group><contrib contrib-type="author" id="Au1"><name><surname>Iglesias</surname><given-names>Guillermo</given-names></name><address><email>guillermo.iglesias@upm.es</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au2"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9480-922X</contrib-id><name><surname>Talavera</surname><given-names>Edgar</given-names></name><address><email>e.talavera@upm.es</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="corresp" rid="IDs00521023084593_cor2">b</xref></contrib><contrib contrib-type="author" id="Au3"><name><surname>González-Prieto</surname><given-names>Ángel</given-names></name><address><email>angelgonzalezprieto@ucm.es</email></address><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au4"><name><surname>Mozo</surname><given-names>Alberto</given-names></name><address><email>a.mozo@upm.es</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" id="Au5"><name><surname>Gómez-Canaval</surname><given-names>Sandra</given-names></name><address><email>sm.gomez@upm.es</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.5690.a</institution-id><institution-id institution-id-type="ISNI">0000 0001 2151 2978</institution-id><institution content-type="org-division">Departamento de Sistemas Informáticos</institution><institution content-type="org-name">Universidad Politécnica de Madrid</institution></institution-wrap><addr-line content-type="city">Madrid</addr-line><country country="ES">Spain</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.4795.f</institution-id><institution-id institution-id-type="ISNI">0000 0001 2157 7667</institution-id><institution content-type="org-division">Departamento de Álgebra, Geometría y Topología</institution><institution content-type="org-name">Universidad Complutense de Madrid</institution></institution-wrap><addr-line content-type="city">Madrid</addr-line><country country="ES">Spain</country></aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.462412.7</institution-id><institution-id institution-id-type="ISNI">0000 0004 0515 9053</institution-id><institution content-type="org-name">Instituto de Ciencias Matemáticas (CSIC-UAM-UCM-UC3M)</institution></institution-wrap><addr-line content-type="city">Madrid</addr-line><country country="ES">Spain</country></aff></contrib-group><author-notes><corresp id="IDs00521023084593_cor2"><label>b</label><email>e.talavera@upm.es</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>24</day><month>3</month><year>2023</year></pub-date><pub-date date-type="pub" publication-format="print"><month>5</month><year>2023</year></pub-date><volume>35</volume><issue seq="13">14</issue><issue-title>Special Issue on Deep Interpretation of Deep Learning: Prediction, Representation, Modeling and Utilization (pp.9947-10108 )/ Regular Papers (pp.10109-10716)</issue-title><fpage>10123</fpage><lpage>10145</lpage><history><date date-type="registration"><day>6</day><month>3</month><year>2023</year></date><date date-type="received"><day>6</day><month>8</month><year>2022</year></date><date date-type="accepted"><day>3</day><month>3</month><year>2023</year></date><date date-type="online"><day>24</day><month>3</month><year>2023</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2023</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">With the latest advances in deep learning-based generative models, it has not taken long to take advantage of their remarkable performance in the area of time series. Deep neural networks used to work with time series heavily depend on the size and consistency of the datasets used in training. These features are not usually abundant in the real world, where they are usually limited and often have constraints that must be guaranteed. Therefore, an effective way to increase the amount of data is by using data augmentation techniques, either by adding noise or permutations and by generating new synthetic data. This work systematically reviews the current state of the art in the area to provide an overview of all available algorithms and proposes a taxonomy of the most relevant research. The efficiency of the different variants will be evaluated as a central part of the process, as well as the different metrics to evaluate the performance and the main problems concerning each model will be analysed. The ultimate aim of this study is to provide a summary of the evolution and performance of areas that produce better results to guide future researchers in this field.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Deep learning</kwd><kwd>Time series</kwd><kwd>Data augmentation</kwd><kwd>Generative models</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution>Universidad Politécnica de Madrid</institution></institution-wrap></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Springer</meta-value></custom-meta><custom-meta><meta-name>volume-issue-count</meta-name><meta-value>36</meta-value></custom-meta><custom-meta><meta-name>issue-article-count</meta-name><meta-value>42</meta-value></custom-meta><custom-meta><meta-name>issue-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>issue-pricelist-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-holder</meta-name><meta-value>Springer-Verlag London Ltd., part of Springer Nature</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>No</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>ContentOnly</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>3</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>6</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>volume-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>ArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>ContentOnly</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>false</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/521_2023_Article_8459.pdf</meta-value></custom-meta><custom-meta><meta-name>pdf-type</meta-name><meta-value>Typeset</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>issue-online-date-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>issue-online-date-month</meta-name><meta-value>4</meta-value></custom-meta><custom-meta><meta-name>issue-online-date-day</meta-name><meta-value>24</meta-value></custom-meta><custom-meta><meta-name>issue-print-date-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>issue-print-date-month</meta-name><meta-value>4</meta-value></custom-meta><custom-meta><meta-name>issue-print-date-day</meta-name><meta-value>24</meta-value></custom-meta><custom-meta><meta-name>issue-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>ReviewPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Computer Science</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Artificial Intelligence</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Data Mining and Knowledge Discovery</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Probability and Statistics in Computer Science</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Computational Science and Engineering</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Image Processing and Computer Vision</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Computational Biology/Bioinformatics</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Computer Science</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">From the advent of deep learning (DL), a large part of research and the efforts of the scientific community have focused on solving and improving supervised training tasks. Supervised learning requires larger datasets, with a large number of different features, and these samples also need to be labelled in order to be feasible. With the latest models, it is becoming more difficult to obtain a suitable dataset, as the models require larger amounts of data to carry out the training. Usually, there exists a large number of public repositories from which to obtain suitable datasets for training in most application areas.</p><p id="Par3">However, in the time series domain, datasets are not that easy to access, where there are usually a number of privacy issues, and it is typically difficult to obtain large enough or balanced datasets. This often leads to a major problem when attempting to train one of these models on an incomplete, unbalanced or privacy-challenged dataset. Typically, these problems are addressed by pre-processing dataset techniques, such as subsampling, or in datasets that are not large enough, by data augmentation (DA) techniques [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>].</p><p id="Par4">Nevertheless, as soon as problems arise, technology evolves to address these boundaries. In recent years, artificial neural network (ANN) and their application to the field of DL have experienced a period of great advances. Although a multitude of models has contributed to this expansion, one of the most revolutionary that has been proposed appeared in 2014 by Ian Goodfellow [<xref ref-type="bibr" rid="CR3">3</xref>], with his  generative adversarial network (GAN).</p><p id="Par5">GAN is certainly not the earliest generative architecture ever introduced; already in 1987 Yann Lecun [<xref ref-type="bibr" rid="CR4">4</xref>] suggested in his thesis the autoencoder (AE) architectures, which were capable of generating data modifications received as input. But it is not until the incorporation of directed probabilistic models into AE architectures, also known as variational autoencoder (VAE) [<xref ref-type="bibr" rid="CR5">5</xref>], that the models begin to be presented as capable of generating synthesised data.</p><p id="Par6">Although these networks show impressive results, the capabilities of GAN have been shown to be far ahead, with impressive results applied to the field of imaging. Furthermore, this is not the unique area of application. Synthetic data generation is a powerful boost for synthesis of sensitive data, such as in the world of telecommunications.</p><p id="Par7">There are many time series applications where these algorithms have shown good results when improving the capabilities of the models by enlarging the datasets [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>]. In this area, time series data are especially sensitive due to aspects such as the low availability of high-quality datasets or privacy of the data [<xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR11">11</xref>].</p><p id="Par8">All these advances in the DL area allow us to synthetically increase the size of the datasets used in machine learning (ML) tasks. As mentioned above, the size of the dataset is a sensible characteristic that can affect the performance of the developed models.</p><p id="Par9">Regarding time series data, the availability of these huge datasets is even more complicated. There are other fields such as image processing or natural language processing (NLP) where data is much more available. But in the time series domain, it is more difficult to obtain these samples [<xref ref-type="bibr" rid="CR9">9</xref>–<xref ref-type="bibr" rid="CR11">11</xref>]. In this sense, DA arises as a technique to counter the scarcity of data.</p><p id="Par10">Another important factor is that time series data have particularities when it comes to processing them. Each dataset of time series is very different and needs special attention on how it is being augmented. Therefore, the proposed techniques for time series data must be analysed and discussed to better understand which technique can be used in which data.</p><p id="Par11">Thus, this paper aims to review all the existing technologies for DA, and to review the positive and negative aspects of each of them. This review can help researchers better understand how DA techniques can be applied to time series data to obtain better results when training machine learning (ML) models. We also expect that it will be useful to highlight the main differences between time series data and other domains.</p><sec id="Sec2"><title>Paper structure</title><p id="Par12">The rest of the paper is structured as follows: Sect. <xref rid="Sec3" ref-type="sec">2</xref>: “Problem Statement” presents the review in its context, providing a view of the importance of this work in the current context; Sect. <xref rid="Sec4" ref-type="sec">3</xref>: “Related Works” reviews previous similar works in this area, highlighting the differences between the previous ones and the present manuscript; Sect. <xref rid="Sec5" ref-type="sec">4</xref>: “Background” introduces a technical background of the performance of the techniques used to augment time series data; Sect. <xref rid="Sec9" ref-type="sec">5</xref>: “Evaluationmetrics” explains the problematic associated with how to evaluate the results of the new synthetic data; Sect. <xref rid="Sec13" ref-type="sec">6</xref>: “Data Augmentation algorithms review” presents the most important and current work in this area, reviewing the technical aspects of each approximation; Sect. <xref rid="Sec36" ref-type="sec">7</xref>: “Discussion” discusses the results and behaviour of each algorithm presented in the previous section and finally Sect. <xref rid="Sec40" ref-type="sec">8</xref>: “Conclusion” summarises the main conclusions of the research.</p></sec></sec><sec id="Sec3"><title>Problem statement</title><p id="Par13">This study addresses the current context of generating new data samples in temporal series datasets. The purpose of this paper is to focus on the most relevant and cutting-edge research in this area to provide an accurate and complete view of this field. This research tries to cover all the possible techniques used to enhance this type of data.</p><p id="Par14">In contrast to previous works, the aim of this survey is to provide a complete view of how different approaches to this problem have been developed. One of the main problems of reviewing a portion of the total techniques used in this area is that it does not fully explain how the current paradigm is structured. This is particularly critic when comparing different techniques, where it is desirable to have all the approximations in the area to fully understand the particularities of each one.</p><p id="Par15">In this sense, it is important to provide an updated and comprehensive study of the state of the art in this area. This manuscript is focused on the three most important pillars of current data augmentation in time series: traditional algorithms VAE and GAN.</p></sec><sec id="Sec4"><title>Related works</title><p id="Par16">In the latest times, several high-quality data augmentation review papers have been published [<xref ref-type="bibr" rid="CR12">12</xref>–<xref ref-type="bibr" rid="CR14">14</xref>]. However, most of them are focused on more popular areas such as imaging, video or natural language processing (NLP). Although these techniques focus on correcting the imbalance or incompleteness of the dataset, there are other areas of application where these problems are more common. The scarcity of valid datasets is not as clear in all areas of DL applications as in time series.</p><p id="Par17">In a first approach to the literature review, in [<xref ref-type="bibr" rid="CR15">15</xref>] an approximation of DA algorithms is made for use in neural network algorithms for time series classification. In the survey, they evaluated 12 methods to enhance time series data in 128 time series classification datasets with six different types of neural networks. Other recent studies focus more specifically on the use of GANs for data augmentation, as in [<xref ref-type="bibr" rid="CR16">16</xref>], where they analyse the taxonomy of discrete-variant GANs and continuous-variant GANs, in which GANs deal with discrete time series and continuous time series data. These surveys analyse DA in time series using neural networks, but lack a comparison of these algorithms with more traditional approaches.</p><p id="Par18">However, improving data sources to feed artificial intelligence (AI) algorithms is not limited to DA exclusively. Therefore, some studies have decided to take the path of building synthetic traffic generators to build their datasets almost from scratch; some examples focusing on this aspect are [<xref ref-type="bibr" rid="CR17">17</xref>–<xref ref-type="bibr" rid="CR19">19</xref>]. In this way, they are able to abstract from the dataset itself, which is only necessary to understand the distribution of the data. Furthermore, in [<xref ref-type="bibr" rid="CR20">20</xref>] they set out a further study of the repercussions of these technologies, highlighting one of the major advantages of generating synthesised data, the abstraction of privacy issues and the ease of obtaining datasets.</p><p id="Par19">Despite the possibilities presented by new technologies to improve the quality of time series datasets, there are no studies that compile all technologies, with a comprehensive comparison of them. Furthermore, to the authors’ knowledge, a survey that compiles all the different techniques is missing in the literature. This work’s goal is precisely to address this problem. It is crucial to develop a review that studies and compares all novel techniques proposed in time series domain. Previous works were centred on a specific model or approximation, with works such as [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>]. The objective of this survey is to have a wider view of the field, and to be able to further compare each technology and different approximations. With respect to previous work, a complete review is presented, extending the explanation of each algorithm’s performance, results, advantages and disadvantages.</p><p id="Par20">In addition, this field is in constant evolution, so it is common for reviews to become outdated due to the publication of new articles. It is considered very important to provide an updated study of the state of the art that follows the latest trends in this area.</p><p id="Par21">Therefore, the goal of this review is to contribute to reducing the existing gap in the area by trying to bring together all the time series DA algorithms that currently exist, contrasting their possible virtues, approaches and differences to help future researchers position themselves in the area.</p></sec><sec id="Sec5"><title>Background</title><sec id="Sec6"><title>Traditional algorithms</title><p id="Par22">DA has been a crucial task when the available data are unbalanced or insufficient. Traditionally, in fields such as image recognition, different transformations have been applied to data such as cropping [<xref ref-type="bibr" rid="CR23">23</xref>–<xref ref-type="bibr" rid="CR26">26</xref>], scaling [<xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR25">25</xref>], mirroring [<xref ref-type="bibr" rid="CR23">23</xref>, <xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR27">27</xref>], colour augmentation [<xref ref-type="bibr" rid="CR23">23</xref>, <xref ref-type="bibr" rid="CR25">25</xref>, <xref ref-type="bibr" rid="CR28">28</xref>] or translation [<xref ref-type="bibr" rid="CR27">27</xref>].</p><p id="Par23">These algorithms cannot be applied directly to time series given the particularity of the time series data distribution [<xref ref-type="bibr" rid="CR29">29</xref>]. For example, if one wants to apply rotation to augment an image dataset, it is possible to rotate each image to generate new ones. This cannot be directly done in the time series domain, e.g., if a time series sample is divided into several portions and these portions are reorganised using linear interpolation between them, the result would not be valid because the tendency of the data would be destroyed. Due to the diversity of the time series data, not all techniques can be applied to every dataset. Some of the previous algorithms used in computer vision must adapted to a time series domain, but, in other cases, new specific algorithms must be designed to treat with time series data.</p><p id="Par24">Another important factor when applying DA to the time series domain, especially in signal processing, is that manipulation of the data could distort the signal too much, leading to negative training.</p><p id="Par25">Traditional algorithms are defined as all the techniques based on taking data input samples and synthesising new samples by modifying these data and applying different transformations. The main difference between this technique and those that are reviewed in Sects. <xref rid="Sec7" ref-type="sec">4.2</xref> and <xref rid="Sec8" ref-type="sec">4.3</xref> is that, in the former algorithms, the transformations are applied directly to the data, while in the latter the objective is to learn the probability distribution of the data in order to generate completely new samples trying to imitate the data distribution.</p></sec><sec id="Sec7"><title>Variational Autoencoder (VAE)</title><p id="Par26">VAEs are neural generative models first introduced by Diederik P. Kingma and Max Welling [<xref ref-type="bibr" rid="CR5">5</xref>]. This algorithm is based on the AE architecture [<xref ref-type="bibr" rid="CR4">4</xref>] proposed in 1987. AEs allow changing typical artificial intelligence problems, such as linear regression or classification, to domain-shifting problems. In order to perform this, AEs take an input, usually an image, and infer as the output modifications of that same input. This is known as self-supervised training, where the objective is to obtain the input with slight modifications as an output. One of the most popular applications of this model is image denoising [<xref ref-type="bibr" rid="CR30">30</xref>]. In this case, the input is an image that contains noise and the output should be the input image without the undesired noise.</p><p id="Par27">AE Network is composed of two components, an encoder and a decoder. The encoder is in charge of reducing the input dimensionality of the data to a latent space, while the decoder reconstructs the input information from this latent representation. This latent space is a lower-dimensional manifold of the input data. Then, synthetic data are generated, interpolating the values of the latent space and decoding them. However, this interpolation of the latent space does not generate completely new values; it just mixes the features of the learned probability distribution.</p><p id="Par28">In order to avoid the overfitting produced in AE, VAE regularises its training, generating more diverse samples. The main difference between both architectures is that VAE encodes the input information in a probability distribution rather than in a point. Then, from this distribution, it samples a point that is then decoded to synthesise new samples.</p><p id="Par29">This intermediate step allows the network to map the input distribution to a lower-dimensional distribution from which new latent points can be generated. To do so, the latent distribution is normally defined by a normal distribution with a mean <inline-formula id="IEq1"><alternatives><mml:math id="IEq1_Math"><mml:mrow><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overrightarrow {\mu } = \left( {\mu _{1} , \ldots ,\mu _{n} } \right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq1.gif"/></alternatives></inline-formula> and a standard deviation <inline-formula id="IEq2"><alternatives><mml:math id="IEq2_Math"><mml:mrow><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overrightarrow {\sigma } = \left( {\sigma _{1} , \ldots ,\sigma _{n} } \right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq2.gif"/></alternatives></inline-formula>. These mean and standard deviation vectors define the latent distribution of the model.</p><p id="Par30">Leaving the network to learn a distribution, instead of a set of points learned in AE, the decoder network associates the features of the input data with the probability areas with their respective mean and deviation. With this representation, the mean of the distribution defines the centre point from which the synthetic samples will be generated and the standard deviation defines the variability in the output, that is, the diversity of the generated samples.</p><p id="Par31">Figure <xref rid="Fig1" ref-type="fig">1</xref> shows the architecture of a VAE network.<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><p>VAE architecture with the both latent space representations (<inline-formula id="IEq3"><alternatives><mml:math id="IEq3_Math"><mml:mi>π</mml:mi></mml:math><tex-math id="IEq3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pi$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq3.gif"/></alternatives></inline-formula> and <inline-formula id="IEq4"><alternatives><mml:math id="IEq4_Math"><mml:mi>σ</mml:mi></mml:math><tex-math id="IEq4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq4.gif"/></alternatives></inline-formula>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/521_2023_8459_Fig1_HTML.png" id="MO1"/></fig></p><p id="Par32">Regarding the training of a VAE network, there are two different loss functions. The <italic>reconstruction term</italic> is in charge of the reconstruction of the input data. It measures the error of the network when it builds. This metric acts the same as the error of a standard AE.</p><p id="Par33">On the other hand, VAE include a <italic>regularisation term</italic> that tries to organise how the latent distribution generates new latent spaces. The function of this term is to measure the distance of the sampled data points and a Gaussian distribution. The distance used to measure this error is the Kullback–Leibler divergence (KL divergence) [<xref ref-type="bibr" rid="CR31">31</xref>]. So in order to calculate the loss of the VAE both errors are added, measuring at the same time the reconstruction error of the output and the error of sampling points following a normal distribution.</p></sec><sec id="Sec8"><title>Generative Adversarial Network (GAN)</title><p id="Par34">GAN is a generative neural model based on a competition between two neural network (NN). They were first introduced by Ian Goodfellow [<xref ref-type="bibr" rid="CR3">3</xref>] in 2014. The objective of the architecture is to replicate a given data distribution in order to synthesise new samples of the distribution. To achieve this goal, the GAN architecture is composed of a generator (G) model and a discriminator (D) model. The former is in charge of generating the synthetic samples of the data distribution, while the latter tries to distinguish the real samples from the synthesised samples.</p><p id="Par35">To accomplish such generation of completely new data that are indistinguishable from the input data distribution, both models interact with each other. The model generator (G) generates samples trying to replicate, without copying, the distribution, while the model discriminator (D) discriminates the real samples from the fake samples. In this way, when discriminator (D) differentiates both distributions, it feedbacks generator (G) negatively; on the other hand, when discriminator (D) is not capable of differentiating each distribution, its positively feedbacks generator (G). In doing so, generator (G) evolves to fool discriminator (D). At the same time, discriminator (D) is positively rewarded when discrimination is done correctly.</p><p id="Par36">This competition encourages both networks to evolve together. If discriminator (D) fails in its task, generator (G) will not evolve because it will always succeed, despite the quality of the synthesised samples. Even if discriminator (D) always perfectly distinguishes both distributions, generator (G) will not be able to fool discriminator (D), making it impossible to evolve. The standard GAN architecture is depicted in Fig. <xref rid="Fig2" ref-type="fig">2</xref>.<fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><p>GAN architecture</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/521_2023_8459_Fig2_HTML.png" id="MO2"/></fig></p><p id="Par37">From a mathematical perspective, this competitive behaviour is based on Game Theory, where two players compete in a zero-sum game. The discriminator (D) estimates the <italic>a posteriori</italic> probability <italic>p</italic>(<italic>y</italic>|<italic>x</italic>) , where <italic>y</italic> is the label (true or fake) of the given sample <italic>x</italic>. And generator (G) generates synthetic samples from a latent vector <italic>z</italic>, which can be denoted as <italic>G</italic>(<italic>z</italic>).</p><p id="Par38">From a formal point of view, this competition is defined as a minimax game where discriminator (D) tries to maximise its accuracy when discriminating between both distributions and generator (G) tries to minimise this accuracy. The formulation of this process is denoted as follows:<disp-formula id="Equ1"><label>1</label><alternatives><mml:math display="block" id="Equ1_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mo movablelimits="true">min</mml:mo><mml:mi>G</mml:mi></mml:msub><mml:msub><mml:mo movablelimits="true">max</mml:mo><mml:mi>D</mml:mi></mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mo movablelimits="true">min</mml:mo><mml:mi>G</mml:mi></mml:msub><mml:msub><mml:mo movablelimits="true">max</mml:mo><mml:mi>D</mml:mi></mml:msub><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>∼</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>log</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mo>+</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mo>∼</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>log</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{*{20}r} \hfill \begin{gathered} \min _{G} \max _{D} L(D,G) = \min _{G} \max _{D} E_{{x\sim p_{r} }} \log [D(x)] \hfill \\ \quad \quad \quad \quad \quad \quad \quad \quad + E_{{z\sim p_{z} }} \log [1 - D(G(x))], \hfill \\ \end{gathered} \\ \end{array}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ1.gif"/></alternatives></disp-formula>where <italic>z</italic> is the latent vector, which is generated randomly by a uniform or Gaussian distribution <inline-formula id="IEq5"><alternatives><mml:math id="IEq5_Math"><mml:msub><mml:mi>p</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:math><tex-math id="IEq5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_z$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq5.gif"/></alternatives></inline-formula> and <inline-formula id="IEq6"><alternatives><mml:math id="IEq6_Math"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∼</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="IEq6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x \sim p_{r}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq6.gif"/></alternatives></inline-formula> is the real distribution.</p><p id="Par39">In the publication in which GAN was presented [<xref ref-type="bibr" rid="CR3">3</xref>], it was proved that the architecture can converge to a unique solution. This point, known as Nash equilibrium, is characterised by the fact that none of the networks can reduce their respective losses. This optimal result is very difficult to achieve in reality due to the instability behaviour of GAN. The Nash equilibrium is, in fact, most of the time not achieved because of the constant competition between both networks.</p><p id="Par40">Respecting DA, GANs synthesise completely new samples, using the dataset distribution as their base on learning the underlying data distribution. Therefore, GANs are able to produce more diverse samples respect with respect to previous approximations. This is known as data generation, where the main difference between data generation and DA is that the former generates new samples of synthetic data while the latter use the original samples to produce new ones using their information.</p></sec></sec><sec id="Sec9"><title>Evaluation metrics</title><p id="Par41">Due to the particularities of the time series field, there is no unique metric to evaluate the reliability of algorithms in all of their applications. Finding a measurement capable of evaluating the quality and diversity of the synthesised data is still an open issue.</p><p id="Par42">For example, in GAN networks, there exists no consensus between the different studies about the evaluation metrics to use. In addition, most of the evaluation metrics designed are centred on computer vision, since it is the most popular field for this kind of network.</p><p id="Par43">Therefore, it will be described the most commonly used metrics that have been used to evaluate the algorithms that will be discussed in this article. However, it should be noted that to choose a proper evaluation metric, one should adapt the metric to the specific data augmentation algorithm and the application field.</p><sec id="Sec10"><title>External performance evaluation</title><p id="Par44">When applying DA to a dataset, the most common objective is to generate new data samples to improve the performance of certain models, reducing the imbalance of the data or the lack of data. One of the most popular ways to measure how the addition of new data changes the behaviour of the models is simply to compare these models before and after DA. Then, it is possible to compare whether each model has improved its performance after applying DA to the input data.</p><p id="Par45">This approximation is purely practical and relies on the correlation between the performance of a defined model and not the quality of the synthetic samples themselves. Most traditional algorithms base their performance on this method because it is a straightforward method to evaluate an algorithm.</p><p id="Par46">In [<xref ref-type="bibr" rid="CR32">32</xref>], the performance of the DA algorithms they propose is achieved using <italic>symmetric Mean Absolute Percentage Error</italic> and <italic>Mean Absolute Scaled Error</italic>, which are the two most common evaluation metrics used in forecasting. This research compares the values of these metrics before and after applying DA to the dataset, then evaluates how the models improve their performance due to the addition of more data to the training set.</p><p id="Par47">In [<xref ref-type="bibr" rid="CR15">15</xref>], they used six different neural networks to evaluate how each DA algorithm affects the classification of the data. In particular, they evaluated VGG [<xref ref-type="bibr" rid="CR24">24</xref>], residual network [<xref ref-type="bibr" rid="CR25">25</xref>], multilayer perceptron [<xref ref-type="bibr" rid="CR33">33</xref>], long short-term memory [<xref ref-type="bibr" rid="CR34">34</xref>], bidirectional long short-term memory [<xref ref-type="bibr" rid="CR35">35</xref>] and long short-term memory fully convolutional network [<xref ref-type="bibr" rid="CR36">36</xref>]. Then, the changes in the accuracy of the models are compared, observing how certain DA algorithms benefit the performance of the models, while in other cases it gets worse. The main drawback stated in the article is that each architecture has its particularities, given the different results for each algorithm and making it a difficult task to differentiate the best algorithm. Furthermore, because all of them are neural models, it is difficult to interpret some of the results.</p><p id="Par48">The approach followed in [<xref ref-type="bibr" rid="CR29">29</xref>] is to compare different DA techniques by the increase in accuracy produced in each case of study. It is worth mentioning how this approximation adapts to each application without having to change anything. The authors of the article are able to compare very different techniques such as noise addition, GAN, sliding window, Fourier transform and recombination of segmentation under the same criteria for a specific domain purpose. This example shows how this approach easily adapts to different DA techniques, making it possible to compare the results for a certain task.</p><p id="Par49">A similar strategy to measure the quality of the generated data is to compare different models using a defined loss function. This approach was followed in GAN architectures in works like [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR37">37</xref>–<xref ref-type="bibr" rid="CR40">40</xref>], where a comparison between networks is possible using the same loss function to evaluate their training. Then, they correlate the quality of the synthetic data with this value. This strategy can be applied naturally to the time series domain, allowing comparison between different networks. However, the main drawback of this method is that it compares the performance of different neural models and cannot be applied to other models. It should be noted that, as in previous metrics, it correlates the quality of the generated data not with the data itself but rather with the performance of the model.</p><p id="Par50">In [<xref ref-type="bibr" rid="CR41">41</xref>], they compare the performance of different DA techniques with mean per-class error (MPCE). This metric, proposed in [<xref ref-type="bibr" rid="CR42">42</xref>], measures the error per class in <italic>J</italic> datasets taking into account the number of classes in each dataset. The main particularity of mean per-class error (MPCE) is that it allows us to quantify the performance of an algorithm for different datasets. The mean per-class error (MPCE) is calculated as follows:<disp-formula id="Equ2"><label>2</label><alternatives><mml:math display="block" id="Equ2_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mspace width="0.333333em"/><mml:mtext>MPCE</mml:mtext><mml:mspace width="0.333333em"/><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:munder><mml:msub><mml:mtext>PCE</mml:mtext><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \text{ MPCE } =\sum _{j \in [J]} \hbox{PCE}_{j}=\frac{e_{j}}{c_{j}} \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ2.gif"/></alternatives></disp-formula>where <inline-formula id="IEq7"><alternatives><mml:math id="IEq7_Math"><mml:msub><mml:mi>e</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="IEq7_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$e_{j}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq7.gif"/></alternatives></inline-formula> is the error rate and <inline-formula id="IEq8"><alternatives><mml:math id="IEq8_Math"><mml:msub><mml:mi>c</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="IEq8_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c_{j}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq8.gif"/></alternatives></inline-formula> is the number of classes in each dataset. This metric is capable of taking into account the number of classes of each dataset, in order to normalise the comparison between different sources of data.</p></sec><sec id="Sec11"><title>GAN related metrics</title><p id="Par51">Since the introduction of GAN, it has always been an open issue to measure the quality of the synthesised samples produced by the architecture [<xref ref-type="bibr" rid="CR43">43</xref>]. One of the most important difficulties when designing a metric for GAN is the ability to capture both the quality and diversity of the generated data.</p><p id="Par52">In addition to being still an open issue, there is consensus on some metrics and many papers measure their results with the same metrics [<xref ref-type="bibr" rid="CR44">44</xref>–<xref ref-type="bibr" rid="CR49">49</xref>]. The main problem in the time series domain is that it is not always possible to adapt the metrics to the particularities of this field because most of the metrics are designed to be useful in computer vision-related tasks.</p><p id="Par53">Over the past few years, some works have suggested applying DA to time series data and treating it as if it were an image [<xref ref-type="bibr" rid="CR50">50</xref>, <xref ref-type="bibr" rid="CR51">51</xref>]. These papers use GAN networks to synthesise new time series data, but to convert the signal data into an image. In these cases, traditional GAN metrics, such as the Inception Score [<xref ref-type="bibr" rid="CR52">52</xref>], Mode Score [<xref ref-type="bibr" rid="CR53">53</xref>] or Fréchet Inception Distance [<xref ref-type="bibr" rid="CR54">54</xref>] are used to evaluate the results. These metrics are based on how the <italic>Inception v3</italic> neural classifier distinguishes the different samples. The idea is to measure the entropy of the synthetic dataset using an external classifier.</p><p id="Par54">In addition to the field of computer vision, studies have been developed that apply GAN directly to time series. That is, in TimeGAN [<xref ref-type="bibr" rid="CR55">55</xref>] two new metrics are proposed to assess the quality of the generated samples. The Discriminative Score is based on the use of an external pre-trained model, as was done with the Inception Score, consisting of a 2-layer LSTM. The Discriminative Score measures how this model distinguishes between real and fake samples and the classification error corresponds to the Discriminative Score. The Predictive Score measurement was introduced in [<xref ref-type="bibr" rid="CR56">56</xref>] with the name Train Synthetic, Test Real (TSTR) which also uses a 2-layer LSTM, but in this case, this model is trained with synthetic samples. The model is then evaluated using the original dataset. The Predictive Score corresponds to mean absolute error (MEA) of the model trained with the synthetic samples evaluated with the real samples. This metric is, at the moment, one of the most effective and used evaluation metrics.</p></sec><sec id="Sec12"><title>Similarity measurements</title><p id="Par55">This set of metrics focuses on the comparison of two probability distributions. The idea is to measure how far from the original distribution the synthetic samples generated with DA. The main advantage of these metrics is that they focus on directly studying the quality of the data, in contrast the previously reviewed methods that measured the quality indirectly. Another advantage of these types of metrics is that they can be applied to synthetic data despite the algorithm used to generate them.</p><p id="Par56">An empirical and qualitative approach to measuring the differences between two distributions is to reduce the dimensionality of the data and perform a visual comparison. The objective is to reduce the dimensionality of the data to plot the samples in a bidimensional space; an empirical comparison is then made by visualising the data. This approach was followed in [<xref ref-type="bibr" rid="CR57">57</xref>] where they applied <italic>t</italic>-distributed stochastic neighbour embedding (t-SNE) and principal component analysis (PCA). Then, they compared the distribution of the data in the two-dimensional space for TimeGAN [<xref ref-type="bibr" rid="CR55">55</xref>], recurrent conditional GAN (RCGAN) [<xref ref-type="bibr" rid="CR56">56</xref>], continuous recurrent GAN (C-RNN-GAN) [<xref ref-type="bibr" rid="CR58">58</xref>], T-Forcing [<xref ref-type="bibr" rid="CR59">59</xref>], WaveNet [<xref ref-type="bibr" rid="CR60">60</xref>] and WaveGAN [<xref ref-type="bibr" rid="CR61">61</xref>]. This approach was also followed in [<xref ref-type="bibr" rid="CR15">15</xref>] where they used principal component analysis (PCA) to compare different traditional algorithms for the GunPoint dataset from the 2018 UCR Time Series Archive [<xref ref-type="bibr" rid="CR62">62</xref>].</p><p id="Par57">Kullback–Leibler divergence (KL divergence) has been used in work such as [<xref ref-type="bibr" rid="CR63">63</xref>, <xref ref-type="bibr" rid="CR64">64</xref>] to measure similarities between synthetic and real datasets. Recall that Kullback–Leibler divergence (KL divergence) [<xref ref-type="bibr" rid="CR31">31</xref>] is defined as<disp-formula id="Equ3"><label>3</label><alternatives><mml:math display="block" id="Equ3_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi mathvariant="italic">KL</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mspace width="0.166667em"/><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mspace width="0.166667em"/><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>log</mml:mo><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} D_{K L}(P \,||\, Q)=\sum _{i} P(x_i) \log \left( \frac{P(x_i)}{Q(x_i)}\right) , \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ3.gif"/></alternatives></disp-formula>where <italic>P</italic> and <italic>Q</italic> are the probability distributions whose distance is calculated and <italic>i</italic> runs over the samples <inline-formula id="IEq9"><alternatives><mml:math id="IEq9_Math"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq9_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_i$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq9.gif"/></alternatives></inline-formula> of the distribution. This Kullback–Leibler divergence (KL divergence) [<xref ref-type="bibr" rid="CR31">31</xref>] is not a symmetric distance, so it can be symmetrized to give rise to the so-called Jensen–Shannon divergence (JSD), defined as<disp-formula id="Equ17"><alternatives><mml:math display="block" id="Equ17_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>J</mml:mi><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mspace width="0.166667em"/><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mspace width="0.166667em"/><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi mathvariant="italic">KL</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mspace width="0.166667em"/><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mspace width="0.166667em"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi mathvariant="italic">KL</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Q</mml:mi><mml:mspace width="0.166667em"/><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mspace width="0.166667em"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ17_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} JSD(P \,||\, Q) = D_{K L}(P \,||\, (P+Q)/2) + D_{K L}(Q \,||\, (P+Q)/2). \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ17.gif"/></alternatives></disp-formula>In [<xref ref-type="bibr" rid="CR65">65</xref>], a novel measurement is proposed to quantify the distance between the time series distribution. It is based on calculating the Wasserstein distance between time series data. The metric is defined by measuring the Wasserstein distance of the energy between frequencies. The Wasserstein–Fourier distance between the probability distributions is computed as follows:<disp-formula id="Equ4"><label>4</label><alternatives><mml:math display="block" id="Equ4_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>WF</mml:mtext><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>s</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \hbox{WF}([x],[y])=W_{2}\left( s_{x}, s_{y}\right) \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ4.gif"/></alternatives></disp-formula>where <inline-formula id="IEq10"><alternatives><mml:math id="IEq10_Math"><mml:msub><mml:mi>s</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math><tex-math id="IEq10_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s_{x}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq10.gif"/></alternatives></inline-formula> and <inline-formula id="IEq11"><alternatives><mml:math id="IEq11_Math"><mml:msub><mml:mi>s</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:math><tex-math id="IEq11_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s_{y}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq11.gif"/></alternatives></inline-formula> are the normalised power spectral densities of the distributions.</p></sec></sec><sec id="Sec13"><title>Data Augmentation algorithms review</title><p id="Par58">During this section, different state-of-the-art algorithms will be reviewed. This section will explain the particularities, strengths and weaknesses of each algorithm. In addition, the different approximations to apply DA will be grouped and related between them. A taxonomy of the different trends and lines of research will be proposed, showing the different existing links between the works of the last years.</p><p id="Par59">It should be noted that not all the algorithms can be applied to all types of time series data; in some cases, the algorithms proposed will be heavily focused on a certain application, while in others more general techniques will be studied.</p><sec id="Sec14"><title>Basic DA Methods</title><p id="Par60">The basic DA algorithms that will be reviewed in this section are all techniques that use data manipulation to generate new synthetic data samples using existing samples and transform the original samples. All these techniques have as their base the deformation, shortening, enlargement or modification of the data samples of the dataset. This group of techniques has been traditionally used in fields such as computer vision and, in some cases, the same algorithms can be adapted to process time series data, but in others, new algorithms must be designed specifically to use time series data as input.</p><p id="Par61">Therefore, the most important traditional algorithms that have been applied to time series data will be reviewed and discussed, outlining their particularities, advantages and disadvantages. Figure <xref rid="Fig3" ref-type="fig">3</xref> shows the taxonomy proposed for the different algorithms reviewed.<fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><p>Traditional DA algorithms taxonomy</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/521_2023_8459_Fig3_HTML.png" id="MO8"/></fig></p><sec id="Sec15"><title>Time slicing window</title><p id="Par62">Slicing, in time series, consists of cutting a portion of each data sample, to generate a different new sample. Normally, slicing is applied to the last steps of the sample, but the snippet of the original sample can be obtained from any step. When the original data is cropped, a different sample is produced, but unlike image processing, it is difficult to maintain all the features of the original data. The process of slicing time series data provides new data given as:<disp-formula id="Equ5"><label>5</label><alternatives><mml:math display="block" id="Equ5_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>x</mml:mi><mml:mi>φ</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>φ</mml:mi><mml:mo>+</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} x^{\prime }(W)=\left\{ x_{\varphi }, \ldots , x_{t}, \ldots , x_{\varphi +W}\right\} , \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ5.gif"/></alternatives></disp-formula>where <italic>W</italic> is the slice window that defines the crop size and <inline-formula id="IEq12"><alternatives><mml:math id="IEq12_Math"><mml:mi>φ</mml:mi></mml:math><tex-math id="IEq12_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varphi$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq12.gif"/></alternatives></inline-formula> is the initial point from where the slicing is performed, such as <inline-formula id="IEq13"><alternatives><mml:math id="IEq13_Math"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>φ</mml:mi><mml:mo>≤</mml:mo><mml:mi>T</mml:mi><mml:mo>-</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:math><tex-math id="IEq13_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1 \le \varphi \le T-W$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq13.gif"/></alternatives></inline-formula>. One of the most important drawbacks of slicing the signal is that it can lead to invalid synthetic samples because it can cut off important features of the data.</p><p id="Par63">A variation of the slicing method is proposed in [<xref ref-type="bibr" rid="CR66">66</xref>], where the concatenating and resampling method is presented. This algorithm first detects features in the data, called characteristic points. This is made by using the Pan-Tompkins QRS detector [<xref ref-type="bibr" rid="CR67">67</xref>]. This algorithm detects the characteristic points in a heartbeat signal, so in order to apply the concatenating and resampling algorithm it must be defined and algorithm to detect these points. Then, after detecting the characteristic points, it is defined a subsequence that starts and ends in a characteristic point. This sequence is replicated several times and sliced in a window to perform DA.</p><p id="Par64">This variation was applied to electrocardiogram (ECG) data of variable length between 9 and 61 s sampled at 300 Hz.</p><p id="Par65">The concatenating and resampling algorithm tries to ensure the validity of the data, taking into account that the signal maintains its features. But the main disadvantage of this method is that it needs a detector of characteristic points that ensure the data validity.</p></sec><sec id="Sec16"><title>Jittering</title><p id="Par66">Jittering consists of adding noise to time series to perform DA. This technique, in addition to being one of the simplest forms of DA, is one of the most popular in time series [<xref ref-type="bibr" rid="CR68">68</xref>, <xref ref-type="bibr" rid="CR69">69</xref>]. Jittering assumes that the data are noisy which, in many cases, i.e., when dealing with sensor data, is true.</p><p id="Par67">Jittering tries to take advantage of the noise of the data and simulate it to generate new samples. Typically, Gaussian noise is added to each time step; the mean and standard deviation of this noise define the magnitude and shape of the deformation, so it is different in each application. The jittering process can be defined as follows:<disp-formula id="Equ6"><label>6</label><alternatives><mml:math display="block" id="Equ6_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ϵ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} x^{\prime }(\epsilon )=\left\{ x_{1}+\epsilon _{1}, \ldots , x_{t}+\epsilon _{t}, \ldots , x_{T}+\epsilon _{T}\right\} , \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ6.gif"/></alternatives></disp-formula>where <inline-formula id="IEq14"><alternatives><mml:math id="IEq14_Math"><mml:mi>ϵ</mml:mi></mml:math><tex-math id="IEq14_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq14.gif"/></alternatives></inline-formula> stands for the noise addition at each step of the signal.</p><p id="Par68">As mentioned above, the jittering process must be adapted to each case, because there are cases such as [<xref ref-type="bibr" rid="CR70">70</xref>] where the effects of jittering lead to negative learning. In this research, it was used as time series data the information received by a wearable sensor, capturing 58 s at 62.5 Hz that were later resampled to 120 Hz per sample.</p></sec><sec id="Sec17"><title>Scaling</title><p id="Par69">Scaling consists of changing the magnitude of a certain step in the time series domain. The idea is to maintain the overall shape of the signal while changing its values. With scaling, the new generated data change the range of values, but keep the shape of the changes. Homogeneous scaling is given as:<disp-formula id="Equ7"><label>7</label><alternatives><mml:math display="block" id="Equ7_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mi>α</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ7_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} x^{\prime }(\alpha )=\left\{ \alpha x_{1}, \ldots , \alpha x_{t}, \ldots , \alpha x_{T}\right\} , \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ7.gif"/></alternatives></disp-formula>where <inline-formula id="IEq15"><alternatives><mml:math id="IEq15_Math"><mml:mrow><mml:mi>α</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><tex-math id="IEq15_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha &gt; 0$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq15.gif"/></alternatives></inline-formula> defines the scale of the change. This value can be defined by a Gaussian distribution with mean 1 and with <inline-formula id="IEq16"><alternatives><mml:math id="IEq16_Math"><mml:mi>σ</mml:mi></mml:math><tex-math id="IEq16_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq16.gif"/></alternatives></inline-formula> as a hyperparameter [<xref ref-type="bibr" rid="CR70">70</xref>], or it can be previously defined from a list of values [<xref ref-type="bibr" rid="CR69">69</xref>].</p><p id="Par70">Within scaling techniques, there are several different approximations for a specific time series domain. They take advantage of the specific properties of the signal data and adapt to perform DA.</p><p id="Par71">Magnitude warping is a technique used in [<xref ref-type="bibr" rid="CR70">70</xref>] that consists of an application of a variable scaling to different points of the data curve. To define where to apply the transformation, a set of knots <inline-formula id="IEq17"><alternatives><mml:math id="IEq17_Math"><mml:mrow><mml:mi mathvariant="bold">u</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="IEq17_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\textbf{u}}=u_{1}, \ldots , u_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq17.gif"/></alternatives></inline-formula> is defined; these represent the step in which the scaling is performed and their values are generated by using a normal distribution. Then, the magnitude of the scaling is defined by a cubic spline interpolation of the knots <inline-formula id="IEq18"><alternatives><mml:math id="IEq18_Math"><mml:mrow><mml:mi>S</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq18_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S({\textbf{x}})$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq18.gif"/></alternatives></inline-formula>. Then, the magnitude warping can be defined as follows:<disp-formula id="Equ8"><label>8</label><alternatives><mml:math display="block" id="Equ8_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>α</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ8_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} x^{\prime }(\mathbf {\alpha })=\left\{ \alpha _{1} x_{1}, \ldots , \alpha _{t} x_{t}, \ldots , \alpha _{T} x_{T}\right\} , \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ8.gif"/></alternatives></disp-formula>where <inline-formula id="IEq19"><alternatives><mml:math id="IEq19_Math"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="IEq19_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf {\alpha }=\alpha _{1}, \ldots , \alpha _{i} = S({\textbf{x}})$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq19.gif"/></alternatives></inline-formula>. With magnitude warping, the main particularity is that it applies a smoothened scaling to each point of the curve, multiplying the possibilities of the transformation while preserving the overall shape of the data. However, it still assumes that the synthetic data maintain validity after transformation.</p><p id="Par72">This technique was used in [<xref ref-type="bibr" rid="CR70">70</xref>] where the data was captured from a wearable device to detect if a patient suffers from Parkinson’s disease.</p><p id="Par73">Frequency warping is a variation of magnitude warping, mostly applied in speech processing [<xref ref-type="bibr" rid="CR71">71</xref>–<xref ref-type="bibr" rid="CR73">73</xref>]. The most popular version in speech recognition is vocal tract length perturbation, which can be applied in a deterministic way [<xref ref-type="bibr" rid="CR72">72</xref>] or stochastically within a range [<xref ref-type="bibr" rid="CR74">74</xref>]. In particular, this technique was used in [<xref ref-type="bibr" rid="CR72">72</xref>] where a dataset of human conversation sampled at 8 KHz was used.</p><p id="Par74">Another scaling technique is time warping, the idea is very similar to magnitude warping, but the main difference between both algorithms is that time warping modifies the curve in the temporal dimension. That is, instead of fluctuating the magnitude of the signal in each step, it stretches and shortens the time slices of the signal. To define how to warp the signal, a smooth curve, as was done in magnitude warping, is defined by using a cubic spline for a set of knots. The time-warping algorithm can be denoted as:<disp-formula id="Equ9"><label>9</label><alternatives><mml:math display="block" id="Equ9_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>τ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ9_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} x^{\prime }(\mathbf {\tau })=\left\{ x_{\tau (1)}, \ldots , x_{\tau (t)}, \ldots , x_{\tau (T)}\right\} , \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ9.gif"/></alternatives></disp-formula>where <inline-formula id="IEq20"><alternatives><mml:math id="IEq20_Math"><mml:mi>τ</mml:mi></mml:math><tex-math id="IEq20_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tau$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq20.gif"/></alternatives></inline-formula> defines the magnitude of the warp, this function is generated by using a cubic spline <italic>S</italic>(<italic>u</italic>) between different knots generated using a normal distribution. This algorithm has been used in several works, such as [<xref ref-type="bibr" rid="CR75">75</xref>, <xref ref-type="bibr" rid="CR76">76</xref>]. There is yet another variation of this algorithm, known as window warping, followed in [<xref ref-type="bibr" rid="CR77">77</xref>] that defines a slice in the time series data and speeds up or down the data by a factor of 1/2 or 2. In this case, the warping is applied to a defined slice of the whole sequence; the rest of the signal is not changed.</p></sec><sec id="Sec18"><title>Rotation</title><p id="Par75">Rotation can be applied to multivariate time series data by applying a rotation matrix with a defined angle. In univariate time series, rotation can be applied by flipping the data. Rotation is defined as follows:<disp-formula id="Equ10"><label>10</label><alternatives><mml:math display="block" id="Equ10_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mi>R</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ10_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} x^{\prime }(R)=\left\{ Rx_{1}, \ldots , Rx_{t}, \ldots , Rx_{T}\right\} , \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ10.gif"/></alternatives></disp-formula>where <italic>R</italic> is the rotation matrix used to twist the data. This algorithm is not very usual in time series due to the fact that rotating a time series sample could make it lose the class information, as it happened in [<xref ref-type="bibr" rid="CR78">78</xref>], where it was used the UCR archive [<xref ref-type="bibr" rid="CR62">62</xref>] with various dataset from different real-world applications were the composition of the samples of each dataset varies. On the other hand, there have been articles [<xref ref-type="bibr" rid="CR70">70</xref>] that demonstrate the benefits of applying rotation, especially combined with other data transformations, in this case, using wearable data samples at 120 Hz.</p></sec><sec id="Sec19"><title>Permutation</title><p id="Par76">Shuffling different time slices of data in order to perform DA is a method that generates new data patterns. It was proposed in [<xref ref-type="bibr" rid="CR70">70</xref>], where a fixed slice window was defined from which the data is rearranged, but it has also been applied with variable windows, as it was done in [<xref ref-type="bibr" rid="CR79">79</xref>] using electrocardiogram (ECG) data at 300 Hz. The main problem of applying permutation is that it does not preserve time dependencies; thus, it can lead to invalid samples. The permutation algorithm can be denoted as follows:<disp-formula id="Equ11"><label>11</label><alternatives><mml:math display="block" id="Equ11_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ11_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} x^{\prime }(w)=\left\{ x_{i}, \ldots , x_{i+w}, \ldots , x_{j}, \ldots , x_{j+w}, \ldots , x_{k}, \ldots , x_{k+w}\right\} \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ11.gif"/></alternatives></disp-formula>where <italic>i</italic>, <italic>j</italic>, <italic>k</italic> represents the first index slice of each window, so that each is selected exactly once, and <italic>w</italic> denotes the window size if the slices are uniform <inline-formula id="IEq21"><alternatives><mml:math id="IEq21_Math"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math><tex-math id="IEq21_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w = T/n$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq21.gif"/></alternatives></inline-formula> where <italic>n</italic> is the number of total slices.</p></sec><sec id="Sec20"><title>Channel permutation</title><p id="Par77">Changing the position of different channels in multidimensional data is a common practice. In computer vision, it is quite popular to swap the RGB channels to perform DA [<xref ref-type="bibr" rid="CR80">80</xref>]. With respect to time series, channel permutation can be applied as long as each channel of the data is still valid. The channel permutation algorithm, for multidimensional data such as <inline-formula id="IEq22"><alternatives><mml:math id="IEq22_Math"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mfenced close="}" open="{"><mml:msub><mml:mi>x</mml:mi><mml:mn>11</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mfenced><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi mathvariant="italic">cT</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq22_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x=\left\{ \left\{ x_{11}, \cdots , x_{1T}\right\} , \cdots , \left\{ x_{c1}, \cdots , x_{cT} \right\} \right\}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq22.gif"/></alternatives></inline-formula> where <italic>c</italic> is the number of channels, is given by<disp-formula id="Equ12"><label>12</label><alternatives><mml:math display="block" id="Equ12_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mfenced close="}" open="{"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mfenced><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mfenced close="}" open="{"><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ12_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} x=\left\{ \left\{ x_{\sigma (1)1}, \ldots , x_{\sigma (1)T}\right\} , \cdots , \left\{ x_{\sigma (c)1}, \ldots , x_{\sigma (c)T} \right\} \right\} , \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ12.gif"/></alternatives></disp-formula>where <inline-formula id="IEq23"><alternatives><mml:math id="IEq23_Math"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>:</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">}</mml:mo><mml:mo stretchy="false">→</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><tex-math id="IEq23_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma : \{1, \ldots , c\} \rightarrow \{1, \ldots , c\}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq23.gif"/></alternatives></inline-formula> is the used permutation of the channels.</p><p id="Par78">In the time series domain, this algorithm is not applicable to the application of the data, because permutation assumes that the channel information is independent of the channel itself. In other words, the information about the channels is not linked to the particular channel.</p><p id="Par79">That is, in [<xref ref-type="bibr" rid="CR63">63</xref>], they applied this algorithm by flipping the position of the sensors that recorded the data signals, recording the data at 20 Hz using a window of 6 s. In the article, the researchers used an exercise mat with eight proximity sensors that they flipped to generate new data. That is, in practice, changing the position of the signal channels.</p></sec><sec id="Sec21"><title>Summary of the traditional algorithms</title><p id="Par80">Figure <xref rid="Fig4" ref-type="fig">4</xref> shows an example of each algorithm reviewed:<fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><p>Summary of traditional algorithms</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/521_2023_8459_Fig4_HTML.png" id="MO17"/></fig></p></sec></sec><sec id="Sec22"><title>Data augmentation through VAE</title><p id="Par81">The use of AE architectures is nothing more than the evolution of data generation algorithms to produce more and better data, which means that, better, they are varied and therefore the standard deviation with respect to the original data is perfect. To precisely control the deviation of the data, VAE arises as the evolution of AE to generate better synthetic data, as shown in [<xref ref-type="bibr" rid="CR81">81</xref>] where VAE is used to generate data for anomaly detection problems with LSTM. Or this other work [<xref ref-type="bibr" rid="CR82">82</xref>], in which they use a dataset augmented with VAE to improve the recognition of human activity with LSTM. Even more exhaustive studies [<xref ref-type="bibr" rid="CR83">83</xref>, <xref ref-type="bibr" rid="CR84">84</xref>] show the efficiency of these algorithms in increasing the size of datasets.</p><p id="Par82">But the use of VAEs for DA is not only intended for neural network models, but can also improve results when traditional machine learning algorithms are applied [<xref ref-type="bibr" rid="CR85">85</xref>]. However, they can also be used in applications with unsupervised training, that is, in [<xref ref-type="bibr" rid="CR86">86</xref>], which applies them to unsupervised domain adaptation for robust speech recognition.</p><p id="Par83">In [<xref ref-type="bibr" rid="CR87">87</xref>], they point out that most data augmentation methods for time series use feature space transformations to artificially enlarge the training set; they propose a composition of autoencoders ( AEs), variational autoencoders ( VAEs) and Wasserstein generative adversarial networks with gradient penalty (WGAN-GPs) for time series augmentation.</p><p id="Par84">In the end, each VAE model and its hyperparameter configuration make them specialise in the area or format of the dataset they want to work on; but above all to the type of problem for which it will be used afterwards. That is to say, what makes the difference between the models is what the generated data will be used for, regarding problems such as: classification, forecasting, value imputation or prediction.</p><sec id="Sec23"><title>Taxonomy for the VAE algorithms reviewed</title><p id="Par85">Figure <xref rid="Fig5" ref-type="fig">5</xref> shows a scheme to group the different investigations reviewed in Sect. <xref rid="Sec22" ref-type="sec">6.2</xref>, this way all the VAE algorithms for DA can be viewed schematically.<fig id="Fig5"><label>Fig. 5</label><caption xml:lang="en"><p>Taxonomy of the presented variational autoencoder (VAE) architectures</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/521_2023_8459_Fig5_HTML.png" id="MO18"/></fig></p></sec><sec id="Sec24"><title>VAE for anomaly detection</title><p id="Par86">As mentioned before, VAE are a DA architecture that has been widely used in the field of anomaly detection. The main objective of using these models in anomaly detection tasks is to be able to generate data in order to avoid the lack of invalid data of the datasets. The most common scenario is that there are not enough available anomalous samples in order to train machine learning models with the dataset, so the use of VAE is focused on generating new data.</p><p id="Par87">The work presented in [<xref ref-type="bibr" rid="CR81">81</xref>] is centred on the classification of electrocardiogram (ECG) signals, distinguishing between the ones with cardiac dysfunction. The data used consists of windows of 3600 samples downsampled to 905 sample points during a period of time of 10 s. In order to augment the data available it is used a conditional VAE (CVAE) [<xref ref-type="bibr" rid="CR91">91</xref>] that is able to learn which samples are normal and which are anomalous. This conditional VAE (CVAE) architecture is composed of LSTM layers [<xref ref-type="bibr" rid="CR92">92</xref>] which process the temporal data of the electrocardiogram (ECG) signals.</p><p id="Par88">Another architecture based on the anomaly detection problem is the smoothness-inducing sequential VAE (SISVAE) [<xref ref-type="bibr" rid="CR88">88</xref>] which uses a VAE with recurrent layers to maintain temporal dependencies. This work focuses on the problem of abrupt changes between time steps, which led to non-smooth reconstructions of the input data of the model, and therefore temporal abrupt changes in the synthesised samples. The mechanism to avoid this is to introduce a corrective bias for each time step of the signal, calculated using the Kullback–Leibler divergence (KL divergence) [<xref ref-type="bibr" rid="CR31">31</xref>] between one point and the next one in the series. The results of the work are tested using two different time series synthetic datasets.</p></sec><sec id="Sec25"><title>VAE for data imputation</title><p id="Par89">One field where the VAE architecture has been widely used is in data imputation tasks. This process consists of generating new data in a sample where there is missing information. In the temporal series domain, this process is usually used to fill gaps in temporal spaces where there are no available data. In this sense, VAE generates synthetic information on demand to fill these gaps, generating new information following the distribution of the original data.</p><p id="Par90">The GlowImp architecture [<xref ref-type="bibr" rid="CR89">89</xref>] was proposed as a combination of the Wasserstein GAN (WGAN) [<xref ref-type="bibr" rid="CR93">93</xref>] architecture together with a VAE to impute missing data. The architecture is composed of the so-called Glow VAE, which incorporates a function that takes the latent distribution of the traditional VAE encoder and interpolates the missing values via the Glow Model. The other main part of the architecture is the GAN model where the generator corresponds with the decoder of the VAE and the discriminator forces the system to produce realistic samples. The results of the model are tested using two different datasets, the KDD Cup Challenge 2018 dataset containing air quality weather data and the PhysioNet Challenge 2012 which is a collection of multivariate clinical time series data. The architecture of the GlowImp can be seen in Fig. <xref rid="Fig6" ref-type="fig">6</xref>.<fig id="Fig6"><label>Fig. 6</label><caption xml:lang="en"><p>GlowImp architecture. Based on the figure of [<xref ref-type="bibr" rid="CR89">89</xref>]</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/521_2023_8459_Fig6_HTML.png" id="MO19"/></fig></p><p id="Par91">The work of Li et al. [<xref ref-type="bibr" rid="CR90">90</xref>] presents a VAE architecture to impute temporal values using meteorological datasets. In order to fill in the missing values of the data samples, shift correction is used. This correction tries to counteract the deviation caused by the missing values. This correction is used in the Gaussian latent distribution, where a shift hyperparameter <inline-formula id="IEq24"><alternatives><mml:math id="IEq24_Math"><mml:mi>λ</mml:mi></mml:math><tex-math id="IEq24_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq24.gif"/></alternatives></inline-formula> is applied which is manually set to centre the latent distribution, thus correcting the possible bias produced by missing values. The VAE architecture used in this work to impute the missing values is <inline-formula id="IEq25"><alternatives><mml:math id="IEq25_Math"><mml:mi>β</mml:mi></mml:math><tex-math id="IEq25_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq25.gif"/></alternatives></inline-formula>- VAE [<xref ref-type="bibr" rid="CR94">94</xref>].</p></sec></sec><sec id="Sec26"><title>Data Augmentation through GAN</title><p id="Par92">GANs are one of the most popular generative models of the last decade, since its introduction in 2014 by Ian Goodfellow [<xref ref-type="bibr" rid="CR3">3</xref>] this generative architecture has positioned itself as one of the main algorithms for DA. The main strength of the GAN architecture is that it learns the distribution of the data by extracting the main features of the samples, without copying the distribution directly. This is known as data generation and its main strength with respect to data augmentation is that it synthesises completely new samples, in contrast with other techniques where the original samples where transformed to generate new instances. This fosters the generalisation and creativity of the synthetic data generated by the model. It is also an important factor that the training of the networks is unsupervised, not necessarily to have labelled data to learn the distribution.</p><sec id="Sec27"><title>Taxonomy for the GAN algorithms reviewed</title><p id="Par93">Fig. <xref rid="Fig7" ref-type="fig">7</xref> shows a scheme to group the different research reviews in Sect. <xref rid="Sec8" ref-type="sec">4.3</xref>, this way all the GAN algorithms for DA can be viewed schematically.<fig id="Fig7"><label>Fig. 7</label><caption xml:lang="en"><p>Taxonomy of the presented GAN architectures</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/521_2023_8459_Fig7_HTML.png" id="MO20"/></fig></p></sec><sec id="Sec28"><title>Long Short-Term Memory (LSTM) based GAN</title><p id="Par94">One of the approaches to adapt the GAN architecture to time series is to use recurrent networks as the base of artificial neural network (ANN). These GANs substitute the regular fully connected or convolutional layers with recurrent layers, able to have memory that links temporal features of the data. The main strength of this set of architectures is that they are able to process this temporal information that the input data have, similar to the spatial information processing of a convolutional neural network.</p><p id="Par95">Continuous recurrent GAN (C-RNN-GAN) [<xref ref-type="bibr" rid="CR58">58</xref>] is one of the first GAN architectures proposed specifically for time series data. In particular, using them to learn and synthesise music tracks was proposed in this work. This GAN uses LSTM blocks [<xref ref-type="bibr" rid="CR92">92</xref>] as its main learning structure. The learning algorithm is the same as standard training GAN, where the network generator concatenates each input with the output of the previous cells and the discriminator is made up of a bidirectional recurrent network [<xref ref-type="bibr" rid="CR35">35</xref>]. The internal composition of the discriminator is based on the work of Horchreiter [<xref ref-type="bibr" rid="CR100">100</xref>] and Bengio et al. [<xref ref-type="bibr" rid="CR101">101</xref>] that avoids the gradient vanishing and strengths the temporal dependencies. The results of the work are discussed using a dataset of 3697 musical midi files from 160 different composers of classical music with a tick resolution of 384 per quarter note.</p><p id="Par96">The work presented by Haradal et al. [<xref ref-type="bibr" rid="CR95">95</xref>] also proposes a GAN architecture based on the implementation of LSTM cells in both the generator and discriminator networks to adapt to time series data. The discriminator output is generated by applying an average pooling to the outputs generated by each layer, averaging the whole data sample into a unique scalar output which corresponds to the probability of the sample being generated by the generator network. This architecture was used to generate electrocardiogram (ECG) [<xref ref-type="bibr" rid="CR102">102</xref>] and electroencephalogram (EEG) [<xref ref-type="bibr" rid="CR103">103</xref>] data to improve the classification accuracy of an artificial neural network (ANN) classifier.</p><p id="Par97">The LSTM and GAN combination has also been used for anomaly detection in the work of Zhu et al. [<xref ref-type="bibr" rid="CR96">96</xref>] where the LSTM layers are used in the discriminator to extract temporal information from the data, while the GAN architecture provides the system with the ability to extract the most important features of the data. Training for detecting anomalies in the data has two phases. The first phase, known as the training phase, is a standard GAN training in which the discriminator learns how to distinguish between real and synthetic data. In the second phase, the so-called testing phase, the training consists of a feature extraction that generates and embedding of the dataset samples, these features are then reconstructed by the generator and compared with the original data, the task of the discriminator is to distinguish the real and the reconstructed data, which is anomalous. This research tested its results using two different datasets, electrocardiogram (ECG) data with a window of 96 data values that is training to detect anomalous cases and a dataset with the statistics of taxi traffic in New York City, with 48 points each data sample.</p><p id="Par98">The work presented by Shi et al. [<xref ref-type="bibr" rid="CR97">97</xref>] uses the GAN architecture to generate sequences of faulty data from two different types. Different models are trained for each type. The generator and discriminator of each GAN are made of a many-to-many LSTM model that processes the voltage signal data and the sampling length of each step of the sequence. In this way, the generator output is composed of two vectors, one for the voltage and the other for the length, while the discriminator processes these data and its output is generated by averaging the classification of each step and generating a unique binary output.</p></sec><sec id="Sec29"><title>Convolutional GAN applied to the time series domain</title><p id="Par99">In order to apply GAN to replicate time series, one of the most popular techniques used is to treat the time data as an image. Different approximations have been used in this field, where the focus is on how to transform the data into an image format, rather than adapting the GAN architecture to process time series information. One of the main advantages of this technique is that it does not have to deal with the design of GAN, which is a complex process due to the particularities of the architecture. The adaptation of the original data to an image is different in each case. Different works published during the last years will be reviewed in order to study different approximations to this transformation.</p><p id="Par100">An example of this use is the one proposed with SpecGAN [<xref ref-type="bibr" rid="CR61">61</xref>] which tries to operate with sound spectrograms that represent audio samples. This approach uses deep convolutional GAN (DCGAN) [<xref ref-type="bibr" rid="CR44">44</xref>] as the main algorithm for DA, but prior to that, it processes the audio signal to generate images for each audio track. The process of transforming audio into image “can be approximately inverted” in the author’s own words. First, the Fourier transformation is applied to each audio to generate a matrix of the frequencies of the data. Then, the scale of the data is adapted logarithmically and normalised to a normal distribution for a better understanding. Finally, the images are clipped to 3 standard deviations and rescaled within the <inline-formula id="IEq26"><alternatives><mml:math id="IEq26_Math"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><tex-math id="IEq26_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[-1, 1]$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq26.gif"/></alternatives></inline-formula> range. In particular, the 16384 points of each sample are converted into a 128x128 pixel image. As mentioned above, this process is reversible, so once the new data are generated using deep convolutional GAN (DCGAN) they can be transformed to audio data using the reverse process. One advantage of using this process is that it opens up the possibility of comparing different audio generation algorithms treating the results as images; in the original paper, the results of the SpecGAN are compared with the WaveGAN, which is proposed in the same article.</p><p id="Par101">The work presented by Jiang et al. [<xref ref-type="bibr" rid="CR98">98</xref>] uses the GANomaly architecture [<xref ref-type="bibr" rid="CR104">104</xref>] to process different time series data. The GANomaly is used for anomaly detection in industrial tasks; it introduces a feature extraction into the network, which pre-processes the input data of both the generator and the generator. The generator is composed of an encoder–decoder–encoder network, which makes it possible to learn the latent representations generated by the feature extraction part. Regarding the data used for training, rolling bearing data was used to detect anomalies, collected at 12–48 kHz in two different datasets. The collected data is converted from the time series domain into images by generating a spectrogram, thus converting the time series data into the image domain. In particular, they used Bearing Data from Case Western Reserve University.<xref ref-type="fn" rid="Fn1">1</xref></p><p id="Par102">The Traffic Sensor Data Imputation GAN (TSDIGAN) [<xref ref-type="bibr" rid="CR99">99</xref>] is an architecture proposed for missing data reconstruction. In particular, traffic data is used consisting on 104,544 traffic records. In this work, GAN is in charge of generating synthetic data that fill in the missing data gaps with realistic information. The approach used in the paper to treat time series traffic data is to transform them into an image format using the proposed method called Gramian Angular Summation Field (GASF). The Gramian Angular Summation Field (GASF) algorithm is focused on maintaining the time dependency of the traffic data; this algorithm is capable of transforming the data into a matrix by representing each time data point to a polar coordinate system within the range <inline-formula id="IEq27"><alternatives><mml:math id="IEq27_Math"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math><tex-math id="IEq27_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[-1, 1]$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq27.gif"/></alternatives></inline-formula>. Then, each point is encoded by its angular cosine and radius. This generates a matrix with the temporal correlation between each point, which is then fed to the networks. Finally, the data are processed using a convolutional-based GAN that uses its generator to generate new data and reconstruct the missing values.</p></sec><sec id="Sec30"><title>1D convolutional GAN</title><p id="Par103">Temporal cnn are cnn [<xref ref-type="bibr" rid="CR105">105</xref>] where the convolutional operation is calculated in 1D instead of traditional 2D convolution. These networks adapt the geometric information captured by the 2D cnn to a temporal domain, lowering the dimensions of the learnt filters to 1D. These networks have been used in works such as [<xref ref-type="bibr" rid="CR15">15</xref>] to classify data from temporal series.</p><p id="Par104">In the recent years, different GAN architectures have been proposed that use these 1D convolutional layers as a base, replacing the traditional 2D convolutions of GAN applied to computer vision tasks. In this approximation, it is very straightforward to adapt traditional GAN architectures to the time series domain, making it very plausible for use in time series-related tasks.</p><p id="Par105">The temporal-conditional GAN (T-CGAN) [<xref ref-type="bibr" rid="CR106">106</xref>] is a GAN architecture based on the idea of transforming the Conditional GAN (CGAN) [<xref ref-type="bibr" rid="CR107">107</xref>] architecture to time series domain by replacing the 2D convolutional layers with the 1D convolutional layers. The performance of the model was validated using one synthetic and three real-world datasets. The synthetic data was constructed using sine waves and sawtooth waves. The other datasets consisted of: astronomical light curves of 1024 points per sample, a power demand dataset of samples of 24 points, and an electrocardiogram (ECG) dataset with 96 points for each sample.</p><p id="Par106">Emotional GAN [<xref ref-type="bibr" rid="CR108">108</xref>] also applies these 1D convolutional layers to create a GAN architecture to augment an electrocardiogram (ECG) dataset improving the classification of support vector machine (SVM) and random forest models when classifying the emotions of each subject. This work used different datasets varying their frequency rate between 256 and 2048 Hz.</p><p id="Par107">The work published by Donahue et al. [<xref ref-type="bibr" rid="CR61">61</xref>] presents the WaveGAN architecture, which is based on the application of 1D convolutional layers to sound data. This GAN uses the deep convolutional GAN (DCGAN) architecture, but changes the convolutions to 1D. As suggested, these 1D convolutions should have a wider receptive field respecting the 2D convolutions of image processing; this is based on the particularities of the audio data, in which each cycle of a musical note sampled at 16 kHz may take 36 samples to complete. Therefore, it is necessary to use wider filters to capture the distanced temporal dependencies of the data. This feature of the sound data was previously taken into account with solutions such as the dilated convolutions proposed in WaveNet [<xref ref-type="bibr" rid="CR60">60</xref>]. This enlargement of the receptive field is compensated for by reducing one dimension, changing from 5x5 convolutions to 25 1-dimensional convolutions and maintaining the number of parameters of the network. The rest of the architecture maintains the standard GAN architecture, allowing the synthesis of audio tracks with unsupervised training GAN.</p><p id="Par108">This approximation has also been followed by Sabir et al. [<xref ref-type="bibr" rid="CR109">109</xref>] for augmenting DC current signals, using samples of current signal with a frequency of 100 Hz during 16 s. The proposed work used the deep convolutional GAN (DCGAN) architecture as a base and changes the original convolutions to 1D convolutions. In particular, this work has two different GANs, one that generates healthy signals and the other is in charge of generating faulty data.</p><p id="Par109">There are also hybrid implementations that combine 1D convolutions with other techniques, such as in [<xref ref-type="bibr" rid="CR96">96</xref>] where LSTM-GAN is proposed. This architecture combines the LSTM cell in the discriminator network with the 1D convolutional layers used in the generator network.</p></sec><sec id="Sec31"><title>Time series Generative Adversarial Networks (TimeGAN)</title><p id="Par110">The TimeGAN architecture [<xref ref-type="bibr" rid="CR55">55</xref>] tries to implement a GAN model to perform DA on time series data, but differentiates itself from other previous alternatives by adding a new loss function that tries to capture the stepwise dependencies of the data. Previous implementations of GAN in data sequences were based on the use of recurrent networks for the generator and discriminator networks of GAN [<xref ref-type="bibr" rid="CR56">56</xref>, <xref ref-type="bibr" rid="CR58">58</xref>], but this approximation may not be sufficient to accurately replicate the temporal transitions of the original data.</p><p id="Par111">This work divides the data features into two different classes: static features and temporal features. Static features <inline-formula id="IEq28"><alternatives><mml:math id="IEq28_Math"><mml:mi mathvariant="bold">S</mml:mi></mml:math><tex-math id="IEq28_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\textbf {S}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq28.gif"/></alternatives></inline-formula> do not vary over time, e.g., gender, while temporal features <inline-formula id="IEq29"><alternatives><mml:math id="IEq29_Math"><mml:mi mathvariant="bold">X</mml:mi></mml:math><tex-math id="IEq29_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\textbf {X}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq29.gif"/></alternatives></inline-formula> change. In other words, the static features are characteristics of the data that are not directly related to the time series sample but capture important properties of it.</p><p id="Par112">The TimeGAN is tested in four different datasets. First, a synthetic dataset is generated using sinusoidal sequences with an average length of 24 points. A stock prices time series dataset from 2004 to 2019 is used with an average length of 24 days. Third, a dataset of energy prediction with samples of 24 h of length on average is used. Finally, a medical lung cancer events dataset is used with an average of 58 events per sample.</p><p id="Par113">The proposed architecture adds, in addition to the generator and discriminator networks, two new networks: the encoder and recovery networks. These networks are responsible for embedding the input data in the latent space, as an autoencoder [<xref ref-type="bibr" rid="CR110">110</xref>] would traditionally do. This system learns the so-called embedding and recovery functions to take the static and temporal features into two separate latent codes <inline-formula id="IEq30"><alternatives><mml:math id="IEq30_Math"><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math><tex-math id="IEq30_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\textbf {h}}}_{s}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq30.gif"/></alternatives></inline-formula> and <inline-formula id="IEq31"><alternatives><mml:math id="IEq31_Math"><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq31_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\textbf {h}}}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq31.gif"/></alternatives></inline-formula> and recover the input information <inline-formula id="IEq32"><alternatives><mml:math id="IEq32_Math"><mml:mi mathvariant="bold">S</mml:mi></mml:math><tex-math id="IEq32_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\textbf {S}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq32.gif"/></alternatives></inline-formula> and <inline-formula id="IEq33"><alternatives><mml:math id="IEq33_Math"><mml:mi mathvariant="bold">X</mml:mi></mml:math><tex-math id="IEq33_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\textbf {X}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq33.gif"/></alternatives></inline-formula>.</p><p id="Par114">The generator and discriminator parts of the network do the same work as they would do in a traditional GAN, using the discriminator to differentiate between real and synthetic samples. But in this case, the generator generates the data for the embedding space, while the discriminator also takes this embedding as input for its classification.</p><p id="Par115">The main innovation of TimeGAN is implemented in the generator, which, in addition to the normal generation of synthetic samples, is also forced to learn the stepwise dependencies of the data. To do so, the generator receives as input the synthetic embedding <inline-formula id="IEq34"><alternatives><mml:math id="IEq34_Math"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="IEq34_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\textbf {h}}}_{s}, {{\textbf {h}}}_{t-1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq34.gif"/></alternatives></inline-formula> and computes the next vector <inline-formula id="IEq35"><alternatives><mml:math id="IEq35_Math"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="IEq35_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\textbf {h}}}_{s}, {{\textbf {h}}}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq35.gif"/></alternatives></inline-formula>. This new function is learned by a new supervised loss function that compares the generator forecast with the real data.</p><p id="Par116">Therefore, the training objectives of the presented architecture can be divided into 3 different loss functions.<list list-type="bullet"><list-item><p id="Par117"><italic>Reconstruction loss</italic> (<inline-formula id="IEq36"><alternatives><mml:math id="IEq36_Math"><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math><tex-math id="IEq36_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {L}}_{R}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq36.gif"/></alternatives></inline-formula>) This loss is used in the reversible mapping part of the network, composed of the encoder and recovery networks. The length T of each sequence is also a random variable, the distribution of which, for notational convenience, it will be absorbed into distribution p. It is given by: <disp-formula id="Equ13"><label>13</label><alternatives><mml:math display="block" id="Equ13_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi mathvariant="bold">s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mfenced close="]" open="["><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo>-</mml:mo></mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:msub><mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:msub><mml:mfenced close="∥" open="∥"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ13_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathcal {L}}_{R}={\mathbb {E}}_{{{\textbf {s}}}, {{\textbf {x}}}_{1: T} \sim p}\left[ \Vert {{\textbf {s}}}-\tilde{{{\textbf {s}}}}\Vert _{2}+\sum _{t}\left\| {{\textbf {x}}}_{t}-\tilde{{{\textbf {x}}}}_{t}\right\| _{2}\right] , \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ13.gif"/></alternatives></disp-formula> where the tilde denotes the reconstructed samples and <inline-formula id="IEq37"><alternatives><mml:math id="IEq37_Math"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math><tex-math id="IEq37_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$||\cdot ||$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq37.gif"/></alternatives></inline-formula> stands for the standard (Euclidean) norm.</p></list-item><list-item><p id="Par118"><italic>Unsupervised loss</italic> (<inline-formula id="IEq38"><alternatives><mml:math id="IEq38_Math"><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:math><tex-math id="IEq38_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {L}}_{U}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq38.gif"/></alternatives></inline-formula>) In TimeGAN, the generator has two different types of input during training. First, the generator receives synthetic embeddings <inline-formula id="IEq39"><alternatives><mml:math id="IEq39_Math"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi mathvariant="script">S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="IEq39_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{h}_{{\mathcal {S}}}, \hat{h}_{1:t-1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq39.gif"/></alternatives></inline-formula>, which are autoregressive, to generate the next synthetic vector <inline-formula id="IEq40"><alternatives><mml:math id="IEq40_Math"><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq40_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{h}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq40.gif"/></alternatives></inline-formula>. In this process, the gradients are computed under unsupervised loss. This is as expected, that is, to allow maximising D or minimising G the probability of providing the correct classifications <inline-formula id="IEq41"><alternatives><mml:math id="IEq41_Math"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi mathvariant="script">S</mml:mi></mml:msub></mml:math><tex-math id="IEq41_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{y}_{{\mathcal {S}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq41.gif"/></alternatives></inline-formula>, <inline-formula id="IEq42"><alternatives><mml:math id="IEq42_Math"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq42_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{y}_{1:T}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq42.gif"/></alternatives></inline-formula> for both training data <inline-formula id="IEq43"><alternatives><mml:math id="IEq43_Math"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="IEq43_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\textbf {h}}}_{s}, {{\textbf {h}}}_{1:T}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq43.gif"/></alternatives></inline-formula> and synthetic output <inline-formula id="IEq44"><alternatives><mml:math id="IEq44_Math"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi mathvariant="script">S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="IEq44_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{h}_{{\mathcal {S}}}, \hat{h}_{1:T}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq44.gif"/></alternatives></inline-formula> from the generator. The unsupervised loss function is the equivalent loss function of a normal GAN that attempts to distinguish real and fake samples. It is given by: <disp-formula id="Equ14"><label>14</label><alternatives><mml:math display="block" id="Equ14_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi mathvariant="normal">U</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>log</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi mathvariant="script">S</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mo>log</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi mathvariant="bold">s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo>log</mml:mo><mml:mfenced close=")" open="("><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi mathvariant="script">S</mml:mi></mml:msub></mml:mfenced><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mo>log</mml:mo><mml:mfenced close=")" open="("><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mfenced><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ14_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathcal {L}}_{{\rm U}}={\mathbb {E}}_{{\rm s}, {\textbf{x}}_{1: T} \sim p}[\log y_{{\mathcal {S}}}+\sum _{t} \log y_{t}]+{\mathbb {E}}_{{\textbf{s}}, {\textbf{x}}_{1: T} \sim \hat{p}}[\log \left( 1-\hat{y}_{{\mathcal {S}}}\right) +\sum _{t} \log \left( 1-\hat{y}_{t}\right) ] \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ14.gif"/></alternatives></disp-formula> where <inline-formula id="IEq45"><alternatives><mml:math id="IEq45_Math"><mml:msub><mml:mi>y</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math><tex-math id="IEq45_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_{s}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq45.gif"/></alternatives></inline-formula> and <inline-formula id="IEq46"><alternatives><mml:math id="IEq46_Math"><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq46_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq46.gif"/></alternatives></inline-formula> are the classification of the discriminator for static and temporal features and the accent denotes synthetic samples.</p></list-item><list-item><p id="Par119"><italic>Supervised loss</italic> (<inline-formula id="IEq47"><alternatives><mml:math id="IEq47_Math"><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math><tex-math id="IEq47_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal {L}}_{S}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq47.gif"/></alternatives></inline-formula>) To encourage the generator to learn the conditional transitions of the data, this function is designed that measures the similarity between the real and the synthetic samples created by the generator when applying the forecasting. The loss function is denoted as follows: <disp-formula id="Equ15"><label>15</label><alternatives><mml:math display="block" id="Equ15_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="script">L</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi mathvariant="bold">s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mfenced close="]" open="["><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:msub><mml:mfenced close="∥" open="∥"><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi mathvariant="script">X</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi mathvariant="script">S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mfenced></mml:mfenced><mml:mn>2</mml:mn></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ15_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {\mathcal {L}}_{{\rm S}}={\mathbb {E}}_{{\textbf{s}}, {\textbf{x}}_{1: T} \sim p}\left[ \sum _{t}\left\| {\textbf{h}}_{t}-g_{\mathcal {X}}\left( {\textbf{h}}_{{\mathcal {S}}}, {\textbf{h}}_{t-1}, {\textbf{z}}_{t}\right) \right\| _{2}\right] \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ15.gif"/></alternatives></disp-formula> where <inline-formula id="IEq48"><alternatives><mml:math id="IEq48_Math"><mml:msub><mml:mi>g</mml:mi><mml:mi mathvariant="script">X</mml:mi></mml:msub></mml:math><tex-math id="IEq48_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g_{\mathcal {X}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq48.gif"/></alternatives></inline-formula> denotes the sample synthesised by the generator, taking as input the embedded anterior sample <inline-formula id="IEq49"><alternatives><mml:math id="IEq49_Math"><mml:mrow><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mi mathvariant="script">S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold">z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="IEq49_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\textbf{h}}_{{\mathcal {S}}}, {\textbf{h}}_{t-1}, {\textbf{z}}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq49.gif"/></alternatives></inline-formula>. An overview of the learning scheme of TimeGAN can be seen in Fig. <xref rid="Fig8" ref-type="fig">8</xref>.</p></list-item></list><fig id="Fig8"><label>Fig. 8</label><caption xml:lang="en"><p>TimeGAN architecture. Extracted from [<xref ref-type="bibr" rid="CR55">55</xref>]</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/521_2023_8459_Fig8_HTML.png" id="MO24"/></fig></p></sec><sec id="Sec32"><title>Conditional Sig-Wasserstein GAN</title><p id="Par120">The Conditional Signature Wasserstein GAN [<xref ref-type="bibr" rid="CR111">111</xref>] was proposed as a method of maintaining long temporal dependencies in time series data. Regarding the previous models, this architecture is able to outperform previous models such as TimeGAN providing better synthetic data for DA.</p><p id="Par121">In this paper, it is proposed a new metric for evaluating the properties of a data stream, providing a description of the sample. This metric is used in the discriminator (D) network to differentiate real and synthetic samples. The Sig-Wasserstein metric measures the path space of the data using the Wasserstein distance. In this case, the main strength of this method is that it simplifies the training by replacing a neural network discriminator (D) for a linear regression using the Sig-Wasserstein distance. This process eliminates the cost of approximating a discriminator (D).</p><p id="Par122">The results of the model are tested using different stock market datasets to predict the close prices and the volatility of different actives.</p><p id="Par123">As a Generator (G) network, it is used an AR-FNN generator, which is able of capturing temporal dependencies of time series data.</p><p id="Par124">Figure <xref rid="Fig9" ref-type="fig">9</xref> shows a scheme of the training process of the Conditional Sig-Wasserstein GAN. As it can be seen, the real and fake samples can be distinguished by using the Sig-Wasserstein metric.<fig id="Fig9"><label>Fig. 9</label><caption xml:lang="en"><p>Conditional Sig-Wasserstein GAN training. Extracted from [<xref ref-type="bibr" rid="CR111">111</xref>]</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/521_2023_8459_Fig9_HTML.png" id="MO25"/></fig></p></sec></sec><sec id="Sec33"><title>Data Augmentation (DA) based on Dynamic Time Warping (DTW)</title><sec id="Sec34"><title>Dynamic Time Warping (DTW) Barycenter Averaging</title><p id="Par125">Dynamic time warping (DTW) [<xref ref-type="bibr" rid="CR112">112</xref>] is a classical algorithm that measures the similarity between two data sequences. This method was used as a base in [<xref ref-type="bibr" rid="CR113">113</xref>], where the effectiveness of the new generated synthetic time series data was evaluated using augmented training sets for time series classification through the 1-NN classifier in conjunction with dynamic time warping (DTW). In particular, 85 datasets of the UCR archive [<xref ref-type="bibr" rid="CR62">62</xref>] were used in the experiments. The idea is to manipulate the distribution manifold to generate infinite new samples of data. They achieve this by changing the weights of a set of time series, such as the set <inline-formula id="IEq50"><alternatives><mml:math id="IEq50_Math"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mfenced close=")" open="("><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfenced><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mfenced close=")" open="("><mml:msub><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mfenced></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq50_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D=\left\{ \left( T_{1}, w_{1}\right) , \ldots ,\left( T_{N}, w_{n}\right) \right\}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq50.gif"/></alternatives></inline-formula> is embedded in a space <italic>E</italic> and the average of dynamic time warping (DTW) is denoted as follows:<disp-formula id="Equ16"><label>16</label><alternatives><mml:math display="block" id="Equ16_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>arg</mml:mo><mml:mo movablelimits="true">min</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mrow></mml:mover><mml:mo>∈</mml:mo><mml:mi>E</mml:mi><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>w</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msup><mml:mtext>DTW</mml:mtext><mml:mn>2</mml:mn></mml:msup><mml:mfenced close=")" open="("><mml:mover accent="true"><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mrow></mml:mover><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equ16_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \arg \min {\bar{T}} \in E \sum _{i=1}^{N} w_{i} \cdot \text {DTW}^{2}\left( {\bar{T}}, T_{i}\right) \end{aligned}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_Equ16.gif"/></alternatives></disp-formula>where <italic>w</italic> is the weight of each sample.</p><p id="Par126">To calculate <inline-formula id="IEq51"><alternatives><mml:math id="IEq51_Math"><mml:mover accent="true"><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mrow></mml:mover></mml:math><tex-math id="IEq51_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bar{T}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq51.gif"/></alternatives></inline-formula>, they use the expectation–maximisation algorithm and to decide the weight values, three different methods are proposed:<list list-type="bullet"><list-item><p id="Par127"><italic>Average all</italic> This method generates the weight vector values using a flat Dirichlet distribution. The main problem with this method is that it tends to fill in data spaces where it should not.</p></list-item><list-item><p id="Par128"><italic>Average selected</italic> This method focusses on selecting a subset of close samples. Thus, it prevents empty spaces from being filled with information because the subsets of samples are close together in the manifold.</p></list-item><list-item><p id="Par129"><italic>Average selected with distance</italic> The difference between this method and the previous one is that this method calculates the relative distance between the near samples of data.</p></list-item></list></p></sec><sec id="Sec35"><title>Suboptimal element alignment averaging</title><p id="Par130">SuboPtimAl Warped time series geNEratoR (SPAWNER) [<xref ref-type="bibr" rid="CR114">114</xref>] is a DA method based on the dynamic time warping (DTW) algorithm [<xref ref-type="bibr" rid="CR112">112</xref>]. The dynamic time warping (DTW) algorithm is used in this DA method to align different multidimensional signals <inline-formula id="IEq52"><alternatives><mml:math id="IEq52_Math"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq52_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X_{1}, X_{2}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq52.gif"/></alternatives></inline-formula>, giving the so-called <italic>warping path</italic><italic>W</italic> which is a sequence of points that minimises the distance between these input signals. The results of the model were tested using two different electrocardiogram (ECG) datasets.</p><p id="Par131">SPAWNER algorithm takes the warping path calculated with the dynamic time warping (DTW) algorithm and introduces a new random element to the sequence, known as <inline-formula id="IEq53"><alternatives><mml:math id="IEq53_Math"><mml:msub><mml:mi>w</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math><tex-math id="IEq53_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_{p}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq53.gif"/></alternatives></inline-formula>. This new point is generated using a uniformly distributed random number within the range (0, 1). Then, the new optimal path is forced to contain the new generated element, obtaining the new warping paths <inline-formula id="IEq54"><alternatives><mml:math id="IEq54_Math"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math><tex-math id="IEq54_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{1}^{*}, W_{2}^{*}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq54.gif"/></alternatives></inline-formula>. Both sequences are aligned using a parameter called <inline-formula id="IEq55"><alternatives><mml:math id="IEq55_Math"><mml:mi>ξ</mml:mi></mml:math><tex-math id="IEq55_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\xi$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq55.gif"/></alternatives></inline-formula>, which reduces the flexibility of the path. Finally, both warp paths are concatenated, generating the path <inline-formula id="IEq56"><alternatives><mml:math id="IEq56_Math"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:math><tex-math id="IEq56_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_{1,2}^{*}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq56.gif"/></alternatives></inline-formula> from which the new time series signals <inline-formula id="IEq57"><alternatives><mml:math id="IEq57_Math"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math><tex-math id="IEq57_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{1}^{*}, x_{2}^{*}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq57.gif"/></alternatives></inline-formula> are obtained.</p><p id="Par132">It is observed that for some multivariate signals, this variation of DA is not enough. Therefore, a random variance is also applied to each point of the signal using a normal distribution such as <inline-formula id="IEq58"><alternatives><mml:math id="IEq58_Math"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="IEq58_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x^{*} \sim N(\mu , \sigma ^{2}),\mu =0.5(x_{1}^{*}+x_{2}^{*}),\sigma =0.05|x_{1}^{*}-x_{2}^{*}|$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="521_2023_8459_Article_IEq58.gif"/></alternatives></inline-formula>.</p><p id="Par133">The use of different alignment methods for text or image data is also proposed, instead of using dynamic time warping (DTW) which is proposed when signals are used. Therefore, the overall algorithm can be easily translated to other domains, with the need for an alignment method between two samples.</p></sec></sec></sec><sec id="Sec36" sec-type="discussion"><title>Discussion</title><p id="Par134">Data augmentation algorithms in the time series domain are really important for improving the available datasets, whose creation is not always easy. In general terms, all the methods presented in this work are algorithms specifically designed for data augmentation (DA) in time series but, in other cases, they are usually adaptations of architectures that were originally designed for other domains, such as image processing. However, the GAN-based algorithms themselves have their beginnings in the field of imaging and have gradually been integrated into other areas.</p><p id="Par135">Regarding the length of the data that each algorithm can process, it should be noted the variety of sizes and dataset types of the different reviewed researches. One of the main strengths that artificial intelligence algorithms have is that, due to the fact that their learning is based on the particular data of each application, they can operate with almost any source of data. This leads to a great variation in the size of the time series windows that most of the algorithms use. In some cases, the data are even processed to treat it as an image, which is symptomatic of the flexibility of DL algorithms. In the case of traditional algorithms, they can also process any length of data if it is properly adapted.</p><p id="Par136">In this section, it will be analysed the main advantages and disadvantages of each type of algorithm.</p><sec id="Sec37"><title>Advantages</title><p id="Par137">Traditional algorithms are widely developed and studied so that their results can be fairly compared. In DA, they allow you to work by modifying the examples already present, which allows you to control variations. In addition, the simplicity of the algorithms themselves by greatly reducing the number of hyperparameters to be configured results in less time to set them up and the need for less data to train them.</p><p id="Par138">Second, the VAE generative algorithms allow one to control to a greater extent the variability of the generated data by directly influencing the standard deviation of the latent distribution of the original dataset. This feature allows, among all algorithms, the greatest control of the variability of the generated data. VAE is commonly used for anomaly detection cases due to its better performance.</p><p id="Par139">Finally, the most current generative models are a breakthrough in the area due to their great results. GANs, like VAEs, allow synthetic data to be generated and, at the cost of losing some control over data generation, they are algorithms capable of much better generalisation. All this is due to the training scheme itself, which allows GANs models to learn the distribution that follows the original dataset and, through it, generate synthetic data according to the distribution of the dataset.</p><p id="Par140">Furthermore, since GANs are relatively recent algorithms, they benefit from greater attention from the scientific community, which means that there is more recent research focused on improving their results than other algorithms.</p></sec><sec id="Sec38"><title>Disadvantages</title><p id="Par141">In terms of limitations, the use of traditional algorithms is quite limited because they are based on making modifications to elements of the real dataset. Therefore, they can often produce invalid examples. In general, they are limited to generate examples of lower quality and never to generating new elements. Normally, the reviewed algorithms require a pre-processing phase to normalise the input data, which can lead to more complex algorithms involving previous steps. Otherwise, the learning of the artificial neural network (ANN) would be inefficient [<xref ref-type="bibr" rid="CR115">115</xref>, <xref ref-type="bibr" rid="CR116">116</xref>]</p><p id="Par142">Although VAEs are algorithms capable of generating synthetic data, as opposed to traditional algorithms that only modify the original data, new neural network (NN) models such as GANs have mitigated their use in the field because by nature they are capable of generating fewer data than the most current generative networks. Despite this, because they can very precisely control the variability of the generated data, there are fields of application that still continue to use them.</p><p id="Par143">Regarding GAN, it can be said that despite their great results, there are certain difficulties that slow down their progress. GANs are by far the most complex models currently available and, due to the particularities of the way they are trained, they are extremely difficult to train and obtain results.</p><p id="Par144">GAN are one of the most difficult models to train. The main problems that these networks suffer are mode collapse [<xref ref-type="bibr" rid="CR117">117</xref>, <xref ref-type="bibr" rid="CR118">118</xref>], instability [<xref ref-type="bibr" rid="CR119">119</xref>], convergence evaluation [<xref ref-type="bibr" rid="CR120">120</xref>] and evaluation metrics.</p><p id="Par145">Due to the GAN instability problems [<xref ref-type="bibr" rid="CR119">119</xref>, <xref ref-type="bibr" rid="CR121">121</xref>, <xref ref-type="bibr" rid="CR122">122</xref>], most of the time a great portion of the samples synthesised by the Generator (G) network lack of quality in certain aspects as the emergence of image artefacts [<xref ref-type="bibr" rid="CR123">123</xref>]. In addition, the lack of convergence evaluation of the networks makes it hard to detect when the generated data is of high quality. Therefore, one of the main problems of GAN is that their results are not fully reliable.</p></sec><sec id="Sec39"><title>Open issues and challenges</title><p id="Par146">Some authors [<xref ref-type="bibr" rid="CR124">124</xref>] tend to differentiate between DA and data generation due to the great advances made in neural network (NN) models. Traditional algorithms are always framed in the area of DA since the data they produce are always based on existing data; as an open problem, they generate less varied data but more control over what is generated. Furthermore, data generation algorithms produce new data so aggressively that much of the generated data is not possible, degenerating the quality of the augmented dataset [<xref ref-type="bibr" rid="CR125">125</xref>].</p><p id="Par147">Unlike the limitation of the scarcity of data augmented with traditional models, AEs and VAEs are born to cover the deficiency of the generated data. In [<xref ref-type="bibr" rid="CR126">126</xref>], they demonstrate the capability of generative neural network (NN) models to add more diversity to the dataset. In addition, traditional algorithms tend not to be flexible in taking a trained model and applying it to another problem, forcing a rethink of the algorithm. Neural networks, in this aspect, tend to be more flexible, and able to use the same trained model in different problems. In [<xref ref-type="bibr" rid="CR106">106</xref>], T-CGAN (Sect. <xref rid="Sec30" ref-type="sec">6.3.4</xref>) where different datasets are exposed with the same architecture, or in [<xref ref-type="bibr" rid="CR96">96</xref>], LSTM-GAN that uses as inputs datasets as disparate as one made of electrocardiograms and another comprising taxi statistics.</p><p id="Par148">However, although generative models offer great advantages, GANs have significant additional problems, especially in training. Typical problems such as modal collapse, Nash equilibria, gradient vanishing or instability are suffered in every training of these models, making their optimisation a very complex process [<xref ref-type="bibr" rid="CR127">127</xref>, <xref ref-type="bibr" rid="CR128">128</xref>].</p><p id="Par149">In general, all generative models share the same open problem that often complicates their validation process. As shown in Sect. <xref rid="Sec9" ref-type="sec">5</xref>, despite the existence of some evaluation metrics, there is no consensus in the community on which should be used. For example, in [<xref ref-type="bibr" rid="CR55">55</xref>] authors use empirical evaluation for data generation, but for visualisation they use PCA and a discriminative and a predictive model to see how they have improved after adding the synthetic images. In [<xref ref-type="bibr" rid="CR61">61</xref>], authors propose the Inception Score, a measure of Nearest Neighbour and empirical measurement by humans, and in [<xref ref-type="bibr" rid="CR99">99</xref>], traditional measures of deep learning (MAE, RMSE and MRE) to compare the generation of future values are used. If the focus is also put on GAN models, it must be taken into account that, to this problem, there is no method for these architectures to define what the stop condition is in a training.</p></sec></sec><sec id="Sec40" sec-type="conclusions"><title>Conclusion</title><p id="Par150">Due to the significant evolution that DA has undergone in recent years, more and more fields are emerging in which to apply and improve the results. This article is focused on giving a comprehensive overview of the main algorithms used for data augmentation (DA) in the field of time series. The review is organised in a taxonomy, consisting of basic and advanced approaches, where it is summarised representative methods of each algorithm (traditional, VAEs and GANs) comparing them empirically, disaggregate by application areas and highlight advantages/disadvantages for future research.</p></sec></body><back><ack><title>Acknowledgements</title><p>This work was supported by the Comunidad de Madrid under Convenio Plurianual with the Universidad Politécnica de Madrid in the actuation line of Programa de Excelencia para el Profesorado Universitario. The third-named author has been partially supported by the Madrid Government (Comunidad de Madrid—Spain) under the Multiannual Agreement with the Universidad Complutense de Madrid in the line Research Incentive for Young PhDs, in the context of the V PRICIT (Regional Programme of Research and Technological Innovation) through the project PR27/21-029 and by the Ministerio de Ciencia e Innovación Project PID2021-124440NB-I00 (Spain).</p></ack><sec><title>Funding</title><p>Open Access funding provided thanks to the CRUE-CSIC agreement with Springer Nature.</p></sec><sec sec-type="data-availability"><title>Data availability</title><p>No datasets were generated or analysed during the current study, and all figures are taken from the papers listed in the references or are generated by us.</p></sec><sec sec-type="ethics-statement"><title>Declarations</title><sec id="FPar1" sec-type="COI-statement"><title>Conflict of interest</title><p id="Par151">All authors declare that there is no conflict of interest in this paper.</p></sec></sec><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duong</surname><given-names>H-T</given-names></name><name><surname>Nguyen-Thi</surname><given-names>T-A</given-names></name></person-group><article-title xml:lang="en">A review: preprocessing techniques and data augmentation for sentiment analysis</article-title><source>Comput Soc Netw</source><year>2021</year><volume>8</volume><issue>1</issue><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">4193379</pub-id></mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felix</surname><given-names>EA</given-names></name><name><surname>Lee</surname><given-names>SP</given-names></name></person-group><article-title xml:lang="en">Systematic literature review of preprocessing techniques for imbalanced data</article-title><source>IET Softw</source><year>2019</year><volume>13</volume><issue>6</issue><fpage>479</fpage><lpage>496</lpage></mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">Goodfellow IJ, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courville A, Bengio Y (2014) Generative adversarial networks</mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="other">Lecun Y (1987) PhD Thesis: Modeles connexionnistes de L’apprentissage (connectionist Learning Models). Universite P. et M. Curie (Paris 6)</mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="other">Kingma DP, Welling M (2014) Auto-encoding variational bayes</mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navidan</surname><given-names>H</given-names></name><name><surname>Moshiri</surname><given-names>PF</given-names></name><name><surname>Nabati</surname><given-names>M</given-names></name><name><surname>Shahbazian</surname><given-names>R</given-names></name><name><surname>Ghorashi</surname><given-names>SA</given-names></name><name><surname>Shah-Mansouri</surname><given-names>V</given-names></name><name><surname>Windridge</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Generative adversarial networks (gans) in networking: a comprehensive survey &amp; evaluation</article-title><source>Comput Netw</source><year>2021</year><volume>194</volume></mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">Rigaki M, Garcia S (2018) Bringing a gan to a knife-fight: adapting malware communication to avoid detection. In: 2018 IEEE security and privacy workshops (SPW), pp 70–75. IEEE</mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mozo</surname><given-names>A</given-names></name><name><surname>González-Prieto</surname><given-names>Á</given-names></name><name><surname>Pastor</surname><given-names>A</given-names></name><name><surname>Gómez-Canaval</surname><given-names>S</given-names></name><name><surname>Talavera</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Synthetic flow-based cryptomining attack generation through generative adversarial networks</article-title><source>Sci Rep</source><year>2022</year><volume>12</volume><issue>1</issue><fpage>1</fpage><lpage>27</lpage></mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Farahat</surname><given-names>A</given-names></name><name><surname>Gupta</surname><given-names>C</given-names></name><name><surname>Zheng</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Deep time series models for scarce data</article-title><source>Neurocomputing</source><year>2021</year><volume>456</volume><fpage>504</fpage><lpage>518</lpage></mixed-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="other">Cao L, Horn S, von Ehrenheim V, Anselmo Stahl R, Landgren H (2022) Simulation-informed revenue extrapolation with confidence estimate for scaleup companies using scarce time-series data. In: Proceedings of the 31st ACM international conference on information &amp; knowledge management, pp. 2954–2963</mixed-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhowmik</surname><given-names>AK</given-names></name><name><surname>Cabral</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Spatially shifting temporal points: estimating pooled within-time series variograms for scarce hydrological data</article-title><source>Hydrol Earth Syst Sci Discuss</source><year>2015</year><volume>12</volume><issue>2</issue><fpage>2243</fpage><lpage>2265</lpage></mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chlap</surname><given-names>P</given-names></name><name><surname>Min</surname><given-names>H</given-names></name><name><surname>Vandenberg</surname><given-names>N</given-names></name><name><surname>Dowling</surname><given-names>J</given-names></name><name><surname>Holloway</surname><given-names>L</given-names></name><name><surname>Haworth</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">A review of medical image data augmentation techniques for deep learning applications</article-title><source>J Med Imaging Radiat Oncol</source><year>2021</year><volume>65</volume><issue>5</issue><fpage>545</fpage><lpage>563</lpage></mixed-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="other">Naveed H (2021) Survey: image mixing and deleting for data augmentation. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/2106.07085" ext-link-type="uri">arXiv:2106.07085</ext-link></mixed-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Feng SY, Gangal V, Wei J, Chandar S, Vosoughi S, Mitamura T, Hovy E (2021) A survey of data augmentation approaches for nlp. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/2105.03075" ext-link-type="uri">arXiv:2105.03075</ext-link></mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iwana</surname><given-names>BK</given-names></name><name><surname>Uchida</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">An empirical survey of data augmentation for time series classification with neural networks</article-title><source>PLoS ONE</source><year>2021</year><volume>16</volume><issue>7</issue><fpage>0254841</fpage></mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Brophy E, Wang Z, She Q, Ward T (2021) Generative adversarial networks in time series: a survey and taxonomy. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/2107.11098" ext-link-type="uri">arXiv:2107.11098</ext-link></mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">Patil AG, Surve A, Gupta AK, Sharma A, Anmulwar S (2016) Survey of synthetic traffic generators. In: 2016 international conference on inventive computation technologies (ICICT), vol. 1, pp. 1–3. IEEE</mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="other">Abufadda M, Mansour K (2021) A survey of synthetic data generation for machine learning. In: 2021 22nd international arab conference on information technology (ACIT), pp. 1–7. IEEE</mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>N</given-names></name><name><surname>Xue</surname><given-names>H</given-names></name><name><surname>Shao</surname><given-names>W</given-names></name><name><surname>Zhao</surname><given-names>S</given-names></name><name><surname>Qin</surname><given-names>KK</given-names></name><name><surname>Prabowo</surname><given-names>A</given-names></name><name><surname>Rahaman</surname><given-names>MS</given-names></name><name><surname>Salim</surname><given-names>FD</given-names></name></person-group><article-title xml:lang="en">Generative adversarial networks for spatio-temporal data: a survey</article-title><source>ACM Trans Intell Syst Technol (TIST)</source><year>2022</year><volume>13</volume><issue>2</issue><fpage>1</fpage><lpage>25</lpage></mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raghunathan</surname><given-names>TE</given-names></name></person-group><article-title xml:lang="en">Synthetic data</article-title><source>Annu Rev Stat Appl</source><year>2021</year><volume>8</volume><fpage>129</fpage><lpage>140</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">4243543</pub-id></mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Wen Q, Sun L, Yang F, Song X, Gao J, Wang X, Xu H (2020) Time series data augmentation for deep learning: A survey. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/2002.12478" ext-link-type="uri">arXiv:2002.12478</ext-link></mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>B</given-names></name><name><surname>Zohren</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Time-series forecasting with deep learning: a survey</article-title><source>Phil Trans R Soc A</source><year>2021</year><volume>379</volume><issue>2194</issue><fpage>20200209</fpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">4236146</pub-id></mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Krizhevsky A, Hinton G, et al (2009) Learning multiple layers of features from tiny images</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Simonyan K, Zisserman A (2014) Very deep convolutional networks for large-scale image recognition. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1409.1556" ext-link-type="uri">arXiv:1409.1556</ext-link></mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">He K, Zhang X, Ren S, Sun J (2016) Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770–778</mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">Szegedy C, Liu W, Jia Y, Sermanet P, Reed S, Anguelov D, Erhan D, Vanhoucke V, Rabinovich A (2015) Going deeper with convolutions. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1–9</mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Huang G, Liu Z, Van Der Maaten L, Weinberger KQ (2017) Densely connected convolutional networks. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4700–4708</mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Mikołajczyk A, Grochowski M (2018) Data augmentation for improving deep learning in image classification problem. In: 2018 international interdisciplinary PhD workshop (IIPhDW), pp. 117–122. IEEE</mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lashgari</surname><given-names>E</given-names></name><name><surname>Liang</surname><given-names>D</given-names></name><name><surname>Maoz</surname><given-names>U</given-names></name></person-group><article-title xml:lang="en">Data augmentation for deep-learning-based electroencephalography</article-title><source>J Neurosci Methods</source><year>2020</year><volume>346</volume></mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashfahani</surname><given-names>A</given-names></name><name><surname>Pratama</surname><given-names>M</given-names></name><name><surname>Lughofer</surname><given-names>E</given-names></name><name><surname>Ong</surname><given-names>Y-S</given-names></name></person-group><article-title xml:lang="en">Devdan: deep evolving denoising autoencoder</article-title><source>Neurocomputing</source><year>2020</year><volume>390</volume><fpage>297</fpage><lpage>314</lpage></mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kullback</surname><given-names>S</given-names></name><name><surname>Leibler</surname><given-names>RA</given-names></name></person-group><article-title xml:lang="en">On information and sufficiency</article-title><source>Ann Math Stat</source><year>1951</year><volume>22</volume><issue>1</issue><fpage>79</fpage><lpage>86</lpage><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">0042.38403</pub-id><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">39968</pub-id></mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bandara</surname><given-names>K</given-names></name><name><surname>Hewamalage</surname><given-names>H</given-names></name><name><surname>Liu</surname><given-names>Y-H</given-names></name><name><surname>Kang</surname><given-names>Y</given-names></name><name><surname>Bergmeir</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Improving the accuracy of global forecasting models using time series data augmentation</article-title><source>Pattern Recogn</source><year>2021</year><volume>120</volume></mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Wang Z, Yan W, Oates T (2017) Time series classification from scratch with deep neural networks: a strong baseline. In: 2017 international joint conference on neural networks (IJCNN), pp. 1578–1585. IEEE</mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">Reimers N, Gurevych I (2017) Optimal hyperparameters for deep lstm-networks for sequence labeling tasks. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1707.06799" ext-link-type="uri">arXiv:1707.06799</ext-link></mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuster</surname><given-names>M</given-names></name><name><surname>Paliwal</surname><given-names>KK</given-names></name></person-group><article-title xml:lang="en">Bidirectional recurrent neural networks</article-title><source>IEEE Trans Signal Process</source><year>1997</year><volume>45</volume><issue>11</issue><fpage>2673</fpage><lpage>2681</lpage></mixed-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karim</surname><given-names>F</given-names></name><name><surname>Majumdar</surname><given-names>S</given-names></name><name><surname>Darabi</surname><given-names>H</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Lstm fully convolutional networks for time series classification</article-title><source>IEEE Access</source><year>2017</year><volume>6</volume><fpage>1662</fpage><lpage>1669</lpage></mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Isola P, Zhu J-Y, Zhou T, Efros AA (2017) Image-to-image translation with conditional adversarial networks. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1125–1134</mixed-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="other">Yi Z, Zhang H, Tan P, Gong M (2017) Dualgan: Unsupervised dual learning for image-to-image translation. In: Proceedings of the IEEE international conference on computer vision, pp. 2849–2857</mixed-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Zhu J-Y, Park T, Isola P, Efros AA (2017) Unpaired image-to-image translation using cycle-consistent adversarial networks. In: Proceedings of the IEEE international conference on computer vision, pp. 2223–2232</mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">Wang L, Sindagi V, Patel V (2018) High-quality facial photo-sketch synthesis using multi-adversarial networks. In: 2018 13th IEEE international conference on automatic face &amp; gesture recognition (FG 2018), pp. 83–90. IEEE</mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="other">Yang C-HH, Tsai Y-Y, Chen P-Y (2021) Voice2series: Reprogramming acoustic models for time series classification. In: International conference on machine learning, pp. 11808–11819. PMLR</mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="other">Wang Z, Yan W, Oates T (2017) Time series classification from scratch with deep neural networks: a strong baseline. In: 2017 International joint conference on neural networks (IJCNN), pp. 1578–1585. IEEE</mixed-citation></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Borji</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Pros and cons of gan evaluation measures</article-title><source>Comput Vis Image Underst</source><year>2019</year><volume>179</volume><fpage>41</fpage><lpage>65</lpage></mixed-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="other">Radford A, Metz L, Chintala S (2015) Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1511.06434" ext-link-type="uri">arXiv:1511.06434</ext-link></mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="other">Karras T, Aila T, Laine S, Lehtinen J (2017) Progressive growing of gans for improved quality, stability, and variation. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1710.10196" ext-link-type="uri">arXiv:1710.10196</ext-link></mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="other">Karras T, Laine S, Aila T (2019) A style-based generator architecture for generative adversarial networks. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 4401–4410</mixed-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karras</surname><given-names>T</given-names></name><name><surname>Aittala</surname><given-names>M</given-names></name><name><surname>Laine</surname><given-names>S</given-names></name><name><surname>Härkönen</surname><given-names>E</given-names></name><name><surname>Hellsten</surname><given-names>J</given-names></name><name><surname>Lehtinen</surname><given-names>J</given-names></name><name><surname>Aila</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">Alias-free generative adversarial networks</article-title><source>Adv Neural Inf Process Syst</source><year>2021</year><volume>34</volume><fpage>852</fpage><lpage>863</lpage></mixed-citation></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="other">Zhu M, Pan P, Chen W, Yang Y (2019) Dm-gan: dynamic memory generative adversarial networks for text-to-image synthesis. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 5802–5810</mixed-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>L</given-names></name><name><surname>Chen</surname><given-names>D</given-names></name><name><surname>Zhao</surname><given-names>Z</given-names></name><name><surname>Shao</surname><given-names>J</given-names></name><name><surname>Shen</surname><given-names>HT</given-names></name></person-group><article-title xml:lang="en">Lightweight dynamic conditional gan with pyramid attention for text-to-image synthesis</article-title><source>Pattern Recognit</source><year>2021</year><volume>110</volume></mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="other">Hartmann KG, Schirrmeister RT, Ball T (2018) Eeg-gan: Generative adversarial networks for electroencephalograhic (eeg) brain signals. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1806.01875" ext-link-type="uri">arXiv:1806.01875</ext-link></mixed-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="other">Wang S, Rudolph C, Nepal S, Grobler M, Chen S (2020) Part-gan: privacy-preserving time-series sharing. In: International conference on artificial neural networks, pp. 578–593. Springer</mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="other">Salimans T, Goodfellow I, Zaremba W, Cheung V, Radford A, Chen X (2016) Improved techniques for training GANs</mixed-citation></ref><ref id="CR53"><label>53.</label><mixed-citation publication-type="other">Gurumurthy S, Sarvadevabhatla RK, Radhakrishnan VB (2017) DeLiGAN : Generative Adversarial Networks for Diverse and Limited Data. In: 2017 IEEE conference on computer vision and pattern recognition. pp. 4941–4949</mixed-citation></ref><ref id="CR54"><label>54.</label><mixed-citation publication-type="other">Heusel M, Ramsauer H, Unterthiner T, Nessler B, Hochreiter S (2017) Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems. In: Neural information processing systems (NIPS). <bold>30</bold></mixed-citation></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="other">Yoon J, Jarrett D, Van der Schaar M (2019) Time-series generative adversarial networks. In: Advances in neural information processing systems <bold>32</bold></mixed-citation></ref><ref id="CR56"><label>56.</label><mixed-citation publication-type="other">Esteban C, Hyland SL, Rätsch G (2017) Real-valued (medical) time series generation with recurrent conditional gans. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1706.02633" ext-link-type="uri">arXiv:1706.02633</ext-link></mixed-citation></ref><ref id="CR57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naaz</surname><given-names>F</given-names></name><name><surname>Herle</surname><given-names>A</given-names></name><name><surname>Channegowda</surname><given-names>J</given-names></name><name><surname>Raj</surname><given-names>A</given-names></name><name><surname>Lakshminarayanan</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">A generative adversarial network-based synthetic data augmentation technique for battery condition evaluation</article-title><source>Int J Energy Res</source><year>2021</year><volume>45</volume><issue>13</issue><fpage>19120</fpage><lpage>19135</lpage></mixed-citation></ref><ref id="CR58"><label>58.</label><mixed-citation publication-type="other">Mogren O (2016) C-rnn-gan: Continuous recurrent neural networks with adversarial training. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1611.09904" ext-link-type="uri">arXiv:1611.09904</ext-link></mixed-citation></ref><ref id="CR59"><label>59.</label><mixed-citation publication-type="other">Sutskever I, Martens J, Hinton GE (2011) Generating text with recurrent neural networks. In: ICML</mixed-citation></ref><ref id="CR60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Den Oord</surname><given-names>A</given-names></name><name><surname>Dieleman</surname><given-names>S</given-names></name><name><surname>Zen</surname><given-names>H</given-names></name><name><surname>Simonyan</surname><given-names>K</given-names></name><name><surname>Vinyals</surname><given-names>O</given-names></name><name><surname>Graves</surname><given-names>A</given-names></name><name><surname>Kalchbrenner</surname><given-names>N</given-names></name><name><surname>Senior</surname><given-names>AW</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Wavenet: a generative model for raw audio</article-title><source>SSW</source><year>2016</year><volume>125</volume><fpage>2</fpage></mixed-citation></ref><ref id="CR61"><label>61.</label><mixed-citation publication-type="other">Donahue C, McAuley J, Puckette M (2018) Adversarial audio synthesis. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1802.04208" ext-link-type="uri">arXiv:1802.04208</ext-link></mixed-citation></ref><ref id="CR62"><label>62.</label><mixed-citation publication-type="other">Dau HA, Keogh E, Kamgar K, Yeh C-CM, Zhu Y, Gharghabi S, Ratanamahatana CA, Yanping Hu B, Begum N, Bagnall A, Mueen A, Batista G, Hexagon-ML (2018) The UCR time series classification archive. <ext-link xlink:href="https://www.cs.ucr.edu/%7eeamonn/time_series_data_2018/" ext-link-type="uri">https://www.cs.ucr.edu/~eamonn/time_series_data_2018/</ext-link></mixed-citation></ref><ref id="CR63"><label>63.</label><mixed-citation publication-type="other">Fu B, Kirchbuchner F, Kuijper A (2020) Data augmentation for time series: traditional vs generative models on capacitive proximity time series. In: Proceedings of the 13th ACM international conference on pervasive technologies related to assistive environments, pp. 1–10</mixed-citation></ref><ref id="CR64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Debnath</surname><given-names>A</given-names></name><name><surname>Waghmare</surname><given-names>G</given-names></name><name><surname>Wadhwa</surname><given-names>H</given-names></name><name><surname>Asthana</surname><given-names>S</given-names></name><name><surname>Arora</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Exploring generative data augmentation in multivariate time series forecasting: opportunities and challenges</article-title><source>Solar-Energy</source><year>2021</year><volume>137</volume><fpage>52</fpage><lpage>560</lpage></mixed-citation></ref><ref id="CR65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cazelles</surname><given-names>E</given-names></name><name><surname>Robert</surname><given-names>A</given-names></name><name><surname>Tobar</surname><given-names>F</given-names></name></person-group><article-title xml:lang="en">The wasserstein-fourier distance for stationary time series</article-title><source>IEEE Trans Signal Process</source><year>2020</year><volume>69</volume><fpage>709</fpage><lpage>721</lpage><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">07591375</pub-id><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">4213374</pub-id></mixed-citation></ref><ref id="CR66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>P</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Mao</surname><given-names>K</given-names></name><name><surname>Lu</surname><given-names>F</given-names></name><name><surname>Ning</surname><given-names>G</given-names></name><name><surname>Fang</surname><given-names>L</given-names></name><name><surname>Pan</surname><given-names>Q</given-names></name></person-group><article-title xml:lang="en">A novel data augmentation method to enhance deep neural networks for detection of atrial fibrillation</article-title><source>Biomed Signal Process Control</source><year>2020</year><volume>56</volume></mixed-citation></ref><ref id="CR67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>J</given-names></name><name><surname>Tompkins</surname><given-names>WJ</given-names></name></person-group><article-title xml:lang="en">A real-time qrs detection algorithm</article-title><source>IEEE Trans Biomed Eng</source><year>1985</year><volume>3</volume><fpage>230</fpage><lpage>236</lpage></mixed-citation></ref><ref id="CR68"><label>68.</label><mixed-citation publication-type="other">Flores A, Tito-Chura H, Apaza-Alanoca H (2021) Data augmentation for short-term time series prediction with deep learning, pp. 492–506</mixed-citation></ref><ref id="CR69"><label>69.</label><mixed-citation publication-type="other">Rashid KM, Louis J (2019) Window-warping: a time series data augmentation of imu data for construction equipment activity identification. In: ISARC. Proceedings of the international symposium on automation and robotics in construction, vol. 36, pp. 651–657. IAARC Publications</mixed-citation></ref><ref id="CR70"><label>70.</label><mixed-citation publication-type="other">Um TT, Pfister FM, Pichler D, Endo S, Lang M, Hirche S, Fietzek U, Kulić D (2017) Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks. In: Proceedings of the 19th ACM international conference on multimodal interaction, pp. 216–220</mixed-citation></ref><ref id="CR71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adachi</surname><given-names>S</given-names></name><name><surname>Takemoto</surname><given-names>H</given-names></name><name><surname>Kitamura</surname><given-names>T</given-names></name><name><surname>Mokhtari</surname><given-names>P</given-names></name><name><surname>Honda</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Vocal tract length perturbation and its application to male-female vocal tract shape conversion</article-title><source>J Acoust Soc Am</source><year>2007</year><volume>121</volume><issue>6</issue><fpage>3874</fpage><lpage>3885</lpage></mixed-citation></ref><ref id="CR72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cui</surname><given-names>X</given-names></name><name><surname>Goel</surname><given-names>V</given-names></name><name><surname>Kingsbury</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Data augmentation for deep neural network acoustic modeling</article-title><source>IEEE/ACM Trans Audio, Speech, Lang Process</source><year>2015</year><volume>23</volume><issue>9</issue><fpage>1469</fpage><lpage>1477</lpage></mixed-citation></ref><ref id="CR73"><label>73.</label><mixed-citation publication-type="other">Ko T, Peddinti V, Povey D, Khudanpur S (2015) Audio augmentation for speech recognition. In: 16th annual conference of the international speech communication association</mixed-citation></ref><ref id="CR74"><label>74.</label><mixed-citation publication-type="other">Jaitly N, Hinton GE (2013) Vocal tract length perturbation (vtlp) improves speech recognition. In: Proceedings of ICML workshop on deep learning for audio, speech and language, vol. 117</mixed-citation></ref><ref id="CR75"><label>75.</label><mixed-citation publication-type="other">Park DS, Chan W, Zhang Y, Chiu C-C, Zoph B, Cubuk ED, Le QV (2019) Specaugment: a simple data augmentation method for automatic speech recognition. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1904.08779" ext-link-type="uri">arXiv:1904.08779</ext-link></mixed-citation></ref><ref id="CR76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeong</surname><given-names>CY</given-names></name><name><surname>Shin</surname><given-names>HC</given-names></name><name><surname>Kim</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Sensor-data augmentation for human activity recognition with time-warping and data masking</article-title><source>Multimed Tools Appl</source><year>2021</year><volume>80</volume><issue>14</issue><fpage>20991</fpage><lpage>21009</lpage></mixed-citation></ref><ref id="CR77"><label>77.</label><mixed-citation publication-type="other">Le Guennec A, Malinowski S, Tavenard R (2016) Data augmentation for time series classification using convolutional neural networks. In: ECML/PKDD workshop on advanced analytics and learning on temporal data</mixed-citation></ref><ref id="CR78"><label>78.</label><mixed-citation publication-type="other">Fawaz HI, Forestier G, Weber J, Idoumghar L, Muller P-A (2018) Data augmentation using synthetic data for time series classification with deep residual networks. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1808.02455" ext-link-type="uri">arXiv:1808.02455</ext-link></mixed-citation></ref><ref id="CR79"><label>79.</label><mixed-citation publication-type="other">Pan Q, Li X, Fang L (2020) Data augmentation for deep learning-based ecg analysis, 91–111</mixed-citation></ref><ref id="CR80"><label>80.</label><mixed-citation publication-type="other">Lee H, Hwang S, Shin J (2019) Rethinking data augmentation: self-supervision and self-distillation. arxiv 2019. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1910.05872" ext-link-type="uri">arXiv:1910.05872</ext-link></mixed-citation></ref><ref id="CR81"><label>81.</label><mixed-citation publication-type="other">Al Nazi Z, Biswas A, Rayhan MA, Abir TA (2019) Classification of ecg signals by dot residual lstm network with data augmentation for anomaly detection. In: 2019 22nd international conference on computer and information technology (ICCIT), pp. 1–5. IEEE</mixed-citation></ref><ref id="CR82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alawneh</surname><given-names>L</given-names></name><name><surname>Alsarhan</surname><given-names>T</given-names></name><name><surname>Al-Zinati</surname><given-names>M</given-names></name><name><surname>Al-Ayyoub</surname><given-names>M</given-names></name><name><surname>Jararweh</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Enhancing human activity recognition using deep learning and time series augmented data</article-title><source>J Ambient Intell Humaniz Comput</source><year>2021</year><volume>12</volume><issue>12</issue><fpage>10565</fpage><lpage>10580</lpage></mixed-citation></ref><ref id="CR83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feng</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Intelligent random noise modeling by the improved variational autoencoding method and its application to data augmentation</article-title><source>Geophysics</source><year>2021</year><volume>86</volume><issue>1</issue><fpage>19</fpage><lpage>31</lpage></mixed-citation></ref><ref id="CR84"><label>84.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno-Barea</surname><given-names>FJ</given-names></name><name><surname>Jerez</surname><given-names>JM</given-names></name><name><surname>Franco</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Improving classification accuracy using data augmentation on small data sets</article-title><source>Expert Syst Appl</source><year>2020</year><volume>161</volume></mixed-citation></ref><ref id="CR85"><label>85.</label><mixed-citation publication-type="other">Goubeaud M, Joußen P, Gmyrek N, Ghorban F, Schelkes L, Kummert A (2021) Using variational autoencoder to augment sparse time series datasets. In: 2021 7th international conference on optimization and applications (ICOA), pp. 1–6. IEEE</mixed-citation></ref><ref id="CR86"><label>86.</label><mixed-citation publication-type="other">Hsu W-N, Zhang Y, Glass J (2017) Unsupervised domain adaptation for robust speech recognition via variational autoencoder-based data augmentation. In: 2017 IEEE automatic speech recognition and understanding workshop (ASRU), pp. 16–23. IEEE</mixed-citation></ref><ref id="CR87"><label>87.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demir</surname><given-names>S</given-names></name><name><surname>Mincev</surname><given-names>K</given-names></name><name><surname>Kok</surname><given-names>K</given-names></name><name><surname>Paterakis</surname><given-names>NG</given-names></name></person-group><article-title xml:lang="en">Data augmentation for time series regression: applying transformations, autoencoders and adversarial networks to electricity price forecasting</article-title><source>Appl Energy</source><year>2021</year><volume>304</volume><pub-id pub-id-type="doi">10.1016/j.apenergy.2021.117695</pub-id></mixed-citation></ref><ref id="CR88"><label>88.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>L</given-names></name><name><surname>Yan</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Jin</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Anomaly detection of time series with smoothness-inducing sequential variational auto-encoder</article-title><source>IEEE Trans Neural Netw Learn Syst</source><year>2020</year><volume>32</volume><issue>3</issue><fpage>1177</fpage><lpage>1191</lpage></mixed-citation></ref><ref id="CR89"><label>89.</label><mixed-citation publication-type="other">Liu C, Zhou H, Sun Z, Cui G (2021) Glowimp: combining glow and gan for multivariate time series imputation. In: International conference on algorithms and architectures for parallel processing, pp. 50–64. Springer</mixed-citation></ref><ref id="CR90"><label>90.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Ren</surname><given-names>W</given-names></name><name><surname>Han</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Variational auto-encoders based on the shift correction for imputation of specific missing in multivariate time series</article-title><source>Measurement</source><year>2021</year><volume>186</volume></mixed-citation></ref><ref id="CR91"><label>91.</label><mixed-citation publication-type="other">Sohn K, Lee H, Yan X (2015) Learning structured output representation using deep conditional generative models. Advances in neural information processing systems <bold>28</bold></mixed-citation></ref><ref id="CR92"><label>92.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Long short-term memory</article-title><source>Neural Comput</source><year>1997</year><volume>9</volume><issue>8</issue><fpage>1735</fpage><lpage>1780</lpage></mixed-citation></ref><ref id="CR93"><label>93.</label><mixed-citation publication-type="other">Arjovsky M, Chintala S, Bottou L (2017) Wasserstein generative adversarial networks. In: International conference on machine learning, pp. 214–223. PMLR</mixed-citation></ref><ref id="CR94"><label>94.</label><mixed-citation publication-type="other">Higgins I, Matthey L, Pal A, Burgess C, Glorot X, Botvinick M, Mohamed S, Lerchner A (2016) beta-vae: learning basic visual concepts with a constrained variational framework. In International conference on learning representations.</mixed-citation></ref><ref id="CR95"><label>95.</label><mixed-citation publication-type="other">Haradal S, Hayashi H, Uchida S (2018) Biosignal data augmentation based on generative adversarial networks. In: 2018 40th annual international conference of the IEEE engineering in medicine and biology society (EMBC), pp. 368–371. IEEE</mixed-citation></ref><ref id="CR96"><label>96.</label><mixed-citation publication-type="other">Zhu G, Zhao H, Liu H, Sun H (2019) A novel lstm-gan algorithm for time series anomaly detection. In: 2019 prognostics and system health management conference (PHM-Qingdao), pp. 1–6. IEEE</mixed-citation></ref><ref id="CR97"><label>97.</label><mixed-citation publication-type="other">Shi J, Ding Y, Lv Z (2021) An intermittent fault data generation method based on lstm and gan. In: 2021 global reliability and prognostics and health management (PHM-Nanjing), pp. 1–4. IEEE</mixed-citation></ref><ref id="CR98"><label>98.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>W</given-names></name><name><surname>Hong</surname><given-names>Y</given-names></name><name><surname>Zhou</surname><given-names>B</given-names></name><name><surname>He</surname><given-names>X</given-names></name><name><surname>Cheng</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">A gan-based anomaly detection approach for imbalanced industrial time series</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>143608</fpage><lpage>143619</lpage></mixed-citation></ref><ref id="CR99"><label>99.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>T</given-names></name><name><surname>Chakraborty</surname><given-names>P</given-names></name><name><surname>Sharma</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Deep convolutional generative adversarial networks for traffic data imputation encoding time series as images</article-title><source>Int J Transp Sci Technol</source><year>2021</year><pub-id pub-id-type="doi">10.1016/j.ijtst.2021.10.007</pub-id></mixed-citation></ref><ref id="CR100"><label>100.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">The vanishing gradient problem during learning recurrent neural nets and problem solutions</article-title><source>Intern. J Uncertain Fuzziness Knowl-Based Syst</source><year>1998</year><volume>6</volume><issue>02</issue><fpage>107</fpage><lpage>116</lpage><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1087.68616</pub-id></mixed-citation></ref><ref id="CR101"><label>101.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Simard</surname><given-names>P</given-names></name><name><surname>Frasconi</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Learning long-term dependencies with gradient descent is difficult</article-title><source>IEEE Trans Neural Netw</source><year>1994</year><volume>5</volume><issue>2</issue><fpage>157</fpage><lpage>166</lpage></mixed-citation></ref><ref id="CR102"><label>102.</label><mixed-citation publication-type="other">Olszewski RT (2001) Generalized feature extraction for structural pattern recognition in time -series data. PhD thesis</mixed-citation></ref><ref id="CR103"><label>103.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrzejak</surname><given-names>RG</given-names></name><name><surname>Lehnertz</surname><given-names>K</given-names></name><name><surname>Mormann</surname><given-names>F</given-names></name><name><surname>Rieke</surname><given-names>C</given-names></name><name><surname>David</surname><given-names>P</given-names></name><name><surname>Elger</surname><given-names>CE</given-names></name></person-group><article-title xml:lang="en">Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: dependence on recording region and brain state</article-title><source>Phys Rev E</source><year>2001</year><volume>64</volume><issue>6</issue></mixed-citation></ref><ref id="CR104"><label>104.</label><mixed-citation publication-type="other">Akcay S, Atapour-Abarghouei A, Breckon TP (2018) Ganomaly: semi-supervised anomaly detection via adversarial training. In: Asian conference on computer vision, pp. 622–637. Springer</mixed-citation></ref><ref id="CR105"><label>105.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Bottou</surname><given-names>L</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Haffner</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Gradient-based learning applied to document recognition</article-title><source>Proc IEEE</source><year>1998</year><volume>86</volume><issue>11</issue><fpage>2278</fpage><lpage>2324</lpage></mixed-citation></ref><ref id="CR106"><label>106.</label><mixed-citation publication-type="other">Ramponi G, Protopapas P, Brambilla M, Janssen R (2018) T-cgan: Conditional generative adversarial network for data augmentation in noisy time series with irregular sampling. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1811.08295" ext-link-type="uri">arXiv:1811.08295</ext-link></mixed-citation></ref><ref id="CR107"><label>107.</label><mixed-citation publication-type="other">Mirza M, Osindero S (2014) Conditional generative adversarial nets. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1411.1784" ext-link-type="uri">arXiv:1411.1784</ext-link></mixed-citation></ref><ref id="CR108"><label>108.</label><mixed-citation publication-type="other">Chen G, Zhu Y, Hong Z, Yang Z (2019) Emotionalgan: generating ecg to enhance emotion state classification. In: Proceedings of the 2019 International conference on artificial intelligence and computer science, pp. 309–313</mixed-citation></ref><ref id="CR109"><label>109.</label><mixed-citation publication-type="other">Sabir R, Rosato D, Hartmann S, Gühmann C (2021) Signal generation using 1d deep convolutional generative adversarial networks for fault diagnosis of electrical machines. In: 2020 25th international conference on pattern recognition (ICPR), pp. 3907–3914. IEEE</mixed-citation></ref><ref id="CR110"><label>110.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kramer</surname><given-names>MA</given-names></name></person-group><article-title xml:lang="en">Nonlinear principal component analysis using autoassociative neural networks</article-title><source>AIChE J</source><year>1991</year><volume>37</volume><issue>2</issue><fpage>233</fpage><lpage>243</lpage></mixed-citation></ref><ref id="CR111"><label>111.</label><mixed-citation publication-type="other">Ni H, Szpruch L, Wiese M, Liao S, Xiao B (2020) Conditional sig-wasserstein gans for time series generation. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/2006.05421" ext-link-type="uri">arXiv:2006.05421</ext-link></mixed-citation></ref><ref id="CR112"><label>112.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sakoe</surname><given-names>H</given-names></name><name><surname>Chiba</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Dynamic programming algorithm optimization for spoken word recognition</article-title><source>IEEE Trans Acoust Speech Signal Process</source><year>1978</year><volume>26</volume><issue>1</issue><fpage>43</fpage><lpage>49</lpage><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">0371.68035</pub-id></mixed-citation></ref><ref id="CR113"><label>113.</label><mixed-citation publication-type="other">Forestier G, Petitjean F, Dau HA, Webb GI, Keogh E (2017) Generating synthetic time series to augment sparse datasets. In: 2017 IEEE International conference on data mining (ICDM), pp. 865–870. IEEE</mixed-citation></ref><ref id="CR114"><label>114.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kamycki</surname><given-names>K</given-names></name><name><surname>Kapuscinski</surname><given-names>T</given-names></name><name><surname>Oszust</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Data augmentation with suboptimal warping for time-series classification</article-title><source>Sensors</source><year>2019</year><volume>20</volume><issue>1</issue><fpage>98</fpage></mixed-citation></ref><ref id="CR115"><label>115.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shao</surname><given-names>J</given-names></name><name><surname>Hu</surname><given-names>K</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Xue</surname><given-names>X</given-names></name><name><surname>Raj</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Is normalization indispensable for training deep neural network?</article-title><source>Adv Neural Inf Process Syst</source><year>2020</year><volume>33</volume><fpage>13434</fpage><lpage>13444</lpage></mixed-citation></ref><ref id="CR116"><label>116.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sola</surname><given-names>J</given-names></name><name><surname>Sevilla</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Importance of input data normalization for the application of neural networks to complex industrial problems</article-title><source>IEEE Trans Nucl Sci</source><year>1997</year><volume>44</volume><issue>3</issue><fpage>1464</fpage><lpage>1468</lpage></mixed-citation></ref><ref id="CR117"><label>117.</label><mixed-citation publication-type="other">Zhang K (2021) On mode collapse in generative adversarial networks. In: International conference on artificial neural networks, pp. 563–574. Springer</mixed-citation></ref><ref id="CR118"><label>118.</label><mixed-citation publication-type="other">Adiga S, Attia MA, Chang W-T, Tandon R (2018) On the tradeoff between mode collapse and sample quality in generative adversarial networks. In: 2018 IEEE global conference on signal and information processing (GlobalSIP), pp. 1184–1188. IEEE</mixed-citation></ref><ref id="CR119"><label>119.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>I</given-names></name><name><surname>Pouget-Abadie</surname><given-names>J</given-names></name><name><surname>Mirza</surname><given-names>M</given-names></name><name><surname>Xu</surname><given-names>B</given-names></name><name><surname>Warde-Farley</surname><given-names>D</given-names></name><name><surname>Ozair</surname><given-names>S</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Generative adversarial networks</article-title><source>Commun ACM</source><year>2020</year><volume>63</volume><issue>11</issue><fpage>139</fpage><lpage>144</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">4173633</pub-id></mixed-citation></ref><ref id="CR120"><label>120.</label><mixed-citation publication-type="other">Barnett SA (2018) Convergence problems with generative adversarial networks (gans). arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1806.11382" ext-link-type="uri">arXiv:1806.11382</ext-link></mixed-citation></ref><ref id="CR121"><label>121.</label><mixed-citation publication-type="other">Arjovsky M, Bottou L (2017) Towards principled methods for training generative adversarial networks. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1701.04862" ext-link-type="uri">arXiv:1701.04862</ext-link></mixed-citation></ref><ref id="CR122"><label>122.</label><mixed-citation publication-type="other">Gonog L, Zhou Y (2019) A review: generative adversarial networks. In: 2019 14th IEEE conference on industrial electronics and applications (ICIEA), pp. 505–510. IEEE</mixed-citation></ref><ref id="CR123"><label>123.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>O-Y</given-names></name><name><surname>Shin</surname><given-names>Y-H</given-names></name><name><surname>Kim</surname><given-names>J-O</given-names></name></person-group><article-title xml:lang="en">Multi-perspective discriminators-based generative adversarial network for image super resolution</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>136496</fpage><lpage>136510</lpage></mixed-citation></ref><ref id="CR124"><label>124.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Lian</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">A survey on face data augmentation for the training of deep neural networks</article-title><source>Neural Comput Appl</source><year>2020</year><volume>32</volume><issue>19</issue><fpage>15503</fpage><lpage>15531</lpage></mixed-citation></ref><ref id="CR125"><label>125.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nalepa</surname><given-names>J</given-names></name><name><surname>Marcinkiewicz</surname><given-names>M</given-names></name><name><surname>Kawulok</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Data augmentation for brain-tumor segmentation: a review</article-title><source>Front Comput Neurosci</source><year>2019</year><volume>13</volume><fpage>83</fpage></mixed-citation></ref><ref id="CR126"><label>126.</label><mixed-citation publication-type="other">Fu B, Kirchbuchner F, Kuijper A (2020) Data augmentation for time series: Traditional vs generative models on capacitive proximity time series. In: Proceedings of the 13th ACM international conference on pervasive technologies related to assistive environments. PETRA ’20. Association for computing machinery, New York, NY (2020). <ext-link xlink:href="10.1145/3389189.3392606" ext-link-type="doi">https://doi.org/10.1145/3389189.3392606</ext-link></mixed-citation></ref><ref id="CR127"><label>127.</label><mixed-citation publication-type="other">Iglesias G, Talavera E, Díaz-Álvarez A (2022) A survey on GANs for computer vision: recent research, analysis and taxonomy. arXiv. <ext-link xlink:href="10.48550/ARXIV.2203.11242" ext-link-type="doi">https://doi.org/10.48550/ARXIV.2203.11242</ext-link>. <ext-link xlink:href="https://arxiv.org/abs/2203.11242" ext-link-type="uri">https://arxiv.org/abs/2203.11242</ext-link></mixed-citation></ref><ref id="CR128"><label>128.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>González-Prieto</surname><given-names>Á</given-names></name><name><surname>Mozo</surname><given-names>A</given-names></name><name><surname>Gómez-Canaval</surname><given-names>S</given-names></name><name><surname>Talavera</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Improving the quality of generative models through smirnov transformation</article-title><source>Inf Sci</source><year>2022</year><volume>609</volume><fpage>1539</fpage><lpage>1566</lpage></mixed-citation></ref></ref-list></ref-list><fn-group><fn id="Fn1"><label>1</label><p id="Par152"><ext-link xlink:href="https://engineering.case.edu/bearingdatacenter" ext-link-type="uri">https://engineering.case.edu/bearingdatacenter</ext-link>.</p></fn></fn-group><notes notes-type="Misc"><title>Publisher's Note</title><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Artificial Intelligence</facet-value><facet-value count="1">Computational Biology/Bioinformatics</facet-value><facet-value count="1">Computational Science and Engineering</facet-value><facet-value count="1">Computer Science</facet-value><facet-value count="1">Data Mining and Knowledge Discovery</facet-value><facet-value count="1">Image Processing and Computer Vision</facet-value><facet-value count="1">Probability and Statistics in Computer Science</facet-value></facet><facet name="keyword"><facet-value count="1">Data augmentation</facet-value><facet-value count="1">Deep learning</facet-value><facet-value count="1">Generative models</facet-value><facet-value count="1">Time series</facet-value></facet><facet name="pub"><facet-value count="1">Neural Computing and Applications</facet-value></facet><facet name="year"><facet-value count="1">2023</facet-value></facet><facet name="country"><facet-value count="1">Spain</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
