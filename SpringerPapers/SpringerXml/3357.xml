<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1038/s41524-019-0231-y</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="research-article" xml:lang="en" specific-use="web-only" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">41524</journal-id><journal-id journal-id-type="doi">10.1038/41524.2057-3960</journal-id><journal-title-group><journal-title>npj Computational Materials</journal-title><abbrev-journal-title abbrev-type="publisher">npj Comput Mater</abbrev-journal-title></journal-title-group><issn pub-type="epub">2057-3960</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s41524-019-0231-y</article-id><article-id pub-id-type="manuscript">231</article-id><article-id pub-id-type="doi">10.1038/s41524-019-0231-y</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/301/299/946</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/301</subject></subj-group><subj-group subj-group-type="NatureArticleTypeID"><subject>article</subject></subj-group></article-categories><title-group><article-title xml:lang="en">Interpretable deep learning for guided microstructure-property explorations in photovoltaics</article-title></title-group><contrib-group><contrib contrib-type="author" id="Au1"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5816-0184</contrib-id><name><surname>Pokuri</surname><given-names>Balaji Sesha Sarath</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" id="Au2"><name><surname>Ghosal</surname><given-names>Sambuddha</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au3"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2353-4171</contrib-id><name><surname>Kokate</surname><given-names>Apurva</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au4"><name><surname>Sarkar</surname><given-names>Soumik</given-names></name><address><email>soumiks@iastate.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="corresp" rid="IDs415240190231y_cor4">d</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au5"><name><surname>Ganapathysubramanian</surname><given-names>Baskar</given-names></name><address><email>baskarg@iastate.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="corresp" rid="IDs415240190231y_cor5">e</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 7312</institution-id><institution-id institution-id-type="GRID">grid.34421.30</institution-id><institution content-type="org-division">Department of Mechanical Engineering</institution><institution content-type="org-name">Iowa State University</institution></institution-wrap><addr-line content-type="city">Ames</addr-line><addr-line content-type="state">IA</addr-line><country country="US">USA</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 7312</institution-id><institution-id institution-id-type="GRID">grid.34421.30</institution-id><institution content-type="org-division">Department of Computer Science</institution><institution content-type="org-name">Iowa State University</institution></institution-wrap><addr-line content-type="city">Ames</addr-line><addr-line content-type="state">IA</addr-line><country country="US">USA</country></aff></contrib-group><author-notes><fn fn-type="con"><p>These authors contributed equally: Balaji Sesha Sarath Pokuri, Sambuddha Ghosal</p></fn><corresp id="IDs415240190231y_cor4"><label>d</label><email>soumiks@iastate.edu</email></corresp><corresp id="IDs415240190231y_cor5"><label>e</label><email>baskarg@iastate.edu</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>1</day><month>10</month><year>2019</year></pub-date><pub-date date-type="collection" publication-format="electronic"><month>12</month><year>2019</year></pub-date><volume>5</volume><issue seq="95">1</issue><elocation-id>95</elocation-id><history><date date-type="registration"><day>3</day><month>9</month><year>2019</year></date><date date-type="received"><day>10</day><month>4</month><year>2019</year></date><date date-type="accepted"><day>30</day><month>8</month><year>2019</year></date><date date-type="online"><day>1</day><month>10</month><year>2019</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2019</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">The microstructure determines the photovoltaic performance of a thin film organic semiconductor film. The relationship between microstructure and performance is usually highly non-linear and expensive to evaluate, thus making microstructure optimization challenging. Here, we show a data-driven approach for mapping the microstructure to photovoltaic performance using deep convolutional neural networks. We characterize this approach in terms of two critical metrics, its generalizability (has it learnt a reasonable map?), and its intepretability (can it produce meaningful microstructure characteristics that influence its prediction?). A surrogate model that exhibits these two features of generalizability and intepretability is particularly useful for subsequent design exploration. We illustrate this by using the surrogate model for both manual exploration (that verifies known domain insight) as well as automated microstructure optimization. We envision such approaches to be widely applicable to a wide variety of microstructure-sensitive design problems.</p></abstract><funding-group><award-group><funding-source><institution-wrap><institution>United States Department of Defense | Defense Advanced Research Projects Agency (DARPA)</institution><institution-id institution-id-type="doi" vocab="open-funder-registry">https://doi.org/10.13039/100000185</institution-id></institution-wrap></funding-source><award-id award-type="FundRef grant">HR00111990031</award-id><award-id award-type="FundRef grant">HR00111990031</award-id><award-id award-type="FundRef grant">HR00111990031</award-id><award-id award-type="FundRef grant">HR00111990031</award-id><principal-award-recipient><name><surname>Ganapathysubramanian</surname><given-names>Baskar</given-names></name></principal-award-recipient><principal-award-recipient><name><surname>Pokuri</surname><given-names>Balaji Sesha Sarath</given-names></name></principal-award-recipient><principal-award-recipient><name><surname>Ghosal</surname><given-names>Sambuddha</given-names></name></principal-award-recipient><principal-award-recipient><name><surname>Sarkar</surname><given-names>Soumik</given-names></name></principal-award-recipient></award-group><award-group><funding-source><institution-wrap><institution>United States Department of Defense | U.S. Air Force (United States Air Force)</institution><institution-id institution-id-type="doi" vocab="open-funder-registry">https://doi.org/10.13039/100006831</institution-id></institution-wrap></funding-source><award-id award-type="FundRef grant">FA9550-17-1-0220</award-id><award-id award-type="FundRef grant">FA9550-17-1-0220</award-id><principal-award-recipient><name><surname>Kokate</surname><given-names>Apurva</given-names></name></principal-award-recipient><principal-award-recipient><name><surname>Sarkar</surname><given-names>Soumik</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Nature Research</meta-value></custom-meta><custom-meta><meta-name>volume-issue-count</meta-name><meta-value>1</meta-value></custom-meta><custom-meta><meta-name>issue-article-count</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>issue-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>issue-pricelist-year</meta-name><meta-value>2019</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-holder</meta-name><meta-value>The Author(s)</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-year</meta-name><meta-value>2019</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>No</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2019</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>9</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>3</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>volume-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>NonStandardArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>false</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/41524_2019_Article_231.pdf</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>issue-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>OriginalPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Materials Science</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Materials Science, general</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Characterization and Evaluation of Materials</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Mathematical and Computational Engineering</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Theoretical, Mathematical and Computational Physics</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Computational Intelligence</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Mathematical Modeling and Industrial Mathematics</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Chemistry and Materials Science</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par2">Modern engineering applications are driving the demand for heterogeneous materials with tailored multifunctional properties. Very often, these properties are dependent on the microstructure. In recent years, there has been a sustained focus on microstructure-sensitive design. The design intent here is to identify tailored microstructures that result in desired properties.</p><p id="Par3">The rational design of heterogenous materials has emerged as a very promising approach towards discovery of new materials and devices with tailored properties and subsequently spur novel applications. One such application example has been that of organic electronics, specifically organic photovoltaics (OPV). In spite of exhibiting multiple benefits (tunability, flexibility, cost, low-temperature manufacturability), organic photovoltaic films still remain a niche market due to relatively poor photoconversion efficiency compared to inorganic counterparts. Careful theoretical<sup><xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR6">6</xref></sup> and experimental analysis<sup><xref ref-type="bibr" rid="CR7">7</xref>–<xref ref-type="bibr" rid="CR10">10</xref></sup> have revealed how the microstructure impacts each stage of the photoconversion process. However, the complexity of these analysis approaches have made systematic exploration infeasible, with the result that there exist no design principles nor approaches for identifying promising microstructure in a systematic way. Thus, a key bottleneck to microstructure-sensitive design is the paucity of techniques that can rapidly evaluate the performance of a microstructure.</p><p id="Par4">Our approach to resolve this bottleneck is through machine learning (ML), which is used to create a fast surrogate for any complex functional map in a data-driven manner. Over the last decade, machine learning models have proved their ability to ingest volumes of data-label pairs and create efficient proxy or surrogate models to predict labels for similar instances of data. Deep Learning, the state-of-the-art ML form, has especially advanced the field by incorporating the ability to learn features from high-dimensional data such as multi-spectral images,<sup><xref ref-type="bibr" rid="CR11">11</xref>–<xref ref-type="bibr" rid="CR13">13</xref></sup> speech<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> and text.<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> A particular form of deep networks called Convolutional Neural Networks (CNN) has become very popular due to its ability to autonomously create and analyze features in image-like inputs. Through the use of convolution operations, these models retain spatial neighbourhood information, thus allowing linking local (hierarchical) features of an image and an associated label, without the need for hand crafting of any features. Due to this special ability of ML algorithms to be input agnostic, i.e., the ability to automatically evaluate features from input data, they have found utility in a wide variety of applications including recommendation systems<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> and self-driving cars.<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> These approaches are slowly gaining popularity in physics and engineered systems,<sup><xref ref-type="bibr" rid="CR18">18</xref>–<xref ref-type="bibr" rid="CR20">20</xref></sup> where modern sensor and computational developments have paved the way for structured data generation.<sup><xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR22">22</xref></sup></p><p id="Par5">Here, we utilize the versatility of CNNs to map the active layer morphology of thin film OPVs to a performance metric, which is the short-circuit current <italic>J</italic><sub><italic>sc</italic></sub>. Specifically, we train a morphology classifier that maps a OPV morphology to a short-circuit current. We test several architectures (of varying depth and width) that can learn from a given set of morphologies and their labels, and demonstrate very high accuracy, and <italic>F</italic>1 score. To distinguish and rank order between these equally well performing models, we used two additional measures. The first is based on the observation that a good model must be able to generalize the learnt structure-property relationship. Thus, we identify network architectures that can generalize the map with the available dataset. We quantify this in terms of the ability of the architecture to ‘project the unseen’ morphology onto the learnt distribution and make good predictions.</p><p id="Par6">Apart from generalizability, the other critical requirement for the ML model in our context is interpretability. While model interpretability is not a very critical metric for some applications (for instance, network failure or stock pricing), it becomes a fairly important metric for understanding the behavior of engineered systems. This is because having a purely predictive ‘black-box’ model that is not interpretable raises a critical question—why should a domain expert believe in the prediction of a black-box model? This lack of “interpretability or explainability” is endemic to most black-box models and presents a major bottleneck to the widespread acceptance of ML models.<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> Recently, there have been several approaches towards extracting interpretation from these “black-box” models.<sup><xref ref-type="bibr" rid="CR23">23</xref>–<xref ref-type="bibr" rid="CR27">27</xref></sup> This includes domain-specific explanation of models.<sup><xref ref-type="bibr" rid="CR28">28</xref>–<xref ref-type="bibr" rid="CR31">31</xref></sup> In the current context, the process of learning the structure-property relationship involves identifying several distinct local morphological traits (i.e., unsupervised feature learning) and weighing them appropriately to predict the performance of the morphology. While several (similarly performing) architectures will learn to look at multiple features, we argue that the most useful network is the one that can also identify the right features of the morphology used to make the (correct) prediction. In other words, the chosen architecture should be interpretable to gain trust in the model.</p><p id="Par7">We introduce an approach called DLSP (Deep Learning for Structure Property interrogation) for learning the structure-property relationship from data. Figure <xref rid="Fig1" ref-type="fig">1</xref> illustrates this approach graphically. We first construct a surrogate model of the structure-property relationship using a custom architecture based on a deep convolutional neural network. After training, this architecture is characterized for its trust using generalizability and interpretability measures. Specifically, generalizability is characterized by the performance of the models on off-sample morphologies, whose characteristics are not present in the training dataset. Subsequently, interpretability is characterized by evaluating the “salient” features using saliency map visualizations. This dual characterization allowed us to pick a custom architecture over standard classifying architectures such as VGG-16 and ResNet50 architectures, all of which had nearly identical predictive power. We further use this trust-worthy architecture to perform manual as well as automated explorations of the structure-property space. Using a graphical web application we simplified the process of manual exploration and intuition building of the structure-property space. Here, the user can manually draw (2D) microstructures, perturb the microstructures and use the trained model to rapidly explore the impact of specific features on performance. Such analysis using a full scale physics model would require established, complex computing resources, which are generally not available to every researcher. Additionally, we integrated this trained model into an optimization framework to enable automated morphology. This work illustrates the substantial promise of such surrogate based design procedures in the design of complex multi-physics systems.<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><p>DLSP (Deep Learning for Structure Property) framework: We construct a forward map from morphology to performance. Upon building trust in this trained model, we use it for performing manual exploration and insight buildings, as well as and automated design</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41524_2019_231_Fig1_HTML.png"/></fig></p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Training and validation</title><p id="Par8">We develop a CNN-based architecture to classify morphologies into performance classes. A diverse set of binary morphologies were computationally created for use in training, testing and validation. We solved a thermodynamically consistent Cahn-Hilliard equation<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> for binary phase separation using an in-house finite element library.<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> We ensured creation of a diverse set of morphologies by simulating systems with different volume fractions and different binary interaction parameters. As the Cahn-Hilliard equation models spinodal decomposition (or coarsening dynamics), we output morphologies at several time-snapshots for each simulation. A total of ~65,000 morphologies were generated. Each of these morphologies was computationally interrogated to evaluate the photovoltaic performance. The short-circuit current, <italic>J</italic><sub><italic>sc</italic></sub>, was evaluated for each morphology using the excitonic drift-diffusion equation,<sup><xref ref-type="bibr" rid="CR1">1</xref></sup> which models photocurrent generation process in organic semiconducting films. Across the dataset, the <italic>J</italic><sub><italic>sc</italic></sub> exhibited a minimum of 0.6 <italic>mA</italic>/<italic>cm</italic><sup>2</sup> and a maximum of 7.0 <italic>mA</italic>/<italic>cm</italic><sup>2</sup>. Subsequently, the continuous output, <italic>J</italic><sub><italic>sc</italic></sub> was binned into 10 distinct equi-spaced bins, and each morphology was assigned a one-hot vector as its label.</p><p id="Par9">The dataset consists of images aggregated from solving the Cahn-Hilliard equations for a binary phase separating mixture with various blend ratios and interaction parameters (the complete dataset is publicly available). Varying interaction parameters produce morphologies with different domain purities, while varying blend ratios produce domains of different sizes. Here, we choose to consider 2D morphologies, with extension to 3D morphologies being conceptually straightforward (but computationally non-trivial<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR34">34</xref></sup>). This dataset of morphologies (i.e., 2D, amorphous, isotropic) chosen is a subset of the diversity of morphologies that OPV films exhibit (amorphous-crystalline, anisotropic, and multi-phase) (Interestingly, we show our model trained on this strict subset of plausible morphologies performs well on morphologies representative of the larger OPV diversity, see Section Out-of-sample testing to characterize model generalizability).</p><p id="Par10">We choose the short-circuit current, <italic>J</italic><sub><italic>sc</italic></sub>, as the output of the model. The performance of an OPV device is characterized by the current-voltage (JV) plot. The JV plot is completely parameterized in terms of three quantities, (a) open circuit voltage <italic>V</italic><sub><italic>oc</italic></sub>, (b) short-circuit current <italic>J</italic><sub><italic>sc</italic></sub>, and (c) fill factor. The <italic>J</italic><sub><italic>sc</italic></sub> explicitly depends on the morphology, while <italic>V</italic><sub><italic>oc</italic></sub> depends on the chemistry of the acceptor-donor materials (essentially the HOMO-LUMO gap). Consequently, this motivates our choice of <italic>J</italic><sub><italic>sc</italic></sub> as the output since it explicitly encodes the influence of morphology. Our custom network architecture for mapping a specific morphology to its label is depicted in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. It has 1.2 million learning parameters, consisting of four blocks comprised of a convolutional layer followed by a pooling layer (downsampling by 2 × 2 max-pooling) followed by a batch normalization layer. The first and second blocks have 16 feature maps with 5 × 5 convolutional kernels. The third block has 64 feature maps with 2 × 2 kernels and the final block has 128 feature maps with 2 × 2 kernels. After the final block, the output is flattened using a flatten layer and is followed by 3 fully connected (FC) layers with 512, 128, and 32 hidden units each, sequentially before reaching the final softmax output (prediction) layer of 10 units. A Dropout layer<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> with 50% dropout was added between each of the FC layers. Training was performed on a total of 45,108 samples (with an additional 11,109 validation samples), and testing was performed on 11,109 samples. The learning rate was initiated at 0.0001. The Rectified Linear Unit (ReLU) function is used as the activation function for each of the convolutional and dense (FC) layers. To address over-fitting issues, we add dropout layers in between the fully connected (FC) layers. The percentage of dropouts used was 50% after each of the fully connected layers (namely, FC Layer 1, FC Layer 2, and FC Layer 3, as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>). After every convolutional and subsequent max-pooling layer, batch normalization was performed to remove internal covariate shift.<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> The network was trained for approximately 120 epochs (18<italic>s</italic> per epoch) with a learning rate of 0.0001, on the 45,000-image training set, giving an accuracy of 95.80%. The loss was denoted using a categorical cross-entropy function and Adam optimizer<sup><xref ref-type="bibr" rid="CR37">37</xref></sup> was used to minimize the error.<fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><p>Confusion matrix for in-sample test predictions. Notice the heavily diagonally dominant matrix, indicating a very good classification accuracy. (Scalebar limits: 0–1)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41524_2019_231_Fig2_HTML.png"/></fig></p><p id="Par11">Apart from this network, we also tested two standard architectures with our dataset:<list list-type="bullet"><list-item><p id="Par12">VGG-16 (learning parameters ~50 million), with learning rate of 0.0001, batch size of 128 initialized with random weights was also trained on the training dataset, achieving a test accuracy of 96.61% at epoch 70 (with 180<italic>s</italic> per epoch) with no further improvement in test accuracy.</p></list-item><list-item><p id="Par13">ResNet-50 (learning parameters ~23 million), with learning rate of 0.0001, batch size of 128 initialized with random weights was also trained on the training dataset, achieving a test accuracy of 96.45% at epoch 70 (580<italic>s</italic> per epoch) with no further improvement in test accuracy.</p></list-item></list></p><p id="Par14">A key point to note is that our network, although shallower, performs as well as the established deeper CNN models. Therefore, we select the network based on the learnt features (’interpretability’) and out-of-sample performance (’generalizability’) and not just the accuracy/f1-score of model on the testing dataset. We also note that deeper networks also have additional problems—vanishing (or exploding) gradients,<sup><xref ref-type="bibr" rid="CR38">38</xref></sup> which hinder convergence, and the saturation of accuracy with increasing depth. We use saliency maps<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> to visualize learnt features (Sec. Building trust via interpretability characteristics), i.e., identify microstructure features used by the model to make classification decisions. It is observed that the heat-maps signify the regions of varying degrees of importance and suggest a physical interpretation, which is further discussed in Sec. Building trust via interpretability characteristics.</p></sec><sec id="Sec4"><title>Performance of models: statistical metrics</title><p id="Par15">A standard approach to quantify performance of a classification based machine learning framework is through the confusion matrix. Figure <xref rid="Fig2" ref-type="fig">2b</xref> shows the confusion matrix for in-sample test data classification. It has an accuracy of 95.80% and F1-score of 97.28%. From the confusion matrix, it can clearly be seen that most of the classification is correct, and those which are incorrectly predicted are usually only off by one class. Some incorrect prediction is not unexpected, as we are binning a continuous variable into non-overlapping classes. As such, the edge cases have the potential to be misclassified. We also note that the other two standard architectures show similar confusion matrices, with similar prediction accuracy (see SI).</p></sec><sec id="Sec5"><title>Out-of-sample testing to characterize model generalizability</title><p id="Par16">It is a commonly known fact<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> that neural networks can possibly overfit, depending on the model capacity, amount of training data and training hyperparameters. The network thus memorizes the data and exhibits poor generalization capacity as well as brittleness (i.e., lack of robustness to perturbations). We, therefore, resort to two methods of checking the robustness of our trained network(s). As noted earlier, the morphology data used for training is generated by solving a PDE. This inherits certain properties to the data such as smooth contours and uniform domain sizes. Hence we try to systematically break these assumptions about the dataset and see the performance of the network. First, we test the network on a columnar structure (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). This structure is postulated as an ideal structure in literature.<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> As the width of the columns decrease (and of the order of the exciton diffusion length) and the length of the columns increase, the performance of the morphology increases. This is an example of out-of-sample data—it has several sharp interface contours, which are completely absent in the training dataset. The results of the performance of the models on this morphology are shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. The actual <italic>J</italic><sub><italic>sc</italic></sub> values from a full scale drift-diffusion simulation (along with the corresponding true label) are also presented. It is promising that the custom network accurately predicts the correct label corresponding to each of the columnar microstructures.<fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><p>Saliency maps and performance of our custom trained CNN. Note how the saliency maps closely follow the interface regions in the microstructure. It should also be noted that the networks shows good performance even on samples outside the training dataset</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41524_2019_231_Fig3_HTML.png"/></fig></p><p id="Par17">In a more difficult generalizability test, we use fractal-like morphologies,<sup><xref ref-type="bibr" rid="CR40">40</xref></sup> that are constructed to maximize the interfacial area while minimizing the amount of tortuous transport. These ’virtual’ morphologies have been shown to exhibit enhanced performance,<sup><xref ref-type="bibr" rid="CR40">40</xref></sup> but are currently difficult to experimentally fabricate. We make this point to emphasize that our training dataset consists fully of morphologies that are experimentally feasible to fabricate. Our model correctly predicts the <italic>J</italic><sub><italic>sc</italic></sub> class of all fractal-like morphologies we considered (100% accuracy). It is very promising that our network has correctly identified (Fig. <xref rid="Fig3" ref-type="fig">3</xref>) all these as high-performing class label 9. This provides substantial evidence of the generalizability of the model.</p></sec><sec id="Sec6"><title>Building trust via interpretability characteristics</title><p id="Par18">We next query the network to characterize the learnt features. We accomplish this using the concept of saliency maps<sup><xref ref-type="bibr" rid="CR27">27</xref>,<xref ref-type="bibr" rid="CR41">41</xref></sup> to identify the important features of the image input. Saliency mapping is a visualization technique that generates heat-maps on images that bring out (highlight) the regions (microstructure regions, for our case) the trained CNN model focuses on to generate a classification output. Figure <xref rid="Fig3" ref-type="fig">3</xref> shows the saliency maps for morphologies in the data, columnar structures and the “high” performing morphologies identified in.<sup><xref ref-type="bibr" rid="CR40">40</xref></sup></p><p id="Par19">We can see, in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, how the network uses the interface between the acceptor and donor regions feature as a key measure for prediction. We believe this is critical evidence that makes this network trust-worthy. This is because the interface is the most critical feature affecting the performance. The length of the interface determines the amount of excitons that are dissociated. Additionally, interfaces that results in isolated islands or highly tortuous pathways result in enhanced recombination thus reducing performance. Finally, the impact of interfaces in the middle of the domain (away from the top and bottom electrodes) are more important, as the charges produced at these locations have a higher chance of recombination. We can see from Fig. <xref rid="Fig3" ref-type="fig">3</xref> how the network is able to identify and utilize this interface information as critical to prediction of device performance.</p><p id="Par20">Finally, we observe in Fig. <xref rid="Fig4" ref-type="fig">4</xref> that the saliency maps from the standard deep networks (VGG-16 and ResNet-50) are unable to locate any interpretable features. Although the test accuracy of these networks is marginally higher than our custom network, we see that the saliency outputs from these networks do not provide us with any understandable information. Extensive numerical experimentation revealed that our model is shallow enough to provide meaningful saliency maps (i.e., be intepretable) while deep enough to produce accurate (and generalizable) predictions. We provide additional details in Appendix. 4.6. This observation is in-line with,<sup><xref ref-type="bibr" rid="CR42">42</xref></sup> where it was shown that deeper models are harder to explain than their shallower counterparts even though they may achieve a higher classification accuracy. These results signify the importance of tailoring architectures to the application. Thus, for performing morphology design, we use this customized architecture as a surrogate map from the microstructure space to the performance space.<fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><p>Comparison of Saliency map outputs for our Custom Model (second column), VGG-net (third column) and ResNet-50 (fourth column), with input morphologies shown in the first column: top row shows an example image for class 0, bottom row shows an example image from fractal-like morphologies (correctly predicted as class 9 by our custom model)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41524_2019_231_Fig4_HTML.png"/></fig></p></sec><sec id="Sec7"><title>Morphology design</title><p id="Par21">Having developed a fast and trust-worthy surrogate map from microstructure to performance, we use it to enable microstructural design. In this section, we show two distinct applications, one manual and one automated, using this surrogate model for microstructures exploration and design. The goal of both these techniques is to explore and identify morphologies that demonstrate superior performance. Traditionally, this was generally achieved through a conventional optimization strategy, like simulated annealing, where an initial morphology is tweaked repeatedly to achieve superior performance. At every stage, the current morphology is evaluated for its performance. Subsequently, the whole process requires several computationally expensive evaluations and hence becomes time consuming. In the OPV context, evaluating the <italic>J</italic><sub><italic>sc</italic></sub> for a 2D morphology requires access to dedicated high-performance computing resources. While our highly optimized in-house excitonic-drift-diffusion<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR43">43</xref></sup> code is able to perform one simulation in a few minutes on 24 processor, this is still not a viable approach for in-line design exploration and insight generation. In contrast, with the CNN-based framework, evaluating the morphology becomes significantly faster and easier. Hence it provides an very powerful way to quickly ’evolve’ morphologies to reach morphologies with optimized performance.</p><p id="Par22">Using the surrogate, we created a browser (Fig. <xref rid="Fig5" ref-type="fig">5a</xref>) that enables the user to interactively modify morphologies to both visualize, test/build intuition and improve morphology performance. Using this interface, the user can get insights into the effect of morphological features on performance. Figure <xref rid="Fig5" ref-type="fig">5</xref> shows how one can modify morphologies to sequentially include several features of varying sizes, with the aim of improving performance. This tool can in turn help identify features of morphology that affect the performance. An example of this is demonstrated in Fig. <xref rid="Fig5" ref-type="fig">5b–j</xref>. It shows a set of morphologies along with the respective performance labels predicted by our network. First, we can see how performance can be improved from a simple bilayer by increasing the amount of surface area between the acceptor and donor.<sup><xref ref-type="bibr" rid="CR44">44</xref></sup> The maximum boost of performance is obtained when the donor(black) domains are fractal-like,<sup><xref ref-type="bibr" rid="CR40">40</xref></sup> as shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>e. Next, we add island type structures to inhibit performance.<sup><xref ref-type="bibr" rid="CR44">44</xref></sup> In our example, a ‘line’ of donor is added to the existing morphology, creating several acceptor domains unconnected to the cathode. The performance suffers drastically as informed by the physics of photoconversion.<sup><xref ref-type="bibr" rid="CR1">1</xref></sup> This reduction can be compensated if the connectivities are improved for the acceptor, which can be seen in Fig. <xref rid="Fig5" ref-type="fig">5h</xref>. And finally, Fig. <xref rid="Fig5" ref-type="fig">5j</xref> shows how larger domains are not beneficial as they lead to geminate recombination and hence lower performance. Finally, a user can use approach as a design tool by incrementally adding changes to the initial morphology that can improve the predicted performance. Since the performance assessment is done by the trained CNN, the whole process happens in real-time.<fig id="Fig5"><label>Fig. 5</label><caption xml:lang="en"><p>Manual exploration and insight building using the browser interface. Notice how several physics based intuitive trends can be identified and understood by incrementally perturbing the original bilayer morphology</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41524_2019_231_Fig5_HTML.png"/></fig></p><p id="Par23">The above interface enables manual exploration and building of insight into the influence of various morphological features on performance. Manual exploration, however, inherently makes full exploration to find the best performing morphology manifold difficult and time-consuming. Thus, to fully explore this space, we link this fast surrogate with a probabilistic optimization algorithm to find promising, high-performing morphology classes. More specifically, we use a population based incremental learning (PBIL) approach to perturb morphologies and evolve them towards higher performance.<sup><xref ref-type="bibr" rid="CR40">40</xref></sup> PBIL estimates the explicit probability distribution of the optimal morphology. The multi variate probability distribution is stored as a probability matrix <italic>P</italic> of the 2D morphology, i.e., each pixel is associated with a probability and is updated at each iteration to evolve towards promising morphology classes. This matrix <italic>P</italic> is updated as follows: the optimization starts with a given probability matrix, generally based on the intuition of the researcher. Subsequently, <italic>n</italic> morphology instances are sampled around this matrix <italic>P</italic>. For each realization, the fast ML surrogate is deployed to evaluate the performance, <italic>f</italic><sub><italic>j</italic></sub>, <italic>j</italic> ∈ [1, <italic>n</italic>]. Then <italic>n</italic><sub><italic>b</italic></sub> best samples (<italic>n</italic><sub><italic>b</italic></sub> &lt; <italic>n</italic>) are used to calculate, <italic>P</italic><sub><italic>u</italic></sub>, the probabilistic update matrix. Next, the probability vector is updated according to <italic>P</italic> = <italic>P</italic> ⋅ (1 − <italic>l</italic><sub><italic>r</italic></sub>) + <italic>P</italic><sub><italic>u</italic></sub> ⋅ <italic>l</italic><sub><italic>r</italic></sub>, where <italic>l</italic><sub><italic>r</italic></sub> is the learning rate. Intuitively, the update step reinforces features present in the best performing morphologies, and dampens those missing. The algorithm terminates by standard criteria (iteration limits and improvement bounds). The integration of a robust and fast surrogate with a probabilistic exploration algorithm produces very promising results. Representative results are shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref> where the evolution of the morphology is towards features with multiple scales, mimicking the finger-like fractal structures that are exhibited by high-performance morphologies.<sup><xref ref-type="bibr" rid="CR40">40</xref></sup> We perform full-physics simulations on one of the optimized morphologies (Fig. <xref rid="Fig6" ref-type="fig">6c</xref>), which confirms that the surrogate-derived morphology is in fact a high-performing morphology (Fig. <xref rid="Fig6" ref-type="fig">6d</xref>).<fig id="Fig6"><label>Fig. 6</label><caption xml:lang="en"><p>Exploration by semi-automated design: The optimization started with a bilayer structure. Notice how the framework directs the formation of finer features. Figure <bold>d</bold> shows the simulated electron and hold current densities under short-circuit conditions for this optimized morphology. The result from automated design has been modified using physics based principles. (Scalebar limits: Jpy: 0–10; Jny: 0–22)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41524_2019_231_Fig6_HTML.png"/></fig></p></sec></sec><sec id="Sec8" sec-type="discussion"><title>Discussion</title><p id="Par24">In this work, we address the computationally challenging issue of rapidly exploring morphology space to identify promising morphologies, especially in the context of multi-physics phenomena. While the approach is general, we illustrate the approach using the case of morphology tuning to enhance the performance of organic photovoltaic films. Our approach is a data-driven approach to learn a morphology quantifier that can perform fast evaluations. We train a custom designed CNN maps a specified morphology into short-circuit current, <italic>J</italic><sub><italic>sc</italic></sub>, classes. Using out-of-sample datasets, we confirm absence of over-fitting issues during the training process. Two other standard networks (VGG-16 and ResNet-50) were also trained. It was observed that the custom network, although shallower, gave very similar accuracy. However, our custom network performed much better when visualized using saliency maps as well as when tested on out-of-sample datasets. It identified critical features of the interface in the morphology, which both VGG- 16 and ResNet- 50 failed to identify consistently. The custom designed network is then used to perform morphology design for achieving enhanced performance. Two approaches were taken to do this—the first one aims to inform the user about the effect of morphology on performance. The second approach uses the trust-worthy network as a fast cost function and performs morphology optimization using PBIL algorithm. This work serves as a proof of concept of using deep neural networks for material morphology quantification and design.</p><p id="Par25">There are several interesting areas of research that this work suggests. First, we show that our model—though trained on a subset of plausible morphologies—is able to make accurate predictions on a much more diverse set of morphologies. This raises the question: ‘What is the minimal diversity of morphologies that is needed for a trained model to be generalizable?’ Such questions are particularly important to answer when data collection is resource intensive. Promising approaches include methods of active learning,<sup><xref ref-type="bibr" rid="CR45">45</xref></sup> and physics-aware models.<sup><xref ref-type="bibr" rid="CR46">46</xref>,<xref ref-type="bibr" rid="CR47">47</xref></sup> Next, we show that CNN-based surrogate models are promising approaches to rapidly explore structure-property manifolds. This raises the question: ‘How can such techniques be extended to map and explore process-structure-property manifolds?’ This question is particularly important to isolate promising processing windows that produce high-performing devices. Promising approaches include surrogate models based on smart sampling,<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> and ideas of manifold learning.<sup><xref ref-type="bibr" rid="CR49">49</xref></sup></p></sec><sec id="Sec9" sec-type="methods"><title>Methods</title><sec id="Sec10"><title>Organic photovoltaics</title><p id="Par26">Organic photovoltaic devices are energy harvesting devices, which employ organic materials for solar energy conversion. These provide multiple advantages over traditional silicon-based cells, like flexibility, transparency, and ease of manufacturability. They, however, are limited by their efficiency of operation. Although major breakthroughs in processing and materials have improved the efficiency drastically, they still lag behind the traditional photovoltaics.</p><p id="Par27">The efficiency of these devices is intricately dependant on the material distribution/morphology in the active layer. The active layer generally is a bulk hetero-junction, enabling multiple sites for energy conversion. Several features of the morphology have different roles in the process of converting solar energy. The ability to change these morphological features by changing the processing protocol is a major source of control in these devices.</p><p id="Par28">The solar power conversion happens in several stages. Firstly, the incident solar energy generates excitons in the donor phase. These excitons are highly unstable and need to diffuse to a nearest interface with the acceptor material to separate into positive and negative charges. This diffusion to the interface is critical to evaluate the efficiency of absorption of incident light. These excitons dissociate at the acceptor-donor interface to form charges. The nature and quality of the interface has a direct impact on this efficiency. For example, interfaces with non-aligned crystal boundaries show lower dissociation than those with aligned crystals. In the next stage, these charges (positive charge in the donor and negative charge in the acceptor) are drifted to the respective electrode to produce electricity. Usually, this drift is provided by the potential difference between the two electrodes. However, these charges also encounter other interfaces which have pairs of positive and negative charges, leading to potential recombination.</p><p id="Par29">In this context, quantifying the stage efficiencies (generation, dissociation, and transport) becomes a critical part in developing strategies to design processing conditions. It can already be seen that the role of morphology cannot be over-estimated in the power conversion efficiency. Hence strategies were developed<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR7">7</xref></sup> to quantify the efficiencies these morphologies.</p><p id="Par30">While these techniques are robust and rigorous, they are expensive and time intensive. This makes them infeasible for further designing morphologies, which often requires several quantifications. So, we turn to modern fast methods of quantifying data, especially images. We represent the morphologies as images and take advantage of deep convolutional neural networks to do performance based classification.</p></sec><sec id="Sec11"><title>Data generation and quantification</title><p id="Par31">In order to train the network, we generate a dataset of microstructures using a thermodynamic consistent binary phase separation simulation. This is done by solving the well known Cahn-Hilliard equation,<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> which tracks the local volume fraction of each material (<italic>ϕ</italic><sub><italic>i</italic></sub>):<disp-formula id="Equ1"><label>1</label><alternatives><mml:math id="Equ1_Math"><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>∇</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>M</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>∇</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>∇</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math><tex-math id="Equ1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{c}\frac{{\partial \phi _i}}{{\partial t}} = \nabla \left( {M\left( {\phi _i} \right)\nabla \mu _i} \right)\\ \mu _i = \frac{{\partial f}}{{\partial \phi _i}} - \epsilon ^2\nabla ^2\phi _i\end{array}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ1.gif"/></alternatives></disp-formula><italic>M</italic>(<italic>ϕ</italic><sub><italic>i</italic></sub>) is the mobility of component <italic>i</italic>. <italic>μ</italic><sub><italic>i</italic></sub> represents the chemical potential of component <italic>i</italic>. The chemical potential as defined in Eq. (<xref rid="Equ1" ref-type="disp-formula">1</xref>) is the variational derivative of the total free energy of the system. The total free energy comprises of the bulk free energy <italic>f</italic> and the interfacial energy. The interfacial free energy is characterized as <inline-formula id="IEq1"><alternatives><mml:math id="IEq1_Math"><mml:mrow><mml:mn>0.5</mml:mn><mml:msup><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>∣</mml:mo><mml:mo>∇</mml:mo><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>∣</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="IEq1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0.5\epsilon ^2|\nabla \phi _i|^2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_IEq1.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq2"><alternatives><mml:math id="IEq2_Math"><mml:mi>ϵ</mml:mi></mml:math><tex-math id="IEq2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_IEq2.gif"/></alternatives></inline-formula> is the interfacial energy parameter. <inline-formula id="IEq3"><alternatives><mml:math id="IEq3_Math"><mml:mi>ϵ</mml:mi></mml:math><tex-math id="IEq3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\epsilon$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_IEq3.gif"/></alternatives></inline-formula> is usually correlated with the thickness of the interface between the components. The bulk free energy is described using the Flory-Huggins<sup><xref ref-type="bibr" rid="CR50">50</xref></sup> energy representation:<disp-formula id="Equ2"><label>2</label><alternatives><mml:math id="Equ2_Math"><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi mathvariant="normal">ln</mml:mi><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi mathvariant="normal">ln</mml:mi><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>χ</mml:mi></mml:mrow><mml:mrow><mml:mn>12</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="Equ2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f = \frac{\phi _{1}}{N_{1}}{\mathrm{ln}}\phi _1 + \frac{\phi_{2}}{N_{2}}{\mathrm{ln}}\phi _2 + \chi _{12}\phi _1\phi _2$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ2.gif"/></alternatives></disp-formula>The degree of polymerization of the components is denoted by <italic>N</italic><sub><italic>i</italic></sub> and <italic>χ</italic><sub><italic>ij</italic></sub> represents the severity of interaction between the components. The values for <italic>χ</italic> are either estimated using molecular simulations<sup><xref ref-type="bibr" rid="CR51">51</xref>,<xref ref-type="bibr" rid="CR52">52</xref></sup>, or experimentally<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>, or calculated through empirical methods<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>.</p><p id="Par32">This process generates time series of morphologies that can be treated as independent morphologies for the sake of training a machine learning model. This method helps to quickly produce several thousands of microstructures within a very short amount of time. In order to generate numerous consistent morphologies, we perform 100 simulations of the above Eq. (<xref rid="Equ10" ref-type="disp-formula">10</xref>) values of <italic>χ</italic><sub>12</sub> with 10 values of initial concentration), with morphologies outputted at every 20 timesteps (which provides distinguishable morphologies across timesteps). Previous analysis using this data can be found in.<sup><xref ref-type="bibr" rid="CR44">44</xref></sup> A characteristic of this procedure for generating morphologies through simulation is their similarity to morphologies in real active layers produced during thermal annealing, for example, the domains are similar in size and have smooth interface contours. These characteristics will also help us to build trust in the training process by manually creating morphologies that break these characteristics and testing the performance of the trained network on such samples. We produce a dataset of nearly 65,000 (2D) gray-scale morphologies of size 101 × 101pix.</p><p id="Par33">These morphologies were then characterized using an in-house physics based simulator.<sup><xref ref-type="bibr" rid="CR1">1</xref></sup> This simulator uses steady state excitonic drift-diffusion equation to model the processes of exciton dissociation and charge transport:<disp-formula id="Equ3"><label>3</label><alternatives><mml:math id="Equ3_Math"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">J</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mi>n</mml:mi><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∇</mml:mo><mml:mi>φ</mml:mi><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>∇</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math><tex-math id="Equ3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\boldsymbol{J}}_{\boldsymbol{n}} = - qn\mu _n\nabla \varphi + qV_t\mu _n\nabla n$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ3.gif"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><mml:math id="Equ4_Math"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">J</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mi>p</mml:mi><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>∇</mml:mo><mml:mi>φ</mml:mi><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>∇</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math><tex-math id="Equ4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\boldsymbol{J}}_{\boldsymbol{p}} = - qp\mu _p\nabla \varphi - qV_t\mu _p\nabla p$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ4.gif"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><mml:math id="Equ5_Math"><mml:mrow><mml:mo>∇</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">J</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>q</mml:mi><mml:mi>f</mml:mi><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mi>f</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="Equ5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\nabla .{\boldsymbol{J}}_{\boldsymbol{n}} = qfR_{[n,p]} - qfD_{[\nabla \varphi ,X]}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ5.gif"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><mml:math id="Equ6_Math"><mml:mrow><mml:mo>−</mml:mo><mml:mo>∇</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">J</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>q</mml:mi><mml:mi>f</mml:mi><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>q</mml:mi><mml:mi>f</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="Equ6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$- \nabla .{\boldsymbol{J}}_{\boldsymbol{p}} = qfR_{[n,p]} - qfD_{[\nabla \varphi ,X]}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ6.gif"/></alternatives></disp-formula><disp-formula id="Equ7"><label>7</label><alternatives><mml:math id="Equ7_Math"><mml:mrow><mml:mo>∇</mml:mo><mml:mo>.</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ϵ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>∇</mml:mo><mml:mi>φ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ7_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\nabla .(\epsilon _r\epsilon _0\nabla \varphi ) = q(n - p)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ7.gif"/></alternatives></disp-formula><disp-formula id="Equ8"><label>8</label><alternatives><mml:math id="Equ8_Math"><mml:mrow><mml:mo>−</mml:mo><mml:mo>∇</mml:mo><mml:mo>.</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>∇</mml:mo><mml:mi>X</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>f</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>∇</mml:mo><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="Equ8_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$- \nabla .(V_t\mu _x\nabla X) - fD_{[\nabla \varphi ,X]} - R_{[x]} = - G - R_{[n,p]}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ8.gif"/></alternatives></disp-formula>where <italic>μ</italic><sub><italic>n</italic></sub>, <italic>μ</italic><sub><italic>p</italic></sub> are the mobilities of electrons and holes, respectively. The quantities of interest are the electrostatic potential in the active layer <italic>φ</italic>, electron density <italic>n</italic>, hole density <italic>p</italic> and exciton density <italic>X</italic>. <italic>G, D</italic><sub>[▽<italic>ϕ</italic>,<italic>X</italic>]</sub> represent the rate of generation and dissociation of excitons, respectively. <italic>R</italic><sub>[<italic>x</italic>]</sub> is the exciton relaxation rate. <italic>J</italic><sub><italic>n</italic></sub>, <italic>J</italic><sub><italic>p</italic></sub> are the current densities of electrons and holes, respectively. We use the short-circuit current <italic>J</italic><sub><italic>sc</italic></sub> as a means of labelling the data. The whole data were divided into 10 classes, which are equally spaced between the best (<italic>J</italic><sub><italic>sc</italic></sub> = 7 <italic>mA</italic>/<italic>cm</italic><sup>2</sup>) and worst performing (<italic>J</italic><sub><italic>sc</italic></sub> = 0.2 <italic>mA</italic>/<italic>cm</italic><sup>2</sup>) in the data.</p></sec><sec id="Sec12"><title>Convolutional Neural Networks (CNNs)</title><p id="Par34">CNNs have become the standard frameworks when it comes to computer vision tasks in recent times. To serve our purpose of classifying microstructures, we also use a CNN-based model to train on our dataset, establish trust in the trained model and then use that trained model to make test/future predictions.</p><p id="Par35">CNNs achieve a high level of performance with fewer parameters to learn<sup><xref ref-type="bibr" rid="CR55">55</xref>,<xref ref-type="bibr" rid="CR56">56</xref></sup> when compared to networks constructed simply via Fully-Connected (FC) layers. By design, they exploit the two-dimensional (2D) structure of an input image by preserving the locality of features and utilize spatially local correlations of an image by using tied weights, which are invariant to the translation of the feature positions.<sup><xref ref-type="bibr" rid="CR55">55</xref>,<xref ref-type="bibr" rid="CR57">57</xref></sup></p><p id="Par36">In CNNs, data are represented by multiple feature maps in each hidden layer. These feature maps are obtained by performing a local convolution of the input image using multiple filters. These feature maps further undergo non-linear downsampling with a max-pooling operation<sup><xref ref-type="bibr" rid="CR58">58</xref></sup> to decrease the data-dimension. Max-pooling partitions the input image into sets of non-overlapping rectangles and uses the maximum value for each partition as the output. This is done so that neighboring pixels in an image sharing similar features can be discarded. Both spatial and feature abstractness are also increased as a result, imparting increased position invariance for the filters.<sup><xref ref-type="bibr" rid="CR58">58</xref>,<xref ref-type="bibr" rid="CR59">59</xref></sup></p><p id="Par37">We use batch normalization layers, which normalize the activations of the previous layer at each batch, to improving the overall performance of the architecture. Batch Normalization applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.<sup><xref ref-type="bibr" rid="CR36">36</xref></sup></p><p id="Par38">Post max-pooling, multiple dimension-reduced vector representations of the input are acquired, and the process is repeated in the next layer to achieve a higher-level representation of the data. At the final pooling layer, the resultant outputs are linked to the FC layer, where Rectified Linear Unit (<italic>ReLU</italic>) activation outputs<sup><xref ref-type="bibr" rid="CR60">60</xref></sup> from the hidden units are joined to output units to infer a predicted class on the basis of the highest joint probability given the input data. Keeping this in mind, the probability of an input vector <italic>v</italic> being a member of the class <italic>i</italic> can be written as follows:<disp-formula id="Equ9"><label>9</label><alternatives><mml:math id="Equ9_Math"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>∣</mml:mo><mml:mi mathvariant="bold">v</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">softmax</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Wv</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ9_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Pr(Y = i|{\mathbf{v}},{\mathbf{W}},{\mathbf{b}}) = {\mathrm{softmax}}_i({\mathbf{Wv}} + {\mathbf{b}}) = \frac{{e^{W_iv + b_i}}}{{\mathop {\sum}\nolimits_j {e^{W_jv + b_j}} }}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ9.gif"/></alternatives></disp-formula>where elements of <bold>W</bold> denote the weights and elements of <bold>b</bold> denote the biases. The model prediction is the class with the highest probability:<disp-formula id="Equ10"><label>10</label><alternatives><mml:math id="Equ10_Math"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">pred</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">argmax</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>∣</mml:mo><mml:mi mathvariant="bold">v</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">W</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ10_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y_{{\mathrm{pred}}} = {\mathrm{argmax}}_iPr(Y = i|{\mathbf{v}},{\mathbf{W}},{\mathbf{b}})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ10.gif"/></alternatives></disp-formula></p><p id="Par39">The model weights, <bold>W</bold>, and biases, <bold>b</bold>, are optimized using error back-propagation algorithm,<sup><xref ref-type="bibr" rid="CR61">61</xref></sup> wherein true class labels are compared against the model prediction by using an error metric/loss function. We choose categorical cross entropy<sup><xref ref-type="bibr" rid="CR62">62</xref></sup> as the loss function, chosen to be minimized for the dataset <bold>V</bold>, and is given as follows:<disp-formula id="Equ11"><label>11</label><alternatives><mml:math id="Equ11_Math"><mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mi mathvariant="normal">ln</mml:mi><mml:mspace width="0.16em"/><mml:mi mathvariant="bold">a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.16em"/><mml:mi mathvariant="normal">ln</mml:mi><mml:mspace width="0.16em"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="bold">a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ11_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\cal{L}}(V,Y) = - \frac{1}{n}\mathop {\sum}\limits_{i = 1}^n {{\mathbf{y}}^{(i)}} {\mathrm{ln}}\;{\mathbf{a}}({\mathbf{v}}^{(i)}) + (1 - {\mathbf{y}}^{(i)})\;{\mathrm{ln}}\;(1 - {\mathbf{a}}({\mathbf{v}}^{(i)}))$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ11.gif"/></alternatives></disp-formula></p><p id="Par40">Here, <bold>V</bold> = {<bold>v</bold><sup>(1)</sup>, …, <bold>v</bold><sup>(<italic>n</italic>)</sup>} is the set of input examples in the training dataset, and <bold>Y</bold> = {<bold>y</bold><sup>(1)</sup>, …, <bold>y</bold><sup>(<italic>n</italic>)</sup>} is the corresponding set of labels for those input examples; <bold>a</bold>(<bold>v</bold>) represents the output of the neural network given an input <bold>v</bold>.</p></sec><sec id="Sec13"><title>Class specific visualization: Saliency Maps</title><p id="Par41">A detailed description of Saliency maps and their use in visualising class specific regions as learnt by CNNs has been given in ref. <sup><xref ref-type="bibr" rid="CR27">27</xref></sup> However, we here give a brief overview as well for the sake of simplicity. Saliency Map generation is a technique, which takes an input image, a learnt classification CNN model and a class of interest as it’s input and generates as an output, an image that is representative of that particular class in terms of what that learnt CNN model sees in the given input image. Formally, we define this as follows: Say, <italic>α</italic><sub><italic>i</italic></sub>(<italic>A</italic>) is the score of class <italic>i</italic>, computed by the classification layer of the CNN for an image <italic>A</italic>. The target is to find a <italic>L</italic><sub>2</sub>-regularized image such that <italic>α</italic><sub><italic>i</italic></sub>(<italic>A</italic>) is high:<disp-formula id="Equ12"><label>12</label><alternatives><mml:math id="Equ12_Math"><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">argmax</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mrow><mml:mfenced close="∥" open="∥" separators=""><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math><tex-math id="Equ12_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathop {{{\mathrm{argmax}}}}\limits_A \alpha _i(A) - \gamma \left\| A \right\|_2^2$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41524_2019_231_Article_Equ12.gif"/></alternatives></disp-formula>where <italic>γ</italic> is the regularization parameter. Using the back-propagation algorithm (which is also used to optimize the layer weights), we obtain a locally optimal <italic>A</italic> by optimizing with respect to the input image, with the model weights fixed to those obtained at the best-training step.</p></sec><sec id="Sec14"><title>Performance of standard architectures</title><p id="Par42">As discussed in Sec. Training and validation, we tested the performance of our custom architecture with standard cpnvolutional network architectures, namely ResNet-50<sup><xref ref-type="bibr" rid="CR63">63</xref></sup> and VGG-16.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> ResNet50 is a 50 layer deep convolutional network pretrained on images from ImageNet and can classify into 1000 object categories. It uses a special architecture called residual network blocks that simultaneously reduce the model size and capture diversity of input images. The final layer was modified to classify into 10 categories and was trained end-to-end with our data. VGG16 is another very popular architecture tested on data from ImageNet, which uses 13 layers of 3 × 3 convolutions with max-pooling followed by two fully connected layers of 4096 neurons each. As with ResNet50, we modify the final layer of VGG16 to classify into only 10 categories. Although our architecture is shallower, it showed similar performance in terms of the confusion matrix. The confusion matrix on validation data for ResNet-50 and VGG-16 are in Fig. <xref rid="Fig7" ref-type="fig">7</xref>.<fig id="Fig7"><label>Fig. 7</label><caption xml:lang="en"><p>Both the standard architectures show performance similar to our custom architecture. But these do not provide any meaningful explanations to their predictions (Fig. <xref rid="Fig3" ref-type="fig">3</xref>) (Scalebar limits: 0–1)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41524_2019_231_Fig7_HTML.png"/></fig></p></sec><sec id="Sec15"><title>How shallow can the network be?</title><p id="Par43">In order to determine the simplest model with desired generalizable and interpretable characteristics, we performed an analysis of shallower variants of the presented architecture (Model <italic>α</italic>). We trained a shallower model (Model <italic>α</italic><sub><italic>s</italic>1</sub>) retaining the first 3 convolution-max-pool-BN blocks of Model <italic>α</italic> (i.e., removing the last block from Model <italic>α</italic>) as well an even shallower model, <italic>α</italic><sub><italic>s</italic>2</sub> which retains first two blocks of Model <italic>α</italic> (i.e., we remove the last 2 blocks from Model <italic>α</italic>). Table <xref rid="Tab1" ref-type="table">1</xref> compiles the performance results of these models on three test datasets: in-sample morphologies, fractal-like morphologies, and columnar morphologies. We observe that progressively shallower models perform worse in terms of prediction accuracy, especially for the out-of-sample data (fractal-like and columnar morphologies). In other words, generalizability suffers when the models become shallower than the presented model (Model <italic>α</italic>). This evidence suggests that Model <italic>α</italic> is the shallowest model that still produces viable accuracy.<table-wrap id="Tab1"><label>Table 1</label><caption xml:lang="en"><p>Effect of depth of network on generalizability</p></caption><table frame="hsides" rules="groups"><thead><tr><th><p>Model</p></th><th><p>Accuracy of in-sample morphologies</p></th><th><p>Accuracy of fractal-like morphologies</p></th><th><p>Accuracy of columnar morphologies (loss value)</p></th></tr></thead><tbody><tr><td><p>Model <italic>α</italic></p></td><td><p>96%</p></td><td><p>100%</p></td><td><p>90% (4.22)</p></td></tr><tr><td><p>Model <italic>α</italic><sub><italic>s</italic>1</sub></p></td><td><p>95%</p></td><td><p>96%</p></td><td><p>90% (14.56)</p></td></tr><tr><td><p>Model <italic>α</italic><sub><italic>s</italic>2</sub></p></td><td><p>95%</p></td><td><p>57%</p></td><td><p>90% (18.34)</p></td></tr></tbody></table></table-wrap></p><p id="Par44">The accuracy values, especially in the case of columnar morphologies is slightly misleading because it considers all wrong classifications as equally bad, irrespective of how close is the prediction to the original class. Hence, we analyzed the weighted categorical cross entropy loss for the columnar morphologies, included in paranthesis in the above table.</p></sec></sec></body><back><ack><title>Acknowledgements</title><p>S.G., A.K., and S.S. were funded by AFOSR YIP FA9550-17-1-0220 and DARPA HR00111990031. B.S.S.P. and B.G. were funded by NSF DMREF 1435587 and DARPA HR00111990031. XSEDE computational resources were used for microstructure simulation and quantification. We gratefully acknowledge financial support from all the above agencies.</p></ack><sec sec-type="author-contribution"><title>Author contributions</title><p>B.S.S.P. contributed to project oversight, data generation and curation, architecture design and analysis, and manuscript preparation and revision. S.G. contributed to architectural refinement and comparison with standard models, saliency map visualization and manuscript review. A.K. contributed to saliency map visualization. S.S. and B.G. contributed to problem formulation, project oversight and manuscript preparation and revision.</p></sec><sec sec-type="data-availability"><title>Data availability</title><p>The dataset and the trained model used to generate the results are available through a Google Form request accessible through GitHub: <ext-link xlink:href="https://github.com/vizer1993/GuidedStructurePropertyExploration" ext-link-type="uri">https://github.com/vizer1993/GuidedStructurePropertyExploration</ext-link>.</p></sec><sec sec-type="data-availability"><title>Code availability</title><p>The code used for the above analysis is openly available at GitHub: <ext-link xlink:href="https://github.com/vizer1993/Photovoltaics_CNN_Surrogate" ext-link-type="uri">https://github.com/vizer1993/Photovoltaics_CNN_Surrogate</ext-link></p></sec><sec sec-type="ethics-statement"><sec id="FPar1" sec-type="COI-statement"><title>Competing interests</title><p id="Par45">The authors declare no competing interests.</p></sec></sec><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kodali</surname><given-names>HK</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Computer simulation of heterogeneous polymer photovoltaic devices</article-title><source>Model. Simul. Mater. Sci. Eng.</source><year>2012</year><volume>20</volume><fpage>035015</fpage><pub-id pub-id-type="doi">10.1088/0965-0393/20/3/035015</pub-id></mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wodo</surname><given-names>O</given-names></name><name><surname>Tirthapura</surname><given-names>S</given-names></name><name><surname>Chaudhary</surname><given-names>S</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">A graph-based formulation for computational characterization of bulk heterojunction morphology</article-title><source>Org. Electron.</source><year>2012</year><volume>13</volume><fpage>1105</fpage><lpage>1113</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XlvFajtLc%3D</pub-id><pub-id pub-id-type="doi">10.1016/j.orgel.2012.03.007</pub-id></mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casalegno</surname><given-names>M</given-names></name><name><surname>Raos</surname><given-names>G</given-names></name><name><surname>Po</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Methodological assessment of kinetic monte carlo simulations of organic photovoltaic devices: the treatment of electrostatic interactions</article-title><source>J. Chem. Phys.</source><year>2010</year><volume>132</volume><fpage>094705</fpage><pub-id pub-id-type="doi">10.1063/1.3337909</pub-id></mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meng</surname><given-names>L</given-names></name><etal/></person-group><article-title xml:lang="en">Dynamic monte carlo simulation for highly efficient polymer blend photovoltaics</article-title><source>J. Phys. Chem. B</source><year>2009</year><volume>114</volume><fpage>36</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1021/jp907167u</pub-id></mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marsh</surname><given-names>R</given-names></name><name><surname>Groves</surname><given-names>C</given-names></name><name><surname>Greenham</surname><given-names>NC</given-names></name></person-group><article-title xml:lang="en">A microscopic model for the behavior of nanostructured organic photovoltaic devices</article-title><source>J. Appl. Phys.</source><year>2007</year><volume>101</volume><fpage>083509</fpage><pub-id pub-id-type="doi">10.1063/1.2718865</pub-id></mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watkins</surname><given-names>PK</given-names></name><name><surname>Walker</surname><given-names>AB</given-names></name><name><surname>Verschoor</surname><given-names>GL</given-names></name></person-group><article-title xml:lang="en">Dynamical monte carlo modelling of organic solar cells: the dependence of internal quantum efficiency on morphology</article-title><source>Nano Lett.</source><year>2005</year><volume>5</volume><fpage>1814</fpage><lpage>1818</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD2MXntVOlsLY%3D</pub-id><pub-id pub-id-type="doi">10.1021/nl051098o</pub-id></mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marsh</surname><given-names>RA</given-names></name><name><surname>Hodgkiss</surname><given-names>JM</given-names></name><name><surname>Friend</surname><given-names>RH</given-names></name></person-group><article-title xml:lang="en">Direct measurement of electric field-assisted charge separation in polymer: fullerene photovoltaic diodes</article-title><source>Adv. Mater.</source><year>2010</year><volume>22</volume><fpage>3672</fpage><lpage>3676</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3cXhtV2gt73M</pub-id><pub-id pub-id-type="doi">10.1002/adma.201001010</pub-id></mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hwang</surname><given-names>I-W</given-names></name><name><surname>Moses</surname><given-names>D</given-names></name><name><surname>Heeger</surname><given-names>AJ</given-names></name></person-group><article-title xml:lang="en">Photoinduced carrier generation in p3ht/pcbm bulk heterojunction materials</article-title><source>J. Phys. Chem. C.</source><year>2008</year><volume>112</volume><fpage>4350</fpage><lpage>4354</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD1cXit1yju78%3D</pub-id><pub-id pub-id-type="doi">10.1021/jp075565x</pub-id></mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoppe</surname><given-names>H</given-names></name><name><surname>Sariciftci</surname><given-names>NS</given-names></name></person-group><article-title xml:lang="en">Organic solar cells: an overview</article-title><source>J. Mater. Res.</source><year>2004</year><volume>19</volume><fpage>1924</fpage><lpage>1945</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD2cXlslSqtrg%3D</pub-id><pub-id pub-id-type="doi">10.1557/JMR.2004.0252</pub-id></mixed-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giridharagopal</surname><given-names>R</given-names></name><name><surname>Shao</surname><given-names>G</given-names></name><name><surname>Groves</surname><given-names>C</given-names></name><name><surname>Ginger</surname><given-names>DS</given-names></name></person-group><article-title xml:lang="en">New spm techniques for analyzing opv materials</article-title><source>Mater. Today</source><year>2010</year><volume>13</volume><fpage>50</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1016/S1369-7021(10)70165-6</pub-id></mixed-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="other">Nagasubramanian, K. et al. Explaining hyperspectral imaging based plant disease identification: 3d cnn and saliency maps. arXiv preprint arXiv:1804.08831 (2018).</mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Simonyan, K. &amp; Zisserman, A. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).</mixed-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="other">Arad, B., Ben-Shahar, O. &amp; Timofte, R. Ntire 2018 challenge on spectral reconstruction from rgb images. in <italic>Proc. IEEE Conf. on Computer Vision and Pattern Recognition Workshops</italic>, 929–938 (2018).</mixed-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Graves, A., Mohamed, A.-r. &amp; Hinton, G. Speech recognition with deep recurrent neural networks. in <italic>2013 IEEE Int. Conf. on Acoustics, Speech And Signal Processing</italic>, 6645–6649 (IEEE, 2013).</mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Wang, T., Wu, D. J., Coates, A. &amp; Ng, A. Y. End-to-end text recognition with convolutional neural networks. in <italic>Proc. 21st Int. Conf. on Pattern Recognition (ICPR2012)</italic>, 3304–3308 (IEEE, 2012).</mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Covington, P., Adams, J. &amp; Sargin, E. Deep neural networks for youtube recommendations. in <italic>Proc. 10th ACM Conf. on Recommender Systems</italic>, 191–198 (ACM, 2016).</mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">Bojarski, M. et al. End to end learning for self-driving cars. arXiv preprint arXiv:1604.07316 (2016).</mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sladojevic</surname><given-names>S</given-names></name><name><surname>Arsenovic</surname><given-names>M</given-names></name><name><surname>Anderla</surname><given-names>A</given-names></name><name><surname>Culibrk</surname><given-names>D</given-names></name><name><surname>Stefanovic</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Deep neural networks based recognition of plant diseases by leaf image classification</article-title><source>Computational Intell. Neurosci.</source><year>2016</year><volume>2016</volume><fpage>11</fpage><pub-id pub-id-type="doi">10.1155/2016/3289801</pub-id></mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stoecklein</surname><given-names>D</given-names></name><name><surname>Lore</surname><given-names>KG</given-names></name><name><surname>Davies</surname><given-names>M</given-names></name><name><surname>Sarkar</surname><given-names>S</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Deep learning for flow sculpting: insights into efficient learning using scientific simulation data</article-title><source>Sci. Rep.</source><year>2017</year><volume>7</volume><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXmtFGlu7g%3D</pub-id><pub-id pub-id-type="doi">10.1038/srep46368</pub-id></mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghadai</surname><given-names>S</given-names></name><name><surname>Balu</surname><given-names>A</given-names></name><name><surname>Sarkar</surname><given-names>S</given-names></name><name><surname>Krishnamurthy</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Learning localized features in 3d cad models for manufacturability analysis of drilled holes</article-title><source>Computer Aided Geometric Des.</source><year>2018</year><volume>62</volume><fpage>263</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1016/j.cagd.2018.03.024</pub-id></mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanchez-Lengeling</surname><given-names>B</given-names></name><name><surname>Aspuru-Guzik</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Inverse molecular design using machine learning: generative models for matter engineering</article-title><source>Science</source><year>2018</year><volume>361</volume><fpage>360</fpage><lpage>365</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXhtlyitr3L</pub-id><pub-id pub-id-type="doi">10.1126/science.aat2663</pub-id></mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Dieb, T. M. &amp; Tsuda, K. <italic>Nanoinformatics</italic> pp. 65–74 (Springer, Singapore, 2018).</mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castelvecchi</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Can we open the black box of ai?</article-title><source>Nat. News</source><year>2016</year><volume>538</volume><fpage>20</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28Xhs1ehsr7F</pub-id><pub-id pub-id-type="doi">10.1038/538020a</pub-id></mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Selvaraju, R. R. et al. Grad-cam: Visual explanations from deep networks via gradient-based localization. <ext-link xlink:href="https://arxiv.org/abs/1610.02391v3" ext-link-type="uri">https://arxiv.org/abs/1610.02391v3</ext-link> (2016).</mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Ribeiro, M. T., Singh, S. &amp; Guestrin, C. “why should i trust you?”: Explaining the predictions of any classifier. in <italic>Proc. 22nd ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining</italic>, KDD ’16, 1135–1144 (ACM, New York, 2016). <ext-link xlink:href="10.1145/2939672.2939778" ext-link-type="doi">https://doi.org/10.1145/2939672.2939778</ext-link>.</mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">Shrikumar, A., Greenside, P. &amp; Kundaje, A. Learning important features through propagating activation differences. in <italic>Proc. 34th Int. Conf. On Machine Learning (ICML-17)</italic> (2017).</mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Simonyan, K., Vedaldi, A. &amp; Zisserman, A. Deep inside convolutional networks: Visualising image classification models and saliency maps. arXiv preprint 1312.6034 (2013).</mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghosal</surname><given-names>S</given-names></name><etal/></person-group><article-title xml:lang="en">An explainable deep machine vision framework for plant stress phenotyping</article-title><source>Proc. Natl Acad. Sci.</source><year>2018</year><volume>115</volume><fpage>4613</fpage><lpage>4618</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXitlWrtLvM</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1716999115</pub-id></mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other">Holzinger, A., Biemann, C., Pattichis, C. S. &amp; Kell, D. B. What do we need to build explainable ai systems for the medical domain? arXiv preprint arXiv:1712.09923 (2017).</mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toda</surname><given-names>Y</given-names></name><etal/></person-group><article-title xml:lang="en">How convolutional neural networks diagnose plant disease</article-title><source>Plant Phenomics</source><year>2019</year><volume>2019</volume><fpage>9237136</fpage><pub-id pub-id-type="doi">10.34133/2019/9237136</pub-id></mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H</given-names></name><etal/></person-group><article-title xml:lang="en">An explainable deep-learning algorithm for the detection of acute intracranial haemorrhage from small datasets</article-title><source>Nat. Biomed. Eng.</source><year>2019</year><volume>3</volume><fpage>173</fpage><pub-id pub-id-type="doi">10.1038/s41551-018-0324-9</pub-id></mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cahn</surname><given-names>JW</given-names></name></person-group><article-title xml:lang="en">On spinodal decomposition</article-title><source>Acta Metall.</source><year>1961</year><volume>9</volume><fpage>795</fpage><lpage>801</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DyaF38Xnt1eqsQ%3D%3D</pub-id><pub-id pub-id-type="doi">10.1016/0001-6160(61)90182-1</pub-id></mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wodo</surname><given-names>O</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Modeling morphology evolution during solvent-based fabrication of organic solar cells</article-title><source>Computational Mater. Sci.</source><year>2012</year><volume>55</volume><fpage>113</fpage><lpage>126</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XhvFKktrk%3D</pub-id><pub-id pub-id-type="doi">10.1016/j.commatsci.2011.12.012</pub-id></mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">Ghadai, S., Balu, A., Krishnamurthy, A. &amp; Sarkar, S. Learning and visualizing localized geometric features using 3d-cnn: An application to manufacturability analysis of drilled holes. In <italic>Interpretability Symposium at the 31st Neural Information Processing Systems (NIPS-17)</italic> (2017).</mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srivastava</surname><given-names>N</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name><name><surname>Krizhevsky</surname><given-names>A</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Salakhutdinov</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Dropout: a simple way to prevent neural networks from overfitting</article-title><source>J. Mach. Learn. Res.</source><year>2014</year><volume>15</volume><fpage>1929</fpage><lpage>1958</lpage></mixed-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="other">Ioffe, S. &amp; Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. in <italic>Proc</italic>. <italic>Int. Conf. on Machine Learning</italic> 448–456 (2015).</mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Kingma, D. &amp; Ba, J. Adam: A method for stochastic optimization. arXiv preprint 1412.6980 (2014).</mixed-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="other">Glorot, X. &amp; Bengio, Y. Understanding the difficulty of training deep feedforward neural networks. <italic>AISTATS</italic><bold>9</bold>, 249–256 (2010). <ext-link xlink:href="http://proceedings.mlr.press/v9/glorot10a.html" ext-link-type="uri">http://proceedings.mlr.press/v9/glorot10a.html</ext-link>.</mixed-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kodali</surname><given-names>HK</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Sensitivity analysis of current generation in organic solar cells—comparing bilayer, sawtooth, and bulk heterojunction morphologies</article-title><source>Sol. energy Mater. Sol. cells</source><year>2013</year><volume>111</volume><fpage>66</fpage><lpage>73</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3sXis1Oks7s%3D</pub-id><pub-id pub-id-type="doi">10.1016/j.solmat.2012.12.004</pub-id></mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>P</given-names></name><name><surname>Zebrowski</surname><given-names>A</given-names></name><name><surname>Zola</surname><given-names>J</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name><name><surname>Wodo</surname><given-names>O</given-names></name></person-group><article-title xml:lang="en">Microstructure design using graphs</article-title><source>npj Computational Mater.</source><year>2018</year><volume>4</volume><pub-id pub-id-type="doi">10.1038/s41524-018-0108-5</pub-id></mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Montavon</surname><given-names>Grégoire</given-names></name><name><surname>Samek</surname><given-names>Wojciech</given-names></name><name><surname>Müller</surname><given-names>Klaus-Robert</given-names></name></person-group><article-title xml:lang="en">Methods for interpreting and understanding deep neural networks</article-title><source>Digital Signal Processing</source><year>2018</year><volume>73</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1016/j.dsp.2017.10.011</pub-id></mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="other">Yosinski, J., Clune, J., Nguyen, A., Fuchs, T. &amp; Lipson, A. Understanding neural networks through deep visualization. arXiv preprint arXiv: 1506.06579 (2015).</mixed-citation></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kodali</surname><given-names>HK</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">A computational framework to investigate charge transport in heterogeneous organic photovoltaic devices</article-title><source>Computer Methods Appl. Mech. Eng.</source><year>2012</year><volume>247</volume><fpage>113</fpage><lpage>129</lpage><pub-id pub-id-type="doi">10.1016/j.cma.2012.08.012</pub-id></mixed-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wodo</surname><given-names>O</given-names></name><name><surname>Zola</surname><given-names>J</given-names></name><name><surname>Pokuri</surname><given-names>BSS</given-names></name><name><surname>Du</surname><given-names>P</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Automated, high throughput exploration of process–structure–property relationships using the mapreduce paradigm</article-title><source>Mater. Discov.</source><year>2015</year><volume>1</volume><fpage>21</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1016/j.md.2015.12.001</pub-id></mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="other">Pokuri, B. S. S., Lofquist, A., Risko, C. M. &amp; Ganapathysubramanian, B. Paryopt: A software for parallel asynchronous remote bayesian optimization. arXiv preprint arXiv:1809.04668 (2018).</mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="other">Singh, R. et al. Physics-aware deep generative models for creating synthetic microstructures. arXiv preprint arXiv:1811.09669 (2018).</mixed-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="other">Shah, V. et al. Encoding invariances in deep generative models. arXiv preprint arXiv:1906.01626 (2019).</mixed-citation></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeifer</surname><given-names>S</given-names></name><name><surname>Pokuri</surname><given-names>BSS</given-names></name><name><surname>Du</surname><given-names>P</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Process optimization for microstructure-dependent properties in thin film organic electronics</article-title><source>Mater. Discov.</source><year>2018</year><volume>11</volume><fpage>6</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.md.2018.06.002</pub-id></mixed-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="other">Schoeneman, F., Chandola, V., Napp, N., Wodo, O. &amp; Zola, J. Entropy-isomap: Manifold learning for high-dimensional dynamic processes. in <italic>2018 IEEE Int. Conf. on Big Data (Big Data)</italic>, 1655–1660 (IEEE, 2018).</mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flory</surname><given-names>PJ</given-names></name></person-group><article-title xml:lang="en">Thermodynamics of high polymer solutions</article-title><source>J. Chem. Phys.</source><year>1942</year><volume>10</volume><fpage>51</fpage><lpage>61</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DyaH38Xns1Gk</pub-id><pub-id pub-id-type="doi">10.1063/1.1723621</pub-id></mixed-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>Y-T</given-names></name><name><surname>Risko</surname><given-names>C</given-names></name><name><surname>Bredas</surname><given-names>J-L</given-names></name></person-group><article-title xml:lang="en">Intermixing at the pentacene-fullerene bilayer interface: a molecular dynamics study</article-title><source>Adv. Mater.</source><year>2013</year><volume>25</volume><fpage>878</fpage><lpage>882</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XhsleisrnF</pub-id><pub-id pub-id-type="doi">10.1002/adma.201203412</pub-id></mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kok</surname><given-names>CM</given-names></name><name><surname>Rudin</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Prediction of flory–huggins interaction parameters from intrinsic viscosities</article-title><source>J. Appl. Polym. Sci.</source><year>1982</year><volume>27</volume><fpage>353</fpage><lpage>362</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DyaL38Xpt1SitA%3D%3D</pub-id><pub-id pub-id-type="doi">10.1002/app.1982.070270203</pub-id></mixed-citation></ref><ref id="CR53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orwoll</surname><given-names>RA</given-names></name></person-group><article-title xml:lang="en">The polymer-solvent interaction parameter x</article-title><source>Rubber Chem. Technol.</source><year>1977</year><volume>50</volume><fpage>451</fpage><lpage>479</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DyaE2sXltValtLg%3D</pub-id><pub-id pub-id-type="doi">10.5254/1.3535155</pub-id></mixed-citation></ref><ref id="CR54"><label>54.</label><mixed-citation publication-type="other">Hansen, C. M. <italic>Hansen Solubility Parameters, A User’s Handbook</italic>, 2nd edn (CRC Press, 2007).</mixed-citation></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="other">Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. Imagenet classification with deep convolutional neural networks. In <italic>Advances in neural information processing systems</italic>, 1097–1105 (2012).</mixed-citation></ref><ref id="CR56"><label>56.</label><mixed-citation publication-type="other">LeCun, Y. &amp; Bengio, Y. <italic>The handbook of brain theory and neural networks. chapter Convolutional Networks for Images, Speech, and Time Series.</italic> MIT press. 255–258 (1998).</mixed-citation></ref><ref id="CR57"><label>57.</label><mixed-citation publication-type="other">Lee, H., Grosse, R., Ranganath, R. &amp; Ng, A. Y. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In <italic>Proceedings of the 26th annual international conference on machine learning</italic>, 609–616 (ACM, 2009).</mixed-citation></ref><ref id="CR58"><label>58.</label><mixed-citation publication-type="other">Boureau, Y.-L., Bach, F., LeCun, Y. &amp; Ponce, J. Learning mid-level features for recognition. in <italic>Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</italic>, 2559–2566 (IEEE, 2010).</mixed-citation></ref><ref id="CR59"><label>59.</label><mixed-citation publication-type="other">Huang, F. J., et al. Unsupervised learning of invariant feature hierarchies with applications to object recognition. in <italic>Computer Vision and Pattern Recognition</italic>, 2007. CVPR’07. IEEE Conference on, 1–8 (IEEE, 2007).</mixed-citation></ref><ref id="CR60"><label>60.</label><mixed-citation publication-type="other">Nair, V. &amp; Hinton, G. E. Rectified linear units improve restricted boltzmann machines. in <italic>Proc. 27th Int. Conf. On Machine Learning (ICML-10)</italic>, 807–814 (2010).</mixed-citation></ref><ref id="CR61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Deep learning</article-title><source>Nature</source><year>2015</year><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXht1WlurzP</pub-id><pub-id pub-id-type="doi">10.1038/nature14539</pub-id></mixed-citation></ref><ref id="CR62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubinstein</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">The cross-entropy method for combinatorial and continuous optimization</article-title><source>Methodol. Comput. Appl. Probab.</source><year>1999</year><volume>1</volume><fpage>127</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1023/A:1010091220143</pub-id></mixed-citation></ref><ref id="CR63"><label>63.</label><mixed-citation publication-type="other">He, K., Zhang, X., Ren, S. &amp; Sun, J. Deep residual learning for image recognition. eprint. arXiv preprint arXiv:0706.1234 (2015).</mixed-citation></ref></ref-list></ref-list><notes notes-type="Misc"><p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Characterization and Evaluation of Materials</facet-value><facet-value count="1">Computational Intelligence</facet-value><facet-value count="1">Materials Science</facet-value><facet-value count="1">Materials Science, general</facet-value><facet-value count="1">Mathematical and Computational Engineering</facet-value><facet-value count="1">Mathematical Modeling and Industrial Mathematics</facet-value><facet-value count="1">Theoretical, Mathematical and Computational Physics</facet-value></facet><facet name="keyword"/><facet name="pub"><facet-value count="1">npj Computational Materials</facet-value></facet><facet name="year"><facet-value count="1">2019</facet-value></facet><facet name="country"><facet-value count="1">United States</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
