<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1038/s41598-023-34332-3</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="research-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">41598</journal-id><journal-id journal-id-type="doi">10.1038/41598.2045-2322</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title><abbrev-journal-title abbrev-type="publisher">Sci Rep</abbrev-journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s41598-023-34332-3</article-id><article-id pub-id-type="manuscript">34332</article-id><article-id pub-id-type="doi">10.1038/s41598-023-34332-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/766/400/1021</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/624/399/1015</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/166/988</subject></subj-group><subj-group subj-group-type="NatureArticleTypeID"><subject>article</subject></subj-group></article-categories><title-group><article-title xml:lang="en">Deep learning-based inverse design of microstructured materials for optical optimization and thermal radiation control</article-title></title-group><contrib-group><contrib contrib-type="author" id="Au1"><name><surname>Sullivan</surname><given-names>Jonathan</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" id="Au2"><name><surname>Mirhashemi</surname><given-names>Arman</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au3"><name><surname>Lee</surname><given-names>Jaeho</given-names></name><address><email>jaeholee@uci.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="corresp" rid="IDs41598023343323_cor3">c</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.266093.8</institution-id><institution-id institution-id-type="ISNI">0000 0001 0668 7243</institution-id><institution content-type="org-division">Department of Mechanical and Aerospace Engineering</institution><institution content-type="org-name">University of California</institution></institution-wrap><addr-line content-type="city">Irvine</addr-line><addr-line content-type="state">CA</addr-line><country country="US">USA</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.419077.c</institution-id><institution-id institution-id-type="ISNI">0000 0004 0637 6607</institution-id><institution content-type="org-name">NASA Glenn Research Center</institution></institution-wrap><addr-line content-type="city">Cleveland</addr-line><addr-line content-type="state">OH</addr-line><country country="US">USA</country></aff></contrib-group><author-notes><corresp id="IDs41598023343323_cor3"><label>c</label><email>jaeholee@uci.edu</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>6</day><month>5</month><year>2023</year></pub-date><pub-date date-type="collection" publication-format="electronic"><month>12</month><year>2023</year></pub-date><volume>13</volume><issue seq="7382">1</issue><elocation-id>7382</elocation-id><history><date date-type="registration"><day>27</day><month>4</month><year>2023</year></date><date date-type="received"><day>7</day><month>12</month><year>2022</year></date><date date-type="accepted"><day>27</day><month>4</month><year>2023</year></date><date date-type="online"><day>6</day><month>5</month><year>2023</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2023</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">Microstructures with engineered properties are critical to thermal management in aerospace and space applications. Due to the overwhelming number of microstructure design variables, traditional approaches to material optimization can have time-consuming processes and limited use cases. Here, we combine a surrogate optical neural network with an inverse neural network and dynamic post-processing to form an aggregated neural network inverse design process. Our surrogate network emulates finite-difference time-domain simulations (FDTD) by developing a relationship between the microstructure’s geometry, wavelength, discrete material properties, and the output optical properties. The surrogate optical solver works in tandem with an inverse neural network to predict a microstructure’s design properties that will match an input optical spectrum. As opposed to conventional approaches that are constrained by material selection, our network can identify new material properties that best optimize the input spectrum and match the output to an existing material. The output is evaluated using critical design constraints, simulated in FDTD, and used to retrain the surrogate—forming a self-learning loop. The presented framework is applicable to the inverse design of various optical microstructures, and the deep learning-derived approach will allow complex and user-constrained optimization for thermal radiation control in future aerospace and space systems.</p></abstract><funding-group><award-group><funding-source><institution-wrap><institution>NASA</institution></institution-wrap></funding-source><award-id award-type="FundRef grant">80NSSC19K1671</award-id><award-id award-type="FundRef grant">80NSSC19K1671</award-id><principal-award-recipient><name><surname>Sullivan</surname><given-names>Jonathan</given-names></name></principal-award-recipient><principal-award-recipient><name><surname>Lee</surname><given-names>Jaeho</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Nature Portfolio</meta-value></custom-meta><custom-meta><meta-name>volume-issue-count</meta-name><meta-value>1</meta-value></custom-meta><custom-meta><meta-name>issue-article-count</meta-name><meta-value>7382</meta-value></custom-meta><custom-meta><meta-name>issue-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>issue-pricelist-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-holder</meta-name><meta-value>Springer Nature Limited</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>Yes</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>4</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>27</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>volume-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>NonStandardArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>false</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/41598_2023_Article_34332.pdf</meta-value></custom-meta><custom-meta><meta-name>pdf-type</meta-name><meta-value>Typeset</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>issue-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>OriginalPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Science, Humanities and Social Sciences, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Science, Humanities and Social Sciences, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Science, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Science (multidisciplinary)</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Engineering surfaces at the microscopic level enable control over the material’s matter-light interactions, and is integral to evolving technologies in areas such as sub-ambient passive cooling<sup><xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR4">4</xref></sup>, radiative heating<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR6">6</xref></sup>, and thermophotovoltaics<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup>. The design of selective emitters for radiative thermal management systems depends on two photonic wavelength (λ) spectrums: the visible (VIS) to near-infrared (NIR) and the mid-infrared (MIR)<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR4">4</xref></sup>. Passive cooling structures—materials that can passively cool beneath ambient temperatures—are surfaces engineered from materials such as polymers<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR9">9</xref></sup>, composites<sup><xref ref-type="bibr" rid="CR10">10</xref>–<xref ref-type="bibr" rid="CR12">12</xref></sup>, and graphene<sup><xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR14">14</xref></sup> to maximize thermal emission in the MIR and minimize absorbed solar radiation (λ = 300–2500 nm) by increasing reflected solar radiation. Methods such as nanostructuring<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, corrugated structures<sup><xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup>, core–shell materials<sup><xref ref-type="bibr" rid="CR17">17</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup>, and periodic gratings<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR19">19</xref></sup> can be used to induce the opposite effect and increase thermal absorption by enhancing a surface’s anti-reflective behavior. A method that can be used to engineer both radiative heating and cooling materials is microscale “micropyramid” surface texturing<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. A form of surface relief grating, micropyramid texturing induces anti-reflective properties due to significant light confinement via the combination of material and geometry<sup><xref ref-type="bibr" rid="CR20">20</xref>–<xref ref-type="bibr" rid="CR22">22</xref></sup>. This method can significantly enhance broadband anti-reflective properties in silicon<sup><xref ref-type="bibr" rid="CR23">23</xref>–<xref ref-type="bibr" rid="CR27">27</xref></sup>, metals<sup><xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR28">28</xref>–<xref ref-type="bibr" rid="CR32">32</xref></sup>, dielectrics<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>, and polymers<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>.</p><p id="Par3">Designing and optimizing structures to selectively control optical properties can be a significant and time-consuming challenge. Beyond the potential for many degrees of freedom in the geometric design space, material selection adds an additional level of complexity. Solving the interplay between a complex geometry and material selection can require both a significant investment in computational resources and a dedicated numerical method such as a finite-difference time-domain (FDTD)<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> solver. A highly effective method that has emerged to counteract the necessity of complex simulation tools is the use of Deep Learning (DL) to predict optical properties. A branch of machine learning (ML), DL methods have shown to have a high degree of non-linear abstraction from datasets<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> and to address complex issues such as self-driving cars<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>, speech recognition<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>, and natural language processing<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. Deep Learning has been used in the field of photonics and nanophotonics to predict and model problems such as plasmonic interactions<sup><xref ref-type="bibr" rid="CR36">36</xref>,<xref ref-type="bibr" rid="CR40">40</xref></sup>, grating structures<sup><xref ref-type="bibr" rid="CR41">41</xref>–<xref ref-type="bibr" rid="CR43">43</xref></sup>, particles<sup><xref ref-type="bibr" rid="CR44">44</xref>,<xref ref-type="bibr" rid="CR45">45</xref></sup>, and nanostructures<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>. DL has also been extensively applied within the field of thermal engineering to study topics such as thermal conductivity<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>, boiling heat transfer<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>, and radiative thermal transport<sup><xref ref-type="bibr" rid="CR49">49</xref>–<xref ref-type="bibr" rid="CR51">51</xref></sup>.</p><p id="Par4">Deep Learning has proven to be not only effective in predicting the “forward” problem by replacing the optical solution process, but also in performing inverse design<sup><xref ref-type="bibr" rid="CR36">36</xref>,<xref ref-type="bibr" rid="CR44">44</xref>,<xref ref-type="bibr" rid="CR45">45</xref>,<xref ref-type="bibr" rid="CR52">52</xref>–<xref ref-type="bibr" rid="CR56">56</xref></sup>. Inverse design, broadly, is taking a desired input and outputting a set of features that generate the input. Compared to common optimization tools, inverse design via machine learning methods is highly effective in increasing throughput and prediction speed. A multitude of methods exist for executing an inverse design scheme in nanophotonics<sup><xref ref-type="bibr" rid="CR57">57</xref></sup>, but several common methods include the use of a surrogate model in conjunction with an optimization method<sup><xref ref-type="bibr" rid="CR58">58</xref>,<xref ref-type="bibr" rid="CR59">59</xref></sup>, the creation of a the “tandem” or bidirectional scheme<sup><xref ref-type="bibr" rid="CR36">36</xref>,<xref ref-type="bibr" rid="CR44">44</xref>,<xref ref-type="bibr" rid="CR55">55</xref>,<xref ref-type="bibr" rid="CR60">60</xref>,<xref ref-type="bibr" rid="CR61">61</xref></sup>, and adversarial networks<sup><xref ref-type="bibr" rid="CR62">62</xref>,<xref ref-type="bibr" rid="CR63">63</xref></sup>. Inverse design methods based on machine learning have been applied to the design of selective emitter structures; methods based on images<sup><xref ref-type="bibr" rid="CR64">64</xref></sup>, deep learning<sup><xref ref-type="bibr" rid="CR65">65</xref></sup>, deep-binary search<sup><xref ref-type="bibr" rid="CR66">66</xref></sup>, transfer learning<sup><xref ref-type="bibr" rid="CR67">67</xref></sup>, and genetic algorithms<sup><xref ref-type="bibr" rid="CR68">68</xref>,<xref ref-type="bibr" rid="CR69">69</xref></sup> have been shown to be effective in previous studies. While some studies do factor in the material selection as an output in the inverse design process, they are often limited to a small set of fixed material outputs<sup><xref ref-type="bibr" rid="CR44">44</xref>,<xref ref-type="bibr" rid="CR67">67</xref></sup>.</p><p id="Par5">Material selection plays a fundamental role in the design of selective emitters as the interaction of light with the surface is regulated by the spectral material properties<sup><xref ref-type="bibr" rid="CR70">70</xref></sup>. If a microstructure or material is not capable of regulating certain wavelengths, a designer can coat additional material(s) to enhance the broadband response<sup><xref ref-type="bibr" rid="CR17">17</xref>,<xref ref-type="bibr" rid="CR31">31</xref>,<xref ref-type="bibr" rid="CR32">32</xref>,<xref ref-type="bibr" rid="CR71">71</xref></sup>, create a new composite material<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR12">12</xref></sup>, or select a new material as the basis for patterning. Thus, it is critical to be able to exhaustively search over the available material space to provide the best match for a given set of thermal design criteria<sup><xref ref-type="bibr" rid="CR72">72</xref></sup>. To be exhaustive in the inverse design approach, the material output cannot be fixed and should be flexible to allow the discovery of unique combinations of material properties with geometric properties.</p><p id="Par6">In this work, we propose an inverse microstructural design method based on a tandem neural network constructed to take in a set of desired optical properties and output a set of material and geometric properties. We supplement the tandem neural network—consisting of a surrogate network and inverse network—with post-processing methods to allow the aggregated network to consider critical physical design constraints. The aggregated network is designed in an adversarial style process loop to facilitate the model to iterate and build upon itself over subsequent generations and consider focused feedback from the post-processing checkpoints. The foundation of our method is built upon a previously developed optical simulation surrogate based on a deep neural network (DNN)<sup><xref ref-type="bibr" rid="CR72">72</xref></sup>. As opposed to many other studies that provide a deep learning approach to optics where a single material is simulated<sup><xref ref-type="bibr" rid="CR73">73</xref></sup>, the materials are fixed<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>, or are one-hot encoded<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>, our surrogate method does not constrain material input and can extrapolate to make predictions for materials that were not used in training. The flexibility provided by this method enables us to build an inverse neural network structure to work in tandem with the surrogate that is similarly unconstrained by material classification. Our inverse network structure is capable of not only predicting an optimal material for a given desired input but is capable of extrapolating new material properties to match a given desired input.</p><p id="Par7">The model we demonstrate takes in a simple input of optical properties across a wavelength range and outputs a material and micropyramid geometry that best match it. Multiple deep learning methods are utilized in the construction of the method. We compare the previously established deep neural network surrogate to an image-based surrogate and incorporate recurrent neural network functionality to improve the inverse network’s prediction performance. While we demonstrated limited optimization using the surrogate<sup><xref ref-type="bibr" rid="CR72">72</xref></sup>, the inverse network enables far more rapid, dynamic, and global optimization. The output of the inverse neural network is put through a post-processing stage where user set geometric and material constraints are used to produce appropriate solutions. The novel generated material properties are matched to a material from a library material, the constrained output is simulated, and the results are incorporated in the surrogate network. Using this process, we can rapidly optimize a material and geometric combination for a desired optical spectrum in a process that would be too computationally expensive to perform otherwise. While we apply our methodology to micropyramid structures, the approach that we demonstrate can be modified to accommodate any number of microstructural surface topologies.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><p id="Par8">Figure <xref rid="Fig1" ref-type="fig">1</xref> provides a comprehensive schematic of the aggregate neural network framework. We divide the framework into four major subcategories: FDTD simulations, surrogate network, inverse neural network, and post-processing. As visualized in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, the general process flow is FDTD simulations are used to train the surrogate neural network and the surrogate is used to make large-scale predictions derived from a library of materials. The predictions are then used to train an inverse neural network component. The input of the inverse network is a desired optical spectrum (λ, ε, R, T) and the output is the predicted micropyramid base span, height, substrate thickness (X<sub>span</sub>, Z<sub>span</sub>, and t<sub>sub</sub>), and a vector of complex refractive index values (n(λ), k(λ)) that correspond to the input wavelength. The post-processing module then interprets the output. Here, user constraints—such as the maximum aspect ratio—are used to adjust the predicted output and provide appropriate new solutions that satisfy the restrictions. The adjusted solutions are then passed through both FDTD and the surrogate model. Based on two metrics—the error between the desired input and the constrained output, and the error between the surrogate and FDTD outputs—a decision is made to either retrain the surrogate with the new simulation data, or to stop the loop if the solution is deemed to be sufficient and accurate. Any details not discussed in any of the major subcategories for all modules and connections can be found in the methods section, the supplementary materials, or in the linked code repository.<fig id="Fig1"><label>Figure 1</label><caption xml:lang="en"><p>Flow-chart representation of aggregated neural network methodology and inverse network architecture. Solutions generated in the surrogate (forward) solution are used to train the inverse solver. The input to the inverse neural network is a 400 × 1 vector of wavelength, and the wavelength dependent emissivity, reflectivity, and transmissivity. The output of the inverse neural network is a set of material properties that correspond to the input wavelength and geometric properties. The output is evaluated in FDTD and if the results violate user set constraints, alternative solutions are calculated that fall within the set constraints.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41598_2023_34332_Fig1_HTML.png" id="MO1"/></fig></p><sec id="Sec3"><title>FDTD simulations</title><p id="Par9">Solutions using the FDTD method, while accurate, can be time intensive—this is especially true for large or geometrically complex structures. For this work, the training, validation, and testing data used by the surrogate neural network is compiled from simulations completed in Lumerical’s commercially available 2D/3D FDTD solver. The simulation framework provides exact solutions for Maxwell’s equations across a finite element mesh, and the absorption and dispersion are derived from the resulting electrical fields<sup><xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR74">74</xref></sup>. Rather than simulating a 3-dimensional (3D) pyramid microstructure, we simulate the middle-cross section in 2-dimensions (2D) to minimize simulation time and to enable the generation of large quantities of simulation data. While this does lead to an overestimation of the micropyramid’s emissivity<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> compared to the 3D micropyramid simulations, the results are still accurate as we do not vary the incidence angle in our simulations and assume the broadband wavelength source to be at a normal angle to the material’s surface. Additionally, while we could choose to use a semi-analytical approach like RCWA to run the simulations<sup><xref ref-type="bibr" rid="CR75">75</xref></sup> to estimate the optical properties of a 2D structure, FDTD’s accuracy, scalability, and its applicability to other more complex geometries make it a far viable long-term solution. The simulations are based upon a micropyramid geometry visualized in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, with the key independent geometric parameters being the triangle base span (x<sub>span</sub>), height (z<sub>span</sub>), and substrate thickness (t<sub>sub</sub>). For this work, we assume that Kirchhoff’s law is valid and the emissivity can be derived from α = ε = 1 – R – T, where reflectivity (R) and transmissivity (T) are calculated from power monitors above and below and domain respectively and where absorptivity (α) is synonymous with emissivity (ε)<sup><xref ref-type="bibr" rid="CR72">72</xref></sup>. To develop the simulation datasets used to train the surrogate, we generate and simulate matrices of randomly generated uniformly values for the x<sub>span,</sub> z<sub>span</sub>, and t<sub>sub</sub> for each material included. For simplicity, we assume no additional coating materials, hierarchical structures or surface roughness. Additional details on our FDTD simulation methodology can be found in both the methods section and in our prior work<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR32">32</xref></sup>.<fig id="Fig2"><label>Figure 2</label><caption xml:lang="en"><p>(<bold>a</bold>) Images for the convolutional neural network are formulated using the wavelength dependent material data. Each image contains information for a singular wavelength point. (<bold>b</bold>) Diagram of the convolutional neural network process for predicting material dependent optical properties from the generated images.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41598_2023_34332_Fig2_HTML.png" id="MO2"/></fig></p></sec><sec id="Sec4"><title>Surrogate neural network</title><p id="Par10">Deep learning modules have been shown to be exceptionally strong and versatile in solving the so called “forward” problem<sup><xref ref-type="bibr" rid="CR36">36</xref>,<xref ref-type="bibr" rid="CR52">52</xref></sup>. In this case, the problem to solve is the optical response from a geometric and material input for a uniform periodic micropyramid surface. The design intent of the surrogate neural network is to act as an ultra-fast and accurate predictor of optical properties such that we can rapidly and accurately predict the optical properties of vast quantities of simulations. Furthermore, it is important that the surrogate network can extrapolate optical properties for materials beyond its original training scope. As such, we compare two methods that serve this function: an improved version of a previously developed deep-neural network<sup><xref ref-type="bibr" rid="CR72">72</xref></sup>, and an image-based deep convolutional neural network (DCNN). Both methods utilize datasets generated in FDTD that are subdivided into training, validation, and test datasets.</p><sec id="Sec5"><title>Surrogate neural network: deep neural network</title><p id="Par11">The architecture of the deep neural network—visualized in Fig. <xref rid="Fig1" ref-type="fig">1</xref> of our previous work<sup><xref ref-type="bibr" rid="CR72">72</xref></sup> and in the supplementary materials—is designed to emulate the critical simulation inputs that influence the computed optical properties. The network employs a total of 8 input neurons: 3 geometric inputs (x<sub>span</sub>, z<sub>span</sub>, t<sub>sub</sub>), the source wavelength (λ), and 4 material inputs (n, k, ε<sub>real</sub>, ε<sub>im</sub>). The substrate thickness is a key geometric parameter to consider as it enables the model to interpret the relationship between the spectral optical properties and underlying material thickness and ultimately to predict the broadband spectral behavior of transmissive materials. Micropyramids of different materials are differentiated using discrete material inputs for the complex refractive index (n and k) and the correlated permittivity values (ε<sub>real</sub>, ε<sub>im</sub>). Compared to using only n and k, using both the complex refractive index and the permittivity is essential to accurately extrapolate the optical properties of materials not seen in the training process. The source wavelength (or frequency) is the fundamental factor that links the geometric and material inputs. For each FDTD simulation, we simulate 100 wavelength points (100 frequency points), each of which has a discrete solution for reflectivity and transmissivity. Accordingly, each simulation is divided into 100 discrete input vectors as the solution to Maxwell’s equations is not sequentially dependent. To strengthen the connection between the input and the output optical properties (R, T) and the key independent parameter (λ), we utilize two smaller multi-layer perceptron groupings (MLPs) to separately consider the relationship between the geometry/wavelength and the material data/wavelength. The MLPs outputs are concatenated and fed into a larger deep neural network, the output of which is a reflectivity and transmissivity value.</p><p id="Par12">The DNN method is effective at being both quick to predict and in making accurate predictions, even when extrapolating. The DNN surrogate neural network has a mean absolute error (MAE) and mean-squared error (MSE) between the simulation data and predictions of 0.0033 and 1.35e-4 respectively for the “test” dataset—data that is held back from the training/validation process. As the network’s design is not limited by constraints in material input, a fundamental evaluation of the surrogate’s performance is in the prediction of the optical properties of microstructures made of materials that are outside of the scope of training. Thus, we evaluate the network on two large (1500 simulation) “unseen” datasets Al2O3/Ti, and on 100 simulations of 25 other materials in a “library”. When the simulations from these datasets are completely unseen by the training/validation process, the DNN yields an MAE between prediction and simulation of 0.0175, 0.0131, and 0.0279 for the Ti, Al2O3, and Material library datasets respectively. As the optical properties are already on a scale of 0 to 1, these errors indicate an exceptional degree of prediction accuracy when extrapolating for new materials. To improve the prediction accuracy when extrapolating, the model benefits from small “calibration” datasets. By including 5–10 simulations from the “unseen” datasets (&lt; 1%) to the training/validation process of the surrogate, we reduce the prediction MAE to 0.0073, 0.0049, and 0.0118 for the Ti, Al2O3, and material library datasets respectively. The included simulations represent an almost insignificant number of simulations when compared to the original training and validation dataset (&lt; 0.05%). Despite this, the inclusion has a dramatic impact on the remainder of the extrapolated data, indicating the model has strong physical understanding and only several simulations are needed to “calibrate” the model to new material behavior. In addition to the observed accuracy, the model can make predictions exceedingly fast– with over 1 million individual input sets per minute.</p></sec><sec id="Sec6"><title>Surrogate neural network: convolutional deep neural network (CDNN)</title><p id="Par13">The architecture of a second proposed surrogate method based on image processing is shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. Here, we enhance our neural network design philosophy of mimicking the FDTD optical solver by making a network that analyzes a pseudo-mesh. In FDTD, the optical solution for a given combination of material and geometry is derived from solving Maxwell’s equations across a discretized mesh<sup><xref ref-type="bibr" rid="CR76">76</xref></sup>. The only way the model can differentiate between two distinct materials (e.g., air and the pyramid) is by assigning the λ-dependent material properties to each cell. Here, we approximate that process by generating an image that utilizes the spectrally dependent material and geometric information.</p><p id="Par14">An image is effectively just a tensor—as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, we take a three-dimensional matrix of material information and translate it to a standard RGB image, with each pixel containing a vector of material data. While the convolutional process is compatible with higher or lower order tensors, for ease of use and to simplify data storage/the image generator, we utilize a standard 3-channel color image. The vector used to generate each image is the same 8-input vector described in the previous section, with two additional static background material properties (n<sub>bkg</sub> = 1 and k<sub>bkg</sub> = 0). As the maximum Xspan and Zspan in the simulations are fixed to a maximum of 10 μm, each image is set to be an effective 10 × 10 μm—with the vertical and horizontal pixel resolution defining the “cell” length. To minimize memory consumption, we employ a 256 × 256-pixel configuration. This effectively means that each pixel represents ~ 40 nm, indicating that the minimum feature size we can effectively depict is ~ 40 nm. Thus, we eliminate any simulations with a pyramid base size or height less than 40 nm. As visualized in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, we build pyramids symmetrically about the center of the image, filling in the remainder of the space symmetrically until the combined pyramid base span is 10 um. As an example, a pyramid with a base span of 10 um will perfectly fill the bottom horizontal axis of the image. A pyramid with a base span of 1 um will be replicated a total of 10 times in the image.</p><p id="Par15">Two set of inputs CDNN architecture evaluates two inputs: the generated image and the 8-input vector of geometric, material, and wavelength information. The image component is interpreted by a convolutional neural network. The convolutional neural network is comprised of multiple “units”—each “unit” contains a convolutional layer with a ReLU activation function (defined by Eq. <xref rid="Equ1" ref-type="disp-formula">1</xref>) followed by a max-pooling layer.<disp-formula id="Equ1"><label>1</label><alternatives><mml:math display="block" id="Equ1_Math"><mml:mrow><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:mi>x</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.277778em"/><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mi>x</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.277778em"/><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equ1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f\left( x \right) = \left\{ {\begin{array}{*{20}l} 0 \hfill &amp; {for\; x &lt; 0} \hfill \\ x \hfill &amp; {for\; x \ge 0} \hfill \\ \end{array} } \right.$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41598_2023_34332_Article_Equ1.gif"/></alternatives></disp-formula></p><p id="Par16">After several convolutions with different filter configurations, we flatten the output and apply a dropout before a dense layer to limit overfitting. The second component, the 8-input vector is used as an input to a deep neural network. This input vector contains details that either cannot be in the image—such as the thickness and excluded material properties—or information present in the image such as the material information and geometry to reinforce the model’s interpretation and prediction performance. The output of this DNN is concatenated with the output of the CNN, and then passed through a final set of dense hidden layers. The model’s output is the same as the DNN’s output—the reflection and transmission value. Precise network design details are in the methods section.</p><p id="Par17">This surrogate method is more effective at accurately extrapolating optical properties for new materials when compared to the DNN only surrogate method. When only 20% of the available simulation data is used in the training/validation/testing process, we can match or exceed the performance of the DNN. The precise performance is dependent upon the selection of the material properties used in the three available pixel matrix dimensions. While the selection of the first two-pixel dimensions (the complex refractive index) is straightforward, the third quantity was a point of study. In Table <xref rid="Tab1" ref-type="table">1</xref>, we show the performance of the CDNN architecture in predicting the Ti, Al2O3, and material library datasets when different quantities are used in the third matrix dimension. Based on these results, we observe that the wavelength is the most effective parameter to use in the third dimension. This provides additional confirmation that the wavelength is an extremely important parameter in enabling the model to build proper connections between the input and output. The model evaluations shown in Table <xref rid="Tab1" ref-type="table">1</xref> are performed with the complete unseen datasets, we apply the 20% limitation only to the model’s training data.<table-wrap id="Tab1"><label>Table 1</label><caption xml:lang="en"><p>Comparison of training, validation, and unseen material dataset performance for the DNN and CDNN methods.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Method (% Data)</p></th><th align="left"><p>Channels</p></th><th align="left"><p>Train</p></th><th align="left"><p>Validation</p></th><th align="left"><p>Ti</p></th><th align="left"><p>Al2O3</p></th><th align="left"><p>Library</p></th></tr></thead><tbody><tr><td align="left"><p>DNN (100%)</p></td><td align="left"><p>N/A</p></td><td char="." align="char"><p>0.0032</p></td><td char="." align="char"><p>0.0033</p></td><td char="." align="char"><p>0.0175</p></td><td char="." align="char"><p>0.0141</p></td><td char="." align="char"><p>0.0279</p></td></tr><tr><td align="left"><p>CDNN (20%)</p></td><td align="left"><p>n, k, 0</p></td><td char="." align="char"><p>0.0031</p></td><td char="." align="char"><p>0.0036</p></td><td char="." align="char"><p>0.0171</p></td><td char="." align="char"><p>0.0225</p></td><td char="." align="char"><p>0.0373</p></td></tr><tr><td align="left"><p>CDNN (20%)</p></td><td align="left"><p>n, k, ε<sub>im</sub></p></td><td char="." align="char"><p>0.0019</p></td><td char="." align="char"><p>0.0032</p></td><td char="." align="char"><p>0.0266</p></td><td char="." align="char"><p>0.0176</p></td><td char="." align="char"><p>0.0378</p></td></tr><tr><td align="left"><p>CDNN (20%)</p></td><td align="left"><p>n, k, ε<sub>real</sub></p></td><td char="." align="char"><p>0.0029</p></td><td char="." align="char"><p>0.0031</p></td><td char="." align="char"><p>0.0233</p></td><td char="." align="char"><p>0.0184</p></td><td char="." align="char"><p>0.0346</p></td></tr><tr><td align="left"><p>CDNN (20%)</p></td><td align="left"><p>n, k, λ</p></td><td char="." align="char"><p>0.0025</p></td><td char="." align="char"><p>0.0031</p></td><td char="." align="char"><p>0.0185</p></td><td char="." align="char"><p>0.0163</p></td><td char="." align="char"><p>0.0314</p></td></tr></tbody></table><table-wrap-foot><p>To greatly speed up the training/validation time, we only use 20% of the available data to train the CDNN (~ 710,000 images of 3.55 million).</p></table-wrap-foot></table-wrap></p><p id="Par18">When we enable the model to see the full simulation dataset in training that the DNN does (3.55 input vectors, or 3.55 million images taken from 35,500 simulations), the CDNN method significantly outperforms the DNN method. The Ti, Al2O3, and library datasets have an evaluated MAE of 0.0155, 0.0113, and 0.0226 respectively. When we calibrate the model with 10 simulations as previously demonstrated in the DNN, this decreases to 0.0067, 0.0043, and 0.0098 respectively. Despite being more accurate than the DNN, due to the relative increase in parameters and memory scale, the training time and prediction time for the CDNN is significantly longer than the DNN.</p></sec></sec><sec id="Sec7"><title>Inverse neural network</title><p id="Par19">We harness the rapid prediction capabilities of the surrogate network to iteratively train a neural network that solves the inverse design problem. That is, we invert the forward problem to predict what material and microstructure geometry will best match a desired system optical response. The input of this network is the spectrally dependent reflectivity, transmissivity, and emissivity corresponding to a desired wavelength range.</p><p id="Par20">The architecture of the inverse neural network, as depicted in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, solves the inverse problem by considering the entire spectral distribution. The network input (400 × 1) is a vertically stacked combination of the predicted reflectivity, transmissivity, derived emissivity (ε = 1 – R – T), and the wavelength vector the optical properties are sequenced to. Correspondingly, the inverse network output is a vertically stacked combination of the geometric input and wavelength dependent material properties (n, k, ε<sub>real</sub>, ε<sub>im</sub>, 403 × 1) as visualized in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. Unlike the surrogate network, we cannot separate the inputs of an inverse network into single input vectors. An “inverted” solution for a single set of wavelength dependent optical properties has an unbounded number of potential solutions, so to design an effective inverted network the input must be the entire sequence. In our first design iterations of the deep neural network surrogate, we considered using the entire sequence of wavelengths/material data as an input and reflectivity/transmissivity as the output. While this method was effective, because Maxwell’s field equations are not sequentially dependent, the surrogate solver was much more effective when the sequences were broken up and individual vectors based on a single wavelength point were used as an input. This method also dramatically expands the scope of the training set from 35,500 simulations to 3.55 million input sets, making a limited number of simulations more effective in developing a surrogate with physical insight that can solve the forward problem more accurately. Once the surrogate is trained and can produce accurate results, however, the number of simulations becomes trivial, as we can effectively estimate the solutions to 10,000 FDTD simulations (with 100 wavelength points each) in approximately 60 s using the surrogate network.</p><p id="Par21">To generate training data for the reverse neural network, we pass in large grids of data to the surrogate network for prediction and collate the output into discrete input and output sets. For each material in a library, we generate a grid of 200 × 200 geometric combinations. These combinations are formed by meshing linearly spaced vectors for the X<sub>span</sub> and Z<sub>span</sub>. The minimum and maximum values for these vectors are based on the minimum and maximum observed value of X<sub>span</sub> and Z<sub>span</sub> in the surrogate’s training dataset. In total, the grid has 40,000 geometric combinations (or 40,000 simulations) for a single material. For each geometric combination we attach a wavelength vector of length 100, leading to a sum of 4 million inputs per material that are passed to the surrogate. While the wavelength vector attached to each geometric combination was originally a linearly spaced vector that ranged from λ = 0.3 um to λ = 16 um, we found that using a linearly spaced wavelength vector with randomized min/max values for each geometric combination increased the versatility of the training dataset and thereby increased the robustness of the inverse neural network. All generated grid data is normalized before being passed into the surrogate network for prediction. The final non-material parameter—the substrate thickness—is also randomized via a uniform random generation process. Details on the random generation process for the substrate thickness and wavelength vector can be found in the methods section. This grid generation process is repeated across all materials in a material library. The material library contains 50 materials: a list of the materials and their references are provided in the supplementary document. The number of materials in the library is easily scalable and are a non-exhaustive representation of material properties available for a microstructure. In total, we use the surrogate network to estimate 2 million simulations, or 200 million sets of inputs. We then sequence the predicted optical properties using the wavelength vector (of length 100) for each simulation.</p><p id="Par22">The inverse network contains three distinct neural network components that are designed to work in tandem to extrapolate a geometry and material that best fit the desired optical response. The first of the components is a deep neural network consisting of multiple hidden layers that directly take in the (400 × 1) input vector. On a rudimentary level, simply inverting the surrogate’s DNN structure—but with the progression of wavelengths instead of an individual wavelength point—could be effective. Through our development process, however, we discovered that this more simplistic approach lacked physical insight and would often result in a non-physically viable output. Although the solutions to Maxwell’s equations for a given wavelength, material, and geometry—the problem the forward network addresses—are not sequentially dependent, abrupt changes or singularities in material properties across a spectrum are seldom. Thus, developing insight on the relationship between a sequence of optical inputs and material properties is crucial in building a physically grounded model. To address this, we remap the linear sequence of optical properties into a “time”-dependent matrix and use it as an input to a recurrent neural network (RNN). That is, we map the 400 × 1 vector of (λ, ε, R, T) into a 1 × 100 × 4 matrix (λ, ε(λ), R(λ), T(λ)). We select bi-directional long-short term memory (LSTM) layers as the constituent component to the RNN. LSTM networks are more effective than other RNN methods for long-range dependencies in data<sup><xref ref-type="bibr" rid="CR77">77</xref></sup>, and the bi-directional attributes enables the network to learn both dependencies in the forward and reverse direction. Additionally, we utilize dropout layers between LSTM layers in conjunction with L2 regularization to reduce overfitting. The outputs of the RNN and DNN components are then combined using a matrix multiplication and fed into a third component, another DNN. As opposed to directly linking the network output to the final DNN/RNN layers, a DNN between these two networks and the final network output facilitates an additional layer of non-linear abstraction and learning from the outputs of the two preceding neural network components.</p><p id="Par23">Figure <xref rid="Fig3" ref-type="fig">3</xref> shows the output of the inverse neural network for several broadband test inputs and results once the network outputs are simulated in FDTD. We utilize three thermally relevant test spectrums as a baseline evaluator of the inverse network—unity emissivity, an ideal heating emission spectrum, and an ideal cooling spectrum. These emission spectrums are shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>g–i. For these test cases, we set the spectral transmission to be 0 and R = 1 – ε. In Fig. <xref rid="Fig3" ref-type="fig">3</xref>a–c we compare the material properties predicted by the neural network to the material properties of a material in the library that best matches it. The predicted geometric conditions are given in Table <xref rid="Tab2" ref-type="table">2</xref>. For all cases, the projected material properties have a close match in the library. In Fig. <xref rid="Fig3" ref-type="fig">3</xref>d–e we compare the results of FDTD simulations using the network generated material and the closest match material for the same predicted optimal geometry. For both the heating and unity case, we observe that the neural network generated material outperforms the library material. Additionally, we note that both the generated material and the library material produce a result that matches the desired input to a high degree of accuracy. This is despite the input having a non-physical step-function behavior. The ideal cooling spectrum (Fig. <xref rid="Fig3" ref-type="fig">3</xref>i) has a larger departure between the desired spectrum and the true outcome for both the ML and library generated materials. The observed error is attributed to the physical limitation of material properties and the imposition of zero spectral transmission. This assumption is outside of usual physical intuition for the ideal cooling case, where due to the physical material limitations, most emissive materials (e.g., TiO<sub>2</sub>, Al<sub>2</sub>O<sub>3</sub>, PDMS, etc.) in the infrared are transmissive in the ultraviolet (UV) to NIR wavelengths. Thus, this represents a design challenge for a single material to perform both functions, and the inverse neural network attempts to abstract a physically bounded material that fits zero spectral transmission. The identified properties match well across the broader spectrum but do not capture the intended performance in the visible to near infrared regions (λ = 0–4 um). If we allow transmission in this region, we receive an expected output of PDMS, details for which can be found in the supplementary document.<fig id="Fig3"><label>Figure 3</label><caption xml:lang="en"><p>(<bold>a</bold>–<bold>c</bold>) Emissivity spectrums of three test cases (Ideal heating, ideal cooling, and unity emissivity) input into the inverse spectrum. The reflectivity is computed as R = 1 – E, and transmissivity is set to 0. (<bold>d</bold>–<bold>f</bold>) ML generated refractive index (n) and extinction coefficient (k) for each of the test cases compared to the material properties of a material in the library that most closely matches it. (<bold>g</bold>–<bold>i</bold>) FDTD simulation results for both the ML generated material and the closest matching library material.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41598_2023_34332_Fig3_HTML.png" id="MO3"/></fig><table-wrap id="Tab2"><label>Table 2</label><caption xml:lang="en"><p>Library material that most closely matches the ML generated material output n and k in addition to the predicted geometric parameters.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Case</p></th><th align="left"><p>Closest material match</p></th><th align="left"><p>Xspan (um)</p></th><th align="left"><p>Zspan (um)</p></th></tr></thead><tbody><tr><td align="left"><p>Unity emissivity</p></td><td align="left"><p>C (Graphite)</p></td><td char="." align="char"><p>4.81</p></td><td char="." align="char"><p>10.3</p></td></tr><tr><td align="left"><p>Ideal heating</p></td><td align="left"><p>Li</p></td><td char="." align="char"><p>0.02</p></td><td char="." align="char"><p>3.43</p></td></tr><tr><td align="left"><p>Ideal cooling</p></td><td align="left"><p>Si<sub>3</sub>N<sub>4</sub></p></td><td char="." align="char"><p>2.29</p></td><td char="." align="char"><p>6.95</p></td></tr></tbody></table></table-wrap></p><p id="Par24">The inverse neural network is not limited to broadband design. In Fig. <xref rid="Fig4" ref-type="fig">4</xref>, we show how the inverse neural network can be applied to narrowband microstructure design. In this case, we define narrowband as 2 emissivity points with a unity value around the intended wavelength peak. The inverse neural network results for 6 different wavelength points (1, 2, 3, 4, 5, and 15 um) are shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>a–f. The design outcome highlights both the strengths and weaknesses of the presented inverse neural network methodology. The geometric design space is limited to the relatively simple micropyramid geometry and can only utilize one material. Thus, with the implemented neural network architecture, our model stays within constrained and physical material behavior, attempting to find valid solutions without creating a completely arbitrary material. This leads to valid narrowband solutions in the low wavelength regions where geometry can be attenuated to generate plasmonic resonance and resonant behavior. This behavior is particularly evident in the solutions visualized in Fig. <xref rid="Fig4" ref-type="fig">4</xref>c,d, with peaks at or near the desired location, albeit with either reduced performance or peaks beyond the desired location. The neural network can readily identify solutions that are physically feasible, but is challenged to find resonant behavior that results in narrowband solutions for the mid-infrared wavelengths. These plots result from the both the physical limitations imposed by the input, the training data available to the network, and the fundamental physics of the micropyramid system. Despite these challenges, the inverse network still can be shown to identify physical behavior outside of the scope of its training data. In Fig. <xref rid="Fig4" ref-type="fig">4</xref>d, the surrogate model’s predictions do not indicate resonant narrowband behavior at 4 um, but when simulated the inverse neural network output shows a significant degree of narrowband performance. This indicates that the reverse neural network can abstract solutions beyond the training data and identify behavior that the surrogate cannot, but the network is still constrained by the fundamental physics.<fig id="Fig4"><label>Figure 4</label><caption xml:lang="en"><p>(<bold>a</bold>–<bold>f</bold>) Narrowband simulation results using the inverse neural network. The input spectrum has an emissivity of 0.05 throughout the λ = 0.3 to 16 um, except for two points that define the “peak” location which have an emissivity of 1. The reflectivity is defined by E = 1 – R and the transmission is set to 0. The results are compared to the desired input as well as the surrogate predictions for the same material.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41598_2023_34332_Fig4_HTML.png" id="MO4"/></fig></p></sec><sec id="Sec8"><title>Post-processing: constraints and solution viability</title><p id="Par25">While the inverse neural network output can accurately predict material and geometric properties that result in the desired optical spectrum, a key limitation of our open-ended neural network architecture is that it cannot directly accommodate design constraints. This presents a significant challenge in making the inverse design process functional. Ideally, our aggregated network will output a solution that is translatable to a fabricated surface morphology. This challenge is evident from the geometric results for the ideal heating case in Table <xref rid="Tab2" ref-type="table">2</xref>; the aspect ratio of the ML predicted structure is ~ 400 (Zspan/Xspan), which is clearly an impractical microstructure. To address this, we take the output of the neural network and use a post-processing methodology to provide new solutions that fit within user set constraints. Though it is possible to constrain the neural network itself via methods such as custom activation functions on the output neurons, limiting the input dataset, or introducing limits in the input, we choose to post-process the neural network output to maintain a robust inverse solver. For this work, we focus on constraining the aspect ratio as it plays a key role in determining if a microstructure is manufacturable. Other constraints, such as a material’s maximum temperature, thickness limitations, etc., are important and can be easily incorporated for more advanced design optimization.</p><p id="Par26">The post-processing methodology has several stages: inverse prediction, material matching, geometric adjustment, surrogate prediction, simulation, and finally output comparison. Precise details for all the stages of the post-processing method are provided in the methods section. The first stage is to take an optical spectrum, pass it through the inverse network, and output a set of geometric properties and spectral material information. From there, the ML generated material data is compared to existing materials in the material library. We then adjust the ML generated geometry to align with the set maximum aspect ratio. Using the adjusted geometry, we randomly select new constrained/viable geometries and simulate them using the surrogate; the most optimal solutions are passed to FDTD. The post-processing method then compares the “ground-truth” FDTD to both the surrogate output and the desired input. This process is performed for both the ML-generated material and “best-fit” library material and identifies a constrained geometry that is optimal for both the ML-generated material and selected library material.</p><p id="Par27">Figure <xref rid="Fig5" ref-type="fig">5</xref>a,b shows the post-processing method’s application to select a new viable solution for the ideal heating case discussed above. For this demonstration, we show solutions when the aspect ratio (Z/X) is limited to 10, 5, and 1. The new geometric solutions are simulated using the surrogate, and the results are compared to the predictions for the unconstrained ML generated geometry. Compared to the desired input spectrum, the constrained cases have an LSE value of 1.229, 1.396, and 1.567 for AR = 10, 5, and 1 respectively. It is evident that while the results decrease in adherence to the desired spectrum as the aspect ratio is limited, it is also evident from Fig. <xref rid="Fig5" ref-type="fig">5</xref>c that the adjustments to the geometry to accommodate the limited aspect ratio constraint still yield highly optimal results. It is evident that these solutions deviate from the global maximum but are still highly effective when constrained. If the constrained solution is deemed to not be viable enough, additional materials can be included in the search, forming a more advanced material matching algorithm than previously utilized<sup><xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR72">72</xref></sup>.<fig id="Fig5"><label>Figure 5</label><caption xml:lang="en"><p>(<bold>a</bold>) Example of vertical and (<bold>b</bold>) horizontal reorientation of inverse ML output and subsequent generation of randomly distributed solution points about the adjusted geometric solution. Example shown is using an aspect ratio limitation of 5. These solutions are evaluated using both FDTD and the surrogate, the most optimal new solution is using a process described in the methods section. (<bold>c</bold>) The identified optimal point at each aspect ratio is shown for each aspect ratio. While the solution is not as optimal as the original ML generated geometry, the we can still identify geometric designs with exceptional performance.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41598_2023_34332_Fig5_HTML.png" id="MO5"/></fig></p></sec><sec id="Sec9"><title>Aggregated neural network</title><p id="Par28">By combining the individual components, we form the aggregated system loop visualized in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. The aggregated system is designed in a way that it can learn from previous mistakes and enhance its capabilities and accuracy over subsequent generations. Despite the accuracy of the image-based surrogate, especially for unseen materials, the time required to train and retrain the image-based convolutional network compared to the simpler deep neural network surrogate eliminates it as an option for the aggregate system. The geometric/wavelength simulation grid data generated for each material is passed into the DNN surrogate and the ensuing predictions are the basis of the inverse network training data. If changes are made to the surrogate or more materials are included in the library, the grid data will be regenerated. We then employ the broadband and narrowband test cases in Figs. <xref rid="Fig3" ref-type="fig">3</xref> and <xref rid="Fig4" ref-type="fig">4</xref> to test the performance of the inverse network in making predictions. If either significant deviations between the desired result and actual result are encountered or the surrogate prediction deviates significantly from the FDTD results, we perform additional simulations via our post-processing solution generation method. These results are incorporated in the training data for the surrogate, and the surrogate/inverse network are retrained. Post-processing then serves an additional function as a pseudo-adversarial checkpoint where the generated results are compared to true results and if there is an undesired outcome the network is retrained with new simulation information.</p></sec></sec><sec id="Sec10" sec-type="discussion"><title>Discussion</title><p id="Par29">A core challenge facing the design of microstructures is the time required to simulate and optimize a design. For the first component, in stark contrast to an FDTD solver, a neural network can make predictions comparatively instantaneously. The generation of the ~ 40,000 FDTD simulations used to train, test, and evaluate our surrogate network required months of computational time, whereas the surrogate network can predict a 40,000-simulation grid (4 million sets) in approximately 4–5 min. The DNN surrogate network can predict a 100-wavelength point simulation in approximately 6 ms, representing a 4 to 6 order of magnitude speed increase compared to using the FDTD solver for the same task. Considering the demonstrated accuracy of the network across a library of materials, this method is highly effective in substantially reducing the need for complex optical solvers to estimate spectral optical properties across a large material library. As previously demonstrated, once the model has a connection to the physics of the problem, very few simulations are required to “calibrate” the model to new materials. Our DNN surrogate only requires an average of 5–20 FDTD simulations to be included in training per material to bring the prediction error for that material to near to the rest of the dataset.</p><p id="Par30">A fundamental advantage of the surrogate network compared to FDTD simulations—speed—is leveraged in this work to build a comprehensive dataset for training an inverse solver that aims to address key challenges in design optimization. In our previous publications, we addressed optimization using a thermal figure of merit and a “brute force” optimization method. That is, we designed an objective function to describe a desired spectrum and use the FDTD or surrogate optical output to solve the thermal equations and then use the objective function to determine which spectrum most optimally matches the input. This method, clearly, is incredibly slow and cumbersome. Using a neural network to perform the inverse task—much like the forward solving network—is orders of magnitude faster than this approach. The speed difference relies on the fact that the inverse neural network can learn the pattern between the optical properties and material/geometric properties, and directly take in a spectrum and output a material/geometry that suits it. Rather than a roundabout methodology that relies on identifying the best spectrum using grids of surrogate generated data across multiple materials, the inverse network trains on those grids and provides a user with a nearly instantaneous output to a selected spectrum. This method also opens the door to non-intuitive solutions as we can potentially identify new materials that are not in the material library.</p><p id="Par31">Determining the appropriate surrogate method to generate the training data for the inverse data is an important consideration in the design of the aggregate system. Ultimately, due to the large grids of data used to generate the training data and the training/retraining process, the inverse network necessitates a fast surrogate. The DNN methodology, as compared to the CNN, is significantly faster in making predictions and in training. When trained on the full dataset, the image-based approach can require hundreds of hours to train using our computational resources. Comparatively, the DNN can train on the entire dataset in approximately 25–50 h. Additionally, the prediction time is significantly longer for the CDNN, making the generation of simulation data to train the inverse network far less efficient. While the CDNN method is more accurate, the incremental accuracy increase we observe does not justify the time cost in this case. We could reduce the size of the images used by the CDNN to speed up the network training and prediction times, but then we would lose spatial resolution and must eliminate a greater quantity of simulations from consideration. The efficacy of the CDNN will be more apparent in future work that relies on more complex structures. The images used as an input are not specifically bound to a single geometry, and a CDNN surrogate could be constructed that solves the optical properties of different geometries or even abstract shapes. This could also include multiple geometries, hierarchies, or even structures that include multiple materials such as coated structures or composite structures. In addition to these options, a CDNN could also be converted into a tandem inverse solver with a generative network. Ultimately, while the micropyramid geometry we show in the present work is relatively simple and does not necessitate the image-based surrogate to train the inverse network, potential future options for complex inverse neural networks based on an “image derived mesh” are boundless.</p><p id="Par32">The primary strength of the inverse neural network design—its ability to generate a unique set of spectral material properties—leads to significant design and implementation challenges. A core concern in the design of the network is determining how to balance a desire to remain physically bounded while also enabling the model to find ways to extrapolate in new and unique ways. A simple approach would have been to simply one-hot encode material classifications, thereby eliminating non-physical material outputs. This approach is undesirable as it not only eliminates the ability to extrapolate new materials, but it also significantly reduces the ability to explore different materials in post-processing. As demonstrated, the model generated material properties can outperform the materials in the library. As the scope of the surrogate and inverse network continue to expand, more materials are added, and more simulations are performed, we expect that the inverse network will not only increasingly outperform existing materials but could be used to identify “effective” refractive indices and inform the reverse engineering of material combinations that match it. These strengths are lost with rigid material classification, and to maintain a robust solver we designed the network to accommodate material outputs that are only bounded by the arbitrary list of materials used to generate the training data.</p><p id="Par33">The design choice to allow the network to choose discrete material properties—as opposed to classification—does lead to significant challenges and necessitated design compromises. Early iterations of the inverse network design utilized a single DNN with a single vector (400 × 1) input, but we found that the output would often be non-physical or unrealistic. Thus, to ground the model from pure abstraction of material properties, we implemented a sequential method utilizing an RNN to ensure that the model could learn the forward and backward relationships of the material properties. This enables the model to have a certain level of physical insight into how materials usually look, so that when it generates the output the output should resemble, but hopefully surpass, the performance of microstructure made of the “best-match” material in the library. Additionally, our network’s early construction only considered the emissivity as an input. Over subsequent model iterations, however, we found that the inclusion of the two parameters that determine the emissivity—the reflectivity and transmission—enabled not only more control for the user, but also additional reinforcement in the model’s ability to abstract physical relationships between the material properties and input spectrum.</p><p id="Par34">An important consideration is the impact that geometry has on the optical properties and thereby the thermal performance compared to an untextured surface. The materials generated and identified through the neural network process conform to physical intuition for each of the test inputs. While this intuition may be sufficient for a material matching algorithm, the application of optimized texture further enhances absorption and improves the thermal and optical outcome for a system. This is particularly true for the Ideal heating input shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>a, where optimal texturing leads to a surface that can absorb over 96% of incident solar radiation, compared to approximately 15% when the surface is untextured. While untextured (completely smooth) graphite of &lt; 100 um thickness has an emission efficiency of ~ 33.5%, ML identified optimal texturing increases the emission efficiency to ~ 99.6%. Texture has a more minimal impact on Si<sub>3</sub>N<sub>4</sub>, raising the emission efficiency from ~ 75.6–99.9%. The derivation and graphical representation of these values is shown in the supporting materials.</p><p id="Par35">Several key issues arise from the selected network design. The first is in identifying and subsequently correcting any mistakes made by the inverse neural network. Due to the open-ended design of the material outputs and the large variability in the inputs, it is very easy for a user to specify a non-physical input that can result in the network making a valid approximation for much of the broadband spectrum but missing a key narrow portion of the spectrum. This is particularly apparent in the narrowband case shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref> where a large broadband wavelength input is used in conjunction with a non-physically intuitive spectrum for a single material microsystem. This design challenge necessitated switching from only broadband wavelength inputs (0.3–16 um) in the training data to randomizing the wavelength/material vector passed into the surrogate. Still, results still demonstrate that the model will attempt to solve the problem but of course cannot correct a user’s input. It should be acknowledged that the network is trained using physically bounded and sequential results, so abstracting a solution for what could be a non-physical desired spectrum should not be expected to have a high degree of accuracy. A second related challenge comes from the material data pathways and generation methods. The FDTD method relies on curve-fit data based on experimentally sampled measurements. Our network builds a cubic-spline fit model based on FDTD generated material data. When we want to simulate the neural network generated material properties, we need to pass it into FDTD in the same way physical measurements would be. This can lead to some fundamental challenges in curve-fitting and automation, as the FDTD curve fit for ML generated data may be completely incorrect and require manual intervention. This process also limits our options to use ML generated data in the aggregated system training loop. If the actual properties deviate from the inputs, incorporating the data could lead to significant prediction inaccuracies. For future modelling efforts with more advanced systems and multi-material composites, very careful interpretation and interpolation of material properties will be required to properly represent and predict new materials.</p><p id="Par36">Another challenge is to constrain the output based on user set limits. Potentially applicable constraints are plentiful, but for this work we focused on constraining the aspect ratio as it is a crucial element in determining the manufacturability and scalability of a microstructure. We presented a solution to both key issues by introducing a post-processing module. This module is not a neural network, and it operates outside of the “black box” of neural network design and can be more easily adjusted to account for real scenarios using the optimal output provided by the inverse network. An apparent shortcoming to neural network design is in understanding the ever-increasing complexity of non-linear abstraction that occurs inside of the “black-box” of the hidden layers. While we could introduce limitations on the network, add new variables, etc., to account for the constraints, this may not only reduce the robustness of the architecture but also could make it difficult to supplement or adjust the solution with physical insight.</p><p id="Par37">In effect, the post-processing module takes the role of both an adversarial checkpoint as well as a local-minimum optimization method. If the imposed constraints are violated, the post-processing module infers new solutions and determines which of these are most optimal. Of course, this method could be used in the same “brute-force” manner that we utilized in previous publications<sup><xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR32">32</xref>,<xref ref-type="bibr" rid="CR72">72</xref></sup> to determine a local minimum optimal solution from the surrogate, particularly if it was combined with a gradient-descent optimization method. However, this has the same issues as the previous approaches in that the result is not only likely to be a local minimum, but that we would be required to repeat the process for every material in the library. The aggregated system is designed to leverage all the modules to automatically learn and correct the networks if an incorrect prediction is made by either the surrogate or inverse network. By generating new solutions, simulating them, and then comparing and simulation results to the surrogate results and desired input, a decision can be automatically made to include the simulation data in a subsequent loop of data generation and model training. This process is directly transferable to any microsystem design, and for more advanced iterations that include additional limiting parameters such as temperature dependence and temperature dependent material properties. The unbounded nature of the entire loop also unlocks unique perspectives and solutions that would otherwise be infeasible.</p></sec><sec id="Sec11" sec-type="conclusions"><title>Conclusion</title><p id="Par38">We have demonstrated a platform that can output discrete and unique material and geometric properties that will lead to an input optical spectrum. The models are not rigidly constrained by material classification, and the network can be used to identify the material properties that would best solve the problem. The inverse solver enables the design of a material matching algorithm that can identify what materials are best suited to match a desired optical response based on user set constraints. Furthermore, the inverse network input is not limited to a preset input wavelength vector, enabling the dynamic exploration of narrow band and limited wavelength solutions in addition to more traditional broadband inverse optimization. As a part of the platform, the exhibited post-processing method takes the output of the inverse neural network, removes it from the black box of neural network processing, and allows for adjustments to the neural network output based on set constraints. The post-processing section also serves as an adversarial node to the combined system, connecting to the FDTD simulation source and introducing targeted simulation data to improve the neural network in subsequent generations. While we only use the deep-neural network derived surrogate solver as a part of this process, the image-based method we developed could play a pivotal role in future iterations of inverse design networks for more complicated microstructures or multi-material systems that cannot be simply represented in a deep-neural network. Our methodology not only effectively replaces FDTD simulations for micropyramids, but it also enables near instantaneous inverse-design and optimization, allowing for near instantaneous complex and comprehensive design optimizations.</p></sec><sec id="Sec12" sec-type="methods"><title>Methods</title><sec id="Sec13"><title>Data and code availability</title><p id="Par39">The datasets and models generated and/or analyzed during the current study are available in the Inverse-Optical-Neural-Network repository, <ext-link xlink:href="https://github.com/jmsulliv/Optical_Prediction_Reverse_Network" ext-link-type="uri">https://github.com/jmsulliv/Optical_Prediction_Reverse_Network.</ext-link></p></sec><sec id="Sec14"><title>FDTD simulations</title><p id="Par40">We perform FDTD simulations in Lumerical/ANSYS’s commercially available FDTD simulation software. The unit cell shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref> replicates the major variables simulated—x<sub>span</sub>, z<sub>span</sub>, and t<sub>sub</sub>. A plane wave source with normal incidence is placed in the z-direction. For this work we do not consider angular dependence of the optical properties or of the dependence of the optical properties on the polarization angle. The injection wavelength spans a linearly spaced vector of 100 wavelength points that begins with λ<sub>min</sub> and ends with λ<sub>max</sub>. Perfectly matched layers are applied in the direction of the injection source to prevent boundary reflection at both the top and bottom of the domain and periodic boundary conditions are placed perpendicular to the wave source. Frequency-domain field and power monitors are placed above and below the PML boundary layers to monitor reflection and transmission respectively. Emissivity is computed using Kirchhoff’s Law, α = ε = 1 – R – T. The monitors are solved at every frequency/wavelength point, leading to a one-to-one matching of the simulation output to the wave source.</p><p id="Par41">For the surrogate training data, while there are some variations in the wavelengths used to generate the material data<sup><xref ref-type="bibr" rid="CR72">72</xref></sup>, the majority of the materials are simulated using a λ<sub>min</sub>/λ<sub>max</sub> of 0.3/16 μm respectively. Vanadium Dioxide is divided into two separate materials: that of an insulation phase (ceramic behavior) and metallic phase (metallic behavior)<sup><xref ref-type="bibr" rid="CR78">78</xref></sup>. The value of t<sub>sub</sub> depends on the material selection. For metals (Ni, Al, Ag, W, Sn, Fe, Ta, Cr, Ti) and SiC we simulate over a range of random t<sub>sub</sub> values confined by a minimum value of 1 μm and a maximum of 3 um. For transmissive materials with a wide range of substrate dependent performance (e.g., VO<sub>2</sub>, SiO<sub>2</sub>, PDMS, Al<sub>2</sub>O<sub>3</sub>) we choose the minimum thickness to be 1 um and the maximum to be 100 μm. For simulations that occur as part of the post-processing phase in the aggregate network loop, simulations directly take in the output properties of the post-processing module/neural network.</p></sec><sec id="Sec15"><title>Network architecture and optimization</title><p id="Par42">We use a deep neural network with fully connected dense layers. Our deep learning approach is built upon the open source keras library in python<sup><xref ref-type="bibr" rid="CR79">79</xref></sup>. The surrogate network, as previously published<sup><xref ref-type="bibr" rid="CR72">72</xref></sup>, uses an optimized DNN with 8 fully connected dense layers with 400 neurons per layer, and both MLPs are 4 layers of 50 neurons each.</p><p id="Par43">The CDNN network combines a similar DNN structure with a CNN architecture. The first DNN structure takes in the same input vector as previously discussed network but uses a smaller set of layers and neurons. The CNN uses 6 groups of convolution – ReLU – max pooling. The filter configuration for the convolutional layers is 64, 128, 256, 512, 512, 512. The final convolutional layer is followed by a max pooling, dropout (0.25), flatten, dense, dropout (0.5), and then a final dense layer. The output is concatenated with the DNN structure and fed into another DNN, which is 7 fully connected dense layers with 1024 neurons each. We utilize a custom image generator process to handle the import of images and their associated deep neural network properties into the model.</p><p id="Par44">The inverse network takes the same set of inputs (1 × 400 vector) and applies it in two separate ways. The first is a direct input to a deep neural network, with a 1 × 400 input shape, which consists of 6 fully connected dense layers of 750 neurons each. The second input recasts the original 1 × 400 vector into a 1 × 100 × 4 vector and is put into a recurrent neural network. The RNN is constructed of 3 bi-directional LSTM modules—that is, a bi-directional LSTM layer followed by a dropout (0.5). Each bi-directional LSTM layer has 320 neurons, and the final layer’s output is non-sequenced. The outputs of the RNN and DNN are concatenated and then fed into a larger deep neural network that consists of 6 layers of 1000 neurons each. The final output is 403 neurons with no applied activation function. We experimented with different methods of combining the two outputs—including matrix multiplication, addition, and subtraction—but found that the concatenation was consistently yielded the best results.</p><p id="Par45">For training all the models, we utilize a MSE loss function and validate/evaluate using an MAE score based on Eqs. (<xref rid="Equ1" ref-type="disp-formula">1</xref>) and (<xref rid="Equ2" ref-type="disp-formula">2</xref>) respectively, where <inline-formula id="IEq1"><alternatives><mml:math id="IEq1_Math"><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Y_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="41598_2023_34332_Article_IEq1.gif"/></alternatives></inline-formula> is the predicted value. A key change to the model training compared to prior results is that all data is made available to the network and there are no “unseen” materials in the training process. For the grid generation process, we do utilize several materials that are outside of the scope of the training process, but no simulation data was generated for these materials prior to training the reverse network. The full list of materials included in training and in grid generation are provided in the<disp-formula id="Equ2"><label>2</label><alternatives><mml:math display="block" id="Equ2_Math"><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="Equ2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MSE = \frac{1}{n}\mathop \sum \limits_{i = 2}^{n} \left( {Y_{i} - \widehat{{Y_{i} }}} \right)^{2}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41598_2023_34332_Article_Equ2.gif"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><mml:math display="block" id="Equ3_Math"><mml:mrow><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:mfenced></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MAE = \frac{{\mathop \sum \nolimits_{i = 1}^{n} \left| {Y_{i} - \widehat{{Y_{i} }}} \right|}}{n}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41598_2023_34332_Article_Equ3.gif"/></alternatives></disp-formula></p><p id="Par46">In all cases, optimization of the hyperparameters is performed with the built-in hyperband optimization method<sup><xref ref-type="bibr" rid="CR80">80</xref></sup>. Adam is the optimization engine used for the network training in all cases. To minimize overfitting, we utilize L2 regularization in the training and validation process, in addition to utilizing early stopping, checkpoint save, and reduce learning rate on plateau callbacks with low patience values<sup><xref ref-type="bibr" rid="CR72">72</xref></sup>. Some models incorporate dropout layers to further reduce model overfitting.</p></sec><sec id="Sec16"><title>Datasets and normalization</title><p id="Par47">All datasets used by the neural networks are derived from FDTD simulation inputs and outputs directly. For each material in the training/validation/test dataset of the surrogate models, we generate a uniformly distributed random matrix for each of the geometric properties to use as inputs for the simulation. The simulation wavelength and n and k values are taken from each simulation and split into sets of input data, spanning a total of 8 neural inputs (n and k are converted into ε<sub>real</sub> and ε<sub>im</sub>). The simulation output is 100 emissivity and 100 reflectivity points that one-to-one match the simulation wavelength vector, which is divided into pairs for each λ. The ε<sub>real</sub> permittivity value is of particular concern due to the negative values induced by -k<sup>2</sup> term shown in Eq. (<xref rid="Equ4" ref-type="disp-formula">4</xref>).<disp-formula id="Equ4"><label>4</label><alternatives><mml:math display="block" id="Equ4_Math"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi mathvariant="italic">real</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="Equ4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varepsilon_{real} = n^{2} - k^{2}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41598_2023_34332_Article_Equ4.gif"/></alternatives></disp-formula></p><p id="Par48">A fundamental problem faced is that optically, the difference between k = 1e-4 and 1e-3 is not mathematically large, but the difference does have a large impact on the transmission behavior through the substrate. Thus, the data is grouped near 0 but we need to differentiate values in a meaningful way to distinguish the physical behavior of each material. Log normalization reduces the severity of the weighted inputs but does not solve it. For all of the datasets shown in this work, we utilize quantile normalization with sklearn’s built in quantile transformer, to generate a uniform distribution of inputs for k, t<sub>sub</sub>, ε<sub>real,</sub> and ε<sub>im</sub>. A change from our previous results<sup><xref ref-type="bibr" rid="CR72">72</xref></sup> is that we simplify the normalization pipeline by normalizing the refractive index n and the geometric properties using the quantile method. All datasets used in this work, and the techniques used to normalize, denormalize, and configure the data are provided in our GitHub repository.</p><p id="Par49">For the surrogate models, we combine 40,500 FDTD simulations for micropyramids made of 41 different materials to form our training, validation, and test dataset. We follow a 70/20/10 percentage split respectively. The test dataset is used to evaluate the performance and overfitting of the model and it is not seen by the network in the training process. We shuffle the complete dataset every time the model is run or generated such that the training, validation, and test datasets are never identical from iteration to iteration.</p><p id="Par50">For the inverse model, the training data is generated using the surrogate data. Whereas the surrogate provides the reflectivity and transmissivity provide an output for an individual wavelength point, the inverse uses a full vector input by stacking predictions from the surrogate. The full wavelength vector input that corresponds to an output we refer to as a “surrogate simulation”. For each material, we develop a grid of surrogate simulations by varying the xspan and zspan of the micropyramid and attaching a randomized wavelength vector and thickness value for each individual set of (xspan, zspan) in the grid. The grid is generated using a randomization process for pairs of x and z geometric coordinates. The process checks to ensure each material has no repeated pairs. The randomization process for the wavelength vector involves creating a linearly spaced vector of 100 points with a randomized minimum and maximum value. The minimum and maximum values are the randomly generated parameters and are between (0.3–15) and (2–16) μm respectively. If the randomly selected “minimum value” is larger than the “maximum” value, the values are switched in generating the wavelength vector. The random process is iterated to ensure that the gap between the minimum and maximum wavelength values is 2 um. The material information is generated from inputting the generated wavelength vector into a splined curve fit. The splined curve-fits are generated using a 2000-point dataset for each material. Due to the size of the inverse dataset, we adopt a 50/40/10 training/validation/test split for the inverse network training process.</p></sec><sec id="Sec17"><title>Post-processing: material fitting</title><p id="Par51">The output of the inverse neural network contains a vector of n and k values, matched to an input of wavelength points. To provide the “best-fit” material, we compare the material data (n, k) to the material data in the library. The library data is generated using the same spline process as described in the previous section and depends on the user wavelength spectrum that was input into the reverse network. We check each (n, k) vector combination in the material library against the model output using the least-squares method shown in Eq. (<xref rid="Equ5" ref-type="disp-formula">5</xref>).</p><p id="Par52">Before comparing the values using Eq. (<xref rid="Equ5" ref-type="disp-formula">5</xref>), we adjust the (n,k) vector using a log transformation shown in Eq. (<xref rid="Equ6" ref-type="disp-formula">6</xref>). While a comparison using Eq. (<xref rid="Equ5" ref-type="disp-formula">5</xref>) is still viable, the log adjustment allows for better comparisons to materials that depend strongly on minute differences in n, k values. As discussed, transmissive materials depend strongly on small changes in the n and k values, so having a scale that enables better comparison for small values enables us to draw better conclusions from Eq. 6as to which materials best match the ML output.<disp-formula id="Equ5"><label>5</label><alternatives><mml:math display="block" id="Equ5_Math"><mml:mrow><mml:mi>L</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="Equ5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$LSE = \mathop \sum \limits_{i = 2}^{n} \left( {Y_{i} - \widehat{{Y_{i} }}} \right)^{2}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41598_2023_34332_Article_Equ5.gif"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><mml:math display="block" id="Equ6_Math"><mml:mrow><mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfenced><mml:mrow><mml:mi mathvariant="italic">adj</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>log</mml:mo><mml:mn>10</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left( {n,k} \right)_{adj} = \log_{10} (\left( {n,k} \right) + a)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="41598_2023_34332_Article_Equ6.gif"/></alternatives></disp-formula></p></sec><sec id="Sec18"><title>Post-processing: new solution generation</title><p id="Par53">In the post-processing module, we adjust the inverse network output according to user set constraints. In our present work, we only limit the aspect ratio, but the method can easily be adjusted to account for more conditions. To do this, we generate two sets of new geometric coordinates (for the same material) that do not violate the constraint. The process starts by adjusting the original solution’s x and z coordinate while fixing the other coordinate until the aspect ratio is within the constraint’s bounds. This follows our previously established intuition on the role of aspect ratio in determining optical/thermal property optimality<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. For a different microstructure, we would need to adjust this process to match the observed patterns for the microtexture and the desired constraint. From these two new points, we generate new geometric pairs within a radius around the modified geometric coordinate. The generation process is random and uniform, and solutions that are not below or equal to the desired aspect ratio are eliminated. All viable solutions are then passed into the surrogate for predictions; the results that best match the desired input are simulated in FDTD. We also select random points from the remaining pool of randomly generated viable geometric solutions to have additional solution variety and to reduce concerns of over-biasing the network when the surrogate incorporates the new FDTD solutions in training. The desired input and model/FDTD outputs are evaluated for optimality using Eq. (<xref rid="Equ5" ref-type="disp-formula">5</xref>). This process is used to generate solutions separately for the direct ML material output and then the “best-fit” material(s). We will often only use a single “best-fit” material, but for some cases we will look beyond the first library match.</p></sec></sec></body><back><sec sec-type="author-contribution"><title>Author contributions</title><p>J.S., A.M., and J.L. conceived the idea. J.S. contributed to the generation of the deep-learning models, optimization, and dataset preparation. J.S. contributed to the FDTD simulations. J.S. contributed to the generation and implementation of the material search algorithm, tandem neural network, and aggregate network architecture. All authors discussed the results and revised the manuscript.</p></sec><sec><title>Funding</title><p>The funding was provided by NASA (Grant Nos. 80NSSC19K1671, 80NSSC19K1671).</p></sec><sec sec-type="ethics-statement"><sec id="FPar1" sec-type="COI-statement"><title>Competing interests</title><p id="Par54">The authors declare no competing interests.</p></sec></sec><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raman</surname><given-names>AP</given-names></name><name><surname>Anoma</surname><given-names>MA</given-names></name><name><surname>Zhu</surname><given-names>L</given-names></name><name><surname>Rephaeli</surname><given-names>E</given-names></name><name><surname>Fan</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Passive radiative cooling below ambient air temperature under direct sunlight</article-title><source>Nature</source><year>2014</year><volume>515</volume><fpage>540</fpage><lpage>544</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2014Natur.515..540R</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2cXitFanu7bN</pub-id><pub-id pub-id-type="doi">10.1038/nature13883</pub-id><pub-id pub-id-type="pmid">25428501</pub-id></mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nie</surname><given-names>X</given-names></name><etal/></person-group><article-title xml:lang="en">Cool white polymer coatings based on glass bubbles for buildings</article-title><source>Sci. Rep.</source><year>2020</year><volume>10</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2020NatSR..10...10N</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXnsFSlsbY%3D</pub-id><pub-id pub-id-type="doi">10.1038/s41598-020-63027-2</pub-id></mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhai</surname><given-names>Y</given-names></name><etal/></person-group><article-title xml:lang="en">Scalable-manufactured randomized glass-polymer hybrid metamaterial for daytime radiative cooling</article-title><source>Science</source><year>2017</year><volume>355</volume><fpage>1062</fpage><lpage>1066</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2017Sci...355.1062Z</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXjvVWjtbo%3D</pub-id><pub-id pub-id-type="doi">10.1126/science.aai7899</pub-id><pub-id pub-id-type="pmid">28183998</pub-id></mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>X</given-names></name><name><surname>Yang</surname><given-names>R</given-names></name><name><surname>Tan</surname><given-names>G</given-names></name><name><surname>Fan</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Terrestrial radiative cooling: Using the cold universe as a renewable and sustainable energy source</article-title><source>Science</source><year>2020</year><volume>370</volume><fpage>786</fpage><lpage>791</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2020Sci...370..786Y</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXitlCmt73K</pub-id><pub-id pub-id-type="doi">10.1126/science.abb0971</pub-id><pub-id pub-id-type="pmid">33184205</pub-id></mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>P</given-names></name><etal/></person-group><article-title xml:lang="en">Large-scale nanophotonic solar selective absorbers for high-efficiency solar thermal energy conversion</article-title><source>Adv. Mater.</source><year>2015</year><volume>27</volume><fpage>4585</fpage><lpage>4591</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXhtFWjtLvM</pub-id><pub-id pub-id-type="doi">10.1002/adma.201501686</pub-id><pub-id pub-id-type="pmid">26134928</pub-id></mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>R</given-names></name><name><surname>Rosen</surname><given-names>MA</given-names></name></person-group><article-title xml:lang="en">Thermal performance of integrated collector storage solar water heater with corrugated absorber surface</article-title><source>Appl. Therm. Eng.</source><year>2010</year><volume>30</volume><fpage>1764</fpage><lpage>1768</lpage><pub-id pub-id-type="doi">10.1016/j.applthermaleng.2010.04.007</pub-id></mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfiester</surname><given-names>NA</given-names></name><name><surname>Vandervelde</surname><given-names>TE</given-names></name></person-group><article-title xml:lang="en">Selective emitters for thermophotovoltaic applications</article-title><source>Phys. Status Solidi Appl. Mater. Sci.</source><year>2017</year><volume>214</volume><fpage>1</fpage><lpage>24</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28XhslyisrrI</pub-id><pub-id pub-id-type="doi">10.1002/pssa.201600410</pub-id></mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Fan</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Nanophotonic control of thermal radiation for energy applications [Invited]</article-title><source>Opt. Express</source><year>2018</year><volume>26</volume><fpage>15995</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018OExpr..2615995L</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXitlyjsLzK</pub-id><pub-id pub-id-type="doi">10.1364/oe.26.015995</pub-id><pub-id pub-id-type="pmid">30114851</pub-id></mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mandal</surname><given-names>J</given-names></name><etal/></person-group><article-title xml:lang="en">Hierarchically porous polymer coatings for highly efficient passive daytime radiative cooling</article-title><source>Science</source><year>2018</year><volume>362</volume><fpage>315</fpage><lpage>319</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018Sci...362..315M</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXhvFWksbnE</pub-id><pub-id pub-id-type="doi">10.1126/science.aat9513</pub-id><pub-id pub-id-type="pmid">30262632</pub-id></mixed-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dang</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Ye</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">An ultrathin transparent radiative cooling photonic structure with a high NIR reflection</article-title><source>Adv. Mater. Interfaces</source><year>2022</year><volume>2201050</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB38XisVagtrrE</pub-id><pub-id pub-id-type="doi">10.1002/admi.202201050</pub-id></mixed-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Z</given-names></name><name><surname>Nie</surname><given-names>X</given-names></name><name><surname>Yuksel</surname><given-names>A</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Reflectivity of solid and hollow microsphere composites and the effects of uniform and varying diameters</article-title><source>J. Appl. Phys.</source><year>2020</year><pub-id pub-id-type="doi">10.1063/5.0015650</pub-id></mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nie</surname><given-names>X</given-names></name><name><surname>Yu</surname><given-names>Z</given-names></name><name><surname>Jackson</surname><given-names>E</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Refractive index and extinction coefficient of hollow microspheres for solar reflection</article-title><source>Appl. Phys. Lett.</source><year>2021</year><pub-id pub-id-type="doi">10.1063/5.0049018</pub-id></mixed-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sala-Casanovas</surname><given-names>M</given-names></name><name><surname>Krishna</surname><given-names>A</given-names></name><name><surname>Yu</surname><given-names>Z</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Bio-inspired stretchable selective emitters based on corrugated nickel for personal thermal management</article-title><source>Nanoscale Microscale Thermophys. Eng.</source><year>2019</year><volume>23</volume><fpage>173</fpage><lpage>187</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2019NMTE...23..173S</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXlsFemtr0%3D</pub-id><pub-id pub-id-type="doi">10.1080/15567265.2019.1586017</pub-id></mixed-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krishna</surname><given-names>A</given-names></name><etal/></person-group><article-title xml:lang="en">Ultraviolet to mid-infrared emissivity control by mechanically reconfigurable graphene</article-title><source>Nano Lett.</source><year>2019</year><volume>19</volume><fpage>5086</fpage><lpage>5092</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2019NanoL..19.5086K</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXht1Oqsb%2FO</pub-id><pub-id pub-id-type="doi">10.1021/acs.nanolett.9b01358</pub-id><pub-id pub-id-type="pmid">31251631</pub-id></mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>J</given-names></name><name><surname>Hsu</surname><given-names>CM</given-names></name><name><surname>Yu</surname><given-names>Z</given-names></name><name><surname>Fan</surname><given-names>S</given-names></name><name><surname>Cui</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Nanodome solar cells with efficient light management and self-cleaning</article-title><source>Nano Lett.</source><year>2010</year><volume>10</volume><fpage>1979</fpage><lpage>1984</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2010NanoL..10.1979Z</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3cXnsFOhs7Y%3D</pub-id><pub-id pub-id-type="doi">10.1021/nl9034237</pub-id><pub-id pub-id-type="pmid">19891462</pub-id></mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>BJ</given-names></name><name><surname>Chen</surname><given-names>YB</given-names></name><name><surname>Han</surname><given-names>S</given-names></name><name><surname>Chiu</surname><given-names>FC</given-names></name><name><surname>Lee</surname><given-names>HJ</given-names></name></person-group><article-title xml:lang="en">Wavelength-selective solar thermal absorber with two-dimensional nickel gratings</article-title><source>J. Heat Transfer</source><year>2014</year><volume>136</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2cXht12nsL7E</pub-id><pub-id pub-id-type="doi">10.1115/1.4026954</pub-id></mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>L</given-names></name><name><surname>Yu</surname><given-names>X</given-names></name><name><surname>Zhu</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Metal-core/semiconductor-shell nanocones for broadband solar absorption enhancement</article-title><source>Nano Lett.</source><year>2014</year><volume>14</volume><fpage>1093</fpage><lpage>1098</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2014NanoL..14.1093Z</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2cXpt1KrsQ%3D%3D</pub-id><pub-id pub-id-type="doi">10.1021/nl500008y</pub-id><pub-id pub-id-type="pmid">24443983</pub-id></mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lung</surname><given-names>CM</given-names></name><name><surname>Wang</surname><given-names>WC</given-names></name><name><surname>Chen</surname><given-names>CH</given-names></name><name><surname>Chen</surname><given-names>LY</given-names></name><name><surname>Chen</surname><given-names>MJ</given-names></name></person-group><article-title xml:lang="en">ZnO/Al2O3 core/shell nanorods array as excellent anti-reflection layers on silicon solar cells</article-title><source>Mater. Chem. Phys.</source><year>2016</year><volume>180</volume><fpage>195</fpage><lpage>202</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28XpsVOku70%3D</pub-id><pub-id pub-id-type="doi">10.1016/j.matchemphys.2016.05.063</pub-id></mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Søndergaard</surname><given-names>T</given-names></name><etal/></person-group><article-title xml:lang="en">Plasmonic black gold by adiabatic nanofocusing and absorption of light in ultra-sharp convex grooves</article-title><source>Nat. Commun.</source><year>2012</year><volume>3</volume><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38Xhsleiu7rP</pub-id><pub-id pub-id-type="doi">10.1038/ncomms1976</pub-id></mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sullivan</surname><given-names>J</given-names></name><name><surname>Yu</surname><given-names>Z</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Optical analysis and optimization of micropyramid texture for thermal radiation control</article-title><source>Nanoscale Microscale Thermophys. Eng.</source><year>2021</year><pub-id pub-id-type="doi">10.1080/15567265.2021.195896010(1080/15567265),pp.1958960,2021</pub-id></mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campbell</surname><given-names>P</given-names></name><name><surname>Green</surname><given-names>MA</given-names></name></person-group><article-title xml:lang="en">Light trapping properties of pyramidally textured surfaces</article-title><source>J. Appl. Phys.</source><year>1987</year><volume>62</volume><fpage>243</fpage><lpage>249</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">1987JAP....62..243C</pub-id><pub-id pub-id-type="doi">10.1063/1.339189</pub-id></mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leon</surname><given-names>JJD</given-names></name><name><surname>Hiszpanski</surname><given-names>AM</given-names></name><name><surname>Bond</surname><given-names>TC</given-names></name><name><surname>Kuntz</surname><given-names>JD</given-names></name></person-group><article-title xml:lang="en">Design rules for tailoring antireflection properties of hierarchical optical structures</article-title><source>Adv. Opt. Mater.</source><year>2017</year><volume>5</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXnvFGls7Y%3D</pub-id><pub-id pub-id-type="doi">10.1002/adom.201700080</pub-id></mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>T</given-names></name><etal/></person-group><article-title xml:lang="en">Black silicon with self-cleaning surface prepared by wetting processes</article-title><source>Nanoscale Res. Lett.</source><year>2013</year><volume>8</volume><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2013NRL.....8....2Z</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2cXht1WitL%2FM</pub-id><pub-id pub-id-type="doi">10.1186/1556-276X-8-351</pub-id></mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><etal/></person-group><article-title xml:lang="en">Hierarchical robust textured structures for large scale self-cleaning black silicon solar cells</article-title><source>Nano Energy</source><year>2014</year><volume>3</volume><fpage>127</fpage><lpage>133</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2cXhtlGrtb8%3D</pub-id><pub-id pub-id-type="doi">10.1016/j.nanoen.2013.11.002</pub-id></mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimitrov</surname><given-names>DZ</given-names></name><name><surname>Du</surname><given-names>CH</given-names></name></person-group><article-title xml:lang="en">Crystalline silicon solar cells with micro/nano texture</article-title><source>Appl. Surf. Sci.</source><year>2013</year><volume>266</volume><fpage>1</fpage><lpage>4</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2013ApSS..266....1D</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XhvV2ktb3E</pub-id><pub-id pub-id-type="doi">10.1016/j.apsusc.2012.10.081</pub-id></mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nishijima</surname><given-names>Y</given-names></name><etal/></person-group><article-title xml:lang="en">Anti-reflective surfaces: Cascading nano/microstructuring</article-title><source>APL Photon.</source><year>2016</year><pub-id pub-id-type="doi">10.1063/1.4964851</pub-id></mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mavrokefalos</surname><given-names>A</given-names></name><name><surname>Han</surname><given-names>SE</given-names></name><name><surname>Yerci</surname><given-names>S</given-names></name><name><surname>Branham</surname><given-names>MS</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Efficient light trapping in inverted nanopyramid thin crystalline silicon membranes for solar cell applications</article-title><source>Nano Lett.</source><year>2012</year><volume>12</volume><fpage>2792</fpage><lpage>2796</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2012NanoL..12.2792M</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XntlOis7g%3D</pub-id><pub-id pub-id-type="doi">10.1021/nl2045777</pub-id><pub-id pub-id-type="pmid">22612694</pub-id></mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Perfect selective metamaterial solar absorbers</article-title><source>Opt. Express</source><year>2013</year><volume>21</volume><fpage>A1078</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2013OExpr..21A1078W</pub-id><pub-id pub-id-type="doi">10.1364/oe.21.0a1078</pub-id><pub-id pub-id-type="pmid">24514927</pub-id></mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sai</surname><given-names>H</given-names></name><name><surname>Yugami</surname><given-names>H</given-names></name><name><surname>Kanamori</surname><given-names>Y</given-names></name><name><surname>Hane</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Solar selective absorbers based on two-dimensional W surface gratings with submicron periods for high-temperature photothermal conversion</article-title><source>Sol. Energy Mater. Sol. Cells</source><year>2003</year><volume>79</volume><fpage>35</fpage><lpage>49</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD3sXmt1ajtbo%3D</pub-id><pub-id pub-id-type="doi">10.1016/S0927-0248(02)00364-1</pub-id></mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qi</surname><given-names>Z</given-names></name><etal/></person-group><article-title xml:lang="en">Au nanoparticle-decorated silicon pyramids for plasmon-enhanced hot electron near-infrared photodetection</article-title><source>Nanotechnology</source><year>2017</year><pub-id pub-id-type="doi">10.1088/1361-6528/aa74a3</pub-id><pub-id pub-id-type="pmid">28930102</pub-id></mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhai</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Ji</surname><given-names>J</given-names></name><name><surname>Wu</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name></person-group><article-title xml:lang="en">Hot electron generation in silicon micropyramids covered with nanometer-thick gold films for near-infrared photodetectors</article-title><source>ACS Appl. Nano Mater.</source><year>2020</year><volume>3</volume><fpage>149</fpage><lpage>155</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXjt1amtQ%3D%3D</pub-id><pub-id pub-id-type="doi">10.1021/acsanm.9b01840</pub-id></mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sullivan</surname><given-names>J</given-names></name><name><surname>Yu</surname><given-names>Z</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Nanometer-thick nickel coatings on silicon micropyramids for infrared absorption</article-title><source>ACS Appl. Nano Mater.</source><year>2022</year><volume>5</volume><fpage>4615</fpage><lpage>4622</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB38XosFequro%3D</pub-id><pub-id pub-id-type="doi">10.1021/acsanm.2c00541</pub-id></mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deinega</surname><given-names>A</given-names></name><name><surname>Valuev</surname><given-names>I</given-names></name><name><surname>Potapkin</surname><given-names>B</given-names></name><name><surname>Lozovik</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Minimizing light reflection from dielectric textured surfaces</article-title><source>J. Opt. Soc. Am. A</source><year>2011</year><volume>28</volume><fpage>770</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2011JOSAA..28..770D</pub-id><pub-id pub-id-type="doi">10.1364/josaa.28.000770</pub-id></mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H</given-names></name><etal/></person-group><article-title xml:lang="en">Biologically inspired flexible photonic films for efficient passive radiative cooling</article-title><source>Proc. Natl. Acad. Sci.</source><year>2020</year><volume>117</volume><fpage>202001802</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXhsV2gtbjK</pub-id><pub-id pub-id-type="doi">10.1073/pnas.2001802117</pub-id></mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="other">Shore, K. A. <italic>Numerical methods in photonics, by Andrei V. Lavrinenko, Jesper Laegsgaard, Niles Gregersen, Frank Schmidt, and Thomas Sondergaard</italic>. <italic>Contemporary Physics</italic> vol. 57 (2016). <ext-link xlink:href="10.1080/00107514.2015.1133707" ext-link-type="doi">https://doi.org/10.1080/00107514.2015.1133707</ext-link>.</mixed-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malkiel</surname><given-names>I</given-names></name><etal/></person-group><article-title xml:lang="en">Plasmonic nanostructure design and characterization via Deep Learning</article-title><source>Light Sci. Appl.</source><year>2018</year><pub-id pub-id-type="doi">10.1038/s41377-018-0060-7</pub-id><pub-id pub-id-type="pmid">30863544</pub-id><pub-id pub-id-type="pmcid">6123479</pub-id></mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Bojarski, M. <italic>et al.</italic> End to End Learning for Self-Driving Cars. 1–9 (2016).</mixed-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="other">Sainath, T. N., Vinyals, O., Senior, A. &amp; Sak, H. Convolutional, Long Short-Term Memory, fully connected Deep Neural Networks. <italic>ICASSP, IEEE Int. Conf. Acoust. Speech Signal Process. - Proc.</italic><bold>2015</bold>-<bold>Augus</bold>, 4580–4584 (2015). <ext-link xlink:href="10.1109/ICASSP.2015.7178838" ext-link-type="doi">https://doi.org/10.1109/ICASSP.2015.7178838</ext-link>.</mixed-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Bock, K. &amp; Garnsey, S. M. Language Processing. in <italic>A Companion to Cognitive Science</italic> vol. 349 226–234 (Blackwell Publishing Ltd, 2017). <ext-link xlink:href="10.1002/9781405164535.ch14" ext-link-type="doi">https://doi.org/10.1002/9781405164535.ch14</ext-link>.</mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sajedian</surname><given-names>I</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Rho</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Finding the optical properties of plasmonic structures by image processing using a combination of convolutional neural networks and recurrent neural networks</article-title><source>Microsyst. Nanoeng.</source><year>2019</year><pub-id pub-id-type="doi">10.1038/s41378-019-0069-y</pub-id><pub-id pub-id-type="pmid">31240107</pub-id><pub-id pub-id-type="pmcid">6572799</pub-id></mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seo</surname><given-names>J</given-names></name><etal/></person-group><article-title xml:lang="en">Design of a broadband solar thermal absorber using a deep neural network and experimental demonstration of its performance</article-title><source>Sci. Rep.</source><year>2019</year><volume>9</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2019NatSR...9....1S</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXitValtL%2FK</pub-id><pub-id pub-id-type="doi">10.1038/s41598-019-51407-2</pub-id></mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>D</given-names></name><etal/></person-group><article-title xml:lang="en">The design of ultra-broadband selective near-perfect absorber based on photonic structures to achieve near-ideal daytime radiative cooling</article-title><source>Mater. Des.</source><year>2018</year><volume>139</volume><fpage>104</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1016/j.matdes.2017.10.077</pub-id></mixed-citation></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Han</surname><given-names>S</given-names></name><name><surname>Shin</surname><given-names>JH</given-names></name><name><surname>Jung</surname><given-names>PH</given-names></name><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Lee</surname><given-names>BJ</given-names></name></person-group><article-title xml:lang="en">Broadband solar thermal absorber based on optical metamaterials for high-temperature applications</article-title><source>Adv. Opt. Mater.</source><year>2016</year><volume>4</volume><fpage>1265</fpage><lpage>1273</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28XovVamsL0%3D</pub-id><pub-id pub-id-type="doi">10.1002/adom.201600236</pub-id></mixed-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elzouka</surname><given-names>M</given-names></name><name><surname>Yang</surname><given-names>C</given-names></name><name><surname>Albert</surname><given-names>A</given-names></name><name><surname>Prasher</surname><given-names>RS</given-names></name><name><surname>Lubner</surname><given-names>SD</given-names></name></person-group><article-title xml:lang="en">Interpretable forward and inverse design of particle spectral emissivity using common machine-learning models</article-title><source>Cell Rep. Phys. Sci.</source><year>2020</year><volume>1</volume><fpage>100259</fpage><pub-id pub-id-type="doi">10.1016/j.xcrp.2020.100259</pub-id></mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="other">Peurifoy, J. <italic>et al.</italic> Nanophotonic particle simulation and inverse design using artificial neural networks. <italic>arXiv</italic> 1–8 (2017). <ext-link xlink:href="10.1117/12.2289195" ext-link-type="doi">https://doi.org/10.1117/12.2289195</ext-link><ext-link xlink:href="10.1117/12.2289195" ext-link-type="doi">https://doi.org/10.1117/12.2289195</ext-link>.</mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balin</surname><given-names>I</given-names></name><name><surname>Garmider</surname><given-names>V</given-names></name><name><surname>Long</surname><given-names>Y</given-names></name><name><surname>Abdulhalim</surname><given-names>I</given-names></name></person-group><article-title xml:lang="en">Training artificial neural network for optimization of nanostructured VO 2 -based smart window performance</article-title><source>Opt. Express</source><year>2019</year><volume>27</volume><fpage>A1030</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2019OExpr..27A1030B</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXotlWisw%3D%3D</pub-id><pub-id pub-id-type="doi">10.1364/oe.27.0a1030</pub-id><pub-id pub-id-type="pmid">31510489</pub-id></mixed-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>S</given-names></name><etal/></person-group><article-title xml:lang="en">Machine-learning-assisted discovery of polymers with high thermal conductivity using a molecular design algorithm</article-title><source>Npj Comput. Mater.</source><year>2019</year><pub-id pub-id-type="doi">10.1038/s41524-019-0203-2</pub-id></mixed-citation></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suh</surname><given-names>Y</given-names></name><name><surname>Bostanabad</surname><given-names>R</given-names></name><name><surname>Won</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Deep learning predicts boiling heat transfer</article-title><source>Sci. Rep.</source><year>2021</year><volume>11</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2021NatSR..11....1S</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXmsVCksrw%3D</pub-id><pub-id pub-id-type="doi">10.1038/s41598-021-85150-4</pub-id></mixed-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kudyshev</surname><given-names>ZA</given-names></name><name><surname>Kildishev</surname><given-names>AV</given-names></name><name><surname>Shalaev</surname><given-names>VM</given-names></name><name><surname>Boltasseva</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Machine-learning-assisted metasurface design for high-efficiency thermal emitter optimization</article-title><source>Appl. Phys. Rev.</source><year>2020</year><pub-id pub-id-type="doi">10.1063/1.5134792</pub-id></mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>HH</given-names></name><name><surname>Kaya</surname><given-names>M</given-names></name><name><surname>Hajimirza</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">A data driven artificial neural network model for predicting radiative properties of metallic packed beds</article-title><source>J. Quant. Spectrosc. Radiat. Transf.</source><year>2019</year><volume>226</volume><fpage>66</fpage><lpage>72</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2019JQSRT.226...66K</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXhtlajsrk%3D</pub-id><pub-id pub-id-type="doi">10.1016/j.jqsrt.2019.01.013</pub-id></mixed-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tausendschön</surname><given-names>J</given-names></name><name><surname>Radl</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Deep neural network-based heat radiation modelling between particles and between walls and particles</article-title><source>Int. J. Heat Mass Transf.</source><year>2021</year><pub-id pub-id-type="doi">10.1016/j.ijheatmasstransfer.2021.121557</pub-id></mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="other">Wiecha, P. R., Arbouet, A., Girard, C. &amp; Muskens, O. L. Deep learning in nano-photonics: Inverse design and beyond. <italic>arXiv</italic><bold>9</bold>, 182–200 (2020). <ext-link xlink:href="10.1364/prj.415960" ext-link-type="doi">https://doi.org/10.1364/prj.415960</ext-link>.</mixed-citation></ref><ref id="CR53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Jiang</surname><given-names>S</given-names></name><name><surname>Balogun</surname><given-names>O</given-names></name><name><surname>Chen</surname><given-names>W</given-names></name></person-group><article-title xml:lang="en">Dynamic control of plasmonic localization by inverse optimization of spatial phase modulation</article-title><source>ACS Photon.</source><year>2022</year><volume>9</volume><fpage>351</fpage><lpage>359</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXivVaqsLfE</pub-id><pub-id pub-id-type="doi">10.1021/acsphotonics.1c01043</pub-id></mixed-citation></ref><ref id="CR54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>J</given-names></name><name><surname>He</surname><given-names>C</given-names></name><name><surname>Zheng</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Ye</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Plasmonic nanoparticle simulations and inverse design using machine learning</article-title><source>Nanoscale</source><year>2019</year><volume>11</volume><fpage>17444</fpage><lpage>17459</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXhs1Cnt7%2FL</pub-id><pub-id pub-id-type="doi">10.1039/c9nr03450a</pub-id><pub-id pub-id-type="pmid">31531431</pub-id></mixed-citation></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Yu</surname><given-names>Z</given-names></name></person-group><article-title xml:lang="en">A bidirectional deep neural network for accurate silicon color design</article-title><source>Adv. Mater.</source><year>2019</year><volume>31</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2019JNuM..524....1G</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXitFant7rP</pub-id><pub-id pub-id-type="doi">10.1002/adma.201905467</pub-id></mixed-citation></ref><ref id="CR56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>W</given-names></name><name><surname>Cheng</surname><given-names>F</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Wen</surname><given-names>Q</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Probabilistic representation and inverse design of metamaterials based on a deep generative model with semi-supervised learning strategy</article-title><source>Adv. Mater.</source><year>2019</year><volume>31</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXhtlaqs7zK</pub-id><pub-id pub-id-type="doi">10.1002/adma.201901111</pub-id></mixed-citation></ref><ref id="CR57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molesky</surname><given-names>S</given-names></name><etal/></person-group><article-title xml:lang="en">Inverse design in nanophotonics</article-title><source>Nat. Photon.</source><year>2018</year><volume>12</volume><fpage>659</fpage><lpage>670</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018NaPho..12..659M</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXitVent7zI</pub-id><pub-id pub-id-type="doi">10.1038/s41566-018-0246-9</pub-id></mixed-citation></ref><ref id="CR58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kudyshev</surname><given-names>ZA</given-names></name><name><surname>Kildishev</surname><given-names>AV</given-names></name><name><surname>Shalaev</surname><given-names>VM</given-names></name><name><surname>Boltasseva</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Machine learning-assisted global optimization of photonic devices</article-title><source>Front. Opt. Photonics</source><year>2021</year><volume>10</volume><fpage>381</fpage><lpage>393</lpage><pub-id pub-id-type="doi">10.1515/9783110710687-028</pub-id></mixed-citation></ref><ref id="CR59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalt</surname><given-names>V</given-names></name><etal/></person-group><article-title xml:lang="en">Metamodeling of high-contrast-index gratings for color reproduction</article-title><source>J. Opt. Soc. Am. A</source><year>2019</year><volume>36</volume><fpage>79</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2019JOSAA..36...79K</pub-id><pub-id pub-id-type="doi">10.1364/josaa.36.000079</pub-id></mixed-citation></ref><ref id="CR60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>W</given-names></name><name><surname>Cheng</surname><given-names>F</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Deep-learning-enabled on-demand design of chiral metamaterials</article-title><source>ACS Nano</source><year>2018</year><volume>12</volume><fpage>6326</fpage><lpage>6334</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXhtVKgtbfF</pub-id><pub-id pub-id-type="doi">10.1021/acsnano.8b03569</pub-id><pub-id pub-id-type="pmid">29856595</pub-id></mixed-citation></ref><ref id="CR61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>D</given-names></name><name><surname>Tan</surname><given-names>Y</given-names></name><name><surname>Khoram</surname><given-names>E</given-names></name><name><surname>Yu</surname><given-names>Z</given-names></name></person-group><article-title xml:lang="en">Training deep neural networks for the inverse design of nanophotonic structures</article-title><source>ACS Photon.</source><year>2018</year><volume>5</volume><fpage>1365</fpage><lpage>1369</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXjtFKqs7w%3D</pub-id><pub-id pub-id-type="doi">10.1021/acsphotonics.7b01377</pub-id></mixed-citation></ref><ref id="CR62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>So</surname><given-names>S</given-names></name><name><surname>Rho</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Designing nanophotonic structures using conditional deep convolutional generative adversarial networks</article-title><source>Nanophotonics</source><year>2019</year><volume>8</volume><fpage>1255</fpage><lpage>1261</lpage><pub-id pub-id-type="doi">10.1515/nanoph-2019-0117</pub-id></mixed-citation></ref><ref id="CR63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Z</given-names></name><name><surname>Zhu</surname><given-names>D</given-names></name><name><surname>Rodrigues</surname><given-names>SP</given-names></name><name><surname>Lee</surname><given-names>KT</given-names></name><name><surname>Cai</surname><given-names>W</given-names></name></person-group><article-title xml:lang="en">Generative model for the inverse design of metasurfaces</article-title><source>Nano Lett.</source><year>2018</year><volume>18</volume><fpage>6570</fpage><lpage>6576</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018NanoL..18.6570L</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXhslSlt77J</pub-id><pub-id pub-id-type="doi">10.1021/acs.nanolett.8b03171</pub-id><pub-id pub-id-type="pmid">30207735</pub-id></mixed-citation></ref><ref id="CR64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shi</surname><given-names>X</given-names></name><name><surname>Qiu</surname><given-names>T</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Zhao</surname><given-names>X</given-names></name><name><surname>Qu</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Metasurface inverse design using machine learning approaches</article-title><source>J. Phys. D. Appl. Phys.</source><year>2020</year><pub-id pub-id-type="doi">10.1088/1361-6463/ab8036</pub-id></mixed-citation></ref><ref id="CR65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>L</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Hybrid inverse design of photonic structures by combining optimization methods with neural networks</article-title><source>Photon. Nanostruct. Fundam. Appl.</source><year>2022</year><volume>52</volume><fpage>101073</fpage><pub-id pub-id-type="doi">10.1016/j.photonics.2022.101073</pub-id></mixed-citation></ref><ref id="CR66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>X</given-names></name><etal/></person-group><article-title xml:lang="en">Implementation of radiative cooling with an inverse-designed selective emitter</article-title><source>Opt. Commun.</source><year>2021</year><volume>497</volume><fpage>127209</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXhtlOlur7K</pub-id><pub-id pub-id-type="doi">10.1016/j.optcom.2021.127209</pub-id></mixed-citation></ref><ref id="CR67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dong</surname><given-names>R</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Hu</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Inverse design of composite metal oxide optical materials based on deep transfer learning and global optimization</article-title><source>Comput. Mater. Sci.</source><year>2021</year><volume>188</volume><fpage>110166</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3cXisFShsbrJ</pub-id><pub-id pub-id-type="doi">10.1016/j.commatsci.2020.110166</pub-id></mixed-citation></ref><ref id="CR68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>X</given-names></name><etal/></person-group><article-title xml:lang="en">Tunable mid-infrared selective emitter based on inverse design metasurface for infrared stealth with thermal management</article-title><source>Opt. Express</source><year>2022</year><volume>30</volume><fpage>18250</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2022OExpr..3018250J</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB38XhvVWqsbzO</pub-id><pub-id pub-id-type="doi">10.1364/oe.456791</pub-id><pub-id pub-id-type="pmid">36221630</pub-id></mixed-citation></ref><ref id="CR69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>X</given-names></name><etal/></person-group><article-title xml:lang="en">Metasurface based on inverse design for maximizing solar spectral absorption</article-title><source>Adv. Opt. Mater.</source><year>2021</year><volume>9</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB3MXhsVKmu73O</pub-id><pub-id pub-id-type="doi">10.1002/adom.202100575</pub-id></mixed-citation></ref><ref id="CR70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macleod</surname><given-names>HA</given-names></name></person-group><article-title xml:lang="en">Thin-film optical filters</article-title><source>Thin-Film Opt. Filters</source><year>1986</year><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">1986tfof.book.....M</pub-id><pub-id pub-id-type="doi">10.1887/075030688210.1887/0750306882</pub-id></mixed-citation></ref><ref id="CR71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>WR</given-names></name><etal/></person-group><article-title xml:lang="en">Above-11%-efficiency organic-inorganic hybrid solar cells with omnidirectional harvesting characteristics by employing hierarchical photon-trapping structures</article-title><source>Nano Lett.</source><year>2013</year><volume>13</volume><fpage>3658</fpage><lpage>3663</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2013NanoL..13.3658W</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3sXhtF2qsrnP</pub-id><pub-id pub-id-type="doi">10.1021/nl401540h</pub-id><pub-id pub-id-type="pmid">23902455</pub-id></mixed-citation></ref><ref id="CR72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sullivan</surname><given-names>J</given-names></name><name><surname>Mirhashemi</surname><given-names>A</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Deep learning based analysis of microstructured materials for thermal radiation control</article-title><source>Sci. Rep.</source><year>2022</year><volume>12</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BB38XhsFGrtbjF</pub-id><pub-id pub-id-type="doi">10.1038/s41598-022-13832-8</pub-id></mixed-citation></ref><ref id="CR73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>An</surname><given-names>S</given-names></name><etal/></person-group><article-title xml:lang="en">A deep learning approach for objective-driven all-dielectric metasurface design</article-title><source>ACS Photon.</source><year>2019</year><volume>6</volume><fpage>3196</fpage><lpage>3207</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXitFKksb7K</pub-id><pub-id pub-id-type="doi">10.1021/acsphotonics.9b00966</pub-id></mixed-citation></ref><ref id="CR74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>DLC</given-names></name><name><surname>Soljačić</surname><given-names>M</given-names></name><name><surname>Joannopoulos</surname><given-names>JD</given-names></name></person-group><article-title xml:lang="en">Thermal emission and design in one-dimensional periodic metallic photonic crystal slabs</article-title><source>Phys. Rev. Stat. Nonlinear Soft Matter Phys.</source><year>2006</year><volume>74</volume><fpage>206</fpage><lpage>214</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD28XotFSqsro%3D</pub-id><pub-id pub-id-type="doi">10.1103/PhysRevE.74.016609</pub-id></mixed-citation></ref><ref id="CR75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krishna</surname><given-names>A</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Morphology-driven emissivity of microscale tree-like structures for radiative thermal management</article-title><source>Nanoscale Microscale Thermophys. Eng.</source><year>2018</year><volume>22</volume><fpage>124</fpage><lpage>136</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018NMTE...22..124K</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXktFWls7Y%3D</pub-id><pub-id pub-id-type="doi">10.1080/15567265.2018.1446065</pub-id></mixed-citation></ref><ref id="CR76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yee</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Numerical solution of initial boundary value problems involving maxwell’s equations in isotropic media</article-title><source>IEEE Trans. Antennas Propag.</source><year>1966</year><volume>14</volume><fpage>302</fpage><lpage>307</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">1966ITAP...14..302Y</pub-id><pub-id pub-id-type="doi">10.1109/TAP.1966.1138693</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1155.78304</pub-id></mixed-citation></ref><ref id="CR77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>D</given-names></name><etal/></person-group><article-title xml:lang="en">Long short-term memory recurrent neural network-based acoustic model using connectionist temporal classification on a large-scale training corpus</article-title><source>China Commun.</source><year>2017</year><volume>14</volume><fpage>23</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1109/CC.2017.8068761</pub-id></mixed-citation></ref><ref id="CR78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>C</given-names></name><etal/></person-group><article-title xml:lang="en">On the optical properties of thin-film vanadium dioxide from the visible to the far infrared</article-title><source>Ann. Phys.</source><year>2019</year><volume>1900188</volume><fpage>1900188</fpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXhvFektr3F</pub-id><pub-id pub-id-type="doi">10.1002/andp.201900188</pub-id></mixed-citation></ref><ref id="CR79"><label>79.</label><mixed-citation publication-type="other">Chollet, F. Keras. <ext-link xlink:href="https://github.com/fchollet/keras" ext-link-type="uri">https://github.com/fchollet/keras</ext-link> (2015).</mixed-citation></ref><ref id="CR80"><label>80.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>L</given-names></name><name><surname>Jamieson</surname><given-names>K</given-names></name><name><surname>DeSalvo</surname><given-names>G</given-names></name><name><surname>Rostamizadeh</surname><given-names>A</given-names></name><name><surname>Talwalkar</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Hyperband: A novel bandit-based approach to hyperparameter optimization</article-title><source>J. Mach. Learn. Res.</source><year>2018</year><volume>18</volume><fpage>1</fpage><lpage>52</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3827073</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1468.68204</pub-id></mixed-citation></ref></ref-list></ref-list><app-group><app id="App1" specific-use="web-only"><sec id="Sec19"><title>Supplementary Information</title><p id="Par55"><supplementary-material content-type="local-data" id="MOESM1" xlink:title="Supplementary Information"><media mimetype="application" mime-subtype="msword" xlink:href="MediaObjects/41598_2023_34332_MOESM1_ESM.docx" position="anchor"><caption xml:lang="en"><p>Supplementary Information.</p></caption></media></supplementary-material></p></sec></app></app-group><notes notes-type="ESMHint"><title>Supplementary Information</title><p>The online version contains supplementary material available at <ext-link xlink:href="10.1038/s41598-023-34332-3" ext-link-type="doi">https://doi.org/10.1038/s41598-023-34332-3</ext-link>.</p></notes><notes notes-type="Misc"><title>Publisher's note</title><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Science, Humanities and Social Sciences, multidisciplinary</facet-value><facet-value count="1">Science, multidisciplinary</facet-value></facet><facet name="keyword"/><facet name="pub"><facet-value count="1">Scientific Reports</facet-value></facet><facet name="year"><facet-value count="1">2023</facet-value></facet><facet name="country"><facet-value count="1">United States</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
