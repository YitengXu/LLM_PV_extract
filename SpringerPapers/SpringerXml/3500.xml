<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1186/s42483-020-00049-8</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="review-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">42483</journal-id><journal-title-group><journal-title>Phytopathology Research</journal-title><abbrev-journal-title abbrev-type="publisher">Phytopathol Res</abbrev-journal-title></journal-title-group><issn pub-type="epub">2524-4167</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s42483-020-00049-8</article-id><article-id pub-id-type="manuscript">49</article-id><article-id pub-id-type="doi">10.1186/s42483-020-00049-8</article-id><article-categories><subj-group subj-group-type="heading"><subject>Review</subject></subj-group></article-categories><title-group><article-title xml:lang="en">From visual estimates to fully automated sensor-based measurements of plant disease severity: status and challenges for improving accuracy</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="Au1"><name><surname>Bock</surname><given-names>Clive H.</given-names></name><address><email>clive.bock@usda.gov</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="corresp" rid="IDs42483020000498_cor1">a</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au2"><name><surname>Barbedo</surname><given-names>Jayme G. A.</given-names></name><address><email>jayme.barbedo@embrapa.br</email></address><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="corresp" rid="IDs42483020000498_cor2">b</xref></contrib><contrib contrib-type="author" id="Au3"><name><surname>Del Ponte</surname><given-names>Emerson M.</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au4"><name><surname>Bohnenkamp</surname><given-names>David</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au5"><name><surname>Mahlein</surname><given-names>Anne-Katrin</given-names></name><address><email>mahlein@ifz-goettingen.de</email></address><xref ref-type="aff" rid="Aff5">5</xref><xref ref-type="corresp" rid="IDs42483020000498_cor5">e</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.463419.d</institution-id><institution-id institution-id-type="ISNI">0000 0004 0404 0958</institution-id><institution content-type="org-name">USDA-ARS Southeastern Fruit and Tree Nut Research Laboratory</institution></institution-wrap><addr-line content-type="postcode">31008</addr-line><addr-line content-type="city">Byron</addr-line><addr-line content-type="state">GA</addr-line><country country="US">USA</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution content-type="org-name">Embrapa Agricultural Informatics</institution></institution-wrap><addr-line content-type="postcode">13083-886</addr-line><addr-line content-type="city">Campinas</addr-line><addr-line content-type="state">SP</addr-line><country country="BR">Brazil</country></aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.12799.34</institution-id><institution-id institution-id-type="ISNI">0000 0000 8338 6359</institution-id><institution content-type="org-division">Departamento de Fitopatologia</institution><institution content-type="org-name">Universidade Federal de Viçosa</institution></institution-wrap><addr-line content-type="postcode">36570-000</addr-line><addr-line content-type="city">Viçosa</addr-line><addr-line content-type="state">MG</addr-line><country country="BR">Brazil</country></aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.10388.32</institution-id><institution-id institution-id-type="ISNI">0000 0001 2240 3300</institution-id><institution content-type="org-division">Institute for Crop Science and Resource Conservation-Phytomedicine</institution><institution content-type="org-name">University of Bonn</institution></institution-wrap><addr-line content-type="street">Nussallee 9</addr-line><addr-line content-type="postcode">53115</addr-line><addr-line content-type="city">Bonn</addr-line><country country="DE">Germany</country></aff><aff id="Aff5"><label>5</label><institution-wrap><institution content-type="org-name">Institute of Sugar Beet Research</institution></institution-wrap><addr-line content-type="street">Holtenser Landstrasse 77</addr-line><addr-line content-type="postcode">37079</addr-line><addr-line content-type="city">Göttingen</addr-line><country country="DE">Germany</country></aff></contrib-group><author-notes><corresp id="IDs42483020000498_cor1"><label>a</label><email>clive.bock@usda.gov</email></corresp><corresp id="IDs42483020000498_cor2"><label>b</label><email>jayme.barbedo@embrapa.br</email></corresp><corresp id="IDs42483020000498_cor5"><label>e</label><email>mahlein@ifz-goettingen.de</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>26</day><month>4</month><year>2020</year></pub-date><pub-date date-type="collection" publication-format="electronic"><month>12</month><year>2020</year></pub-date><volume>2</volume><issue seq="9">1</issue><elocation-id>9</elocation-id><history><date date-type="registration"><day>20</day><month>3</month><year>2020</year></date><date date-type="received"><day>31</day><month>12</month><year>2019</year></date><date date-type="accepted"><day>20</day><month>3</month><year>2020</year></date><date date-type="online"><day>26</day><month>4</month><year>2020</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2020</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">The severity of plant diseases, traditionally the proportion of the plant tissue exhibiting symptoms, is a key quantitative variable to know for many diseases and is prone to error. Good quality disease severity data should be accurate (close to the true value). Earliest quantification of disease severity was by visual estimates. Sensor-based image analysis including visible spectrum and hyperspectral and multispectral sensors are established technologies that promise to substitute, or complement visual ratings. Indeed, these technologies have measured disease severity accurately under controlled conditions but are yet to demonstrate their full potential for accurate measurement under field conditions. Sensor technology is advancing rapidly, and artificial intelligence may help overcome issues for automating severity measurement under hyper-variable field conditions. The adoption of appropriate scales, training, instruction and aids (standard area diagrams) has contributed to improved accuracy of visual estimates. The apogee of accuracy for visual estimation is likely being approached, and any remaining increases in accuracy are likely to be small. Due to automation and rapidity, sensor-based measurement offers potential advantages compared with visual estimates, but the latter will remain important for years to come. Mobile, automated sensor-based systems will become increasingly common in controlled conditions and, eventually, in the field for measuring plant disease severity for the purpose of research and decision making.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Disease severity</kwd><kwd>Assessment</kwd><kwd>Sensor</kwd><kwd>Mobile device</kwd><kwd>Digital technologies</kwd><kwd>Artificial intelligence</kwd><kwd>Machine learning</kwd><kwd>Deep learning</kwd><kwd>Phenotyping</kwd><kwd>Precision agriculture</kwd><kwd>Accuracy</kwd><kwd>Precision</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>BioMed Central</meta-value></custom-meta><custom-meta><meta-name>volume-issue-count</meta-name><meta-value>1</meta-value></custom-meta><custom-meta><meta-name>issue-article-count</meta-name><meta-value>9</meta-value></custom-meta><custom-meta><meta-name>issue-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>issue-pricelist-year</meta-name><meta-value>2020</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-holder</meta-name><meta-value>The Author(s)</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-year</meta-name><meta-value>2020</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>No</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2020</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>3</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>20</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>volume-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>ArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>false</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/42483_2020_Article_49.pdf</meta-value></custom-meta><custom-meta><meta-name>pdf-type</meta-name><meta-value>Typeset</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>issue-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>ReviewPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Life Sciences</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Plant Sciences</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Plant Pathology</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Biomedical and Life Sciences</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p id="Par2">Plant disease epidemics impact agriculture and forestry by reducing the quantity and quality of the product, and pose a threat to food security and food safety (Strange and Scott <xref ref-type="bibr" rid="CR221">2005</xref>; Oerke <xref ref-type="bibr" rid="CR187">2006</xref>; Madden et al. <xref ref-type="bibr" rid="CR154">2007</xref>; Savary et al. <xref ref-type="bibr" rid="CR205">2012</xref>, <xref ref-type="bibr" rid="CR204">2017</xref>). Knowledge of the quantity of disease is fundamental to a) determine crop losses; b) conduct disease surveys; c) establish thresholds for decision-making; d) improve knowledge of disease epidemiology, and e) evaluate the effect of treatments (e.g. cultivar, fungicides, etc). Plant disease intensity (a generic term) can be expressed by incidence or severity at the field/plot scale and below. Incidence is the proportion of the plant units that are diseased in a defined population or sample (Madden et al. <xref ref-type="bibr" rid="CR154">2007</xref>) while severity is the proportion of the plant unit exhibiting visible disease symptoms, usually expressed as a percentage (Madden et al. <xref ref-type="bibr" rid="CR154">2007</xref>). Symptoms of disease on a plant may change in size, shape and color. Disease severity is often the variable that is of most importance or interest in a particular experimental situation (Paul et al. <xref ref-type="bibr" rid="CR194">2005</xref>). Quantification of disease severity caused by biotic agents is the focus of this article.</p><p id="Par3">Visual estimation is the action of assigning a value to severity of symptoms perceived by the human eye. A sensor or instrument directly or indirectly measures the amount of disease or stress signal based on remote sensing (Nilsson <xref ref-type="bibr" rid="CR179">1995</xref>; Bock et al. <xref ref-type="bibr" rid="CR38">2010a</xref>). Thus, an image can be captured in the visible spectrum (VIS) and processed using image analysis (Bock et al. <xref ref-type="bibr" rid="CR38">2010a</xref>; Bock and Nutter Jr <xref ref-type="bibr" rid="CR34">2011</xref>; Barbedo <xref ref-type="bibr" rid="CR15">2013</xref>, <xref ref-type="bibr" rid="CR17">2016a</xref>). The amount of disease can also be measured by image capture in the non-VIS spectral range, including by hyperspectral and multispectral imaging (HSI and MSI), and chlorophyll fluorescence or other methods. The latter methods are conceptually different to that estimate or measurement of disease severity based on visible symptoms or the visible spectrum alone (Mahlein et al. <xref ref-type="bibr" rid="CR158">2012a</xref>; Mutka and Bart <xref ref-type="bibr" rid="CR171">2015</xref>; Simko et al. <xref ref-type="bibr" rid="CR213">2017</xref>; Kuska and Mahlein <xref ref-type="bibr" rid="CR136">2018</xref>; Mahlein et al. <xref ref-type="bibr" rid="CR156">2018</xref>). Visual estimates are based only on the perception of wavelengths of the electromagnetic spectrum in the VIS range (380 to 750 nm), while HSI and MSI systems use wavelengths in the range 250 to 2500 nm (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). In general, only part of this range is chosen (usually the near-infrared (NIR) and infrared (IR) bands) - no single system covers the entire range. Raters perceive and learn to discriminate symptomatic from asymptomatic tissue in order to estimate percent diseased tissue. VIS spectrum image analysis bases measurement on the number of pixels that conform to pre-defined properties of pixels representing a diseased state vs. healthy state, which are identified using a range of statistical procedures. HSI and MSI systems measure signature wavelengths associated with the diseased state. Image acquisition and analysis has additional challenges but also advantages over visual estimates (Mahlein <xref ref-type="bibr" rid="CR155">2016</xref>). Similar to visual ratings, image-based systems, depending on the objective, should: (i) detect disease or other stress as early as possible, (ii) differentiate among biotic diseases, (iii) differentiate biotic from abiotic stresses, and (iv) quantify disease severity accurately.
<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><p>The electromagnetic spectrum showing wavelengths and frequencies illustrating the visible (VIS) range of light (specifically RGB) and the hyperspectral range used for disease severity estimation and measurement</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/42483_2020_49_Fig1_HTML.png" id="MO1"/></fig></p><p id="Par4">Information on disease severity is needed at various spatial scales from the microscopic to plant organs, whole plants, plots, fields or regions, so scalability is an important criterion to take into account when choosing an assessment method. Furthermore, assessment of severity is needed to complement genomics-scale data and provide timely, appropriate and correct measurements to fulfil the needs of ‘phenomics’ in plant breeding (Mutka and Bart <xref ref-type="bibr" rid="CR171">2015</xref>; Simko et al. <xref ref-type="bibr" rid="CR213">2017</xref>). High throughput is an important consideration in the era of phenomics, affecting progress and resource use efficiency.</p><p id="Par5">Optical sensors perform non-invasively and have been developed and used to support disease detection, classification and severity measurement. Precision agriculture and plant phenotyping for resistance breeding already benefit from these technologies (Fiorani and Schurr <xref ref-type="bibr" rid="CR79">2013</xref>; Kruse et al. <xref ref-type="bibr" rid="CR134">2014</xref>; Stewart et al. <xref ref-type="bibr" rid="CR219">2016</xref>; Mahlein et al. <xref ref-type="bibr" rid="CR156">2018</xref>). Although other sensor-based methods of disease or pathogen quantification exist (thermal imaging, chlorophyll fluorescence and molecular or serological approaches), the reader is recommended to seek out recent publications on these topics elsewhere (Oerke and Steiner <xref ref-type="bibr" rid="CR189">2010</xref>; Sankaran et al. <xref ref-type="bibr" rid="CR203">2010</xref>; Mutka and Bart <xref ref-type="bibr" rid="CR171">2015</xref>; Mahlein <xref ref-type="bibr" rid="CR155">2016</xref>). This review will focus primarily on the status and use of visual estimation, VIS spectrum and HSI image analysis as methods to quantify disease severity, paying particular attention to recent developments and challenges to improve accuracy and reliability of the estimates and measurements.</p><sec id="Sec2"><title>Terms, concepts and the importance of accurate plant disease severity quantification</title><p id="Par6">An accurate estimate or measurement is one that is close to the actual or true value, or ‘gold standard’ (Nutter Jr et al. <xref ref-type="bibr" rid="CR185">1991</xref>; Madden et al. <xref ref-type="bibr" rid="CR154">2007</xref>; Bock et al. <xref ref-type="bibr" rid="CR38">2010a</xref>; Bock et al. <xref ref-type="bibr" rid="CR29">2016a</xref>). In remote sensing, the actual or true values are referred to as ‘ground truth’ data. Biased estimates or measurements are those that deviate from actual accuracy. Two biases exist: systematic bias (over or underestimation which is related to the magnitude of the actual value) and constant bias (overall tendency to over or underestimate). Precision is the variability of estimates, but in disease severity estimation or measurement accuracy, precision must accommodate closeness to the true value (Madden et al. <xref ref-type="bibr" rid="CR154">2007</xref>). By definition, consistently accurate estimates must be reliable (Bock et al. <xref ref-type="bibr" rid="CR29">2016a</xref>), where reliability is the tendency for repeated estimates or measurements of the same specimen(s) to be close to one another (Nutter Jr et al. <xref ref-type="bibr" rid="CR185">1991</xref>; Madden et al. <xref ref-type="bibr" rid="CR154">2007</xref>). Reliability can be described as inter-rater (or method, e.g. various imaging methods) reliability or intra-rater (or method) reliability. Reliability may be less of an issue when measuring disease under controlled conditions using devices like VIS image analysis or HSI compared to estimates by different visual raters, or measurements under field conditions.</p><p id="Par7">Accurate measurements or estimates of severity are important: it ensures that treatment effects are correctly analyzed, yield loss relationships understood, surveys are meaningful, and germplasm phenotypes rated appropriately. Furthermore, severity data might be used as a decision threshold or for disease forecasting purposes and thus the need to spray (or not). Inaccuracy can hamper the research process, waste resources, and could impact grower profitability. The required level of accuracy may vary among situations. Several empirical and simulation-based studies have demonstrated that disease assessment can result in a type II error (a false negative) (Christ <xref ref-type="bibr" rid="CR55">1991</xref>; Newton and Hackett <xref ref-type="bibr" rid="CR178">1994</xref>; Parker et al. <xref ref-type="bibr" rid="CR191">1995a</xref>; Bock et al. <xref ref-type="bibr" rid="CR32">2010b</xref>; Chiang et al. <xref ref-type="bibr" rid="CR54">2014</xref>; Chiang et al. <xref ref-type="bibr" rid="CR51">2017a</xref>, <xref ref-type="bibr" rid="CR53">2017b</xref>). A type I error (a false positive) could be as damaging, although this has not been found in disease assessment studies. Accurate estimates or measurements will minimize these two errors.</p></sec><sec id="Sec3"><title>Visual estimation of disease severity</title><p id="Par8">The evolving status of visual estimates has been punctuated by various reviews and book chapters (Anon <xref ref-type="bibr" rid="CR6">1947</xref>; Chester <xref ref-type="bibr" rid="CR48">1950</xref>; Large <xref ref-type="bibr" rid="CR142">1966</xref>; James <xref ref-type="bibr" rid="CR122">1974</xref>; Horsfall and Cowling <xref ref-type="bibr" rid="CR111">1978</xref>, Chapter 6; Kranz <xref ref-type="bibr" rid="CR133">1988</xref>, Chapter 3; Campbell and Madden <xref ref-type="bibr" rid="CR44">1990</xref>, Chapter 6; Chaube and Singh <xref ref-type="bibr" rid="CR46">1991</xref>, Chapter 9; Nilsson <xref ref-type="bibr" rid="CR179">1995</xref>; Cooke <xref ref-type="bibr" rid="CR59">2006</xref>, Chapter 2; Madden et al. <xref ref-type="bibr" rid="CR154">2007</xref>, Chapter 2; Bock et al. <xref ref-type="bibr" rid="CR38">2010a</xref>). Since 2010 there have been only two reviews, one relating to the issue of accuracy (Bock et al. <xref ref-type="bibr" rid="CR29">2016a</xref>), and the other providing a summary of the development and validation of standard area diagrams (SADs, Del Ponte et al. <xref ref-type="bibr" rid="CR67">2017</xref>).</p><sec id="Sec4"><title>Methods of visual estimation and nature of the data</title><sec><p id="Par9">Visual estimates of disease severity are based on various kinds of scales typical of measurement science (Stevens <xref ref-type="bibr" rid="CR218">1946</xref>; Baird and Norma <xref ref-type="bibr" rid="CR12">1978</xref>). Of the four main scale types, only interval scales are not represented in plant disease severity estimation as they lack a true zero (it is not possible to estimate less than zero disease). Disease severity has been assessed using nominal, ordinal and ratio scales. Their perceived utility, advantages and disadvantages are as follows:</p></sec><sec id="FPar1"><title>Nominal scales</title><p id="Par10">These qualitative (descriptive) scales have been defined and described (Newell and Tysdal <xref ref-type="bibr" rid="CR177">1945</xref>; Campbell and Madden <xref ref-type="bibr" rid="CR44">1990</xref>; Madden et al. <xref ref-type="bibr" rid="CR154">2007</xref>; Bock et al. <xref ref-type="bibr" rid="CR38">2010a</xref>; Bock et al. <xref ref-type="bibr" rid="CR29">2016a</xref>). Nominal scales are based on brief descriptions such as “no disease”, “mild disease”, “moderate disease” and “severe disease”, or symbols “- “(healthy), “+”, “++” and “+++” (various levels of severity). Nominal scales are subjective, and may vary by rater and assessment time. The data may be analyzed using statistical methods based on rank or frequencies.</p></sec><sec id="FPar2"><title>Ordinal scales (quantitative and qualitative)</title><p id="Par11">There remains a lack of clarity on what in this review is termed a ‘quantitative ordinal scale’, which has a set number of classes describing numeric intervals between 0 and 100%. These have been termed interval scales (Nutter Jr and Esker <xref ref-type="bibr" rid="CR181">2006</xref>; Bock et al. <xref ref-type="bibr" rid="CR37">2009a</xref>), ordinal scales (Hartung and Piepho <xref ref-type="bibr" rid="CR101">2007</xref>), category scales (Chiang et al. <xref ref-type="bibr" rid="CR54">2014</xref>) and quantitative ordinal scales (Bock et al. <xref ref-type="bibr" rid="CR29">2016a</xref>) in the literature. The American Phytopathology Society in its instruction to authors considers them an ordinal scale (Anon <xref ref-type="bibr" rid="CR7">2020</xref>). Qualitative ordinal scales have a clear and significant order of values, but the numeric magnitude of the differences between each class is unknown (for example, the Likert scale, Likert <xref ref-type="bibr" rid="CR148">1932</xref>). Quantitative ordinal scales have a clear and significant order of values, and the magnitude of each ordered number is numerically bounded by a specified range.</p><p id="Par12">Qualitative ordinal scales are valuable for comparing severity of some diseases that do not have easily quantified symptom. Many virus, other systemic diseases and root diseases may fall into this category, for example, cassava mosaic disease (Hahn et al. <xref ref-type="bibr" rid="CR99">1980</xref>) and huanglongbing of citrus (Gottwald et al. <xref ref-type="bibr" rid="CR98">2007</xref>). These rank data are based on discrete descriptions of symptom types and progression that is almost certainly not linear. It is not statistically appropriate to take means or use mid-points of these scales (Stevens <xref ref-type="bibr" rid="CR218">1946</xref>), as the mid-point and mean have little biological relation and violate assumptions of parametric tests. An index based on class frequencies can be calculated for qualitative ordinal scales, which may then be analyzed using parametric statistics, or they can be analyzed using non-parametric statistics suitable for various experiment designs and distribution functions (Shah and Madden <xref ref-type="bibr" rid="CR208">2004</xref>; Fu et al. <xref ref-type="bibr" rid="CR83">2012</xref>).</p><p id="Par13">Quantitative ordinal scales may have equal or unequal intervals (Horsfall and Heuberger <xref ref-type="bibr" rid="CR112">1942</xref>; Horsfall and Barratt <xref ref-type="bibr" rid="CR110">1945</xref>; Hunter and Roberts <xref ref-type="bibr" rid="CR118">1978</xref>). The Horsfall-Barratt scale (HB, Horsfall and Barratt <xref ref-type="bibr" rid="CR110">1945</xref>) has been widely used (Table <xref rid="Tab1" ref-type="table">1</xref>; Haynes et al. <xref ref-type="bibr" rid="CR103">2002</xref>; Miyasaka et al. <xref ref-type="bibr" rid="CR169">2012</xref>; Jones and Stansly <xref ref-type="bibr" rid="CR125">2014</xref>; Rioux et al. <xref ref-type="bibr" rid="CR200">2017</xref>; Kutcher et al. <xref ref-type="bibr" rid="CR137">2018</xref>; Strayer-Scherer et al. <xref ref-type="bibr" rid="CR222">2018</xref>). The US Forestry Service uses it to assess ozone injury (<ext-link xlink:href="https://www.nrs.fs.fed.us/fia/topics/ozone/methods/" ext-link-type="uri">https://www.nrs.fs.fed.us/fia/topics/ozone/methods/</ext-link>). However, it is based on the nonexistent Weber-Fechner law (Nutter Jr and Esker <xref ref-type="bibr" rid="CR181">2006</xref>), and the ability of raters to estimate in the broad categories in the middle of the scale is better compared to what the scale indicated (Forbes and Korva <xref ref-type="bibr" rid="CR81">1994</xref>; Nutter Jr and Esker <xref ref-type="bibr" rid="CR181">2006</xref>; Bock et al. <xref ref-type="bibr" rid="CR31">2009b</xref>). Inappropriate scale structure is illustrated in results of studies in plant breeding (Xie et al. <xref ref-type="bibr" rid="CR244">2012</xref>). An improved quantitative ordinal scale has been developed that provides a lower risk of type II error, which is recommended where an ordinal scale is required (Chiang et al. <xref ref-type="bibr" rid="CR54">2014</xref>) (Table <xref rid="Tab2" ref-type="table">2</xref>). Analysis of quantitative ordinal scales may be through mid-point conversion (mid-point of the percent interval, not mid-point of the scale itself) and subsequent parametric analysis, or as described above for qualitative ordinal scales, or using a proportional odds model (Chiang et al. <xref ref-type="bibr" rid="CR52">2019</xref>).
<table-wrap id="Tab1"><label>Table 1</label><caption xml:lang="en"><p>The Horsfall and Barratt (H-B) quantitative ordinal scale showing the disease severity ranges, midpoints and interval sizes (Horsfall and Barratt <xref ref-type="bibr" rid="CR110">1945</xref>)</p></caption><table frame="hsides" rules="groups"><thead><tr><th><p>H-B category</p></th><th><p>Disease severity range</p></th><th><p>Midpoint</p></th><th><p>Interval size</p></th></tr></thead><tbody><tr><td><p>1</p></td><td><p>0</p></td><td><p>0</p></td><td><p>0</p></td></tr><tr><td><p>2</p></td><td><p>0<sup>+</sup>-3</p></td><td><p>1.5</p></td><td><p>3</p></td></tr><tr><td><p>3</p></td><td><p>3<sup>+</sup>-6</p></td><td><p>4.5</p></td><td><p>3</p></td></tr><tr><td><p>4</p></td><td><p>6<sup>+</sup>-12</p></td><td><p>9.0</p></td><td><p>6</p></td></tr><tr><td><p>5</p></td><td><p>12<sup>+</sup>-25</p></td><td><p>18.5</p></td><td><p>13</p></td></tr><tr><td><p>6</p></td><td><p>25<sup>+</sup>-50</p></td><td><p>37.5</p></td><td><p>25</p></td></tr><tr><td><p>7</p></td><td><p>50<sup>+</sup>-75</p></td><td><p>62.5</p></td><td><p>25</p></td></tr><tr><td><p>8</p></td><td><p>75<sup>+</sup>-88</p></td><td><p>81.5</p></td><td><p>13</p></td></tr><tr><td><p>9</p></td><td><p>88<sup>+</sup>-94</p></td><td><p>91.0</p></td><td><p>6</p></td></tr><tr><td><p>10</p></td><td><p>94<sup>+</sup>-97</p></td><td><p>95.5</p></td><td><p>3</p></td></tr><tr><td><p>11</p></td><td><p>97<sup>+</sup>-100</p></td><td><p>98.5</p></td><td><p>3</p></td></tr><tr><td><p>12</p></td><td><p>100</p></td><td><p>100</p></td><td><p>0</p></td></tr></tbody></table></table-wrap><table-wrap id="Tab2"><label>Table 2</label><caption xml:lang="en"><p>An improved 16-class quantitative ordinal scale for general assessment of plant disease severity based on the scale developed by Chiang et al. (<xref ref-type="bibr" rid="CR54">2014</xref>)</p></caption><table frame="hsides" rules="groups"><thead><tr><th><p>Ordinal equivalent</p></th><th><p>Midpoint</p></th><th><p>Severity (% range)</p></th></tr></thead><tbody><tr><td><p>0</p></td><td><p>–</p></td><td><p>–</p></td></tr><tr><td><p>1</p></td><td><p>0.05</p></td><td><p>0<sup>+</sup> to 0.1</p></td></tr><tr><td><p>2</p></td><td><p>0.30</p></td><td><p>0.1<sup>+</sup> to 0.5</p></td></tr><tr><td><p>3</p></td><td><p>0.75</p></td><td><p>0.5<sup>+</sup> to 1.0</p></td></tr><tr><td><p>4</p></td><td><p>1.50</p></td><td><p>1.0<sup>+</sup> to 2.0</p></td></tr><tr><td><p>5</p></td><td><p>3.50</p></td><td><p>2.0<sup>+</sup> to 5.0</p></td></tr><tr><td><p>6</p></td><td><p>7.50</p></td><td><p>5.0<sup>+</sup> to 10.0</p></td></tr><tr><td><p>7</p></td><td><p>15.0</p></td><td><p>10.0<sup>+</sup> to 20.0</p></td></tr><tr><td><p>8</p></td><td><p>25.0</p></td><td><p>20.0<sup>+</sup> to 30.0</p></td></tr><tr><td><p>9</p></td><td><p>35.0</p></td><td><p>30.0<sup>+</sup> to 40.0</p></td></tr><tr><td><p>10</p></td><td><p>45.0</p></td><td><p>40.0<sup>+</sup> to 50.0</p></td></tr><tr><td><p>11</p></td><td><p>55.0</p></td><td><p>50.0<sup>+</sup> to 60.0</p></td></tr><tr><td><p>12</p></td><td><p>65.0</p></td><td><p>60.0<sup>+</sup> to 70.0</p></td></tr><tr><td><p>13</p></td><td><p>75.0</p></td><td><p>70.0<sup>+</sup> to 80.0</p></td></tr><tr><td><p>14</p></td><td><p>85.0</p></td><td><p>80.0<sup>+</sup> to 90.0</p></td></tr><tr><td><p>15</p></td><td><p>95.0</p></td><td><p>90.0<sup>+</sup> to 100.0</p></td></tr></tbody></table></table-wrap></p><p id="Par14">The frequency of ordinal scores may be used to obtain a disease severity index (DSI) (Chester <xref ref-type="bibr" rid="CR48">1950</xref>). Disease severity is estimated on the specimens by a rater using the scale and is used to determine the DSI (%) = [sum (class frequency × score of rating class)] / [(total number of plants) × (maximal disease index)] × 100 (Chester <xref ref-type="bibr" rid="CR48">1950</xref>; Hunter and Roberts <xref ref-type="bibr" rid="CR118">1978</xref>; Chaube and Singh <xref ref-type="bibr" rid="CR46">1991</xref>; Kora et al. <xref ref-type="bibr" rid="CR132">2005</xref>; Vieira et al. <xref ref-type="bibr" rid="CR233">2012</xref>). Although a relationship may exist between true severity and a severity index, they are intrinsically different and should not be used interchangeably. Recent studies by Chiang et al. (<xref ref-type="bibr" rid="CR51">2017a</xref>, <xref ref-type="bibr" rid="CR53">2017b</xref>) indicate that the DSI can be particularly prone to overestimation when using the above formula if the midpoint values of the rating class are not considered.</p></sec><sec id="FPar3"><title>Ratio scales</title><p id="Par15">Many diseases lend themselves to severity estimation by ratio scales. The percentage scale is a widely applied scale to visually estimate severity (recent examples include Gent et al. <xref ref-type="bibr" rid="CR89">2018</xref>; Bock and Chiang <xref ref-type="bibr" rid="CR28">2019</xref>; Hamada et al. <xref ref-type="bibr" rid="CR100">2019</xref>; Xu et al. <xref ref-type="bibr" rid="CR245">2019</xref>). The percentage scale ranges from zero to 100% and a rater gauges the proportion of the organ showing symptoms and estimates the severity accordingly. The percentage scale data is amenable to analysis by parametric statistics and means and standard deviations are appropriate measures.</p><p id="Par16">Very few studies have addressed resource use efficiency in visual disease assessment – how to minimize the risk of a type II error while optimizing use of specimen numbers and assessment method (Chiang et al. <xref ref-type="bibr" rid="CR50">2016b</xref>). The results of that study indicated that choice of assessment method, optimizing specimen numbers and number of replicate estimates while using a balanced experimental design are important criteria to consider for maximizing the power of hypothesis tests.</p></sec></sec><sec id="Sec5"><title>Sources of error</title><sec id="FPar4"><title>Rater variation</title><p id="Par17">The earliest study to clearly demonstrate rater variability was that of Nutter Jr et al. (<xref ref-type="bibr" rid="CR182">1993</xref>), although Sherwood et al. (<xref ref-type="bibr" rid="CR209">1983</xref>) demonstrated rater effects in their study comparing rater estimates of disease caused by <italic>Stagonospora arenaria</italic> on leaves of <italic>Dactylis glomerata</italic>. Bock et al. (<xref ref-type="bibr" rid="CR37">2009a</xref>) described rater variability for 28 different raters assessing symptoms of citrus canker on leaves of grapefruit. Some individuals are innately accurate, yet others are inaccurate. Individual raters tend to over or under-estimate and this may extend over the whole scale, or the rater may have variable tendencies over the range of the percentage scale (Hau et al. <xref ref-type="bibr" rid="CR102">1989</xref>; Nita et al. <xref ref-type="bibr" rid="CR180">2003</xref>; Godoy et al. <xref ref-type="bibr" rid="CR95">2006</xref>; Bock et al. <xref ref-type="bibr" rid="CR37">2009a</xref>; Bardsley and Ngugi <xref ref-type="bibr" rid="CR22">2013</xref>; Yadav et al. <xref ref-type="bibr" rid="CR246">2013</xref>; Schwanck and Del Ponte <xref ref-type="bibr" rid="CR206">2014</xref>). Where rater bias is concerned, type II error can be exacerbated using quantitative ordinal scales (Chiang et al. <xref ref-type="bibr" rid="CR49">2016a</xref>).</p><p id="Par18">Some rater-related characteristics may be associated with  cognitive type, gender or other psychological traits, but this is yet to be explored in severity estimation. Inter-rater variability may be problematic although no studies have investigated the impact of different raters in an experiment. Minimizing the number of raters on a specific experiment will help remove potential variability from the data; or deploying raters by block or replicate will help minimize effects of individual raters.</p></sec><sec id="FPar5"><title>Responses to disease characteristics</title><p id="Par19">A common tendency is to overestimate at low disease severities, which is particularly sensitive to the number of lesions and lesion size – the more lesions there are, the greater the tendency to overestimate (Sherwood et al. <xref ref-type="bibr" rid="CR209">1983</xref>; Forbes and Jeger <xref ref-type="bibr" rid="CR80">1987</xref>; Bock et al. <xref ref-type="bibr" rid="CR36">2008b</xref>).</p></sec><sec id="FPar6"><title>Preferred rating values or “knots”</title><p id="Par20">Raters have shown a consistent preference for certain severities at intervals of 5% and particularly 10% at severities &gt; 10%. Thus, raters prefer 10, 15, 20, 25%...95 and 100% (Koch and Hau <xref ref-type="bibr" rid="CR130">1980</xref>; Bock et al. <xref ref-type="bibr" rid="CR36">2008b</xref>; Schwanck and Del Ponte <xref ref-type="bibr" rid="CR206">2014</xref>), which can lead to error.</p></sec><sec id="FPar7"><title>Host organ characteristics</title><p id="Par21">Forbes and Jeger (<xref ref-type="bibr" rid="CR80">1987</xref>) found that visual assessments of severity on simulated root structures were overestimated. Other organ types were not notably different in terms of accuracy (stems, leaves (various types), panicles, pods, tubers heads and roots). But few studies that have investigated the effect of organ type. Studies on the development and validation of SADs may be useful in this regard, but most diagrams have been developed for foliar diseases (Del Ponte et al. <xref ref-type="bibr" rid="CR67">2017</xref>).</p></sec><sec id="FPar8"><title>Other factors</title><p id="Par22">Rating environment: does a rater perform more accurately under certain conditions? What is the effect of noise, heat, exhaustion or time allotted for an assessment? Fast assessments are not necessarily less precise (Parker et al. <xref ref-type="bibr" rid="CR191">1995a</xref>). Color blindness may impact disease severity estimation of some pathosystems (Nilsson <xref ref-type="bibr" rid="CR179">1995</xref>).</p></sec></sec><sec id="Sec6"><title>Methods to improve accuracy of estimates</title><sec id="FPar9"><title>Standard area diagrams (SADs)</title><p id="Par23">SADs are a simple and widely used tool to improve accuracy of rater estimates (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). The diagrams developed by Cobb (<xref ref-type="bibr" rid="CR57">1892</xref>) are the oldest assessment aid. James (<xref ref-type="bibr" rid="CR121">1971</xref>) subsequently developed SADs for several crops. During the last 25 years, research on SAD development and validation has intensified, further demonstrating the value of SADs for improving accuracy (Del Ponte et al. <xref ref-type="bibr" rid="CR67">2017</xref>). Gains using SADs are variable among raters and across pathosystems (Spolti et al. <xref ref-type="bibr" rid="CR216">2011</xref>; Yadav et al. <xref ref-type="bibr" rid="CR246">2013</xref>; Schwanck and Del Ponte <xref ref-type="bibr" rid="CR206">2014</xref>), and are generally greatest for those raters who are least accurate (Yadav et al. <xref ref-type="bibr" rid="CR246">2013</xref>; Braido et al. <xref ref-type="bibr" rid="CR40">2014</xref>; González-Domínguez et al. <xref ref-type="bibr" rid="CR96">2014</xref>; Debona et al. <xref ref-type="bibr" rid="CR65">2015</xref>; Duan et al. <xref ref-type="bibr" rid="CR73">2015</xref>). Increase (Δ) in agreement (based on Lin’s concordance correlation, ρ<sub>c</sub>) may range from Δ &gt; 0.4 for inexperienced raters, to Δ ~ 0, or possibly a slight loss in agreement for innately accurate raters. Overall, the use of SADs helps standardize raters, improving inter-rater reliability (itself a result of the accuracy of estimates of severity on individual specimens). Agreement (ρ<sub>c</sub>) on the 0 to 100% range with actual values from image analysis frequently &gt; 0.90 when using SADs (Spolti et al. <xref ref-type="bibr" rid="CR216">2011</xref>; Duarte et al. <xref ref-type="bibr" rid="CR74">2013</xref>; Domiciano et al. <xref ref-type="bibr" rid="CR72">2014</xref>; González-Domínguez et al. <xref ref-type="bibr" rid="CR96">2014</xref>). This can be considered excellent agreement in measurement science (Altman <xref ref-type="bibr" rid="CR4">1991</xref>), although others are more conservative (McBride <xref ref-type="bibr" rid="CR164">2005</xref>). When SADs are not used, agreement is often &lt; 0.85. There may be symptomatic patterns where unaided estimates can be quite accurate and so SADs are less useful (Del Ponte et al. unpublished).
<fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><p>Standard area diagram (SAD) examples to aid in severity estimation of <bold>a</bold> spot blotch severity on wheat leaves (Domiciano et al. <xref ref-type="bibr" rid="CR72">2014</xref>), <bold>b</bold> frogeye leaf spot on soybean (Debona et al. <xref ref-type="bibr" rid="CR66">2015</xref>), <bold>c</bold> potato early blight (Duarte et al. <xref ref-type="bibr" rid="CR74">2013</xref>), and <bold>d</bold> anthracnose on fruit of sweet pepper (Pedroso et al. <xref ref-type="bibr" rid="CR196">2011</xref>). The numbers represent percentage (%) of leaf area showing symptoms</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/42483_2020_49_Fig2_HTML.png" id="MO2"/></fig></p><p id="Par24">A recent, comprehensive review of SADs quantitatively summarizes their characteristics and provides guidelines for additional research (see Table <xref rid="Tab3" ref-type="table">3</xref> in Del Ponte et al. <xref ref-type="bibr" rid="CR67">2017</xref>). Several questions remain to be addressed. Does diagram number in a SADs affect accuracy of the estimates (Bock et al. 2016b)? Recently, an electronic version of interactive SADs was developed for portable devices. The app, called ‘Estimate’ displays an ordinal quantitative scale (severity intervals in either linear or log increments) accompanied by a SAD representing the mid-point. The severity value is not entered directly as in typical use of a SAD. The rater first selects a main category (specific % interval) and, alternatively, a subcategory in 1 % units (Pethybridge and Nelson 2015 ). Recently, Del Ponte et al. (<xref ref-type="bibr" rid="CR67">2019</xref>) discerned shortcomings of some scale options in the Estimate app. The study showed the superiority of linear over the log-incremental scale, but only for the two-stage (category and subcategory) assessment process. The delivery of SADs in portable devices may increase in the future, as sophistication improves usability.
<table-wrap id="Tab3"><label>Table 3</label><caption xml:lang="en"><p>Best practices for maximizing accuracy of visual estimates of severity of plant disease</p></caption><table frame="hsides" rules="groups"><tbody><tr><td colspan="2"><p>1. Training in the process of assessing and estimating plant disease severity.</p></td></tr><tr><td colspan="2"><p>2. Detailed instruction or understanding of the specific symptoms and what constitutes healthy and diseased tissue.</p></td></tr><tr><td colspan="2"><p>3. Use of SADs</p></td></tr><tr><td colspan="2"><p> • Ensure the  SAD set is developed and validated appropriately (Del Ponte et al. <xref ref-type="bibr" rid="CR67">2017</xref>)</p></td></tr><tr><td colspan="2"><p> • Instruction on how to use SADs (generally to interpolate to the nearest percentage point, occasionally as an ordinal scale).</p></td></tr><tr><td colspan="2"><p>4. Emphasize the risks of estimates falling on preferred, characterized values. Endeavor to estimate to the nearest percent, which is not necessarily at a 5% or 10% step value on the 100% point scale.</p></td></tr><tr><td colspan="2"><p>5. Appropriate sample sizes – usually 30 (Chiang et al. 2016b), but less or more depending on the errors of the estimates which can vary with actual severity and disease distribution.</p></td></tr></tbody></table></table-wrap></p></sec><sec id="FPar10"><title>Training</title><p id="Par25">Nutter Jr and Schultz (<xref ref-type="bibr" rid="CR184">1995</xref>) demonstrated that computer-based training improved accuracy, but this may be short-lived (Parker et al. <xref ref-type="bibr" rid="CR192">1995b</xref>). In a few cases training may reduce accuracy – possibly due to training on pathosystems not related to the one being used in practice (Bardsley and Ngugi <xref ref-type="bibr" rid="CR22">2013</xref>). Nutter Jr and Schultz (<xref ref-type="bibr" rid="CR184">1995</xref>) found that one rater’s coefficient of determination (<italic>R</italic><sup>2</sup>), indicative of precision, changed from 0.825 to 0.933 before and after training. Training software programs were developed for older computer operating systems, for example DISTRAIN (Tomerlin and Howell <xref ref-type="bibr" rid="CR229">1988</xref>) and Severity. Pro (Nutter Jr and Litwiller <xref ref-type="bibr" rid="CR183">1998</xref>). Neither new nor updated versions of these training programs based on computer-generated images exist; they may have been replaced by training raters with true-color photos of symptoms combined with the use of SADs technology.</p></sec><sec id="FPar11"><title>Instruction</title><p id="Par26">Instruction provides an opportunity for the raters to recognize symptoms and estimate severity accurately. Bardsley and Ngugi (<xref ref-type="bibr" rid="CR22">2013</xref>) found good instruction of symptoms of bacterial spot on peach and nectarine resulted in the greatest improvement in inter-rater reliability (which could also be tangentially related to improvements in accuracy in that study) by inexperienced raters compared to training. The coefficient of determination (<italic>R</italic><sup>2</sup>) increased from 0.76 to 0.96 after instruction (and to 0.88 after training).</p></sec><sec id="FPar12"><title>Experience, general field-based training and other methods</title><p id="Par27">Experience in recognizing disease symptoms does have an impact on ability to estimate accurately. Although individual, inexperienced raters may be innately more accurate than some experienced raters, as a group, experienced raters tend to be more accurate (Yadav et al. <xref ref-type="bibr" rid="CR246">2013</xref>; González-Domínguez et al. <xref ref-type="bibr" rid="CR96">2014</xref>). Grids comprised of squares that overlay a leaf (or other specimen area) were shown to improve accuracy (Parker et al. <xref ref-type="bibr" rid="CR192">1995b</xref>) but have never been widely implemented.</p><p id="Par28">Considering these tools available to improve accuracy and reliability (and acknowledging that many questions remain), standardized procedures may be outlined that will provide a basis to maximize accuracy of individual specimen estimates when performing visual assessments (Table <xref rid="Tab3" ref-type="table">3</xref>).</p></sec></sec><sec id="Sec7"><title>Application in research and practice</title><p id="Par29">Visual assessments are most often applied at the scale of individual organs (leaflets, leaves, fruit, flowers etc.), plants, and occasionally fields. However, these data are used at regional and global levels. Visually estimating severity at the field scale is somewhat archaic. For example, a key was developed during the 1950s to assess late blight of potato in the UK at the field scale (Moore <xref ref-type="bibr" rid="CR170">1943</xref>). Such field keys, although a valid method of disease severity assessment, are not considered further as they have been rarely used in recent times.</p><p id="Par30">Visual severity assessment has been applied to compare treatments (for example, fungicide or cultural control methods), assess the effect of disease on yield, for surveys, assess the severity of disease on different genotypes etc.</p></sec><sec id="Sec8"><title>Summary of how accuracy has been improved for visual estimates</title><p id="Par31">Based on current research, where possible, the percentage scale is demonstrably the most accurate tool on which to base visual estimates of disease severity (Nita et al. <xref ref-type="bibr" rid="CR180">2003</xref>; Hartung and Piepho <xref ref-type="bibr" rid="CR101">2007</xref>; Bock et al. <xref ref-type="bibr" rid="CR32">2010b</xref>; Chiang et al. <xref ref-type="bibr" rid="CR54">2014</xref>). Thus, accuracy of disease severity estimation has been improved through a better understanding of error, methods to reduce bias, particularly with the use of SADs, but also through instruction and training.</p><p id="Par32">Visual estimation (with use of the approaches outlined in Table <xref rid="Tab3" ref-type="table">3</xref>) has probably come close to maximizing accuracy of estimates. Appropriate scales, SADs, training and instruction, if correctly implemented can provide remarkably accurate estimates that will minimize the risk of any type II errors.</p></sec></sec><sec id="Sec9"><title>Measurement of disease severity using visible spectrum image analysis</title><p id="Par33">Assessment based on VIS spectrum image analysis have the potential to be accurate, repeatable and reproducible (Martin and Rybicki <xref ref-type="bibr" rid="CR163">1998</xref>; Bock et al. <xref ref-type="bibr" rid="CR35">2008a</xref>; Barbedo <xref ref-type="bibr" rid="CR16">2014</xref>; Clément et al. <xref ref-type="bibr" rid="CR56">2015</xref>). Lindow and Webb (<xref ref-type="bibr" rid="CR150">1983</xref>) were among the earliest pioneers of digital image analysis of plant disease. Particularly since 2000, more sophisticated algorithms and statistical approaches have advanced the capability of differentiating symptomatic from healthy tissue in digital images (Table <xref rid="Tab4" ref-type="table">4</xref>) (Bock and Nutter Jr <xref ref-type="bibr" rid="CR34">2011</xref>; Barbedo <xref ref-type="bibr" rid="CR15">2013</xref>, <xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR19">2017</xref>, <xref ref-type="bibr" rid="CR20">2019</xref>).
<table-wrap id="Tab4"><label>Table 4</label><caption xml:lang="en"><p>The crop, stress, and analysis technique used to describe severity measurement using visible spectrum (RGB) image analysis with symptom segmentation. The superscript numbers cross-reference the “Reference” with the “Analysis software/technique” and “Symptom measured” for each study. For example, in the first row ‘Color Transformations’ and ‘filtering’ were used only by Camargo and Smith, and ‘Scion image’ only by Wijekoon. Both measured ‘Area affected’</p></caption><table frame="hsides" rules="groups"><thead><tr><th><p>Crop<sup>a</sup></p></th><th><p>Analysis software/technique</p></th><th><p>Symptom measured</p></th><th><p>References</p></th></tr></thead><tbody><tr><td><p>Alfalfa</p></td><td><p>Color transformations<sup>8</sup>, filtering<sup>8</sup>, Scion Image<sup>38</sup></p></td><td><p>Area affected<sup>8,38</sup></p></td><td><p>Camargo and Smith (<xref ref-type="bibr" rid="CR43">2009</xref>)<sup>8</sup>, Wijekoon et al. (<xref ref-type="bibr" rid="CR243">2008</xref>)<sup>38</sup></p></td></tr><tr><td><p>Apple</p></td><td><p>CNN<sup>37</sup></p></td><td><p>Severity<sup>37</sup></p></td><td><p>Wang et al. (<xref ref-type="bibr" rid="CR238">2017</xref>)<sup>37</sup></p></td></tr><tr><td><p>Banana</p></td><td><p>Color transformations<sup>8</sup>, filtering<sup>8</sup></p></td><td><p>Area affected<sup>8,16</sup></p></td><td><p>Camargo and Smith (<xref ref-type="bibr" rid="CR43">2009</xref>)<sup>8</sup></p></td></tr><tr><td><p>Bean</p></td><td><p>Mathematical morphology<sup>3,4,5</sup>, color transformations<sup>5</sup>, color analysis<sup>9</sup>, thresholding<sup>31</sup>, Scion Image<sup>38</sup></p></td><td><p>Area affected<sup>4,5,9,31,38</sup>, Deformation<sup>9</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>5</sup>, Contreras-Medina et al. (<xref ref-type="bibr" rid="CR58">2012</xref>)<sup>9</sup>, Škaloudová et al. (<xref ref-type="bibr" rid="CR215">2006</xref>)<sup>31</sup>, Wijekoon et al. (<xref ref-type="bibr" rid="CR243">2008</xref>)<sup>38</sup></p></td></tr><tr><td><p>Cassava</p></td><td><p>Mathematical morphology<sup>4,5</sup>, color transformations<sup>5</sup>, ImageJ<sup>22</sup>, support vector classifier<sup>25</sup>, k-nearest neighbors<sup>25</sup>, extra trees<sup>25</sup></p></td><td><p>Area affected<sup>4,5,22</sup>, Severity levels<sup>25</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>5</sup>, Mutka et al. (<xref ref-type="bibr" rid="CR172">2016</xref>)<sup>22</sup>, Mwebaze and Owomugisha (<xref ref-type="bibr" rid="CR173">2016</xref>)<sup>25</sup></p></td></tr><tr><td><p>Citrus</p></td><td><p>Mathematical morphology<sup>4,5</sup>, color transformations<sup>5</sup>, Assess 1.0<sup>6,7</sup></p></td><td><p>Area affected<sup>4,5,6,7</sup>, Number of lesions<sup>6</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>5</sup>, Bock et al. (<xref ref-type="bibr" rid="CR35">2008a</xref>, <xref ref-type="bibr" rid="CR36">2008b</xref>)<sup>6</sup>, Bock et al. (<xref ref-type="bibr" rid="CR37">2009a</xref>, <xref ref-type="bibr" rid="CR31">2009b</xref>)<sup>7</sup></p></td></tr><tr><td><p>Coconut</p></td><td><p>Mathematical morphology<sup>4,5</sup>, color transformations<sup>5</sup></p></td><td><p>Area affected<sup>4,5</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>5</sup></p></td></tr><tr><td><p>Coffee</p></td><td><p>Color transformations<sup>3,5,29</sup>, mathematical morphology<sup>3,4,5</sup>, thresholding<sup>29</sup>, CNN<sup>41</sup></p></td><td><p>Area affected<sup>3,4,5,29</sup>, Severity levels<sup>41</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR16">2014</xref>)<sup>3</sup>, Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>3</sup>, Price et al. (<xref ref-type="bibr" rid="CR198">1993</xref>)<sup>29</sup>, Esgario et al. (<xref ref-type="bibr" rid="CR78">2019</xref>)<sup>41</sup></p></td></tr><tr><td><p>Cotton</p></td><td><p>Mathematical morphology<sup>4,5</sup>, color transformations<sup>5</sup></p></td><td><p>Area affected<sup>4,5</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>5</sup></p></td></tr><tr><td><p>Cucumber</p></td><td><p>Color comparison<sup>2</sup>, self-organizing map + linear perceptron<sup>13,17</sup>, Photoshop 6.0 + Matrox Inspector 2.2<sup>18</sup>, Superpixel clustering + expectation maximization<sup>39</sup></p></td><td><p>Area affected<sup>2,13,17,18,39</sup></p></td><td><p>Bakr (<xref ref-type="bibr" rid="CR13">2005</xref>)<sup>2</sup>, Goclawski et al. (<xref ref-type="bibr" rid="CR94">2012</xref>)<sup>13</sup>, Kuźniak et al. (<xref ref-type="bibr" rid="CR138">2014</xref>)<sup>17</sup>, Kwack et al. (<xref ref-type="bibr" rid="CR139">2005</xref>)<sup>18</sup>, Zhang et al. (<xref ref-type="bibr" rid="CR249">2019</xref>)<sup>39</sup></p></td></tr><tr><td><p>Grapevine</p></td><td><p>Mathematical morphology<sup>4,5</sup>, color transformations<sup>5</sup>, ImageJ<sup>27</sup></p></td><td><p>Area affected<sup>4,5,27</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>5</sup>, Peressotti et al. (<xref ref-type="bibr" rid="CR196">2011</xref>)<sup>27</sup></p></td></tr><tr><td><p>Maize</p></td><td><p>Assess 2.0<sup>1</sup>, mathematical morphology<sup>4, 5</sup>, color transformations<sup>5,8</sup>, filtering<sup>8</sup>, thresholding<sup>20</sup>, Scion Image<sup>38</sup></p></td><td><p>Area affected<sup>1,4,5,20,38</sup>, Pustule count<sup>1</sup></p></td><td><p>Bade and Carmona (<xref ref-type="bibr" rid="CR11">2011</xref>)<sup>1</sup>, Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>5</sup>, Camargo and Smith (<xref ref-type="bibr" rid="CR43">2009</xref>)<sup>8</sup>, Martin and Rybicki (<xref ref-type="bibr" rid="CR163">1998</xref>)<sup>20</sup>, Wijekoon et al. (<xref ref-type="bibr" rid="CR243">2008</xref>)<sup>38</sup></p></td></tr><tr><td><p>Oat</p></td><td><p>Color transformations<sup>19</sup>, thresholding<sup>19,36</sup></p></td><td><p>Area affected<sup>19,36</sup></p></td><td><p>Macedo-Cruz et al. (<xref ref-type="bibr" rid="CR153">2011</xref>)<sup>19</sup>, Tucker and Chakraborty (<xref ref-type="bibr" rid="CR230">1997</xref>)<sup>36</sup></p></td></tr><tr><td><p>Passion fruit</p></td><td><p>Color transformations<sup>3,5</sup>, mathematical morphology<sup>3,4,5</sup></p></td><td><p>Area affected<sup>3,4,5</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR16">2014</xref>)<sup>3</sup>, Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>5</sup></p></td></tr><tr><td><p>Pumpkin</p></td><td><p>Color analysis<sup>9,17</sup></p></td><td><p>Area affected<sup>9,17</sup>, Deformation<sup>9</sup></p></td><td><p>Contreras-Medina et al. (<xref ref-type="bibr" rid="CR58">2012</xref>)<sup>9</sup>, Kuźniak et al. (<xref ref-type="bibr" rid="CR138">2014</xref>)<sup>17</sup></p></td></tr><tr><td><p>Rice</p></td><td><p>Mathematical morphology<sup>4</sup>, fractal dimensions + fuzzy C-means<sup>40</sup></p></td><td><p>Area affected<sup>4</sup>, Severity<sup>40</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Zhou et al. (<xref ref-type="bibr" rid="CR252">2013</xref>)<sup>40</sup></p></td></tr><tr><td><p>Soybean</p></td><td><p>Color transformations<sup>3,5,30</sup>, mathematical morphology<sup>3,4,5,30</sup>, DCNN<sup>12</sup>, Linear Discriminant Analysis + Support Vector Machine<sup>23</sup></p></td><td><p>Area affected<sup>3,4,5,30</sup>, Severity<sup>12,23</sup>, number of lesions<sup>30</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR16">2014</xref>)<sup>3</sup>, Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>5</sup>, Ghosal et al. (<xref ref-type="bibr" rid="CR90">2018</xref>)<sup>12</sup>, Naik et al. (<xref ref-type="bibr" rid="CR176">2017</xref>)<sup>23</sup>, Shrivastava et al. (<xref ref-type="bibr" rid="CR210">2015</xref>)<sup>30</sup></p></td></tr><tr><td><p>Sugar beet</p></td><td><p>Color transformations<sup>3</sup>, mathematical morphology<sup>3</sup>, Assess 2.0<sup>10</sup></p></td><td><p>Area affected<sup>3,10</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR16">2014</xref>)<sup>3</sup>, De Coninck et al. (<xref ref-type="bibr" rid="CR64">2012</xref>)<sup>10</sup></p></td></tr><tr><td><p>Sugarcane</p></td><td><p>Mathematical morphology<sup>4,5</sup>, color transformations<sup>5,26</sup>, thresholding<sup>26</sup></p></td><td><p>Area affected<sup>4,5,26</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>5</sup>, Patil and Bodhe (<xref ref-type="bibr" rid="CR193">2011</xref>)<sup>26</sup></p></td></tr><tr><td><p>Tomato</p></td><td><p>Color transformations<sup>3</sup>, mathematical morphology<sup>3</sup>, Self-organizing maps + Bayesian classifier<sup>14</sup>, thresholding<sup>18,28</sup>, Assess 2.24<sup>35</sup></p></td><td><p>Area affected<sup>3,14,18,28,35</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR16">2014</xref>)<sup>3</sup>, Hernández-Rabadán et al. (<xref ref-type="bibr" rid="CR105">2014</xref>)<sup>14</sup>, Lindow and Webb (<xref ref-type="bibr" rid="CR150">1983</xref>)<sup>18</sup>, Pethybridge and Nelson (<xref ref-type="bibr" rid="CR197">2015</xref>)<sup>28</sup>, Sun et al. (<xref ref-type="bibr" rid="CR224">2014</xref>)<sup>35</sup></p></td></tr><tr><td><p>Wheat</p></td><td><p>Mathematical morphology<sup>4,5</sup>, color transformations<sup>5</sup>, Assess 2.0<sup>11</sup>, Chan-Vese model + PCA<sup>15</sup>, Assess 1.0<sup>21,32</sup>, ImageJ<sup>33,34</sup>, Scion Image<sup>38</sup></p></td><td><p>Area affected<sup>4,5,11,15,21,32,38</sup>, Number of lesions<sup>33,34</sup></p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>)<sup>4</sup>, Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>)<sup>5</sup>, El Jarroudi et al. (<xref ref-type="bibr" rid="CR76">2015</xref>)<sup>11</sup>, Hu et al. (<xref ref-type="bibr" rid="CR114">2017</xref>)<sup>15</sup>, Mirik et al. (<xref ref-type="bibr" rid="CR167">2006</xref>)<sup>21</sup>, Steddom et al. (<xref ref-type="bibr" rid="CR217">2005</xref>)<sup>32</sup>, Stewart and McDonald (<xref ref-type="bibr" rid="CR220">2014</xref>)<sup>33</sup>, Stewart et al. (<xref ref-type="bibr" rid="CR219">2016</xref>)<sup>34</sup>, Wijekoon et al. (<xref ref-type="bibr" rid="CR243">2008</xref>)<sup>38</sup></p></td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>There are a some crops with only one associated reference: <italic>Arabidopsis thaliana</italic> (Laflamme et al. <xref ref-type="bibr" rid="CR140">2016</xref>), avocado (Kerguelen and Hoddle <xref ref-type="bibr" rid="CR127">1999</xref>), barley (Kokko et al. <xref ref-type="bibr" rid="CR131">2000</xref>), black pepper (Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>), bracken fern (Lindow and Webb <xref ref-type="bibr" rid="CR150">1983</xref>), California buckeye (Lindow and Webb <xref ref-type="bibr" rid="CR150">1983</xref>), cashew (Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>), clover (Wijekoon et al. <xref ref-type="bibr" rid="CR243">2008</xref>), collards (Pethybridge and Nelson <xref ref-type="bibr" rid="CR197">2015</xref>), dahlia (Bakr <xref ref-type="bibr" rid="CR13">2005</xref>), goldenrod (Goodwin and Hsiang <xref ref-type="bibr" rid="CR97">2010</xref>), green bean (Bakr <xref ref-type="bibr" rid="CR13">2005</xref>), kale (Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>), lilac (Pethybridge and Nelson <xref ref-type="bibr" rid="CR197">2015</xref>), lily-of-the-valley (Goodwin and Hsiang <xref ref-type="bibr" rid="CR97">2010</xref>), lima bean (Pethybridge and Nelson <xref ref-type="bibr" rid="CR197">2015</xref>), mallow (Pethybridge and Nelson <xref ref-type="bibr" rid="CR197">2015</xref>), melon (Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>), palm tree (Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>), papaya (Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>), peanut (Barbedo <xref ref-type="bibr" rid="CR16">2014</xref>), pepper (Contreras-Medina et al. <xref ref-type="bibr" rid="CR58">2012</xref>), Phalaenopsis seedling (Huang <xref ref-type="bibr" rid="CR115">2007</xref>), phlox (Goodwin and Hsiang <xref ref-type="bibr" rid="CR97">2010</xref>), plane tree (Clément et al. <xref ref-type="bibr" rid="CR56">2015</xref>), potato (Wijekoon et al. <xref ref-type="bibr" rid="CR243">2008</xref>), rose (Bakr <xref ref-type="bibr" rid="CR13">2005</xref>), squash (Bakr <xref ref-type="bibr" rid="CR13">2005</xref>), subterranean clover (Kruse et al. <xref ref-type="bibr" rid="CR134">2014</xref>), sunflower (Tucker and Chakraborty <xref ref-type="bibr" rid="CR230">1997</xref>), sweet cherry (Olmstead et al. <xref ref-type="bibr" rid="CR190">2001</xref>), sycamore (Lindow and Webb <xref ref-type="bibr" rid="CR150">1983</xref>), turfgrass (Horvath and Vargas <xref ref-type="bibr" rid="CR113">2005</xref>), vigna (Bakr <xref ref-type="bibr" rid="CR13">2005</xref>), watermelon (Pethybridge and Nelson <xref ref-type="bibr" rid="CR197">2015</xref>), yellow starthistle (Berner and Paxson <xref ref-type="bibr" rid="CR26">2003</xref>)</p></table-wrap-foot></table-wrap></p><sec id="Sec10"><title>Methods of image acquisition</title><p id="Par34">Various cameras or image capturing devices record in the VIS spectrum. Red-green-blue (RGB) sensors are portable and widely available. With the advent of handheld devices with cameras the possibilities of easily obtaining numerous images is increased many-fold (Pethybridge and Nelson <xref ref-type="bibr" rid="CR197">2015</xref>). Analog video cameras (Lindow and Webb <xref ref-type="bibr" rid="CR150">1983</xref>; Hetzroni et al. <xref ref-type="bibr" rid="CR106">1994</xref>; Martin and Rybicki <xref ref-type="bibr" rid="CR163">1998</xref>), digital videos sensors (Lloret et al. <xref ref-type="bibr" rid="CR152">2011</xref>; Clément et al. <xref ref-type="bibr" rid="CR56">2015</xref>) and flatbed scanners (Olmstead et al. <xref ref-type="bibr" rid="CR190">2001</xref>; O’Neal et al. <xref ref-type="bibr" rid="CR186">2002</xref>; Berner and Paxson <xref ref-type="bibr" rid="CR26">2003</xref>; Kwack et al. <xref ref-type="bibr" rid="CR139">2005</xref>; Škaloudová et al. <xref ref-type="bibr" rid="CR215">2006</xref>) have also been used.</p></sec><sec id="Sec11"><title>Methods of image analysis and processing</title><sec id="FPar13"><title>Segmentation</title><p id="Par35">Segmentation (delineation of the area of interest) is a step in many image analysis algorithms (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). In testing image analysis, leaf segmentation is generally performed manually, but for practical application segmentation must be automated. The only difference between segmentation and severity measurement is that the latter includes an additional step relating the areas occupied by diseased and healthy tissues. With the rise of artificial intelligence (AI, machine learning, and its off-shoot, deep learning) segmentation is less of a requirement.
<fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><p>Segmentation steps during image analysis. An image of <bold>a</bold> a pecan leaflet with symptoms of scab (caused by <italic>Venturia effusa</italic>), <bold>b</bold> the same image with the whole leaf segmented from the background, and <bold>c</bold> the leaf with only the diseased areas segmented out. Diseased area on this leaflet is 30.14%</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/42483_2020_49_Fig3_HTML.png" id="MO3"/></fig></p></sec><sec id="FPar14"><title>Software for image analysis</title><p id="Par36">Many studies have employed third-party software to measure severity including Assess (Horvath and Vargas <xref ref-type="bibr" rid="CR113">2005</xref>; Steddom et al. <xref ref-type="bibr" rid="CR217">2005</xref>; Mirik et al. <xref ref-type="bibr" rid="CR167">2006</xref>; Bock et al. <xref ref-type="bibr" rid="CR35">2008a</xref>, <xref ref-type="bibr" rid="CR36">2008b</xref>; Bock et al. <xref ref-type="bibr" rid="CR37">2009a</xref>, <xref ref-type="bibr" rid="CR31">2009b</xref>, <xref ref-type="bibr" rid="CR30">2009c</xref>; De Coninck et al. <xref ref-type="bibr" rid="CR64">2012</xref>; Sun et al. <xref ref-type="bibr" rid="CR224">2014</xref>; El Jarroudi et al. <xref ref-type="bibr" rid="CR76">2015</xref>), launched in 2002 (Lamari <xref ref-type="bibr" rid="CR141">2002</xref>). Assess requires the user to predefine segmentation parameters for automation, but this works only if all images were captured under the same conditions (Bock et al. <xref ref-type="bibr" rid="CR30">2009c</xref>). Other software include Sigma Pro (Kerguelen and Hoddle <xref ref-type="bibr" rid="CR127">1999</xref>; Olmstead et al. <xref ref-type="bibr" rid="CR190">2001</xref>; Berner and Paxson <xref ref-type="bibr" rid="CR26">2003</xref>), ImageJ (O’Neal et al. <xref ref-type="bibr" rid="CR186">2002</xref>; Abramoff et al. <xref ref-type="bibr" rid="CR1">2004</xref>; Peressotti et al. <xref ref-type="bibr" rid="CR196">2011</xref>; Stewart and McDonald <xref ref-type="bibr" rid="CR220">2014</xref>; Laflamme et al. <xref ref-type="bibr" rid="CR140">2016</xref>), Adobe Photoshop (Kwack et al. <xref ref-type="bibr" rid="CR139">2005</xref>; Cui et al. <xref ref-type="bibr" rid="CR61">2010</xref>) and Scion Image Software (Wijekoon et al. <xref ref-type="bibr" rid="CR243">2008</xref>; Goodwin and Hsiang <xref ref-type="bibr" rid="CR97">2010</xref>). In the review on SADs, 20 programs were reported to obtain actual severity measurements, but Assess and Quant (Vale et al. <xref ref-type="bibr" rid="CR232">2003</xref>) were the most commonly used (Del Ponte et al. <xref ref-type="bibr" rid="CR67">2017</xref>)</p></sec><sec id="FPar15"><title>Validation</title><p id="Par37">Validation involves comparing the image analyzed measurement to an actual or “gold-standard”. The actual value may be based on a visual estimate (Steddom et al. <xref ref-type="bibr" rid="CR217">2005</xref>; De Coninck et al. <xref ref-type="bibr" rid="CR64">2012</xref>; El Jarroudi et al. <xref ref-type="bibr" rid="CR76">2015</xref>) or manually delineated image analysis data (Martin and Rybicki <xref ref-type="bibr" rid="CR163">1998</xref>; Bock et al. <xref ref-type="bibr" rid="CR37">2009a</xref>; Peressotti et al. <xref ref-type="bibr" rid="CR196">2011</xref>). Regression has been widely used to compare accuracy of image analysis systems (Horvath and Vargas <xref ref-type="bibr" rid="CR113">2005</xref>; Steddom et al. <xref ref-type="bibr" rid="CR217">2005</xref>; Peressotti et al. <xref ref-type="bibr" rid="CR196">2011</xref>; El Jarroudi et al. <xref ref-type="bibr" rid="CR76">2015</xref>), although other statistical criteria are often used to provide more meaningful insights (Bock et al. <xref ref-type="bibr" rid="CR37">2009a</xref>; De Coninck et al. <xref ref-type="bibr" rid="CR64">2012</xref>; Stewart and McDonald <xref ref-type="bibr" rid="CR220">2014</xref>). Because experimental setups and contexts vary between studies, the results are not always comparable (Horvath and Vargas <xref ref-type="bibr" rid="CR113">2005</xref>); reported variabilities based on regressions (<italic>R</italic><sup>2</sup>) and correlations (r) fall within the 0.70–1.00 range (Martin and Rybicki <xref ref-type="bibr" rid="CR163">1998</xref>; Steddom et al. <xref ref-type="bibr" rid="CR217">2005</xref>; Peressotti et al. <xref ref-type="bibr" rid="CR196">2011</xref>; De Coninck et al. <xref ref-type="bibr" rid="CR64">2012</xref>).</p></sec><sec id="FPar16"><title>Custom systems using color transformations and artificial intelligence</title><p id="Par38">Newer methods for severity measurement can be divided in two categories. The first relies on color transformations; the second on AI using machine or deep learning techniques.
<list list-type="order"><list-item><p id="Par39">Color transformation increases the contrast between healthy and diseased areas in images (Hu et al. <xref ref-type="bibr" rid="CR114">2017</xref>), often coupled with mathematical morphology operations (Macedo-Cruz et al. <xref ref-type="bibr" rid="CR153">2011</xref>; Contreras-Medina et al. <xref ref-type="bibr" rid="CR58">2012</xref>; Barbedo <xref ref-type="bibr" rid="CR16">2014</xref>; Shrivastava et al. <xref ref-type="bibr" rid="CR210">2015</xref>; Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR19">2017</xref>), thresholding (Price et al. <xref ref-type="bibr" rid="CR198">1993</xref>; Patil and Bodhe <xref ref-type="bibr" rid="CR193">2011</xref>; Clément et al. <xref ref-type="bibr" rid="CR56">2015</xref>) and filtering (Camargo and Smith <xref ref-type="bibr" rid="CR43">2009</xref>), with the objective of isolating the regions of interest. These algorithms are generally quick to develop and simple to implement but may not be suitable for dealing with subtle symptoms.</p></list-item><list-item><p id="Par40">Many applications of AI for image analysis are based on machine learning, which may be supervised or unsupervised. Supervised learning typically involves methods of classification (including logistic regression, support vector machines and artificial neural networks), while unsupervised learning relies on methods of clustering (including k-means clustering and principal component analysis) that rely on structural patterns in the data. For disease severity measurement the classifiers require the severity to be transformed from continuous data to a discrete scale of values. This is usually accomplished by either labelling each pixel as healthy or diseased, or by defining severity levels based on a nominal or ordinal scale, for example as “low”, “medium” and “high”. A variety of methods have been tested and reported in the literature, including K-means clustering (Kruse et al. <xref ref-type="bibr" rid="CR134">2014</xref>), Fuzzy C-means (Zhou et al. <xref ref-type="bibr" rid="CR252">2013</xref>), k-nearest neighbors (Mwebaze and Owomugisha <xref ref-type="bibr" rid="CR173">2016</xref>; Naik et al. <xref ref-type="bibr" rid="CR176">2017</xref>), linear discriminant analysis (Kruse et al. <xref ref-type="bibr" rid="CR134">2014</xref>; Naik et al. <xref ref-type="bibr" rid="CR176">2017</xref>), expectation maximization (Zhang et al. <xref ref-type="bibr" rid="CR249">2019</xref>) and support vector machines (Mwebaze and Owomugisha <xref ref-type="bibr" rid="CR173">2016</xref>; Naik et al. <xref ref-type="bibr" rid="CR176">2017</xref>), among others.</p></list-item></list></p><p id="Par41">Neural networks employing deep learning architectures have become predominant in image-based classification systems (Barbedo <xref ref-type="bibr" rid="CR20">2019</xref>). Deep learning efficiently extracts complex features from images without the need for segmentation and is being applied to severity measurement, usually in the form of deep Convolutional Neural Network (CNN) architectures (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). Many images are needed for deep learning systems (Wiesner-Hanks et al. <xref ref-type="bibr" rid="CR242">2018</xref>; Ramcharan et al. <xref ref-type="bibr" rid="CR199">2019</xref>). The largest database for a disease was reported in 2018 (Wiesner-Hanks et al. <xref ref-type="bibr" rid="CR242">2018</xref>); there were 8222 images of corn leaves annotated with 105,705 lesions of northern leaf blight, although all were from a single field in New York. The set was used for detection only. Two other important databases containing images of plant diseases are available: the PlantVillage (Hughes and Salathé <xref ref-type="bibr" rid="CR117">2015</xref>), which contains &gt; 50,000 curated images of many crop diseases; and Digipathos (Barbedo et al. <xref ref-type="bibr" rid="CR21">2018</xref>, available at <ext-link xlink:href="https://www.digipathos-rep.cnptia.embrapa.br" ext-link-type="uri">https://www.digipathos-rep.cnptia.embrapa.br</ext-link>), also containing &gt; 50,000 images of crop diseases. However, neither has image annotation for sample source location or actual severity. Image libraries are a progress-limiting gap. Data sharing is one solution: globally, plant pathologists working on various pathosystems could capture images to represent the diversity of characteristics and enable image analysis systems (Barbedo <xref ref-type="bibr" rid="CR20">2019</xref>).
<fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><p>Flow chart showing an example of CNN architecture for image analysis (adapted from Amara et al. <xref ref-type="bibr" rid="CR5">2017</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/42483_2020_49_Fig4_HTML.png" id="MO4"/></fig></p><p id="Par42">Many trained deep learning models are lightweight enough for mobile applications, so they can be run directly on the device without the need for connectivity (Ramcharan et al. <xref ref-type="bibr" rid="CR199">2019</xref>), important in remote areas.</p></sec></sec><sec id="Sec12"><title>Accuracy of image analysis</title><p id="Par43">The number of studies employing CNN has increased in the last few years. Ramcharan et al. (<xref ref-type="bibr" rid="CR199">2019</xref>) used CNN and 2415 leaf samples to automatically detect two severity classes of cassava mosaic disease. Accuracy of low severity detection was 29.4%. Esgario et al. (<xref ref-type="bibr" rid="CR78">2019</xref>) found that assigning severity of multiple diseases of coffee using deep learning was up to 84.13% accurate. Wang et al. (<xref ref-type="bibr" rid="CR238">2017</xref>) found accuracy of severity of apple leaf black rot measurements ranged from 83.3 to 100%, depending on class (there were 4 classes of severity). Thus, estimates of accuracy are often being considered at a lower resolution compared to visual estimation using the 0 to 100% scale. Scale type, number of intervals and replication may differ considerably to achieve the same power in a hypothesis test (Bock et al. <xref ref-type="bibr" rid="CR32">2010b</xref>; Chiang et al. <xref ref-type="bibr" rid="CR54">2014</xref>, <xref ref-type="bibr" rid="CR49">2016a</xref>, <xref ref-type="bibr" rid="CR50">2016b</xref>, <xref ref-type="bibr" rid="CR52">2019</xref>).</p><p id="Par44">Much of the variation in image analysis may be attributed to two factors. Firstly, conditions under which the images were captured and the variety of symptoms in the images. Studies using VIS spectrum images captured in the field often report lower accuracies. Examples of images captured under variable conditions include the systems proposed by Macedo-Cruz et al. (<xref ref-type="bibr" rid="CR153">2011</xref>), Barbedo (<xref ref-type="bibr" rid="CR19">2017</xref>) and Hu et al. (<xref ref-type="bibr" rid="CR114">2017</xref>) (resulting in 92, 91, and 84% accuracy, respectively); images captured under controlled conditions include methods proposed by Patil and Bodhe (<xref ref-type="bibr" rid="CR193">2011</xref>), Kruse et al. (<xref ref-type="bibr" rid="CR134">2014</xref>) and Stewart et al. (<xref ref-type="bibr" rid="CR219">2016</xref>) (resulting in 98, 95, and 94% accuracy, respectively). Secondly, the actual reference values to which the estimates are compared will affect accuracy. Where the reference is a visual estimate, subjectivity will be directly related to the perceptions of the rater (Bock et al. <xref ref-type="bibr" rid="CR35">2008a</xref>).</p></sec><sec id="Sec13"><title>Sources of error affecting accuracy</title><sec id="FPar17"><title>Operator</title><p id="Par45">Operators must accurately pair the diagnosis guidelines with the symptoms. Even manual measurements using image analysis have some subjectivity. Actual values based on image analysis used to validate automatic methods (or other methods of assessment) are variable (Barbedo <xref ref-type="bibr" rid="CR15">2013</xref>; Bock et al. <xref ref-type="bibr" rid="CR35">2008a</xref>). But the error should be small.</p></sec><sec id="FPar18"><title>Variation in symptoms, host and background</title><p id="Par46">To work effectively, deep learning models must be trained using images covering a wide range of conditions. For most other techniques segmentation of leaf and disease is required (Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>). Threshold values and other parameters derived under one set of conditions generally fail under a different set of conditions due to variation in brightness, contrast, reflections, weather conditions and numerous other factors (Barbedo <xref ref-type="bibr" rid="CR16">2014</xref>). Symptoms may vary depending on stage of development (Patil and Bodhe <xref ref-type="bibr" rid="CR193">2011</xref>) and the interaction with environmental factors (Mutka et al. <xref ref-type="bibr" rid="CR172">2016</xref>). Separating image components automatically with field-acquired images is a challenging and complex task and solutions are only recently being developed (Zhang et al. <xref ref-type="bibr" rid="CR247">2018a</xref>). Automatic segmentation can be easier if a screen is placed behind the leaf prior to image capture (El Jarroudi et al. <xref ref-type="bibr" rid="CR76">2015</xref>; Pethybridge and Nelson <xref ref-type="bibr" rid="CR197">2015</xref>; Shrivastava et al. <xref ref-type="bibr" rid="CR210">2015</xref>), but this makes image capture more time-consuming and problematic. Thus, most methods using field-captured images rely on the user to manually segment the leaf (Barbedo <xref ref-type="bibr" rid="CR16">2014</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>, <xref ref-type="bibr" rid="CR19">2017</xref>).</p></sec><sec id="FPar19"><title>Issues with image acquisition and differentiating diseased vs. healthy areas</title><p id="Par47">There is subjectivity in determining the edges of some symptoms (Barbedo <xref ref-type="bibr" rid="CR16">2014</xref>; Stewart et al. <xref ref-type="bibr" rid="CR219">2016</xref>). Leaves are not always flat causing perspective problems (Barbedo <xref ref-type="bibr" rid="CR16">2014</xref>), or require flattening (Clément et al. <xref ref-type="bibr" rid="CR56">2015</xref>). Small symptoms may be confused with debris (Barbedo <xref ref-type="bibr" rid="CR16">2014</xref>). Shadows, leaf veins, and other parts of the plant may mimic symptoms, causing error (Olmstead et al. <xref ref-type="bibr" rid="CR190">2001</xref>; Bade and Carmona <xref ref-type="bibr" rid="CR11">2011</xref>; Barbedo <xref ref-type="bibr" rid="CR16">2014</xref>; Clément et al. <xref ref-type="bibr" rid="CR56">2015</xref>; Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>). Groups of lesions may merge, impairing a counting process (Bock et al. <xref ref-type="bibr" rid="CR35">2008a</xref>; Bade and Carmona <xref ref-type="bibr" rid="CR11">2011</xref>). The presence of other disorders may exacerbate delineation of the symptoms of interest (Bock et al. <xref ref-type="bibr" rid="CR35">2008a</xref>, <xref ref-type="bibr" rid="CR37">2009a</xref>; El Jarroudi et al. <xref ref-type="bibr" rid="CR76">2015</xref>; Barbedo <xref ref-type="bibr" rid="CR18">2016b</xref>). Specular reflections may render parts of the leaf featureless (Steddom et al. <xref ref-type="bibr" rid="CR217">2005</xref>; Peressotti et al. <xref ref-type="bibr" rid="CR196">2011</xref>; Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>). Image compression may introduce distortions and artifacts (Steddom et al. <xref ref-type="bibr" rid="CR217">2005</xref>; Bock et al. <xref ref-type="bibr" rid="CR38">2010a</xref>). Symptom complexity affects the difficulty of the task (Bock et al. <xref ref-type="bibr" rid="CR35">2008a</xref>; Barbedo <xref ref-type="bibr" rid="CR19">2017</xref>), which has led some authors to argue that different algorithms are needed for each symptom (Contreras-Medina et al. <xref ref-type="bibr" rid="CR58">2012</xref>), or each host-pathogen pair (Mutka and Bart <xref ref-type="bibr" rid="CR171">2015</xref>). AI techniques can address some of these issues if trained with sufficiently comprehensive data. Factors that cause loss of information (specular reflections, shadows, etc.) can only be addressed by appropriate protocols during image capture.</p><p id="Par79">Automatic image capture in the field can result in underlying leaves being obscured. Perspectives will be variable. This is an issue for plants with dense canopies if severity measurement on lower leaves is needed (Wiesner-Hanks et al. <xref ref-type="bibr" rid="CR242">2018</xref>).</p></sec><sec id="FPar20"><title>Actual values</title><p id="Par49">Evaluation of measurements obtained using VIS image analysis is not straightforward. Generally, the “gold standard” reference is generated manually by image analysis (Peressotti et al. <xref ref-type="bibr" rid="CR196">2011</xref>; El Jarroudi et al. <xref ref-type="bibr" rid="CR76">2015</xref>), by expert visual estimation, or rarely other methods (Martin and Rybicki <xref ref-type="bibr" rid="CR163">1998</xref>). Due to subjectivity, even manually delineated image analysis may harbor operator error, and thus the systems developed are dependent on the references they are tasked to mimic; they could vary if other “gold standard” references were used.</p></sec><sec id="FPar21"><title>System limitations</title><p id="Par50">As effective as various new techniques are, including deep learning, sometimes images in the visible range do not carry enough information for distinction of severity classes. In such cases, combining different imaging methods may be a viable solution (Berdugo et al. <xref ref-type="bibr" rid="CR25">2014</xref>), perhaps with the sacrifice of higher costs and reduced mobility.</p></sec></sec><sec id="Sec14"><title>Application in research and practice</title><sec id="FPar22"><title>Scales of application</title><p id="Par51">Although VIS image analysis can be applied at different scales, the majority of the studies are at the scale of individual plant organs (Barbedo <xref ref-type="bibr" rid="CR16">2014</xref>; Kruse et al. <xref ref-type="bibr" rid="CR134">2014</xref>; Clément et al. <xref ref-type="bibr" rid="CR56">2015</xref>; El Jarroudi et al. <xref ref-type="bibr" rid="CR76">2015</xref>; Pethybridge and Nelson <xref ref-type="bibr" rid="CR197">2015</xref>; Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>, <xref ref-type="bibr" rid="CR19">2017</xref>; Esgario et al. <xref ref-type="bibr" rid="CR78">2019</xref>; Ghosal et al. <xref ref-type="bibr" rid="CR90">2018</xref>; Ramcharan et al. <xref ref-type="bibr" rid="CR199">2019</xref>; Zhang et al. <xref ref-type="bibr" rid="CR249">2019</xref>) or the crop canopy (Macedo-Cruz et al. <xref ref-type="bibr" rid="CR153">2011</xref>; Laflamme et al. <xref ref-type="bibr" rid="CR140">2016</xref>; Naik et al. <xref ref-type="bibr" rid="CR176">2017</xref>). Image analysis of microscopic samples requires a sophisticated lab-based system (Ihlow et al. <xref ref-type="bibr" rid="CR119">2008</xref>).</p></sec><sec id="FPar23"><title>Uses of image analysis</title><p id="Par52">Applications of RGB image-based severity measurement include: crop breeding and phenotyping, in which the objective is to rapidly measure severity on numerous specimens (Peressotti et al. <xref ref-type="bibr" rid="CR196">2011</xref>; De Coninck et al. <xref ref-type="bibr" rid="CR64">2012</xref>; Stewart and McDonald <xref ref-type="bibr" rid="CR220">2014</xref>; Laflamme et al. <xref ref-type="bibr" rid="CR140">2016</xref>; Naik et al. <xref ref-type="bibr" rid="CR176">2017</xref>; Ghosal et al. <xref ref-type="bibr" rid="CR90">2018</xref>; Karisto et al. <xref ref-type="bibr" rid="CR126">2018</xref>); the effect of disease on yield (Macedo-Cruz et al. <xref ref-type="bibr" rid="CR153">2011</xref>); to compare various treatments (Clément et al. <xref ref-type="bibr" rid="CR56">2015</xref>); in precision agriculture, in which the objective is to pinpoint areas where symptoms are more severe for a more focused control of the disease (Kruse et al. <xref ref-type="bibr" rid="CR134">2014</xref>), including aspects of biocontrol (Berner and Paxson <xref ref-type="bibr" rid="CR26">2003</xref>); and for general crop management, in which the objective is to provide information to aid decision making (Zhou et al. <xref ref-type="bibr" rid="CR252">2013</xref>; Barbedo <xref ref-type="bibr" rid="CR16">2014</xref>; Pethybridge and Nelson <xref ref-type="bibr" rid="CR197">2015</xref>; Barbedo <xref ref-type="bibr" rid="CR17">2016a</xref>, <xref ref-type="bibr" rid="CR18">2016b</xref>, <xref ref-type="bibr" rid="CR19">2017</xref>; Hu et al. <xref ref-type="bibr" rid="CR114">2017</xref>).</p><p id="Par53">Image analysis software for disease severity measurement is available for mobile devices (Pethybridge and Nelson <xref ref-type="bibr" rid="CR197">2015</xref>; Manso et al. <xref ref-type="bibr" rid="CR162">2019</xref>). Mobile device-based applications generally require the user to set thresholds, which can lead to inconsistencies (Bock et al. <xref ref-type="bibr" rid="CR35">2008a</xref>, <xref ref-type="bibr" rid="CR30">2009c</xref>). Software was recently developed automating severity estimation using Fuzzy Logic rules and image segmentation for the mobile application ‘Leaf Doctor’ (Sibiya and Sumbwanyambe <xref ref-type="bibr" rid="CR211">2019</xref>).</p><p id="Par54">Image capture using mobile platforms (UAVs, ground robots etc) is being studied in the field, although disease detection is the primary focus (Johnson et al. <xref ref-type="bibr" rid="CR124">2003</xref>; Garcia-Ruiz et al. <xref ref-type="bibr" rid="CR86">2013</xref>; de Castro et al. <xref ref-type="bibr" rid="CR63">2015</xref>). Measurement of severity with VIS spectrum image analysis using mobile platforms is less common (Lelong et al. <xref ref-type="bibr" rid="CR144">2008</xref>; Sugiura et al. <xref ref-type="bibr" rid="CR223">2016</xref>; Duarte-Carvajalino et al. <xref ref-type="bibr" rid="CR75">2018</xref>; Franceschini et al. <xref ref-type="bibr" rid="CR82">2019</xref>; Ganthaler et al. <xref ref-type="bibr" rid="CR85">2018</xref>; Liu et al. <xref ref-type="bibr" rid="CR151">2018</xref>), but is an area of research need. An automated VIS image analysis system on a UAV for measuring severity had moderate precision compared to visual rating (<italic>R</italic><sup>2</sup> = 0.73), but was deemed acceptable for rating potato resistance to late blight (Sugiura et al. <xref ref-type="bibr" rid="CR223">2016</xref>). Zhang et al. (<xref ref-type="bibr" rid="CR248">2018b</xref>) found RGB images taken using a UAV were less effective (<italic>R</italic><sup>2</sup> ≤ 0.554) in differentiating severity of sheath blight of rice compared to HSI sensors (<italic>R</italic><sup>2</sup> ≤ 0.627). VIS image analysis to measure disease severity is not yet routinely used outside the research realm. There are a few examples of controlled environment, high-throughput systems used routinely for research purposes. Karisto et al. (<xref ref-type="bibr" rid="CR126">2018</xref>) described automated VIS image analysis to measure severity of Septoria leaf blotch on wheat. There was a good relationship between image analyzed measurements and visual estimates (Lin’s concordance correlation, ρ<sub>c</sub> = 0.76 to 0.99, depending on rater (Stewart and McDonald <xref ref-type="bibr" rid="CR220">2014</xref>)). Microscopic imaging of powdery mildew on barley for genotype screening was considered ready for high-throughput processing (Ihlow et al. <xref ref-type="bibr" rid="CR119">2008</xref>). But both still require time-consuming sample preparation.</p></sec></sec></sec><sec id="Sec15"><title>Spectral sensor technology to measure plant disease severity</title><p id="Par55">MSI and HSI sensors measure the light reflected by an object. In plant disease detection and severity measurement this might be a single plant organ (leaf, fruit, and/or storage root), a plant, or a crop stand. Several studies have demonstrated that diseases can be detected accurately even before symptoms are visible to the human eye (Rumpf et al. <xref ref-type="bibr" rid="CR202">2010</xref>; Zhao et al. <xref ref-type="bibr" rid="CR250">2017</xref>). Indeed, detecting the quantity of disease at very early stages is valuable for disease management decisions, and neither raters nor VIS image analysis can detect latent disease. Furthermore, HSI is non-invasive and non-destructive, and is an objective method, and if automated can significantly reduce the workload compared to other methods of assessment (Walter et al. <xref ref-type="bibr" rid="CR237">2015</xref>; Mahlein <xref ref-type="bibr" rid="CR155">2016</xref>; Virlet et al. <xref ref-type="bibr" rid="CR234">2017</xref>).</p><sec id="Sec16"><title>Characteristics of light reflectance from plants</title><sec><p id="Par56">The optical properties of plants are determined mainly by their reflectance, transmission and absorbance of light. Diseases affect these signature characteristics.</p></sec><sec id="FPar24"><title>Reflectance of light from plants</title><p id="Par57">Reflectance depends on leaf properties. Transmission and absorbance are influenced by pigments and water (Gates et al. <xref ref-type="bibr" rid="CR87">1965</xref>; Curran <xref ref-type="bibr" rid="CR62">1989</xref>). Reflectance is caused by biochemical properties that result in a mixed signal (Gates et al. <xref ref-type="bibr" rid="CR87">1965</xref>; Carter and Knapp <xref ref-type="bibr" rid="CR45">2001</xref>; Gay et al. <xref ref-type="bibr" rid="CR88">2008</xref>). The visible range (400–700 nm) is characterized by absorption by chlorophyll, carotenoids and anthocyanins (Gay et al. <xref ref-type="bibr" rid="CR88">2008</xref>). According to Hindle (<xref ref-type="bibr" rid="CR109">2008</xref>), NIR and SWIR stimulate molecular motion that induces absorption or reflection by compounds having characteristic spectral patterns. The NIR reflectance of leaves is determined mainly by the leaf and cell structures and the canopy architecture (Gates et al. <xref ref-type="bibr" rid="CR87">1965</xref>; Elvidge <xref ref-type="bibr" rid="CR77">1990</xref>). The NIR and SWIR regions have bands that are absorbed by water (particularly the SWIR region) (Seelig et al. <xref ref-type="bibr" rid="CR207">2008</xref>).</p></sec><sec id="FPar25"><title>How do plant diseases influence the optical properties of plants?</title><p id="Par58">The pathogen causes changes in physiological and biochemical processes in the host (Mahlein et al. <xref ref-type="bibr" rid="CR160">2010</xref>), resulting in disease, often accompanied by symptoms. The pathogen and symptom types have consequences for the detectability and measurement of disease severity. Each host-parasite interaction has a specific spatial and temporal dynamic, impacting different wavebands during pathogenesis (Wahabzada et al. <xref ref-type="bibr" rid="CR235">2015</xref>; Wahabzada et al. <xref ref-type="bibr" rid="CR236">2016</xref>). Sensors offer the potential to extract new features of disease severity and dynamics, and a new way to visualize and analyze severity. Progress in disease symptoms can be directly related to HSI measurements (as “metro maps” or “disease traces”, Kuska et al. <xref ref-type="bibr" rid="CR135">2015</xref>; Wahabzada et al. <xref ref-type="bibr" rid="CR235">2015</xref>, <xref ref-type="bibr" rid="CR236">2016</xref>). Metro maps of plant disease dynamics explicitly track the host-pathogen interaction, providing an abstract yet interpretable view of disease progress.</p></sec></sec><sec id="Sec17"><title>Methods of hyperspectral image acquisition</title><sec><p id="Par59">In contrast to RGB cameras having a spatial resolution of several megapixels, spectral sensors include high-resolution techniques with greater spectral resolution (Fig. <xref rid="Fig5" ref-type="fig">5</xref>; Mahlein et al. <xref ref-type="bibr" rid="CR156">2018</xref>). HSI and MSI sensors assess narrow wavebands in specific ranges of the electromagnetic spectrum in combination with a high spatial resolution. The VIS and NIR region (400–1000 nm) have the highest information content for monitoring plant stress. The ultraviolet-range (UV, 250–400 nm) (Brugger et al. <xref ref-type="bibr" rid="CR42">2019</xref>) and SWIR-range (1000–2500 nm) (Wahabzada et al. <xref ref-type="bibr" rid="CR235">2015</xref>) provide information as well. Spectral sensors can be characterized by resolution (number of wavebands per nm) and the type of the detector. Often, MSI sensors cover the RGB range in addition to NIR but provide less data due to lower spectral resolution, although they are lightweight and cost less (Mahlein et al. <xref ref-type="bibr" rid="CR156">2018</xref>). In contrast, HSI sensors are more complex, heavier, expensive and the measurement takes longer, demanding strict protocols. Systems consist of the sensor, a light source and a control unit for measuring, storing and processing the data (Thomas et al. <xref ref-type="bibr" rid="CR227">2018b</xref>).
<fig id="Fig5"><label>Fig. 5</label><caption xml:lang="en"><p>“Spectral data cube”. Three-dimensional structure of hyperspectral imaging data with two spatial dimensions y and x and a spectral dimension z. Each image pixel contains the spectral information over the measured range. In this example, the reflectance from barley leaves diseased with rust is illustrated at different disease severities</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/42483_2020_49_Fig5_HTML.png" id="MO5"/></fig></p></sec><sec><p id="Par60">Choice of HSI sensor in combination with the measuring design and platform is the basis of a data set. Accuracy and resolution are influenced by the distance between the sensor and the object. Thus, airborne or space borne systems have lower spatial resolution compared to near-range systems. Data preprocessing and analysis is closely linked and individually designed depending on the sensor, setup and purpose of measuring (Behmann et al. <xref ref-type="bibr" rid="CR23">2015a</xref>; Mishra et al. <xref ref-type="bibr" rid="CR168">2018</xref>).</p></sec><sec id="FPar26"><title>Non-imaging sensors</title><p id="Par61">Non-imaging HSI sensors do not provide spatial information. The focal length of the viewing angle and the distance to the target determine the size of the measured area. The signal comprises mixed information from healthy and diseased areas, affecting the sensitivity and specificity, so early detection and measurement of symptoms by non-imaging sensors is limited, especially at low disease severities. Measurement of severity of mixed infections is challenging using non-imaging sensors. Mahlein et al. (<xref ref-type="bibr" rid="CR160">2010</xref>, <xref ref-type="bibr" rid="CR161">2012b</xref>) found the detection limit using non-imaging HSI for Cercospora leaf spot (CLS) and powdery mildew of sugar beet was 10 and 20% diseased leaf area, respectively.</p></sec><sec id="FPar27"><title>Imaging sensors</title><p id="Par62">Imaging HSI sensors collect extra information on shape, gradient or color of the spatial dimension (Behmann et al. <xref ref-type="bibr" rid="CR23">2015a</xref>). There are push-broom and whisk-broom scanners that capture the spectral information of a pixel point or a pixel line at the same time, respectively. The image emerges due to movement of the sensor and has high spatial and spectral resolution. Depending on image size, image acquisition time may take minutes, limiting imaging sensors to motionless objects (Thomas et al. <xref ref-type="bibr" rid="CR228">2017</xref>).</p></sec><sec id="FPar28"><title>Other HSI sensors</title><p id="Par63">Filter-based HSI sensors do not require the sensor to move and are generally faster than push- and whisk-broom sensors, but the subject must be motionless. HSI snapshot cameras capture images akin to RGB cameras, but have lower resolution compared to push- or whisk-broom sensors, although they have a fast image acquisition time (Thomas et al. <xref ref-type="bibr" rid="CR228">2017</xref>).</p></sec></sec><sec id="Sec18"><title>Choice of sensor platform</title><p id="Par64">It is critical to consider purpose and subject. HSI sensor setups can be handheld or mounted on a platform (vehicles, robots, UAVs, airplanes or satellites). Choosing the right sensor in combination with the right measurement scale is the key requirement for successful field measurement. Possible targets could be early disease detection/identification, or quantifying disease incidence or severity. Drone measurements at a height of 50 m above the crop in combination with a low spatial resolution hyperspectral camera will not detect single leaf lesions compared to a measuring device close to the leaf canopy that has high spatial resolution. Pixel-wise attribution of diseased and healthy tissue is conducive to observe spectral reflectance patterns of diseases in detail. It should be noted that some disease symptoms can only be distinguished from other diseases and stresses when using HSI imaging with high spatial resolution.</p></sec><sec id="Sec19"><title>Data handling, training and analysis</title><sec><p id="Par65">There are several approaches for analyzing HSI and MSI data – but no standard one. Data preprocessing typically consists of normalization to a white reference standard and dark current images (Behmann et al. <xref ref-type="bibr" rid="CR23">2015a</xref>). A smoothing of the data can be performed. Often the background and parts of the image which are not required for further analysis are masked to reduce the data complexity.</p></sec><sec id="FPar29"><title>Vegetation indices</title><p id="Par66">A common and straightforward way to analyze hyperspectral images are vegetation indices (VI) (Devadas et al. <xref ref-type="bibr" rid="CR71">2009</xref>; Ashourloo et al. <xref ref-type="bibr" rid="CR10">2014</xref>; Behmann et al. <xref ref-type="bibr" rid="CR23">2015a</xref>). VIs are algorithms based on band ratios. Often 2–6 bands are involved. VIs are used to highlight a specific factor while reducing data complexity and the impact of other factors (Jackson and Huete <xref ref-type="bibr" rid="CR120">1991</xref>; Gitelson et al. <xref ref-type="bibr" rid="CR92">2014</xref>; Blackburn <xref ref-type="bibr" rid="CR27">2007</xref>). Several well-described VIs have been used for the detection or quantification of diseases, but weren’t specifically developed for that purpose. Moreover, VIs are related to pigment content, vitality, biomass, water content and so on. For the analysis of MSI data, VIs are often the method of choice.</p><p id="Par67">Some disease specific VIs have been developed (Mahlein et al. <xref ref-type="bibr" rid="CR159">2013</xref>; Ashourloo et al. <xref ref-type="bibr" rid="CR10">2014</xref>; Oerke et al. <xref ref-type="bibr" rid="CR188">2016</xref>). The correlation between disease severity and reflectance wavebands are calculated and those wavebands with the highest correlations are integrated into disease specific indices. Comparative studies have demonstrated that disease specific VIs are superior to standard VIs (Mahlein et al. <xref ref-type="bibr" rid="CR159">2013</xref>; Ashourloo et al. <xref ref-type="bibr" rid="CR10">2014</xref>). An overview of VIs for the detection and/or quantification of diseases is presented, including disease specific VIs (Table <xref rid="Tab5" ref-type="table">5</xref>).
<table-wrap id="Tab5"><label>Table 5</label><caption xml:lang="en"><p>Examples of different general spectral vegetation indices and disease-specific vegetation indices used to detect and measure severity of various plant disease</p></caption><table frame="hsides" rules="groups"><thead><tr><th><p>Type</p></th><th><p>Name</p></th><th><p>Parameter / Disease</p></th><th><p>Calculation<sup>a</sup></p></th><th><p>Reference</p></th></tr></thead><tbody><tr><td rowspan="6"><p>General spectral vegetation indices</p></td><td><p>Normalized Difference Vegetation Index (NDVI)</p></td><td><p>Chlorophyll</p></td><td><p>(R<sub>800</sub>-R<sub>670</sub>)/(R<sub>800</sub> + R<sub>670</sub>)</p></td><td><p>Rouse et al. (<xref ref-type="bibr" rid="CR201">1974</xref>) Tucker et al. (<xref ref-type="bibr" rid="CR231">1991</xref>)</p></td></tr><tr><td><p>Plant Senescence Reflectance Index (PSRI)</p></td><td><p>Pigment content, Senescence</p></td><td><p>(R<sub>680</sub>-R<sub>500</sub>)/R<sub>750</sub></p></td><td><p>Merzlyak et al. (<xref ref-type="bibr" rid="CR165">1999</xref>)</p></td></tr><tr><td><p>Carotenoid Reflectance Index (CAR1)</p></td><td><p>Carotenoids</p></td><td><p>1/R<sub>510</sub>–1/R<sub>550</sub></p></td><td><p>Gitelson et al. (<xref ref-type="bibr" rid="CR93">2002</xref>)</p></td></tr><tr><td><p>Anthocyanin Reflectance Index (ARI)</p></td><td><p>Anthocyanins/Yellow rust (wheat)</p></td><td><p>1/R<sub>510</sub>–1/R<sub>700</sub></p></td><td><p>Gitelson et al. (<xref ref-type="bibr" rid="CR91">2001</xref>) Zheng et al. (<xref ref-type="bibr" rid="CR251">2018</xref>)</p></td></tr><tr><td><p>Photochemical Reflectance Index (PRI)</p></td><td><p>Photosynthesis, Carotenoids/Yellow rust (wheat)</p></td><td><p>(R<sub>570</sub>-R<sub>531</sub>)/(R<sub>570</sub> + <sub>531</sub>)</p></td><td><p>Gamon et al. (<xref ref-type="bibr" rid="CR84">1992</xref>) Zheng et al. (<xref ref-type="bibr" rid="CR251">2018</xref>)</p></td></tr><tr><td><p>Normalized Difference Spectral Index (NDSI)</p></td><td><p>Leaf spot diseases (peanut)</p></td><td><p>(R<sub>800</sub> − R<sub>670</sub>)/(R<sub>800</sub> + R<sub>670</sub>)</p></td><td><p>Rouse et al. (<xref ref-type="bibr" rid="CR201">1974</xref>) Chen et al. (<xref ref-type="bibr" rid="CR47">2019</xref>)</p></td></tr><tr><td rowspan="7"><p>Disease-specific vegetation indices</p></td><td><p>Cercospora Leaf Spot Index (CLSI)</p></td><td><p>Cercospora leaf spot (sugar beet)</p></td><td><p>(R<sub>698</sub>-R<sub>570</sub>/(R<sub>698</sub> + R<sub>570</sub>)-R<sub>734</sub></p></td><td><p>Mahlein et al. (<xref ref-type="bibr" rid="CR159">2013</xref>)</p></td></tr><tr><td><p>Sugar Beet Rust Index (SBRI)</p></td><td><p>Sugar beet rust (sugar beet)</p></td><td><p>(R<sub>570</sub> − R<sub>513</sub>)/(R<sub>570</sub> + R<sub>513</sub>) + (1/2*R<sub>704</sub>)</p></td><td><p>Mahlein et al. (<xref ref-type="bibr" rid="CR159">2013</xref>)</p></td></tr><tr><td><p>Powdery Mildew Index (PMI)</p></td><td><p>Powdery mildew (sugar beet)</p></td><td><p>(R<sub>520</sub> − R<sub>584</sub>)/(R<sub>520</sub> + R<sub>584</sub>) + R<sub>724</sub></p></td><td><p>Mahlein et al. (<xref ref-type="bibr" rid="CR159">2013</xref>)</p></td></tr><tr><td><p>Leaf Rust Disease Severity Index 1 (LRDSI_1)</p></td><td><p>Brown rust (wheat)</p></td><td><p>6.9*(R<sub>605</sub>/R<sub>455</sub>)-1.2</p></td><td><p>Ashourloo et al. (<xref ref-type="bibr" rid="CR10">2014</xref>)</p></td></tr><tr><td><p>Leaf Rust Disease Severity Index 2 (LRDSI_2)</p></td><td><p>Brown rust (wheat)</p></td><td><p>4.2*(R<sub>695</sub>/R<sub>455</sub>)-3.8</p></td><td><p>Ashourloo et al. (<xref ref-type="bibr" rid="CR10">2014</xref>)</p></td></tr><tr><td><p>Red Edge Disease Stress Index (REDSI)</p></td><td><p>Yellow rust (wheat)</p></td><td><p>(705–665)*(R<sub>783</sub> − R<sub>665</sub>) − (783–665)*(R<sub>705</sub> − R<sub>665</sub>)2 × R<sub>665</sub></p></td><td><p>Zheng et al. (<xref ref-type="bibr" rid="CR251">2018</xref>)</p></td></tr><tr><td><p>Lemon Myrtle-Myrtle Rust Index (LMMRI)</p></td><td><p>Myrtle rust (myrtle)</p></td><td><p>(R<sub>545</sub>/R<sub>555</sub>)<sup>5/3</sup>*R<sub>1505</sub>/R<sub>2195</sub></p></td><td><p>Heim et al. (<xref ref-type="bibr" rid="CR104">2019</xref>)</p></td></tr></tbody></table><table-wrap-foot><p><sup>a</sup>R<sub><italic>i</italic></sub>: indicates reflectance at waveband <italic>i</italic></p></table-wrap-foot></table-wrap></p></sec><sec id="FPar30"><title>Symptom recognition and analysis</title><p id="Par68">As for VIS image analysis, hyperspectral image analysis is challenging. The aim is to extract a small proportion of relevant information from the hyperspectral signal (Behmann et al. <xref ref-type="bibr" rid="CR24">2015b</xref>). Algorithms are developed to learn and make predictions about the data (Kersting et al. <xref ref-type="bibr" rid="CR128">2016</xref>) and can cope with hundreds of wave bands used for detection, quantification and characterization of plant diseases in the laboratory, greenhouse and field (Behmann et al. <xref ref-type="bibr" rid="CR24">2015b</xref>; Singh et al. <xref ref-type="bibr" rid="CR214">2016</xref>). Either the entire spectral data set can be analyzed, and patterns identified, or feature selection methods can be applied to reduce the data complexity. As with VIS image analysis methods, there are supervised and unsupervised learning approaches.</p><p id="Par69">Supervised approaches like regression and classification demand annotated training data. Provision of training data is a limiting factor in severity measurement as sufficiently large image sets of annotated data for specific diseases under a full range of conditions are not available.</p><p id="Par70">Compared to supervised approaches, unsupervised approaches are less well explored, but do not rely on annotation and training data. Unsupervised methods can be assigned to pattern recognition in hyperspectral image data. A ‘crossover’ is a data driven learning model that relies on the actual data set, and not on predefined models; the algorithm utilizes extreme data points to define archetypal signatures, including latent aspects of the data (Wahabzada et al. <xref ref-type="bibr" rid="CR235">2015</xref>, <xref ref-type="bibr" rid="CR236">2016</xref>).</p><p id="Par71">Approaches using AI for measuring severity are based on deep learning. In contrast to the predefined features of machine learning approaches, deep learning models determine more abstract and more informative data representation within the process of optimization to a particular task. Deep learning offers potential to identify optimal features for the detection and measurement of a specific disease. As with RGB images, CNNs show great potential as a component of deep learning. Nagasubramanian et al. (<xref ref-type="bibr" rid="CR174">2017</xref>, <xref ref-type="bibr" rid="CR175">2019</xref>) applied a 3D CNN for detection of charcoal rot on soybean using close-range VIS-NIR hyperspectral images and achieved a detection accuracy of 97% and was able to predict lesion length on most stems. However, these technologies demand substantial training data. Establishing a library of ground-truthed data for different diseases is crucial to the successful implementation of deep learning for disease quantification.</p><p id="Par72">Related to general disease severity measurement, the importance of early detection (a “pre-visible symptom severity measurement”) cannot be overstated and is critical in many circumstances; HSI can excel when severity is nascent.</p></sec></sec><sec id="Sec20"><title>Ground truthing, accuracy and measuring disease severity with spectral sensors</title><p id="Par73">Various actual values or “ground truthing” have been used in HSI disease severity measurement including visual estimates based on nominal or ordinal scales (Huang et al. <xref ref-type="bibr" rid="CR116">2007</xref>; Wang et al. <xref ref-type="bibr" rid="CR239">2016</xref>; Leucker et al. <xref ref-type="bibr" rid="CR146">2017</xref>), described stages of symptom progression (Kuska et al. <xref ref-type="bibr" rid="CR135">2015</xref>; Wahabzada et al. <xref ref-type="bibr" rid="CR235">2015</xref>, <xref ref-type="bibr" rid="CR236">2016</xref>; Zhu et al. <xref ref-type="bibr" rid="CR253">2017</xref>), and molecular quantification of the pathogen (Thomas et al. <xref ref-type="bibr" rid="CR228">2017</xref>; Zhao et al. <xref ref-type="bibr" rid="CR250">2017</xref>). An increasing number of studies have demonstrated that HSI and MSI data can be used to accurately detect, differentiate and quantify symptoms of plant diseases (Mahlein et al. <xref ref-type="bibr" rid="CR158">2012a</xref>). However, as noted, accuracy is not necessarily measured using the 0 to 100% scale as it has historically been for visual estimates or even for VIS image analysis. It may be related directly to the physiological, biochemical, structural and development changes in the host and pathogen. Comparing estimated or measured symptoms using the 0 to 100% scale to HSI, measurements can easily be done as HSI sensors provide pixel-based results on disease status (Fig. <xref rid="Fig6" ref-type="fig">6</xref>). The relation among visual rating and sensor measurement can be evaluated by post-classification routines and confusion matrixes.
<fig id="Fig6"><label>Fig. 6</label><caption xml:lang="en"><p>RGB images and false-color classification of diseased pixels of wheat leaves with symptoms of powdery mildew caused by <italic>Blumera graminis</italic> f.sp. <italic>tritici.</italic> Hyperspectral images were acquired using a Specim V10 camera system, and classification was performed using Support Vector Machines (SVM). Percentage of diseased leaf area assessed by SVM classification is indicated on the right; classification accuracy ranged from 90% to 95%</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/42483_2020_49_Fig6_HTML.png" id="MO6"/></fig></p><p id="Par74">Accuracy of detection can be robust. Apan et al. (<xref ref-type="bibr" rid="CR8">2004</xref>) detected sugarcane orange rust with 96.9% accuracy compared to visually ground-truthed data; Bravo et al. (<xref ref-type="bibr" rid="CR41">2003</xref>) used in-field spectral images for early detection of yellow rust infected wheat with 96% when compared to a visually-assessed disease map; Hillnhütter et al. (<xref ref-type="bibr" rid="CR108">2011</xref>, <xref ref-type="bibr" rid="CR107">2012</xref>) discriminated symptoms caused by the nematode <italic>Heterodera schachtii</italic> and the soil borne fungus <italic>Rhizoctonia solani</italic> in sugar beet under both field and controlled conditions (spectral reflectance data and manual symptom assessment were correlated, <italic>P</italic> &lt; 0.01); Delalieux et al. (<xref ref-type="bibr" rid="CR70">2007</xref>, Delalieux et al. 2009a, 2009b) identified narrow waveband ratios with c-values (the c-index is derived from Received Operator Curves maximizing sensitivity for low values of the false-positive fraction) ranging from 0.80 to 0.88 for detecting scab (caused by <italic>Venturia inaequalis</italic>) on apple.</p><p id="Par75">For measuring severity, Wahabzada et al. (<xref ref-type="bibr" rid="CR235">2015</xref>, <xref ref-type="bibr" rid="CR236">2016</xref>) used advanced data mining techniques to define cardinal points during pathogenesis and differentiate spatial and temporal development of symptom dynamics of foliar diseases (caused by <italic>Pyrenophora teres</italic>, <italic>Puccinia hordei</italic> and <italic>Blumeria graminis hordei</italic>) of barley. Disease was quantified by counting the number of diseased pixels to equate to the stage of infection which has a relationship with severity (leaf area diseased), although severity (as a percent area diseased) was not explicitly performed. Some of these ideas are ushering in novel paradigms in the progress of disease severity for HSI. Huang et al. (<xref ref-type="bibr" rid="CR116">2007</xref>) demonstrated reliable measurement of severity using a 9-class ordinal scale for severity of yellow rust in wheat (<italic>R</italic><sup>2</sup> = 0.91). Other studies have explored classification accuracy using ordinal groupings in classes of visually assessed specimens as the assumed gold standard (Bravo et al. <xref ref-type="bibr" rid="CR41">2003</xref>; Alisaac et al. <xref ref-type="bibr" rid="CR2">2018</xref>; Thomas et al. <xref ref-type="bibr" rid="CR226">2018a</xref>; Alisaac et al. <xref ref-type="bibr" rid="CR3">2019</xref>), including the use of confusion matrices. Regression analysis of visual estimates of diseased wheat spikes on a percentage scale and hyperspectral measurements also had demonstrable reliability (<italic>R</italic><sup>2</sup> up to 0.828, Kobayashi et al. <xref ref-type="bibr" rid="CR129">2016</xref>). Thomas et al. (<xref ref-type="bibr" rid="CR228">2017</xref>), using pathogen DNA to ground-truth achieved a coefficient of determination (<italic>R</italic><sup>2</sup>) of 0.72 from 3 to 9 days after infection of barley with <italic>Blumeria graminis</italic> f.sp. <italic>hordei</italic>.</p></sec><sec id="Sec21"><title>Sources of error affecting accuracy</title><sec id="FPar31"><title>Illumination</title><p id="Par76">Measurements in the field can be performed using shading and artificial light. If sunlight is used, robust checks against variation in sunlight intensity are critical (Wendel and Underwood <xref ref-type="bibr" rid="CR240">2017</xref>). Interpolation approaches may fail through lack of continuous illumination (Suomalainen et al. <xref ref-type="bibr" rid="CR225">2014</xref>). Solar altitude, clouds, dew or dust can be problematic. The application of suitable radiation transfer models may help reduce environmental effects (Jay et al. <xref ref-type="bibr" rid="CR123">2016</xref>) but is complex and time consuming. Appropriate calibration to reflectance standards or the continuous assessment of radiation intensity is necessary. Varying illumination issues are more acute in direct sunlight and less severe under cloudy conditions, where the light is more diffuse. So far there are no standard calibration methods, the method of choice has to be designed depending on the senor-platform and illumination situation (Banerjee et al. <xref ref-type="bibr" rid="CR14">2020</xref>). For HSI under laboratory conditions, calibration routines are well established (Behmann et al. <xref ref-type="bibr" rid="CR23">2015a</xref>).</p></sec><sec id="FPar32"><title>Motion</title><p id="Par77">Crop motion due to wind can be an issue. Most HSI sensors record information with a small temporal offset. With line scanning HSI cameras, the single lines are measured consecutively, and movement distorts the spatial image, whereas the spectral information remains valid (Thomas et al. <xref ref-type="bibr" rid="CR228">2017</xref>). Filter based systems often demand several seconds to record an image. If the object moves, the spectrum will consist of the reflectance information from different leaf areas and possibly even the ground, which cannot be corrected as the movement geometry is unknown. However, averaging the entire hyperspectral image mostly eliminates the effect, but spatial resolution is lost and the resulting data is comparable to that obtained using a simple spectrometer.</p></sec><sec id="FPar33"><title>Mixed infection and mixed stress</title><p id="Par78">Quantification of a disease can be hindered by simultaneous stress (biotic or abiotic) or mixed infection. This aspect has only begun to be addressed. Studies are needed to demonstrate the potential of HSI to simultaneously identify and quantify multiple stressors or diseases.</p></sec><sec id="FPar34"><title>Technical setup</title><p>Leaves at different levels in a complex canopy require different exposure times. Shadows complicate saturation and since the choice of the exposure time is based on the brightest object, the exposure time is often much lower than required for shaded leaves low in the canopy, resulting in a noisier image.</p></sec><sec id="FPar35"><title>Characteristics of the disease distribution</title><p id="Par80">Disease distributions may affect the ease with which the sensor can access specimens to sample. Some diseases spread from the lower leaves to the upper leaves through wind or the kinetic energy of rain droplets (e.g Septoria leaf blotch). Also, Septoria leaf blotch has a prolonged biotrophic phase. Thus, the upper leaves may not reflect the true disease severity in the crop stand when measurements are captured from above the canopy. Wind borne pathogens may be more likely to infect upper parts of a plant. In cereals, this favors the detection of foliar rust diseases or powdery mildews.</p><p id="Par81">These challenges notwithstanding, HSI has great potential to provide a sophisticated, accurate and rapid method to measure disease severity at multiple spatial scales. The challenges are technically surmountable, and the advances over the last several years demonstrate the utility of this technology.</p></sec></sec><sec id="Sec22"><title>Application in research and practice</title><sec id="FPar36"><title>Controlled conditions</title><p id="Par82">Many studies have measured disease severity using HSI under controlled conditions in the laboratory (Delalieux et al. <xref ref-type="bibr" rid="CR68">2009a</xref>, <xref ref-type="bibr" rid="CR69">2009b</xref>; Arens et al. <xref ref-type="bibr" rid="CR9">2016</xref>; Leucker et al. <xref ref-type="bibr" rid="CR146">2017</xref>). High spatial resolution can be obtained by hyperspectral microscopes (Kuska et al. <xref ref-type="bibr" rid="CR135">2015</xref>; Leucker et al. <xref ref-type="bibr" rid="CR145">2016</xref>), detecting plant-pathogen interactions at the submillimeter scale, before they are visible, or detectable using field-based HSI systems. Scale independent transfer of characteristic spectral signatures may be possible (Bohnenkamp et al. <xref ref-type="bibr" rid="CR39">2019</xref>), whereby spectral signatures of different diseases over time is used for detection and quantification models at different spatial scales. The approach will help process large numbers of complex host-pathogen interactions and the impact of mixed infections or abiotic stressors.</p></sec><sec id="FPar37"><title>Field conditions</title><p id="Par83">HSI measurement of disease severity under field conditions is particularly challenging (Bravo et al. <xref ref-type="bibr" rid="CR41">2003</xref>; West et al. <xref ref-type="bibr" rid="CR241">2003</xref>). As with systems under controlled conditions, these are at an early experimental phase. Applied systems do not yet exist. Variable environmental conditions and biological heterogeneity impair the quality of field data. Additionally, the infection biology and epidemiology of a disease may impact detectability and measurability (West et al. <xref ref-type="bibr" rid="CR241">2003</xref>; Mahlein et al. <xref ref-type="bibr" rid="CR157">2019</xref>).</p></sec></sec></sec><sec id="Sec23"><title>Contrasting the methods</title><p id="Par84">An overview of the methods is presented in Fig. <xref rid="Fig7" ref-type="fig">7</xref>, and some of the advantages and disadvantages of the methods are contrasted (Table <xref rid="Tab6" ref-type="table">6</xref>). Clearly, they have different levels of subjectivity, speed, scalability and cost. Accuracy also varies. Inexperienced, untrained/uninstructed and unaided raters can be wildly inaccurate in severity estimation. But trained, well-instructed and aided raters can provide very accurate estimates. Raters are slow, may be more expensive, and have low throughput. Scalability for visual rating is limited to plot or at most, field levels of assessment. However, both VIS and HSI/MSI image analysis offer less variable measurements of severity under tightly controlled conditions. Both can offer high throughput. Early detection and measurement of severity, particularly by HSI or MSI (and other remote sensors) is a major advantage and is being realized in the research arena. However, both HSI and MSI are limited in field situations as they are currently less capable of dealing with the wide variability in host, pathogen and disease characteristics experienced in the field. Raters, when well-trained and instructed can differentiate symptoms of diseases and suitable samples for assessment. Visual estimation of disease severity will be widely used for many years yet and may be needed alongside automated systems for validation and ground-truthing of new or improved fully automated AI-based methods for the foreseeable future.
<fig id="Fig7"><label>Fig. 7</label><caption xml:lang="en"><p>The main characteristics of visual severity estimation and imaging severity measurement methods as described and discussed in the text</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/42483_2020_49_Fig7_HTML.png" id="MO7"/></fig><table-wrap id="Tab6"><label>Table 6</label><caption xml:lang="en"><p>A comparison of different criteria for  visual assessment, visible spectrum image analysis (RGB) and hyperspectral image analysis as methods for obtaining plant disease severity data</p></caption><graphic xlink:href="MediaObjects/42483_2020_49_Tab6_HTML.png" id="MO8"/></table-wrap></p><p id="Par85">Visual rating, when performed by trained, well-instructed and aided raters has probably reached its zenith of accuracy. But much is left to be understood regarding visual severity estimation, and the level of improvement will vary according to disease symptoms and how consistency within and among raters can be improved. In contrast, both VIS and HSI/MSI image analysis are rapidly evolving fields with ever more sophisticated approaches being developed and used for image acquisition and processing to measure severity. This is clear in the recent development of high-throughput systems for measuring disease under controlled conditions. Although measuring disease severity under field conditions remains challenging, the technical hurdles are being addressed and various systems have been demonstrated to have some utility, if not yet of practical value. It is possible that a combination of manual operations with automated measures will be required to overcome some limitations.</p><p id="Par86">Visual rating of plant disease severity remains the most widely performed method for all purposes of field research where severity is a required variable. Very few mobile, or field operated VIS and HSI/MSI image analysis systems are routinely used in plant breeding, plant disease management, or for other purposes requiring severity measurement. This will doubtless change as research makes more advances facilitating the field application of VIS and HSI/MSI image analysis. As described, new tools based on AI have demonstrated capability and the potential to overcome many of the barriers. Already some small companies and start-ups provide HSI services for crop monitoring. These may be a model for the future where plant disease assessment is a standard service using HSI and may be provided using various platforms. Furthermore, new digital technologies must be linked to existing prognosis and expert systems with integration into disease thresholding models for real-time management of disease. VIS and HSI/MSI image analysis will continue to play a more prominent role for quantifying disease in research and practice.</p><p id="Par87">Most visual estimates are assessed for accuracy based on the percentage scale, which offers high resolution for differentiating severity of disease. VIS image analysis under tightly controlled conditions can accurately measure disease either when manually operated or automated based on the percentage scale. But under field conditions accuracy is less certain, and the measurements are most often compared to a limited number of classes on an ordinal scale (up to 9 classes), which results in lower resolution to differentiate severity compared to the percentage scale. However, sample sizes can be rapidly and easily increased with VIS image analysis, which can improve the power of a hypothesis test. Severity data collected by HSI/MSI sensors is sometimes related to the percentage scale, but often the data are related to an ordinal or nominal scale rating of the ground-truthed samples, or to characteristic stages during the pathogenesis process. This may provide a new paradigm for rating severity other than using a ratio, ordinal or nominal scales.</p><p id="Par88">A major challenge for both VIS and HSI/MSI is training image sample sizes covering the range in variability of symptoms and conditions expected to be experienced. This will require considerable effort. A possible solution is citizen science (Barbedo <xref ref-type="bibr" rid="CR20">2019</xref>), in which non-professional volunteers collect and/or process data (Silvertown <xref ref-type="bibr" rid="CR212">2009</xref>). Practitioners and stakeholders could capture images in the field and an expert could annotate these. This idea has been implemented by Plantix™ (<ext-link xlink:href="https://plantix.net/en/" ext-link-type="uri">https://plantix.net/en/</ext-link>, PEAT, Berlin). This, and other studies referenced provide a sound basis for being optimistic for the technology in the future.</p><p id="Par89">Furthermore, accuracies of different methods cannot be directly compared unless they are tested against identical gold standards or actual values. Thus, inferring the state of art quantitatively is challenging. It is worth noting that sharing the datasets used in published studies is being encouraged by many journals, so it might be possible to test new methodologies with the data used in prior experiments (Barbedo <xref ref-type="bibr" rid="CR20">2019</xref>), thus enabling more direct comparisons. Examples of accuracies attained by each of these methods are summarized by examples (Table <xref rid="Tab7" ref-type="table">7</xref>). These and other studies have demonstrated that all three methods can provide accurate estimates or measurements of disease severity. However, VIS and HSI/MSI image analysis are still primarily at a research and developmental stage. Remote sensor-based methods are becoming less expensive, readily available and portable, and have the advantage of high throughput and scalability. However, the capability of raters in providing accurate estimates should not be overlooked as more sophisticated methods become available. Indeed, it behooves us to assure that the accuracy and reliability being attained by remote sensing methods is providing information at least sufficient for the purpose. Methods of validation should be in place to determine this – use of actual values or ground-truthing in all studies is critical to the ongoing process of ensuring accuracy.
<table-wrap id="Tab7"><label>Table 7</label><caption xml:lang="en"><p>Comparison of different disease severity assessment methods in relation to accuracy-related measures, statistical methods and scale type and resolution used for method validation</p></caption><table frame="hsides" rules="groups"><thead><tr><th><p>Method</p></th><th><p>Actual value</p></th><th><p>Scale type and number of classes used for comparison</p></th><th><p>Resolution to differentiate severity</p></th><th><p>Statistic used to assess accuracy</p></th><th><p>Range</p></th><th><p>Reference</p></th></tr></thead><tbody><tr><td rowspan="9"><p>Visual assessment</p></td><td><p>Images traced from slide projections for contrast and image analyzed</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Regression, intercept and slope coefficient (a and b)</p></td><td><p><italic>R</italic><sup>2</sup> = 0.913 to 0.960;</p><p>a = 1.064 to 12.958;</p><p>b = 1.029 to 1.245</p></td><td><p>Martin and Rybicki (1998</p></td></tr><tr><td><p>Images on paper cut by symptom border and weighed</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>LCC (ρ<sub>c</sub>)</p></td><td><p>ρ<sub>c</sub> = 0.51–0.99</p></td><td><p>Nita et al. (<xref ref-type="bibr" rid="CR180">2003</xref>)</p></td></tr><tr><td><p>Manual image analysis</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Regression, intercept and slope coefficient (a and b)</p></td><td><p><italic>R</italic><sup>2</sup> = 0.51 to 0.93;</p><p>a = −1.90 to 41.38;</p><p>b = 0.65 to 1.24</p></td><td><p>Godoy et al. (<xref ref-type="bibr" rid="CR95">2006</xref>)</p></td></tr><tr><td><p>Manual image analysis</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Regression, intercept and slope coefficient (a and b)</p><p>LCC (ρ<sub>c</sub>)</p></td><td><p>Depending on symptom types:</p><p><italic>R</italic><sup>2</sup> = 0.59 to 0.88;</p><p>a = − 1.52 to 2.83;</p><p>b = 0.10 to 1.21;</p><p>ρ<sub>c</sub> = 0.85 to 0.94</p></td><td><p>Bock et al. (<xref ref-type="bibr" rid="CR35">2008a</xref>)</p></td></tr><tr><td><p>Manual image analysis</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Regression, intercept and slope coefficient (a and b)</p></td><td><p><italic>R</italic><sup>2</sup> = 0.88 to 0.98;</p><p>a = −6.68 to 5.09;</p><p>b = 0.75 to 0.94</p></td><td><p>Michereff et al. (<xref ref-type="bibr" rid="CR166">2009</xref>)</p></td></tr><tr><td><p>Manual image analysis</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>LCC (ρ<sub>c</sub>)</p></td><td><p>Means of ρ<sub>c</sub> = 0.76 to 0.98 depending on fruit perspective and use of SADs</p></td><td><p>Spolti et al. (<xref ref-type="bibr" rid="CR216">2011</xref>)</p></td></tr><tr><td><p>Manual image analysis</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>LCC (ρ<sub>c</sub>)</p></td><td><p>Mean of ρ<sub>c</sub> = 0.79 and 0.89 (with and without SADs)</p></td><td><p>Yadav et al. (<xref ref-type="bibr" rid="CR246">2013</xref>)</p></td></tr><tr><td><p>Manual image analysis</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>LCC (ρ<sub>c</sub>)</p></td><td><p>ρ<sub>c</sub> = 0.83 to 1.00 (mean = 0.95)</p></td><td><p>Bardsley and Ngugi (<xref ref-type="bibr" rid="CR22">2013</xref>)</p></td></tr><tr><td><p>Manual image analysis</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>LCC (ρ<sub>c</sub>)</p></td><td><p>Means of ρ<sub>c</sub> = 0.53, 0.87, 0.86 and 0.87 (without SADs, with SADs, and with color or black and white SADs)</p></td><td><p>Schwanck and Del Ponte (<xref ref-type="bibr" rid="CR206">2014</xref>)</p></td></tr><tr><td rowspan="13"><p>VIS (RGB) image analysis</p></td><td><p>Images on paper cut by symptom border and weighed</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Regression, intercept and slope coeffficient (a and b)</p></td><td><p><italic>R</italic><sup>2</sup> = 0.996;</p><p>a = −0.91;</p><p>b = 0.99</p></td><td><p>Lindow (<xref ref-type="bibr" rid="CR149">1983</xref>)</p></td></tr><tr><td><p>Planimeter measurement, various pathosystems</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Regression, intercept and slope</p></td><td><p><italic>R</italic><sup>2</sup> = 0.976 to 0.992;</p><p>a = 0.914 to 1.06;</p><p>b = − 0.17 to −4.35</p></td><td><p>Lindow and Webb (<xref ref-type="bibr" rid="CR150">1983</xref>)</p></td></tr><tr><td><p>Images traced from slide projections for contrast and image analyzed</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Regression, intercept and slope</p></td><td><p><italic>R</italic><sup>2</sup> = 0.971 to 0.985;</p><p>a = − 0.877 to 0.610;</p><p>b = 0.999 to 1.045</p></td><td><p>Martin and Rybicki (<xref ref-type="bibr" rid="CR163">1998</xref>)</p></td></tr><tr><td><p>Manual image analysis</p></td><td><p>Area in pixels</p></td><td><p>–</p></td><td><p>Regression, intercept and slope</p></td><td><p><italic>R</italic><sup>2</sup> = 0.980;</p><p>a = 0.901;</p><p>b = 16,097</p></td><td><p>Peressotti et al.( 2011)</p></td></tr><tr><td><p>Severity measured with multiplex real-time PCR</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Regression</p></td><td><p><italic>R</italic><sup>2</sup> = 0.9945</p></td><td><p>De Coninck et al.( 2012)</p></td></tr><tr><td><p>Visual (pixels)</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Accuracy (%)</p></td><td><p>Overall accuracy = 96%</p></td><td><p>Barbedo (<xref ref-type="bibr" rid="CR16">2014</xref>)</p></td></tr><tr><td><p>Visual ratings by 16 raters (inspection deemed image analysis was accurate)</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>LCC (ρ<sub>c</sub>)</p></td><td><p>ρ<sub>c</sub> = 0.76–0.99 (mean = 0.92)</p></td><td><p>Stewart and McDonald (<xref ref-type="bibr" rid="CR220">2014</xref>)</p></td></tr><tr><td><p>Visual (Pixels)</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>PCC (r)</p></td><td><p><italic>r</italic> = 0.60–0.90</p></td><td><p>Clément et al.( 2015)</p></td></tr><tr><td><p>Manual segmentation using Photoshop</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Quality of segmentation (Q<sub>s</sub>)</p></td><td><p>Q<sub>s</sub> = 84.17%</p></td><td><p>Hu et al. (<xref ref-type="bibr" rid="CR114">2017</xref>)</p></td></tr><tr><td><p>Visual</p></td><td><p>Ordinal (4 classes)</p></td><td><p>Healthy stage, early stage, middle stage, end stage</p></td><td><p>Classification accuracy (%)</p></td><td><p>Classification accuracy:</p><p>Healthy stage = 100%;</p><p>Early stage = 93.1%;</p><p>Middle stage = 83.3%;</p><p>End stage = 97.0%</p></td><td><p>Wang et al.( <xref ref-type="bibr" rid="CR238">2017</xref>)</p></td></tr><tr><td><p>Visual</p></td><td><p>Ordinal (5 classes)</p></td><td><p>Healthy, very low, low, high, very high</p></td><td><p>Classification accuracy (%) compared to other diseases and severities</p></td><td><p>Accuracy of severity measurement = 78.57–86.51% (depending on architecture of CNN)</p></td><td><p>Esgario et al. (<xref ref-type="bibr" rid="CR78">2019</xref>)</p></td></tr><tr><td><p>Visual</p></td><td><p>Ordinal (2 classes)</p></td><td><p>Mild, severe</p></td><td><p>Classification accuracy (%) compared to other diseases and severities</p></td><td><p>Severe symptoms = 70.4%;</p><p>Mild symptoms = 29.4%</p></td><td><p>Ramcharan et al. (<xref ref-type="bibr" rid="CR199">2019</xref>)</p></td></tr><tr><td><p>Visual</p></td><td><p>Ordinal (3 classes)</p></td><td><p>Healthy, general, serious</p></td><td><p>Proportion accurately classified</p></td><td><p>0.91</p></td><td><p>Liang et al. (<xref ref-type="bibr" rid="CR147">2019</xref>)</p></td></tr><tr><td rowspan="13"><p>Multspectral (MSI) and Hyperspectral (HSI)</p></td><td><p>Visual</p></td><td><p>Ordinal (3 classes)</p></td><td><p>Low, medium high</p></td><td><p>Classification accuracy (%)</p></td><td><p>71 to 91%, depending on class (a 5-class scale had accuracy = 11 to 40%)</p></td><td><p>Coops et al. (<xref ref-type="bibr" rid="CR60">2003</xref>)</p></td></tr><tr><td><p>Visual</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Percentage results with error ≥ 5%</p></td><td><p>24.1%</p></td><td><p>Larsolle and Muhammed (<xref ref-type="bibr" rid="CR143">2007</xref>)</p></td></tr><tr><td><p>Visual</p></td><td><p>Ordinal (9 classes)</p></td><td><p>0, 1, 10, 20, 30, 45, 60, 80% or 100%</p></td><td><p>Regression, intercept and slope</p></td><td><p><italic>R</italic><sup>2</sup> = 0.91;</p><p>a = 2.40;</p><p>b = − 721.22</p></td><td><p>Huang et al. (<xref ref-type="bibr" rid="CR116">2007</xref>)</p></td></tr><tr><td><p>Visual</p></td><td><p>Ordinal (4 classes)</p></td><td><p>Severe, medium, light, non-visible</p></td><td><p>None given</p></td><td><p>None given</p></td><td><p>Cui et al. (2009, <xref ref-type="bibr" rid="CR61">2010</xref></p></td></tr><tr><td><p>Visual</p></td><td><p>Ordinal (3 classes)</p></td><td><p>Healthy tissue, light mycelium, dense mycelium</p></td><td><p>Classification accuracy (%) including 3 diseases and their severities</p></td><td><p>Healthy tissue = 100%;</p><p>Overall accuracy with disease = 61.70 to 98.90%</p></td><td><p>Mahlein et al. (<xref ref-type="bibr" rid="CR161">2012b</xref>)</p></td></tr><tr><td><p>Symptom progression</p></td><td><p>Changing symptoms related to spectral changes</p></td><td><p>–</p></td><td><p>Metro maps</p></td><td><p>–</p></td><td><p>Wahabzada et al. (<xref ref-type="bibr" rid="CR235">2015</xref>)</p></td></tr><tr><td><p>Symptom progression</p></td><td><p>Changing symptoms related to spectral changes</p></td><td><p>–</p></td><td><p>Leaf traces (similar to above)</p></td><td><p>–</p></td><td><p>Kuska et al. (<xref ref-type="bibr" rid="CR135">2015</xref>)</p></td></tr><tr><td><p>Visual</p></td><td><p>Ordinal (9 classes)</p></td><td><p>0, 1, 5, 10, 20, 40, 60, 80 or 100</p></td><td><p>Regression (<italic>R</italic><sup>2</sup>)</p><p>RMSE</p></td><td><p><italic>R</italic><sup>2</sup> &gt; 0.90;</p><p>RMSE&lt; 0.15</p></td><td><p>Wang et al. (<xref ref-type="bibr" rid="CR239">2016</xref>)</p></td></tr><tr><td><p>Visual (in-field disease incidence of infected wheat spikes)</p></td><td><p>Ratio scale</p><p>0 to 100% (100)</p></td><td><p>100</p></td><td><p>Regression, intercept and slope (depending on VI)</p></td><td><p><italic>R</italic><sup>2</sup> = 0.801, 0.828;</p><p>a = 0.2902, 0.4572;</p><p>b = 0.0013, 0.0020</p></td><td><p>Kobayashi et al. (<xref ref-type="bibr" rid="CR129">2016</xref>)</p></td></tr><tr><td><p>DNA quantification (presymptomatic)</p></td><td><p>Continuous</p></td><td><p>DNA content</p></td><td><p>Regression (<italic>R</italic><sup>2</sup>)</p></td><td><p><italic>R</italic><sup>2</sup> = 0.868</p></td><td><p>Zhao et al. (<xref ref-type="bibr" rid="CR250">2017</xref>)</p></td></tr><tr><td><p>DNA quantification (presymptomatic to symptomatic)</p></td><td><p>Continuous</p></td><td><p>DNA content</p></td><td><p>Regression (<italic>R</italic><sup>2</sup>)</p></td><td><p><italic>R</italic><sup>2</sup> = 0.72</p></td><td><p>Thomas et al. (<xref ref-type="bibr" rid="CR228">2017</xref>)</p></td></tr><tr><td><p>Length of lesion</p></td><td><p>mm</p></td><td><p>mm</p></td><td><p>–</p></td><td><p>Predicted lesion length was proportional to the interior lesion length.</p></td><td><p>Nagasubramanian et al. (<xref ref-type="bibr" rid="CR174">2017</xref>)</p></td></tr><tr><td><p>Visual</p></td><td><p>Ordinal (3 classes)</p></td><td><p>Low (≤5%), moderate (5 to 20%), severe (&gt; 20%) severity.</p></td><td><p>Classification accuracy (%)</p></td><td><p>94.83%</p></td><td><p>Thomas et al. (<xref ref-type="bibr" rid="CR226">2018a</xref>, <xref ref-type="bibr" rid="CR227">b</xref>)</p></td></tr></tbody></table></table-wrap></p></sec><sec id="Sec24"><title>Some needs for future research in visual disease assessment, RGB and HSI image analysis</title><sec><p id="Par90">This section is structured to pose specific questions and issues that need to be addressed through research. It does not intend to be exhaustive, but suggestive of some important avenues for future study.</p></sec><sec id="FPar38"><title>Visual severity estimation</title><p id="Par91">When dealing with multiple raters, some individual or environment-related sources of errors that may affect accuracy remain unknown:
<list list-type="bullet"><list-item><p id="Par92">Do raters’ characteristics such as information processing speed (reflective or impulsive) affect accuracy?</p></list-item><list-item><p id="Par93">Does the environment (heat, cold etc.) affect accuracy of estimates?</p></list-item></list></p><p id="Par94">We need to continue to optimize quantitative ordinal scales and SAD design to ensure that accuracy is maximized:
<list list-type="bullet"><list-item><p id="Par95">Are there ordinal scales applicable for different pathosystems, regardless of severity range?</p></list-item><list-item><p id="Par96">How do we design SADs for diseases with different characteristics (lesion size, shape, colors, etc)?</p></list-item><list-item><p id="Par97">Do the number of diagrams in a SADs affect severity estimates?</p></list-item><list-item><p id="Par98">Is it possible to develop a few generic SADs to cover the range of leaf types and diseases that have to be assessed?</p></list-item><list-item><p id="Par99">Is one SAD representative of a percent sufficient as a reference diagram?</p></list-item><list-item><p id="Par100">How can instruction be performed to maximize accuracy?</p></list-item></list></p><p id="Par101">The role of training in plant disease severity estimation is only partially explored:
<list list-type="bullet"><list-item><p id="Par102">What kind of training is most appropriate?</p></list-item><list-item><p id="Par103">Must it be in the specific pathosystem?</p></list-item><list-item><p id="Par104">Should training use actual photographs of the target disease, computer-generated images, or a combination of both?</p></list-item></list></p></sec><sec id="FPar39"><title>RGB image analysis</title><p id="Par105">Research is needed to determine if classification of severity using VIS image analysis and AI techniques provides the resolution and accuracy needed under field conditions.
<list list-type="bullet"><list-item><p id="Par106">Can this be achieved using the 100% ratio scale?</p></list-item><list-item><p id="Par107">If ordinal type scales are used, how many classes are needed? How will that vary with pathosystem?</p></list-item><list-item><p id="Par108">How can RGB sensor-based systems penetrate the crop canopy where severity estimates of lower leaves might be required?</p></list-item></list></p><p id="Par109">Databases of annotated images are needed for developing reliable and accurate automated systems based on AI:
<list list-type="bullet"><list-item><p id="Par110">Is development of sufficient image databases for the numbers of diseases and crop combinations practical (true for both VIS and HSI/MSI image analysis)?</p></list-item><list-item><p id="Par111">If so, how best to coordinate the logistics of image acquisition?</p></list-item></list></p><p id="Par112">Particularly for training using AI, systems need to be developed that do not need connectivity to a database:
<list list-type="bullet"><list-item><p id="Par113">Can we develop more efficiently packaged mobile applications?</p></list-item></list></p><p id="Par114">Explore further combining RGB with HSI/MSI or other techniques:
<list list-type="bullet"><list-item><p id="Par115">Will this help maximize (and possibly synergize) information for accurate measurement of severity?</p></list-item></list></p></sec><sec id="FPar40"><title>HSI/MSI and image processing</title><p id="Par116">Several of the issues that affect RGB image analysis are common to HSI/MSI too (for example, databases of appropriately ground-truthed images for accurately measuring severity).</p><p id="Par117">Ideally it would be best if hyperspectral signatures were transferrable across scales:
<list list-type="bullet"><list-item><p id="Par118">Can we transfer discriminating hyperspectral signatures to different scales (leaf – plant – field scale) for different diseases?</p></list-item><list-item><p id="Par119">If so, are they effective for measuring severity in the variable field situation?</p></list-item><list-item><p id="Par120">If scalability is indeed practical for most diseases, how to resolve the issue of proximal and distal sensing and resolution and still maintain accuracy of severity measurements (may not be an issue for detection)?</p></list-item></list></p><p id="Par121">A major issue that remains is related to data quality:
<list list-type="bullet"><list-item><p id="Par122">How does ground resolution, shadowing, crop motion and image capture influences accuracy of measurements?</p></list-item><list-item><p id="Par123">What standard is required for disease measurement?</p></list-item><list-item><p id="Par124">Are HSI/MSI measures based on disease development equally or more effective than traditional measures of severity using the percentage scale (metro maps, etc).</p></list-item><list-item><p id="Par125">Can more sophisticated mobile platforms or combinations of 3D sensors provide a method to resolve issues of architecture or hidden sampling units?</p></list-item></list></p><p id="Par126">Intensive knowledge transfer is needed:
<list list-type="bullet"><list-item><p id="Par127">What can we learn from other disciplines such as informatics, medicine, electrical engineering, etc.?</p></list-item></list></p></sec></sec></sec></body><back><ack><title>Acknowledgements</title><p>All authors are indebted to the contributions of Dr. Kuo-Szu Chiang (National Chung Hsing University) in providing invaluable comments and suggestions on earlier versions of this article. His knowledge and expertise on the use of assessment scales for severity estimation is well-recognized, and his input on those sections was particularly insightful.</p><p>AKM and DB would like to thank all group members and former group members of the INRES-Pflanzenkrankheiten, IfZ and partners for contributing to research on hyperspectral imaging for plant diseases measurement.</p><p>The article reports the results of research only. Mention of a trademark or proprietary product is solely for the purpose of providing specific information and does not constitute a guarantee or warranty of the product by the U.S. Department of Agriculture and does not imply its approval to the exclusion of other products that may also be suitable.</p></ack><sec sec-type="author-contribution"><title>Authors’ contributions</title><p>CHB led and coordinated the writing of the review, with emphasis on the section on visual disease assessment. EMD provided input on various sections including on SADs and visual disease assessment. JGAB led the section on VIS image analysis, and AKM led the section on HSI/MSI with input from DB. All authors coordinated writing of the introduction and conclusion sections. The author(s) read and approved the final manuscript.</p></sec><sec><title>Funding</title><p>CHB is funded by the USDA-ARS project 6606–21220-013–00D. EMD is funded by CAPES-PROEX and a CNPq Research Fellowship. JGAB is funded by Embrapa under grant 02.14.09.001.00.00. AKM and DB are partially funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany’s Excellence Strategy - EXC 2070–390732324, project PhenoRob. DB is also funded by BASF Digital Farming.</p></sec><sec sec-type="data-availability"><title>Availability of data and materials</title><p>Not applicable.</p></sec><sec sec-type="ethics-statement"><sec id="FPar41"><title>Ethics approval and consent to participate</title><p id="Par128">Not applicable (no human/animal subjects).</p></sec><sec id="FPar42"><title>Consent for publication</title><p id="Par129">Not applicable.</p></sec><sec id="FPar43" sec-type="COI-statement"><title>Competing interests</title><p id="Par130">The authors declare that they have no competing interests.</p></sec></sec><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abramoff</surname><given-names>MD</given-names></name><name><surname>Magalhães</surname><given-names>PJ</given-names></name><name><surname>Ram</surname><given-names>SJ</given-names></name></person-group><article-title xml:lang="en">Image processing with ImageJ</article-title><source>Biophoton Int.</source><year>2004</year><volume>11</volume><fpage>36</fpage><lpage>42</lpage></mixed-citation></ref><ref id="CR2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alisaac</surname><given-names>E</given-names></name><name><surname>Behmann</surname><given-names>J</given-names></name><name><surname>Kuska</surname><given-names>MT</given-names></name><name><surname>Dehne</surname><given-names>H</given-names></name><name><surname>Mahlein</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Hyperspectral quantification of wheat resistance to Fusarium head blight: comparison of two <italic>Fusarium</italic> species</article-title><source>Eur J Plant Pathol.</source><year>2018</year><volume>152</volume><fpage>869</fpage><lpage>884</lpage><pub-id pub-id-type="doi">10.1007/s10658-018-1505-9</pub-id></mixed-citation></ref><ref id="CR3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alisaac</surname><given-names>E</given-names></name><name><surname>Behmann</surname><given-names>J</given-names></name><name><surname>Rathgeb</surname><given-names>A</given-names></name><name><surname>Karlovsky</surname><given-names>P</given-names></name><name><surname>Dehne</surname><given-names>HW</given-names></name><name><surname>Mahlein</surname><given-names>AK</given-names></name></person-group><article-title xml:lang="en">Assessment of <italic>Fusarium</italic> infection and mycotoxin contamination of wheat kernels and flour using hyperspectral imaging</article-title><source>Toxins.</source><year>2019</year><volume>11</volume><issue>10</issue><fpage>556</fpage><pub-id pub-id-type="pmcid">6832122</pub-id><pub-id pub-id-type="doi">10.3390/toxins11100556</pub-id></mixed-citation></ref><ref id="CR4"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Altman</surname><given-names>DG</given-names></name></person-group><source>Practical statistics for medical research</source><year>1991</year><publisher-loc>London</publisher-loc><publisher-name>Chapman and Hall</publisher-name></mixed-citation></ref><ref id="CR5"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Amara</surname><given-names>J</given-names></name><name><surname>Bouaziz</surname><given-names>B</given-names></name><name><surname>Algergawy</surname><given-names>A</given-names></name></person-group><source>A deep learning-based approach for banana leaf diseases classification</source><year>2017</year><publisher-loc>Stuttgart</publisher-loc><publisher-name>BTW workshop</publisher-name><fpage>79</fpage><lpage>88</lpage></mixed-citation></ref><ref id="CR6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anon</surname></name></person-group><article-title xml:lang="en">The measurement of potato blight</article-title><source>Trans Br Mycol Soc</source><year>1947</year><volume>31</volume><fpage>140</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1016/S0007-1536(47)80017-8</pub-id></mixed-citation></ref><ref id="CR7"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Anon</surname></name></person-group><source>Instruction to authors</source><year>2020</year><publisher-loc>St Paul</publisher-loc><publisher-name>American Phytopathology Society</publisher-name><comment>https://apsjournals.apsnet.org/page/authorinformation#preparing</comment></mixed-citation></ref><ref id="CR8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Apan</surname><given-names>A</given-names></name><name><surname>Held</surname><given-names>A</given-names></name><name><surname>Phinn</surname><given-names>S</given-names></name><name><surname>Markley</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Detecting sugarcane ‘orange rust’ disease using EO-1 Hyperion hyperspectral imagery</article-title><source>Int J Remote Sens.</source><year>2004</year><volume>25</volume><fpage>489</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1080/01431160310001618031</pub-id></mixed-citation></ref><ref id="CR9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arens</surname><given-names>N</given-names></name><name><surname>Backhaus</surname><given-names>A</given-names></name><name><surname>Döll</surname><given-names>S</given-names></name><name><surname>Fischer</surname><given-names>S</given-names></name><name><surname>Seiffert</surname><given-names>U</given-names></name><name><surname>Mock</surname><given-names>H-P</given-names></name></person-group><article-title xml:lang="en">Non-invasive presymptomatic detection of <italic>Cercospora beticola</italic> infection and identification of early metabolic responses in sugar beet</article-title><source>Front Plant Sci.</source><year>2016</year><volume>7</volume><fpage>1377</fpage><pub-id pub-id-type="pmid">27713750</pub-id><pub-id pub-id-type="pmcid">5031787</pub-id><pub-id pub-id-type="doi">10.3389/fpls.2016.01377</pub-id></mixed-citation></ref><ref id="CR10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashourloo</surname><given-names>D</given-names></name><name><surname>Mobasheri</surname><given-names>MR</given-names></name><name><surname>Huete</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Developing two spectral disease indices for detection of wheat leaf rust (<italic>Puccinia triticina</italic>)</article-title><source>Remote Sens.</source><year>2014</year><volume>6</volume><fpage>4723</fpage><lpage>4740</lpage><pub-id pub-id-type="doi">10.3390/rs6064723</pub-id></mixed-citation></ref><ref id="CR11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bade</surname><given-names>CIA</given-names></name><name><surname>Carmona</surname><given-names>MA</given-names></name></person-group><article-title xml:lang="en">Comparison of methods to assess severity of common rust caused by <italic>Puccinia sorghi</italic> in maize</article-title><source>Trop Plant Pathol.</source><year>2011</year><volume>36</volume><fpage>264</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1590/S1982-56762011000400009</pub-id></mixed-citation></ref><ref id="CR12"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Baird</surname><given-names>JC</given-names></name><name><surname>Norma</surname><given-names>E</given-names></name></person-group><source>Fundamentals of scaling and psychophysics</source><year>1978</year><publisher-loc>New York</publisher-loc><publisher-name>Wiley</publisher-name></mixed-citation></ref><ref id="CR13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bakr</surname><given-names>EM</given-names></name></person-group><article-title xml:lang="en">A new software for measuring leaf area, and area damaged by <italic>Tetranychus urticae</italic> Koch</article-title><source>J Appl Entomol.</source><year>2005</year><volume>129</volume><fpage>173</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1111/j.1439-0418.2005.00948.x</pub-id></mixed-citation></ref><ref id="CR14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banerjee</surname><given-names>BP</given-names></name><name><surname>Raval</surname><given-names>S</given-names></name><name><surname>Cullen</surname><given-names>PJ</given-names></name></person-group><article-title xml:lang="en">UAV-hyperspectral imaging of spectrally complex environments</article-title><source>Int J Remote Sens.</source><year>2020</year><volume>41</volume><fpage>4136</fpage><lpage>4159</lpage><pub-id pub-id-type="doi">10.1080/01431161.2020.1714771</pub-id></mixed-citation></ref><ref id="CR15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbedo</surname><given-names>JGA</given-names></name></person-group><article-title xml:lang="en">Digital image processing techniques for detecting, quantifying and classifying plant diseases</article-title><source>SpringerPlus.</source><year>2013</year><volume>2</volume><fpage>660</fpage><pub-id pub-id-type="doi">10.1186/2193-1801-2-660</pub-id></mixed-citation></ref><ref id="CR16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbedo</surname><given-names>JGA</given-names></name></person-group><article-title xml:lang="en">An automatic method to detect and measure leaf disease symptoms using digital image processing</article-title><source>Plant Dis.</source><year>2014</year><volume>98</volume><fpage>1709</fpage><lpage>1716</lpage><pub-id pub-id-type="pmid">30703885</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-03-14-0290-RE</pub-id></mixed-citation></ref><ref id="CR17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbedo</surname><given-names>JGA</given-names></name></person-group><article-title xml:lang="en">A novel algorithm for semi-automatic segmentation of plant leaf disease symptoms using digital image processing</article-title><source>Trop Plant Pathol.</source><year>2016</year><volume>41</volume><fpage>210</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1007/s40858-016-0090-8</pub-id></mixed-citation></ref><ref id="CR18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbedo</surname><given-names>JGA</given-names></name></person-group><article-title xml:lang="en">A review on the main challenges in automatic plant disease identification based on visible range images</article-title><source>Biosyst Eng.</source><year>2016</year><volume>144</volume><fpage>52</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1016/j.biosystemseng.2016.01.017</pub-id></mixed-citation></ref><ref id="CR19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbedo</surname><given-names>JGA</given-names></name></person-group><article-title xml:lang="en">A new automatic method for disease symptom segmentation in digital photographs of plant leaves</article-title><source>Eur J Plant Pathol.</source><year>2017</year><volume>147</volume><fpage>349</fpage><lpage>364</lpage><pub-id pub-id-type="doi">10.1007/s10658-016-1007-6</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28Xht1KrsLbL</pub-id></mixed-citation></ref><ref id="CR20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbedo</surname><given-names>JGA</given-names></name></person-group><article-title xml:lang="en">Plant disease identification from individual lesions and spots using deep learning</article-title><source>Biosyst Eng.</source><year>2019</year><volume>180</volume><fpage>96</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1016/j.biosystemseng.2019.02.002</pub-id></mixed-citation></ref><ref id="CR21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barbedo</surname><given-names>JGA</given-names></name><name><surname>Koenigkan</surname><given-names>LV</given-names></name><name><surname>Halfeld-Vieira</surname><given-names>BA</given-names></name><name><surname>Costa</surname><given-names>RV</given-names></name><name><surname>Nechet</surname><given-names>KL</given-names></name><name><surname>Godoy</surname><given-names>CV</given-names></name><etal/></person-group><article-title xml:lang="en">Annotated plant pathology databases for image-based detection and recognition of diseases</article-title><source>IEEE Lat Am Trans.</source><year>2018</year><volume>16</volume><fpage>1749</fpage><lpage>1757</lpage><pub-id pub-id-type="doi">10.1109/TLA.2018.8444395</pub-id></mixed-citation></ref><ref id="CR22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bardsley</surname><given-names>SJ</given-names></name><name><surname>Ngugi</surname><given-names>HK</given-names></name></person-group><article-title xml:lang="en">Reliability and accuracy of visual methods to quantify severity of foliar bacterial spot symptoms on peach and nectarine</article-title><source>Plant Pathol.</source><year>2013</year><volume>62</volume><fpage>460</fpage><lpage>474</lpage><pub-id pub-id-type="doi">10.1111/j.1365-3059.2012.02651.x</pub-id></mixed-citation></ref><ref id="CR23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behmann</surname><given-names>J</given-names></name><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Paulus</surname><given-names>S</given-names></name><name><surname>Kuhlmann</surname><given-names>H</given-names></name><name><surname>Oerke</surname><given-names>E-C</given-names></name><name><surname>Plümer</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Calibration of hyperspectral close-range pushbroom cameras for plant phenotyping</article-title><source>ISPRS J Photogramm Remote Sens.</source><year>2015</year><volume>106</volume><fpage>172</fpage><lpage>182</lpage><pub-id pub-id-type="doi">10.1016/j.isprsjprs.2015.05.010</pub-id></mixed-citation></ref><ref id="CR24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behmann</surname><given-names>J</given-names></name><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Rumpf</surname><given-names>T</given-names></name><name><surname>Römer</surname><given-names>C</given-names></name><name><surname>Plümer</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">A review of advanced machine learning methods for the detection of biotic stress in precision crop protection</article-title><source>Precis Agric.</source><year>2015</year><volume>16</volume><fpage>239</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1007/s11119-014-9372-7</pub-id></mixed-citation></ref><ref id="CR25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berdugo</surname><given-names>CA</given-names></name><name><surname>Zito</surname><given-names>R</given-names></name><name><surname>Paulus</surname><given-names>S</given-names></name><name><surname>Mahlein</surname><given-names>AK</given-names></name></person-group><article-title xml:lang="en">Fusion of sensor data for the detection and differentiation of plant diseases in cucumber</article-title><source>Plant Pathol.</source><year>2014</year><volume>63</volume><fpage>1344</fpage><lpage>1356</lpage><pub-id pub-id-type="doi">10.1111/ppa.12219</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2cXhvFShs73M</pub-id></mixed-citation></ref><ref id="CR26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berner</surname><given-names>DK</given-names></name><name><surname>Paxson</surname><given-names>LX</given-names></name></person-group><article-title xml:lang="en">Use of digital images to differentiate reactions of collections of yellow star thistle (<italic>Centaurea solstitialis</italic>) to infection by <italic>Puccinia jaceae</italic></article-title><source>Biol Control.</source><year>2003</year><volume>28</volume><fpage>171</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/S1049-9644(03)00096-3</pub-id></mixed-citation></ref><ref id="CR27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blackburn</surname><given-names>GA</given-names></name></person-group><article-title xml:lang="en">Hyperspectral remote sensing of plant pigments</article-title><source>J Exp Bot.</source><year>2007</year><volume>58</volume><fpage>855</fpage><lpage>867</lpage><pub-id pub-id-type="pmid">16990372</pub-id><pub-id pub-id-type="doi">10.1093/jxb/erl123</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD2sXislCrtrc%3D</pub-id></mixed-citation></ref><ref id="CR28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Chiang</surname><given-names>K-S</given-names></name></person-group><article-title xml:lang="en">Disease incidence–severity relationships on leaflets, leaves, and fruit in the pecan–<italic>Venturia effusa</italic> pathosystem</article-title><source>Plant Dis.</source><year>2019</year><volume>103</volume><fpage>2865</fpage><lpage>2876</lpage><pub-id pub-id-type="pmid">31469360</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-11-18-1950-RE</pub-id></mixed-citation></ref><ref id="CR29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Chiang</surname><given-names>KS</given-names></name><name><surname>del Ponte</surname><given-names>EM</given-names></name></person-group><article-title xml:lang="en">Accuracy of plant specimen disease severity estimates: concepts, history, methods, ramifications and challenges for the future</article-title><source>CAB Rev.</source><year>2016</year><volume>11</volume><fpage>1</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1079/PAVSNNR201611032</pub-id><comment>https://doi.org/10.1079/PAVSNNR201611032</comment></mixed-citation></ref><ref id="CR30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Cook</surname><given-names>AZ</given-names></name><name><surname>Parker</surname><given-names>PE</given-names></name><name><surname>Gottwald</surname><given-names>TR</given-names></name></person-group><article-title xml:lang="en">Automated image analysis of the severity of foliar citrus canker symptoms</article-title><source>Plant Dis.</source><year>2009</year><volume>93</volume><fpage>660</fpage><lpage>665</lpage><pub-id pub-id-type="pmid">30764402</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-93-6-0660</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BB3cfjsV2gsA%3D%3D</pub-id></mixed-citation></ref><ref id="CR31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Gottwald</surname><given-names>TR</given-names></name><name><surname>Parker</surname><given-names>PE</given-names></name><name><surname>Cook</surname><given-names>AZ</given-names></name><name><surname>Ferrandino</surname><given-names>F</given-names></name><name><surname>Parnell</surname><given-names>S</given-names></name><etal/></person-group><article-title xml:lang="en">The Horsfall-Barratt scale and severity estimates of citrus canker</article-title><source>Eur J Plant Pathol.</source><year>2009</year><volume>125</volume><fpage>23</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1007/s10658-009-9455-x</pub-id></mixed-citation></ref><ref id="CR32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Gottwald</surname><given-names>TR</given-names></name><name><surname>Parker</surname><given-names>PE</given-names></name><name><surname>Ferrandino</surname><given-names>F</given-names></name><name><surname>Welham</surname><given-names>S</given-names></name><name><surname>van den Bosch</surname><given-names>F</given-names></name><etal/></person-group><article-title xml:lang="en">Some consequences of using the Horsfall-Barratt scale for hypothesis testing</article-title><source>Phytopathology.</source><year>2010</year><volume>100</volume><fpage>1030</fpage><lpage>1041</lpage><pub-id pub-id-type="pmid">20839938</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-08-09-0220</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BC3cfisFCgtA%3D%3D</pub-id></mixed-citation></ref><ref id="CR33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Hotchkiss</surname><given-names>MW</given-names></name><name><surname>Wood</surname><given-names>BW</given-names></name></person-group><article-title xml:lang="en">Assessing disease severity: accuracy and reliability of rater estimates in relation to number of diagrams in a standard area diagram set</article-title><source>Plant Pathol.</source><year>2016</year><volume>65</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1111/ppa.12403</pub-id></mixed-citation></ref><ref id="CR34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Nutter</surname><given-names>FW</given-names><suffix>Jr</suffix></name></person-group><article-title xml:lang="en">Detection and measurement of plant disease symptoms using visible-wavelength photography and image analysis</article-title><source>CAB Rev.</source><year>2011</year><volume>6</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1079/PAVSNNR20116027</pub-id><comment>https://doi.org/10.1079/PAVSNNR20116027</comment></mixed-citation></ref><ref id="CR35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Parker</surname><given-names>PE</given-names></name><name><surname>Cook</surname><given-names>AZ</given-names></name><name><surname>Gottwald</surname><given-names>TR</given-names></name></person-group><article-title xml:lang="en">Characteristics of the perception of different severity measures of citrus canker and the relationships between the various symptom types</article-title><source>Plant Dis.</source><year>2008</year><volume>92</volume><fpage>927</fpage><lpage>939</lpage><pub-id pub-id-type="pmid">30769723</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-92-6-0927</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BB3cfktVagug%3D%3D</pub-id></mixed-citation></ref><ref id="CR36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Parker</surname><given-names>PE</given-names></name><name><surname>Cook</surname><given-names>AZ</given-names></name><name><surname>Gottwald</surname><given-names>TR</given-names></name></person-group><article-title xml:lang="en">Visual rating and the use of image analysis for assessing different symptoms of citrus canker on grapefruit leaves</article-title><source>Plant Dis.</source><year>2008</year><volume>92</volume><fpage>530</fpage><lpage>541</lpage><pub-id pub-id-type="pmid">30769647</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-92-4-0530</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BB3cfktVWlsA%3D%3D</pub-id></mixed-citation></ref><ref id="CR37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Parker</surname><given-names>PE</given-names></name><name><surname>Cook</surname><given-names>AZ</given-names></name><name><surname>Gottwald</surname><given-names>TR</given-names></name></person-group><article-title xml:lang="en">Comparison of assessment of citrus canker foliar symptoms by experienced and inexperienced raters</article-title><source>Plant Dis.</source><year>2009</year><volume>93</volume><fpage>412</fpage><lpage>424</lpage><pub-id pub-id-type="pmid">30764221</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-93-4-0412</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BB3cfjsVOmsw%3D%3D</pub-id></mixed-citation></ref><ref id="CR38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Poole</surname><given-names>GH</given-names></name><name><surname>Parker</surname><given-names>PE</given-names></name><name><surname>Gottwald</surname><given-names>TR</given-names></name></person-group><article-title xml:lang="en">Plant disease severity estimated visually, by digital photography and image analysis, and by hyperspectral imaging</article-title><source>Crit Rev Plant Sci.</source><year>2010</year><volume>29</volume><fpage>59</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1080/07352681003617285</pub-id></mixed-citation></ref><ref id="CR39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohnenkamp</surname><given-names>D</given-names></name><name><surname>Behmann</surname><given-names>J</given-names></name><name><surname>Mahlein</surname><given-names>A-K</given-names></name></person-group><article-title xml:lang="en">In-field detection of yellow rust in wheat on the ground canopy and UAV scale</article-title><source>Remote Sens.</source><year>2019</year><volume>11</volume><fpage>2495</fpage><pub-id pub-id-type="doi">10.3390/rs11212495</pub-id></mixed-citation></ref><ref id="CR40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braido</surname><given-names>R</given-names></name><name><surname>Goncalves-Zuliani</surname><given-names>AMO</given-names></name><name><surname>Janeiro</surname><given-names>V</given-names></name><name><surname>Carvalho</surname><given-names>SA</given-names></name><name><surname>Junior</surname><given-names>JB</given-names></name><name><surname>Bock</surname><given-names>CH</given-names></name><etal/></person-group><article-title xml:lang="en">Development and validation of standard area diagrams as assessment aids for estimating the severity of citrus canker on unripe oranges</article-title><source>Plant Dis.</source><year>2014</year><volume>98</volume><fpage>1543</fpage><lpage>1550</lpage><pub-id pub-id-type="pmid">30699788</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-01-14-0090-RE</pub-id></mixed-citation></ref><ref id="CR41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bravo</surname><given-names>C</given-names></name><name><surname>Moshou</surname><given-names>D</given-names></name><name><surname>West</surname><given-names>J</given-names></name><name><surname>McCartney</surname><given-names>A</given-names></name><name><surname>Ramon</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Early disease detection in wheat fields using spectral reflectance</article-title><source>Biosyst Eng.</source><year>2003</year><volume>84</volume><fpage>137</fpage><lpage>145</lpage><pub-id pub-id-type="doi">10.1016/S1537-5110(02)00269-6</pub-id></mixed-citation></ref><ref id="CR42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brugger</surname><given-names>A</given-names></name><name><surname>Behmann</surname><given-names>J</given-names></name><name><surname>Paulus</surname><given-names>S</given-names></name><name><surname>Luigs</surname><given-names>H-G</given-names></name><name><surname>Kuska</surname><given-names>MT</given-names></name><name><surname>Schramowski</surname><given-names>P</given-names></name><etal/></person-group><article-title xml:lang="en">Extending hyperspectral imaging for plant phenotyping to the UV-range</article-title><source>Remote Sens.</source><year>2019</year><volume>11</volume><fpage>1401</fpage><pub-id pub-id-type="doi">10.3390/rs11121401</pub-id></mixed-citation></ref><ref id="CR43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Camargo</surname><given-names>A</given-names></name><name><surname>Smith</surname><given-names>JS</given-names></name></person-group><article-title xml:lang="en">An image-processing based algorithm to automatically identify plant disease visual symptoms</article-title><source>Biosyst Eng.</source><year>2009</year><volume>102</volume><fpage>9</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.biosystemseng.2008.09.030</pub-id></mixed-citation></ref><ref id="CR44"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Campbell</surname><given-names>CL</given-names></name><name><surname>Madden</surname><given-names>LV</given-names></name></person-group><source>Introduction to plant disease epidemiology</source><year>1990</year><publisher-loc>New York</publisher-loc><publisher-name>Wiley</publisher-name></mixed-citation></ref><ref id="CR45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carter</surname><given-names>GA</given-names></name><name><surname>Knapp</surname><given-names>AK</given-names></name></person-group><article-title xml:lang="en">Leaf optical properties in higher plants: linking spectral characteristics to stress and chlorophyll concentration</article-title><source>Amer J Bot.</source><year>2001</year><volume>88</volume><issue>4</issue><fpage>677</fpage><lpage>684</lpage><pub-id pub-id-type="doi">10.2307/2657068</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD3MXjsVWgs7Y%3D</pub-id></mixed-citation></ref><ref id="CR46"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chaube</surname><given-names>HS</given-names></name><name><surname>Singh</surname><given-names>US</given-names></name></person-group><source>Plant disease management: principles and practices</source><year>1991</year><publisher-loc>Boca Raton</publisher-loc><publisher-name>CRC Press</publisher-name></mixed-citation></ref><ref id="CR47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>F</given-names></name><name><surname>Lou</surname><given-names>S</given-names></name><name><surname>Fan</surname><given-names>Q</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Claverie</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><etal/></person-group><article-title xml:lang="en">Normalized difference vegetation index continuity of the Landsat 4-5 MSS and TM: investigations based on simulation</article-title><source>Remote Sens.</source><year>2019</year><volume>11</volume><fpage>1681</fpage><pub-id pub-id-type="doi">10.3390/rs11141681</pub-id></mixed-citation></ref><ref id="CR48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chester</surname><given-names>KS</given-names></name></person-group><article-title xml:lang="en">Plant disease losses: their appraisal and interpretation</article-title><source>Plant Dis Rep.</source><year>1950</year><volume>193</volume><issue>Suppl</issue><fpage>190</fpage><lpage>362</lpage></mixed-citation></ref><ref id="CR49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiang</surname><given-names>K-S</given-names></name><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>El Jarroudi</surname><given-names>M</given-names></name><name><surname>Delfosse</surname><given-names>P</given-names></name><name><surname>Lee</surname><given-names>IH</given-names></name><name><surname>Liu</surname><given-names>HI</given-names></name></person-group><article-title xml:lang="en">Effects of rater bias and assessment method on disease severity estimation with regard to hypothesis testing</article-title><source>Plant Pathol.</source><year>2016</year><volume>65</volume><fpage>523</fpage><lpage>535</lpage><pub-id pub-id-type="doi">10.1111/ppa.12435</pub-id></mixed-citation></ref><ref id="CR50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiang</surname><given-names>K-S</given-names></name><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Lee</surname><given-names>IH</given-names></name><name><surname>El Jarroudi</surname><given-names>M</given-names></name><name><surname>Delfosse</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Plant disease severity assessment - how rater bias, assessment method and experimental design affect hypothesis testing and resource use efficiency</article-title><source>Phytopathology.</source><year>2016</year><volume>106</volume><fpage>1451</fpage><lpage>1464</lpage><pub-id pub-id-type="pmid">27532427</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-12-15-0315-R</pub-id></mixed-citation></ref><ref id="CR51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiang</surname><given-names>K-S</given-names></name><name><surname>Liu</surname><given-names>HI</given-names></name><name><surname>Bock</surname><given-names>CH</given-names></name></person-group><article-title xml:lang="en">A discussion on disease severity index values. Part I: warning on inherent errors and suggestions to maximize accuracy</article-title><source>Ann Appl Biol.</source><year>2017</year><volume>171</volume><fpage>139</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1111/aab.12362</pub-id></mixed-citation></ref><ref id="CR52"><mixed-citation publication-type="other">Chiang K-S, Liu HI, Chen YL, El Jarroudi M, Bock CH. Quantitative ordinal scale estimates of plant disease severity: comparing treatments using a proportional odds model. Phytopathology. 2019; <ext-link xlink:href="10.1094/PHYTO-10-18-0372-R" ext-link-type="doi">https://doi.org/10.1094/PHYTO-10-18-0372-R</ext-link>.</mixed-citation></ref><ref id="CR53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiang</surname><given-names>K-S</given-names></name><name><surname>Liu</surname><given-names>HI</given-names></name><name><surname>Tsai</surname><given-names>JW</given-names></name><name><surname>Tsai</surname><given-names>JR</given-names></name><name><surname>Bock</surname><given-names>CH</given-names></name></person-group><article-title xml:lang="en">A discussion on disease severity index values. Part II: using the disease severity index for null hypothesis testing</article-title><source>Ann Appl Biol.</source><year>2017</year><volume>171</volume><fpage>490</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1111/aab.12396</pub-id></mixed-citation></ref><ref id="CR54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiang</surname><given-names>K-S</given-names></name><name><surname>Liu</surname><given-names>SC</given-names></name><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Gottwald</surname><given-names>TR</given-names></name></person-group><article-title xml:lang="en">What interval characteristics make a good categorical disease assessment scale?</article-title><source>Phytopathology.</source><year>2014</year><volume>104</volume><fpage>575</fpage><lpage>585</lpage><pub-id pub-id-type="pmid">24450461</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-10-13-0279-R</pub-id></mixed-citation></ref><ref id="CR55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christ</surname><given-names>BJ</given-names></name></person-group><article-title xml:lang="en">Effect of disease assessment method on ranking potato cultivars for resistance to early blight</article-title><source>Plant Dis.</source><year>1991</year><volume>75</volume><fpage>353</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1094/PD-75-0353</pub-id></mixed-citation></ref><ref id="CR56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clément</surname><given-names>A</given-names></name><name><surname>Verfaille</surname><given-names>T</given-names></name><name><surname>Lormel</surname><given-names>C</given-names></name><name><surname>Jaloux</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">A new colour vision system to quantify automatically foliar discoloration caused by insect pests feeding on leaf cells</article-title><source>Biosyst Eng.</source><year>2015</year><volume>133</volume><fpage>128</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/j.biosystemseng.2015.03.007</pub-id></mixed-citation></ref><ref id="CR57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cobb</surname><given-names>NA</given-names></name></person-group><article-title xml:lang="en">Contribution to an economic knowledge of the Australian rusts (Uredinae)</article-title><source>Agric Gaz NSW.</source><year>1892</year><volume>3</volume><fpage>60</fpage></mixed-citation></ref><ref id="CR58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Contreras-Medina</surname><given-names>LM</given-names></name><name><surname>Osornio-Rios</surname><given-names>RA</given-names></name><name><surname>Torres-Pacheco</surname><given-names>I</given-names></name><name><surname>Romero-Troncoso</surname><given-names>RJ</given-names></name><name><surname>Guevara-González</surname><given-names>RG</given-names></name><name><surname>Millan-Almaraz</surname><given-names>JR</given-names></name></person-group><article-title xml:lang="en">Smart sensor for real-time quantification of common symptoms present in unhealthy plants</article-title><source>Sensors.</source><year>2012</year><volume>12</volume><fpage>784</fpage><lpage>805</lpage><pub-id pub-id-type="pmid">22368496</pub-id><pub-id pub-id-type="doi">10.3390/s120100784</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XhslKgurc%3D</pub-id></mixed-citation></ref><ref id="CR59"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cooke</surname><given-names>BM</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Cooke</surname><given-names>BM</given-names></name><name><surname>Jones</surname><given-names>DG</given-names></name><name><surname>Kaye</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Disease assessment and yield loss</article-title><source>The epidemiology of plant diseases</source><year>2006</year><edition>2</edition><publisher-loc>The Netherlands</publisher-loc><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/1-4020-4581-6</pub-id></mixed-citation></ref><ref id="CR60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coops</surname><given-names>N</given-names></name><name><surname>Stanford</surname><given-names>M</given-names></name><name><surname>Old</surname><given-names>K</given-names></name><name><surname>Dudzinski</surname><given-names>M</given-names></name><name><surname>Culvenor</surname><given-names>D</given-names></name><name><surname>Stone</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Assessment of <italic>Dothistroma</italic> needle blight of <italic>Pinus radiata</italic> using airborne hyperspectral imagery</article-title><source>Phytopathology.</source><year>2003</year><volume>93</volume><fpage>1524</fpage><lpage>1532</lpage><pub-id pub-id-type="pmid">18943616</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO.2003.93.12.1524</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BD1cjkt1GqsQ%3D%3D</pub-id></mixed-citation></ref><ref id="CR61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cui</surname><given-names>D</given-names></name><name><surname>Zhang</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Hartman</surname><given-names>GL</given-names></name><name><surname>Zhao</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Image processing methods for quantitatively detecting soybean rust from multispectral images</article-title><source>Biosyst Eng.</source><year>2010</year><volume>107</volume><fpage>186</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1016/j.biosystemseng.2010.06.004</pub-id></mixed-citation></ref><ref id="CR62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Curran</surname><given-names>PJ</given-names></name></person-group><article-title xml:lang="en">Remote sensing of foliar chemistry</article-title><source>Remote Sens Environ.</source><year>1989</year><volume>30</volume><fpage>271</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1016/0034-4257(89)90069-2</pub-id></mixed-citation></ref><ref id="CR63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Castro</surname><given-names>AI</given-names></name><name><surname>Ehsani</surname><given-names>R</given-names></name><name><surname>Ploetz</surname><given-names>RC</given-names></name><name><surname>Crane</surname><given-names>JH</given-names></name><name><surname>Buchanon</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Detection of laurel wilt disease in avocado using low altitude aerial imaging</article-title><source>PLoS One.</source><year>2015</year><volume>10</volume><fpage>e0124642</fpage><pub-id pub-id-type="pmid">25927209</pub-id><pub-id pub-id-type="pmcid">4415916</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0124642</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXhslCrs7vI</pub-id></mixed-citation></ref><ref id="CR64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Coninck</surname><given-names>BMA</given-names></name><name><surname>Amand</surname><given-names>O</given-names></name><name><surname>Delauré</surname><given-names>SL</given-names></name><name><surname>Lucas</surname><given-names>S</given-names></name><name><surname>Hias</surname><given-names>N</given-names></name><name><surname>Weyens</surname><given-names>G</given-names></name><etal/></person-group><article-title xml:lang="en">The use of digital image analysis and real-time PCR fine-tunes bioassays for quantification of Cercospora leaf spot disease in sugar beet breeding</article-title><source>Plant Pathol.</source><year>2012</year><volume>61</volume><fpage>76</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1111/j.1365-3059.2011.02497.x</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XislyjtbY%3D</pub-id></mixed-citation></ref><ref id="CR65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Debona</surname><given-names>D</given-names></name><name><surname>Nascimento</surname><given-names>KJT</given-names></name><name><surname>Rezende</surname><given-names>D</given-names></name><name><surname>Rios</surname><given-names>JA</given-names></name><name><surname>Bernardeli</surname><given-names>AMA</given-names></name><name><surname>Silva</surname><given-names>LC</given-names></name><etal/></person-group><article-title xml:lang="en">A set of standard area diagrams to assess severity of frogeye leaf spot on soybean</article-title><source>Eur J Plant Pathol.</source><year>2015</year><volume>142</volume><fpage>603</fpage><lpage>614</lpage><pub-id pub-id-type="doi">10.1007/s10658-015-0638-3</pub-id></mixed-citation></ref><ref id="CR66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Del Ponte</surname><given-names>EM</given-names></name><name><surname>Nelson</surname><given-names>SC</given-names></name><name><surname>Pethybridge</surname><given-names>SJ</given-names></name></person-group><article-title xml:lang="en">Evaluation of app-embedded disease scales for aiding visual severity estimation of Cercospora leaf spot of table beet</article-title><source>Plant Dis.</source><year>2019</year><volume>103</volume><fpage>1347</fpage><lpage>1356</lpage><pub-id pub-id-type="pmid">30983523</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-10-18-1718-RE</pub-id></mixed-citation></ref><ref id="CR67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Del Ponte</surname><given-names>EM</given-names></name><name><surname>Pethybridge</surname><given-names>SJ</given-names></name><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Michereff</surname><given-names>SJ</given-names></name><name><surname>Machado</surname><given-names>FJ</given-names></name><name><surname>Spolti</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Standard area diagrams for aiding severity estimation: scientometrics, pathosystems, and methodological trends in the last 25 years</article-title><source>Phytopathology.</source><year>2017</year><volume>107</volume><fpage>1161</fpage><lpage>1174</lpage><pub-id pub-id-type="pmid">28504619</pub-id></mixed-citation></ref><ref id="CR68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delalieux</surname><given-names>S</given-names></name><name><surname>Auwerkerken</surname><given-names>A</given-names></name><name><surname>Verstraeten</surname><given-names>W</given-names></name><name><surname>Somers</surname><given-names>B</given-names></name><name><surname>Valcke</surname><given-names>R</given-names></name><name><surname>Lhermitte</surname><given-names>S</given-names></name><etal/></person-group><article-title xml:lang="en">Hyperspectral reflectance and fluorescence imaging to detect scab induced stress in apple leaves</article-title><source>Remote Sens.</source><year>2009</year><volume>1</volume><fpage>858</fpage><lpage>874</lpage><pub-id pub-id-type="doi">10.3390/rs1040858</pub-id></mixed-citation></ref><ref id="CR69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delalieux</surname><given-names>S</given-names></name><name><surname>Somers</surname><given-names>B</given-names></name><name><surname>Verstraeten</surname><given-names>WW</given-names></name><name><surname>van Aardt</surname><given-names>JAN</given-names></name><name><surname>Keulemans</surname><given-names>W</given-names></name><name><surname>Coppin</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Hyperspectral indices to diagnose leaf biotic stress of apple plants, considering leaf phenology</article-title><source>Int J Remote Sens.</source><year>2009</year><volume>30</volume><fpage>1887</fpage><lpage>1912</lpage><pub-id pub-id-type="doi">10.1080/01431160802541556</pub-id></mixed-citation></ref><ref id="CR70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delalieux</surname><given-names>S</given-names></name><name><surname>van Aardt</surname><given-names>J</given-names></name><name><surname>Keulemans</surname><given-names>W</given-names></name><name><surname>Schrevens</surname><given-names>E</given-names></name><name><surname>Coppin</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Detection of biotic stress (Venturia inaequalis) in apple trees using hyperspectral data: Non-parametric statistical approaches and physiological implications</article-title><source>Eur J Agronomy</source><year>2007</year><volume>27</volume><fpage>130</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1016/j.eja.2007.02.005</pub-id></mixed-citation></ref><ref id="CR71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devadas</surname><given-names>R</given-names></name><name><surname>Lamb</surname><given-names>DW</given-names></name><name><surname>Simpfendorfer</surname><given-names>S</given-names></name><name><surname>Backhouse</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Evaluating ten spectral vegetation indices for identifying rust infection in individual wheat leaves</article-title><source>Precis Agric.</source><year>2009</year><volume>10</volume><fpage>459</fpage><lpage>470</lpage><pub-id pub-id-type="doi">10.1007/s11119-008-9100-2</pub-id></mixed-citation></ref><ref id="CR72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Domiciano</surname><given-names>GP</given-names></name><name><surname>Duarte</surname><given-names>HSS</given-names></name><name><surname>Moreira</surname><given-names>EN</given-names></name><name><surname>Rodrigues</surname><given-names>FA</given-names></name></person-group><article-title xml:lang="en">Development and validation of a set of standard area diagrams to aid in estimation of spot blotch severity on wheat leaves</article-title><source>Plant Pathol.</source><year>2014</year><volume>63</volume><fpage>922</fpage><lpage>928</lpage><pub-id pub-id-type="doi">10.1111/ppa.12150</pub-id></mixed-citation></ref><ref id="CR73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duan</surname><given-names>J</given-names></name><name><surname>Zhao</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Yang</surname><given-names>W</given-names></name></person-group><article-title xml:lang="en">Development and validation of a standard area diagram set to aid estimation of bacterial spot severity on tomato leaves</article-title><source>Eur J Plant Pathol.</source><year>2015</year><volume>142</volume><fpage>665</fpage><lpage>675</lpage><pub-id pub-id-type="doi">10.1007/s10658-015-0642-7</pub-id></mixed-citation></ref><ref id="CR74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duarte</surname><given-names>HSS</given-names></name><name><surname>Zambolim</surname><given-names>L</given-names></name><name><surname>Capucho</surname><given-names>AS</given-names></name><name><surname>Nogueira Júnior</surname><given-names>AF</given-names></name><name><surname>Rosado</surname><given-names>AWC</given-names></name><name><surname>Cardoso</surname><given-names>CR</given-names></name><etal/></person-group><article-title xml:lang="en">Development and validation of a set of standard area diagrams to estimate severity of potato early blight</article-title><source>Eur J Plant Pathol.</source><year>2013</year><volume>137</volume><fpage>249</fpage><lpage>257</lpage><pub-id pub-id-type="doi">10.1007/s10658-013-0234-3</pub-id></mixed-citation></ref><ref id="CR75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duarte-Carvajalino</surname><given-names>JM</given-names></name><name><surname>Alzate</surname><given-names>DF</given-names></name><name><surname>Ramirez</surname><given-names>AA</given-names></name><name><surname>Santa-Sepulveda</surname><given-names>JD</given-names></name><name><surname>Fajardo-Rojas</surname><given-names>AE</given-names></name><name><surname>Soto-Suárez</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Evaluating late blight severity in potato crops using unmanned aerial vehicles and machine learning algorithms</article-title><source>Remote Sens.</source><year>2018</year><volume>10</volume><fpage>1513</fpage><pub-id pub-id-type="doi">10.3390/rs10101513</pub-id></mixed-citation></ref><ref id="CR76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>El Jarroudi</surname><given-names>M</given-names></name><name><surname>Kouadio</surname><given-names>AL</given-names></name><name><surname>Mackels</surname><given-names>C</given-names></name><name><surname>Tychon</surname><given-names>B</given-names></name><name><surname>Delfosse</surname><given-names>P</given-names></name><name><surname>Bock</surname><given-names>CH</given-names></name></person-group><article-title xml:lang="en">A comparison between visual estimates and image analysis measurements to determine Septoria leaf blotch severity in winter wheat</article-title><source>Plant Pathol.</source><year>2015</year><volume>64</volume><fpage>355</fpage><lpage>364</lpage><pub-id pub-id-type="doi">10.1111/ppa.12252</pub-id></mixed-citation></ref><ref id="CR77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elvidge</surname><given-names>CD</given-names></name></person-group><article-title xml:lang="en">Visible and near infrared reflectance characteristics of dry plant materials</article-title><source>Int J Remote Sens.</source><year>1990</year><volume>11</volume><fpage>1775</fpage><lpage>1795</lpage><pub-id pub-id-type="doi">10.1080/01431169008955129</pub-id></mixed-citation></ref><ref id="CR78"><mixed-citation publication-type="other">Esgario JGM, Krohling RA, Ventura JA. Deep learning for classification and severity estimation of coffee leaf biotic stress. arXiv. 2019; <ext-link xlink:href="https://arxiv.org/pdf/1907.11561.pdf" ext-link-type="uri">https://arxiv.org/pdf/1907.11561.pdf</ext-link>. (11 pages).</mixed-citation></ref><ref id="CR79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiorani</surname><given-names>F</given-names></name><name><surname>Schurr</surname><given-names>U</given-names></name></person-group><article-title xml:lang="en">Future scenarios for plant phenotyping</article-title><source>Annu Rev Plant Biol.</source><year>2013</year><volume>64</volume><fpage>267</fpage><lpage>291</lpage><pub-id pub-id-type="pmid">23451789</pub-id><pub-id pub-id-type="doi">10.1146/annurev-arplant-050312-120137</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3sXosFSktLw%3D</pub-id></mixed-citation></ref><ref id="CR80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Forbes</surname><given-names>GA</given-names></name><name><surname>Jeger</surname><given-names>MJ</given-names></name></person-group><article-title xml:lang="en">Factors affecting the estimation of disease intensity in simulated plant structures</article-title><source>J Plant Dis Prot.</source><year>1987</year><volume>94</volume><fpage>113</fpage><lpage>120</lpage></mixed-citation></ref><ref id="CR81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Forbes</surname><given-names>GA</given-names></name><name><surname>Korva</surname><given-names>JT</given-names></name></person-group><article-title xml:lang="en">The effect of using a Horsfall-Barratt scale on precision and accuracy of visual estimation of potato late blight severity in the field</article-title><source>Plant Pathol.</source><year>1994</year><volume>43</volume><fpage>675</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1111/j.1365-3059.1994.tb01606.x</pub-id></mixed-citation></ref><ref id="CR82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franceschini</surname><given-names>MHD</given-names></name><name><surname>Bartholomeus</surname><given-names>H</given-names></name><name><surname>van Apeldoorn</surname><given-names>DF</given-names></name><name><surname>Suomalainen</surname><given-names>J</given-names></name><name><surname>Kooistra</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Feasibility of unmanned aerial vehicle optical imagery for early detection and severity assessment of late blight in potato</article-title><source>Remote Sens.</source><year>2019</year><volume>11</volume><fpage>224</fpage><pub-id pub-id-type="doi">10.3390/rs11030224</pub-id></mixed-citation></ref><ref id="CR83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>LY</given-names></name><name><surname>Wang</surname><given-names>Y-G</given-names></name><name><surname>Liu</surname><given-names>CJ</given-names></name></person-group><article-title xml:lang="en">Rank regression for analyzing ordinal qualitative data for treatment comparison</article-title><source>Phytopathology.</source><year>2012</year><volume>102</volume><fpage>1064</fpage><lpage>1070</lpage><pub-id pub-id-type="pmid">22835014</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-05-11-0128</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BC38fjt1Crsw%3D%3D</pub-id><pub-id pub-id-type="pmcid">22835014</pub-id></mixed-citation></ref><ref id="CR84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gamon</surname><given-names>JA</given-names></name><name><surname>Peñuelas</surname><given-names>J</given-names></name><name><surname>Field</surname><given-names>CB</given-names></name></person-group><article-title xml:lang="en">A narrow-waveband spectral index that tracks diurnal changes in photosynthetic efficiency</article-title><source>Remote Sens Environ.</source><year>1992</year><volume>41</volume><fpage>35</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1016/0034-4257(92)90059-S</pub-id></mixed-citation></ref><ref id="CR85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ganthaler</surname><given-names>A</given-names></name><name><surname>Losso</surname><given-names>A</given-names></name><name><surname>Mayr</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Using image analysis for quantitative assessment of needle bladder rust disease of Norway spruce</article-title><source>Plant Pathol.</source><year>2018</year><volume>67</volume><fpage>1122</fpage><lpage>1130</lpage><pub-id pub-id-type="pmid">29861507</pub-id><pub-id pub-id-type="pmcid">5969058</pub-id><pub-id pub-id-type="doi">10.1111/ppa.12842</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BC1Mbjt1erug%3D%3D</pub-id></mixed-citation></ref><ref id="CR86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garcia-Ruiz</surname><given-names>F</given-names></name><name><surname>Sankaran</surname><given-names>S</given-names></name><name><surname>Maja</surname><given-names>JM</given-names></name><name><surname>Lee</surname><given-names>WS</given-names></name><name><surname>Rasmussen</surname><given-names>J</given-names></name><name><surname>Ehsani</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Comparison of two aerial imaging platforms for identification of Huanglongbing-infected citrus trees</article-title><source>Comput Electron Agric.</source><year>2013</year><volume>91</volume><fpage>106</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2012.12.002</pub-id></mixed-citation></ref><ref id="CR87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gates</surname><given-names>DM</given-names></name><name><surname>Keegan</surname><given-names>HJ</given-names></name><name><surname>Schleter</surname><given-names>JC</given-names></name><name><surname>Weidner</surname><given-names>VR</given-names></name></person-group><article-title xml:lang="en">Spectral properties of plants</article-title><source>Appl Opt.</source><year>1965</year><volume>4</volume><fpage>11</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1364/AO.4.000011</pub-id></mixed-citation></ref><ref id="CR88"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gay</surname><given-names>A</given-names></name><name><surname>Thomas</surname><given-names>H</given-names></name><name><surname>Roca</surname><given-names>M</given-names></name><name><surname>James</surname><given-names>C</given-names></name><name><surname>Taylor</surname><given-names>J</given-names></name><name><surname>Rowland</surname><given-names>J</given-names></name><etal/></person-group><article-title xml:lang="en">Nondestructive analysis of senescence in mesophyll cells by spectral resolution of protein synthesis-dependent pigment metabolism</article-title><source>New Phytol.</source><year>2008</year><volume>179</volume><fpage>663</fpage><lpage>674</lpage><pub-id pub-id-type="pmid">18346109</pub-id><pub-id pub-id-type="doi">10.1111/j.1469-8137.2008.02412.x</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD1cXhtVKns7zF</pub-id><pub-id pub-id-type="pmcid">18346109</pub-id></mixed-citation></ref><ref id="CR89"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gent</surname><given-names>DH</given-names></name><name><surname>Claasen</surname><given-names>BJ</given-names></name><name><surname>Tworney</surname><given-names>MC</given-names></name><name><surname>Wolfenbarger</surname><given-names>SN</given-names></name><name><surname>Woods</surname><given-names>JL</given-names></name></person-group><article-title xml:lang="en">Susceptibility of hop crown buds to powdery mildew and its relation to perennation of <italic>Podosphaera macularis</italic></article-title><source>Plant Dis.</source><year>2018</year><volume>102</volume><fpage>1316</fpage><lpage>1325</lpage><pub-id pub-id-type="pmid">30673566</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-10-17-1530-RE</pub-id><pub-id pub-id-type="pmcid">30673566</pub-id></mixed-citation></ref><ref id="CR90"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghosal</surname><given-names>S</given-names></name><name><surname>Blystone</surname><given-names>D</given-names></name><name><surname>Singh</surname><given-names>AK</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name><name><surname>Singh</surname><given-names>A</given-names></name><name><surname>Sarkar</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">An explainable deep machine vision framework for plant stress phenotyping</article-title><source>Proc Natl Acad Sci U S A.</source><year>2018</year><volume>115</volume><fpage>4613</fpage><lpage>4618</lpage><pub-id pub-id-type="pmid">29666265</pub-id><pub-id pub-id-type="pmcid">5939070</pub-id><pub-id pub-id-type="doi">10.1073/pnas.1716999115</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXitlWrtLvM</pub-id></mixed-citation></ref><ref id="CR91"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gitelson</surname><given-names>AA</given-names></name><name><surname>Merzlyak</surname><given-names>MN</given-names></name><name><surname>Chivkunova</surname><given-names>OB</given-names></name></person-group><article-title xml:lang="en">Optical properties and nondestructive estimation of anthocyanin content in plant leaves</article-title><source>Photochem Photobiol.</source><year>2001</year><volume>74</volume><fpage>38</fpage><lpage>45</lpage><pub-id pub-id-type="pmid">11460535</pub-id><pub-id pub-id-type="doi">10.1562/0031-8655(2001)074&lt;0038:OPANEO&gt;2.0.CO;2</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD3MXltVyks7c%3D</pub-id><pub-id pub-id-type="pmcid">11460535</pub-id></mixed-citation></ref><ref id="CR92"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gitelson</surname><given-names>AA</given-names></name><name><surname>Peng</surname><given-names>Y</given-names></name><name><surname>Huemmrich</surname><given-names>KF</given-names></name></person-group><article-title xml:lang="en">Relationship between fraction of radiation absorbed by photosynthesizing maize and soybean canopies and NDVI from remotely sensed data taken at close range and from MODIS 250 m resolution data</article-title><source>Remote Sens Environ.</source><year>2014</year><volume>147</volume><fpage>108</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2014.02.014</pub-id></mixed-citation></ref><ref id="CR93"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gitelson</surname><given-names>AA</given-names></name><name><surname>Zur</surname><given-names>Y</given-names></name><name><surname>Chivkunova</surname><given-names>OB</given-names></name><name><surname>Merzlyak</surname><given-names>MN</given-names></name></person-group><article-title xml:lang="en">Assessing carotenoid content in plant leaves with reflectance spectroscopy</article-title><source>Photochem Photobiol.</source><year>2002</year><volume>75</volume><fpage>272</fpage><lpage>281</lpage><pub-id pub-id-type="pmid">11950093</pub-id><pub-id pub-id-type="doi">10.1562/0031-8655(2002)075&lt;0272:ACCIPL&gt;2.0.CO;2</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD38XivFGntLk%3D</pub-id><pub-id pub-id-type="pmcid">11950093</pub-id></mixed-citation></ref><ref id="CR94"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goclawski</surname><given-names>J</given-names></name><name><surname>Sekulska-Nalewajko</surname><given-names>J</given-names></name><name><surname>Kuzniak</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Neural network segmentation of images from stained cucurbits leaves with colour symptoms of biotic and abiotic stresses</article-title><source>Int J Appl Math Comput Sci.</source><year>2012</year><volume>22</volume><fpage>669</fpage><lpage>684</lpage><pub-id pub-id-type="doi">10.2478/v10006-012-0050-5</pub-id></mixed-citation></ref><ref id="CR95"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Godoy</surname><given-names>CV</given-names></name><name><surname>Koga</surname><given-names>LJ</given-names></name><name><surname>Canteri</surname><given-names>MG</given-names></name></person-group><article-title xml:lang="en">Diagrammatic scale for assessment of soybean rust severity</article-title><source>Fitopatol Bras.</source><year>2006</year><volume>31</volume><fpage>63</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1590/S0100-41582006000100011</pub-id><comment>https://doi.org/10.1590/S0100-41582006000100011</comment></mixed-citation></ref><ref id="CR96"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>González-Domínguez</surname><given-names>E</given-names></name><name><surname>Martins</surname><given-names>RB</given-names></name><name><surname>Del Ponte</surname><given-names>EM</given-names></name><name><surname>Michereff</surname><given-names>SM</given-names></name><name><surname>García-Jiménez</surname><given-names>J</given-names></name><name><surname>Armengol</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Development and validation of a standard area diagram set to aid assessment of severity of loquat scab on fruit</article-title><source>Eur J Plant Pathol.</source><year>2014</year><volume>139</volume><fpage>419</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1007/s10658-014-0439-0</pub-id></mixed-citation></ref><ref id="CR97"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodwin</surname><given-names>PH</given-names></name><name><surname>Hsiang</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">Quantification of fungal infection of leaves with digital images and Scion image software</article-title><source>Methods Mol Biol.</source><year>2010</year><volume>638</volume><fpage>125</fpage><lpage>135</lpage><pub-id pub-id-type="pmid">20238265</pub-id><pub-id pub-id-type="doi">10.1007/978-1-60761-611-5_9</pub-id><pub-id pub-id-type="pmcid">20238265</pub-id></mixed-citation></ref><ref id="CR98"><mixed-citation publication-type="other">Gottwald TR, da Graça JV, Bassanezi RB. Citrus Huanglongbing: the pathogen and its impact. Plant Health Prog. 2007;8(1) <ext-link xlink:href="10.1094/PHP-2007-0906-01-RV" ext-link-type="doi">https://doi.org/10.1094/PHP-2007-0906-01-RV</ext-link>.</mixed-citation></ref><ref id="CR99"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hahn</surname><given-names>SK</given-names></name><name><surname>Howland</surname><given-names>AK</given-names></name><name><surname>Terry</surname><given-names>ER</given-names></name></person-group><article-title xml:lang="en">Correlated resistance of cassava to mosaic and bacterial blight diseases</article-title><source>Euphytica.</source><year>1980</year><volume>29</volume><fpage>305</fpage><lpage>311</lpage><pub-id pub-id-type="doi">10.1007/BF00025127</pub-id></mixed-citation></ref><ref id="CR100"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamada</surname><given-names>NA</given-names></name><name><surname>Moreira</surname><given-names>RR</given-names></name><name><surname>Nesi</surname><given-names>CN</given-names></name><name><surname>De Mio</surname><given-names>LLM</given-names></name></person-group><article-title xml:lang="en">Pathogen dispersal and <italic>Glomerella</italic> leaf spot progress within apple canopy in Brazil</article-title><source>Plant Dis.</source><year>2019</year><volume>103</volume><fpage>3209</fpage><lpage>3217</lpage><pub-id pub-id-type="pmid">31657997</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-08-18-1375-RE</pub-id></mixed-citation></ref><ref id="CR101"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartung</surname><given-names>K</given-names></name><name><surname>Piepho</surname><given-names>H-P</given-names></name></person-group><article-title xml:lang="en">Are ordinal rating scales better than percent ratings? - a statistical and "psychological" view</article-title><source>Euphytica.</source><year>2007</year><volume>155</volume><fpage>15</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1007/s10681-006-9296-z</pub-id></mixed-citation></ref><ref id="CR102"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hau</surname><given-names>B</given-names></name><name><surname>Kranz</surname><given-names>J</given-names></name><name><surname>König</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Errors in the assessment of plant disease severities</article-title><source>J Plant Dis Prot.</source><year>1989</year><volume>96</volume><fpage>649</fpage><lpage>674</lpage></mixed-citation></ref><ref id="CR103"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haynes</surname><given-names>KG</given-names></name><name><surname>Christ</surname><given-names>BJ</given-names></name><name><surname>Weingartner</surname><given-names>DP</given-names></name><name><surname>Douches</surname><given-names>DS</given-names></name><name><surname>Thill</surname><given-names>CA</given-names></name><name><surname>Secor</surname><given-names>G</given-names></name><etal/></person-group><article-title xml:lang="en">Foliar resistance to late blight in potato clones evaluated in national trials in 1997</article-title><source>Am J Potato Res.</source><year>2002</year><volume>79</volume><fpage>451</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1007/BF02871690</pub-id></mixed-citation></ref><ref id="CR104"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heim</surname><given-names>RHJ</given-names></name><name><surname>Wright</surname><given-names>IJ</given-names></name><name><surname>Allen</surname><given-names>AP</given-names></name><name><surname>Geedicke</surname><given-names>I</given-names></name><name><surname>Oldeland</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Developing a spectral disease index for myrtle rust (<italic>Austropuccinia psidii</italic>)</article-title><source>Plant Pathol.</source><year>2019</year><volume>68</volume><fpage>738</fpage><lpage>745</lpage><pub-id pub-id-type="doi">10.1111/ppa.12996</pub-id></mixed-citation></ref><ref id="CR105"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hernández-Rabadán</surname><given-names>DL</given-names></name><name><surname>Ramos-Quintana</surname><given-names>F</given-names></name><name><surname>Guerrero</surname><given-names>JJ</given-names></name></person-group><article-title xml:lang="en">Integrating SOMs and a Bayesian classifier for segmenting diseased plants in uncontrolled environments</article-title><source>Sci World J.</source><year>2014</year><volume>2014</volume><fpage>214674</fpage><comment>https://doi.org/10.1155/2014/214674</comment></mixed-citation></ref><ref id="CR106"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hetzroni</surname><given-names>A</given-names></name><name><surname>Miles</surname><given-names>GE</given-names></name><name><surname>Engel</surname><given-names>BA</given-names></name><name><surname>Hammer</surname><given-names>PA</given-names></name><name><surname>Latin</surname><given-names>RX</given-names></name></person-group><article-title xml:lang="en">Machine vision monitoring of plant health</article-title><source>Adv Space Res.</source><year>1994</year><volume>14</volume><issue>11</issue><fpage>203</fpage><lpage>212</lpage><pub-id pub-id-type="pmid">11540182</pub-id><pub-id pub-id-type="doi">10.1016/0273-1177(94)90298-4</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BD3MnlvVOmsg%3D%3D</pub-id></mixed-citation></ref><ref id="CR107"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hillnhütter</surname><given-names>C</given-names></name><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Sikora</surname><given-names>RA</given-names></name><name><surname>Oerke</surname><given-names>EC</given-names></name></person-group><article-title xml:lang="en">Use of imaging spectroscopy to discriminate symptoms caused by <italic>Heterodera schachtii</italic> and <italic>Rhizoctonia solani</italic> on sugar beet</article-title><source>Precis Agric.</source><year>2012</year><volume>13</volume><fpage>17</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1007/s11119-011-9237-2</pub-id></mixed-citation></ref><ref id="CR108"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hillnhütter</surname><given-names>C</given-names></name><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Sikora</surname><given-names>RA</given-names></name><name><surname>Oerke</surname><given-names>E-C</given-names></name></person-group><article-title xml:lang="en">Remote sensing to detect plant stress induced by <italic>Heterodera schachtii</italic> and <italic>Rhizoctonia solani</italic> in sugar beet fields</article-title><source>Field Crop Res.</source><year>2011</year><volume>122</volume><fpage>70</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.fcr.2011.02.007</pub-id></mixed-citation></ref><ref id="CR109"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hindle</surname><given-names>PH</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Burns</surname><given-names>DA</given-names></name><name><surname>Ciurczak</surname><given-names>EW</given-names></name></person-group><article-title xml:lang="en">Historical development</article-title><source>Handbook of near-infrared analysis</source><year>2008</year><edition>3</edition><publisher-loc>Boca Raton</publisher-loc><publisher-name>CRC Press</publisher-name><fpage>3</fpage><lpage>6</lpage></mixed-citation></ref><ref id="CR110"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horsfall</surname><given-names>JG</given-names></name><name><surname>Barratt</surname><given-names>RW</given-names></name></person-group><article-title xml:lang="en">An improved grading system for measuring plant disease</article-title><source>Phytopathology.</source><year>1945</year><volume>35</volume><fpage>655</fpage></mixed-citation></ref><ref id="CR111"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Horsfall</surname><given-names>JG</given-names></name><name><surname>Cowling</surname><given-names>EB</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Horsfall</surname><given-names>JG</given-names></name><name><surname>Cowling</surname><given-names>EB</given-names></name></person-group><article-title xml:lang="en">Pathometry: the measurement of plant disease</article-title><source>Plant disease: an advanced treatise</source><year>1978</year><publisher-loc>New York</publisher-loc><publisher-name>Academic Press</publisher-name><fpage>120</fpage><lpage>136</lpage></mixed-citation></ref><ref id="CR112"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horsfall</surname><given-names>JG</given-names></name><name><surname>Heuberger</surname><given-names>JW</given-names></name></person-group><article-title xml:lang="en">Measuring magnitude of a defoliation disease of tomatoes</article-title><source>Phytopathology.</source><year>1942</year><volume>32</volume><fpage>226</fpage><lpage>232</lpage></mixed-citation></ref><ref id="CR113"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horvath</surname><given-names>B</given-names></name><name><surname>Vargas</surname><given-names>JJ</given-names></name></person-group><article-title xml:lang="en">Analysis of dollar spot disease severity using digital image analysis</article-title><source>Int Turfgrass Soc Res J.</source><year>2005</year><volume>10</volume><fpage>196</fpage><lpage>201</lpage></mixed-citation></ref><ref id="CR114"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>Q-X</given-names></name><name><surname>Tian</surname><given-names>J</given-names></name><name><surname>He</surname><given-names>D-J</given-names></name></person-group><article-title xml:lang="en">Wheat leaf lesion color image segmentation with improved multichannel selection based on the Chan–Vese model</article-title><source>Comput Electron Agric.</source><year>2017</year><volume>135</volume><fpage>260</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2017.01.016</pub-id></mixed-citation></ref><ref id="CR115"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>K-Y</given-names></name></person-group><article-title xml:lang="en">Application of artificial neural network for detecting Phalaenopsis seedling diseases using color and texture features</article-title><source>Comput Electron Agric.</source><year>2007</year><volume>57</volume><fpage>3</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2007.01.015</pub-id></mixed-citation></ref><ref id="CR116"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>W</given-names></name><name><surname>Lamb</surname><given-names>DW</given-names></name><name><surname>Niu</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Identification of yellow rust in wheat using in-situ spectral reflectance measurements and airborne hyperspectral imaging</article-title><source>Precis Agric.</source><year>2007</year><volume>8</volume><fpage>187</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1007/s11119-007-9038-9</pub-id></mixed-citation></ref><ref id="CR117"><mixed-citation publication-type="other">Hughes DP, Salathé M. An open access repository of images on plant health to enable the development of mobile disease diagnostics. arXiv. 2015; <ext-link xlink:href="https://arxiv.org/ftp/arxiv/papers/1511/1511.08060.pdf" ext-link-type="uri">https://arxiv.org/ftp/arxiv/papers/1511/1511.08060.pdf</ext-link>. (13 pages).</mixed-citation></ref><ref id="CR118"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname><given-names>RE</given-names></name><name><surname>Roberts</surname><given-names>DD</given-names></name></person-group><article-title xml:lang="en">A disease grading system for pecan scab [<italic>Fusicladium effusum</italic>]</article-title><source>Pecan Quarterly.</source><year>1978</year><volume>12</volume><fpage>3</fpage><lpage>6</lpage></mixed-citation></ref><ref id="CR119"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ihlow</surname><given-names>A</given-names></name><name><surname>Schweizer</surname><given-names>P</given-names></name><name><surname>Seiffert</surname><given-names>U</given-names></name></person-group><article-title xml:lang="en">A high-throughput screening system for barley/powdery mildew interactions based on automated analysis of light micrographs</article-title><source>BMC Plant Biol.</source><year>2008</year><volume>8</volume><fpage>6</fpage><pub-id pub-id-type="pmid">18215267</pub-id><pub-id pub-id-type="pmcid">2262080</pub-id><pub-id pub-id-type="doi">10.1186/1471-2229-8-6</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD1cXmslCmsLs%3D</pub-id></mixed-citation></ref><ref id="CR120"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jackson</surname><given-names>RD</given-names></name><name><surname>Huete</surname><given-names>AR</given-names></name></person-group><article-title xml:lang="en">Interpreting vegetation indices</article-title><source>Prev Vet Med.</source><year>1991</year><volume>11</volume><fpage>185</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1016/S0167-5877(05)80004-2</pub-id></mixed-citation></ref><ref id="CR121"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>James</surname><given-names>WC</given-names></name></person-group><article-title xml:lang="en">An illustrated series of assessment keys for plant diseases, their preparation and usage</article-title><source>Can Plant Dis Surv.</source><year>1971</year><volume>51</volume><fpage>39</fpage><lpage>65</lpage></mixed-citation></ref><ref id="CR122"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>James</surname><given-names>WC</given-names></name></person-group><article-title xml:lang="en">Assessment of plant disease losses</article-title><source>Annu Rev Phytopathol.</source><year>1974</year><volume>12</volume><fpage>27</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1146/annurev.py.12.090174.000331</pub-id></mixed-citation></ref><ref id="CR123"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jay</surname><given-names>S</given-names></name><name><surname>Bendoula</surname><given-names>R</given-names></name><name><surname>Hadoux</surname><given-names>X</given-names></name><name><surname>Féret</surname><given-names>J-B</given-names></name><name><surname>Gorretta</surname><given-names>N</given-names></name></person-group><article-title xml:lang="en">A physically-based model for retrieving foliar biochemistry and leaf orientation using close-range imaging spectroscopy</article-title><source>Remote Sens Environ.</source><year>2016</year><volume>177</volume><fpage>220</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2016.02.029</pub-id></mixed-citation></ref><ref id="CR124"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>DA</given-names></name><name><surname>Alldredge</surname><given-names>JR</given-names></name><name><surname>Hamm</surname><given-names>PB</given-names></name><name><surname>Frazier</surname><given-names>BE</given-names></name></person-group><article-title xml:lang="en">Aerial photography used for spatial pattern analysis of late blight infection in irrigated potato circles</article-title><source>Phytopathology.</source><year>2003</year><volume>93</volume><fpage>805</fpage><lpage>812</lpage><pub-id pub-id-type="pmid">18943161</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO.2003.93.7.805</pub-id></mixed-citation></ref><ref id="CR125"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>MM</given-names></name><name><surname>Stansly</surname><given-names>PA</given-names></name></person-group><article-title xml:lang="en">Frequent low volume sprays of horticultural mineral oil (HMO) for psyllid and leafminer control</article-title><source>J Citrus Pathol.</source><year>2014</year><volume>1</volume><issue>1</issue><fpage>178</fpage><comment>https://escholarship.org/uc/item/1z03d071</comment></mixed-citation></ref><ref id="CR126"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karisto</surname><given-names>P</given-names></name><name><surname>Hund</surname><given-names>A</given-names></name><name><surname>Yu</surname><given-names>K</given-names></name><name><surname>Anderegg</surname><given-names>J</given-names></name><name><surname>Walter</surname><given-names>A</given-names></name><name><surname>Mascher</surname><given-names>F</given-names></name><etal/></person-group><article-title xml:lang="en">Ranking quantitative resistance to <italic>Septoria tritici</italic> blotch in elite wheat cultivars using automated image analysis</article-title><source>Phytopathology.</source><year>2018</year><volume>108</volume><fpage>568</fpage><lpage>581</lpage><pub-id pub-id-type="pmid">29210601</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-04-17-0163-R</pub-id></mixed-citation></ref><ref id="CR127"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kerguelen</surname><given-names>V</given-names></name><name><surname>Hoddle</surname><given-names>MS</given-names></name></person-group><article-title xml:lang="en">Measuring mite feeding damage on avocado leaves with automated image analysis software</article-title><source>The Florida Entomol.</source><year>1999</year><volume>82</volume><fpage>119</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.2307/3495843</pub-id></mixed-citation></ref><ref id="CR128"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kersting</surname><given-names>K</given-names></name><name><surname>Bauckhage</surname><given-names>C</given-names></name><name><surname>Wahabzada</surname><given-names>M</given-names></name><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Steiner</surname><given-names>U</given-names></name><etal/></person-group><person-group person-group-type="editor"><name><surname>Lässig</surname><given-names>J</given-names></name><name><surname>Kersting</surname><given-names>K</given-names></name><name><surname>Morik</surname><given-names>K</given-names></name><etal/></person-group><article-title xml:lang="en">Feeding the world with big data: uncovering spectral characteristics and dynamics of stressed plants</article-title><source>Computational sustainability</source><year>2016</year><publisher-loc>Cham</publisher-loc><publisher-name>Springer</publisher-name><fpage>99</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-31858-5_6</pub-id></mixed-citation></ref><ref id="CR129"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobayashi</surname><given-names>T</given-names></name><name><surname>Sasahara</surname><given-names>M</given-names></name><name><surname>Kanda</surname><given-names>E</given-names></name><name><surname>Ishiguro</surname><given-names>K</given-names></name><name><surname>Hase</surname><given-names>S</given-names></name><name><surname>Torigoe</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Assessment of rice panicle blast disease using airborne hyperspectral imagery</article-title><source>Open Agric J.</source><year>2016</year><volume>10</volume><fpage>28</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.2174/1874331501610010028</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28XhvFSrsrfI</pub-id></mixed-citation></ref><ref id="CR130"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koch</surname><given-names>H</given-names></name><name><surname>Hau</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">A psychological aspect of plant disease assessment</article-title><source>J Plant Dis Prot.</source><year>1980</year><volume>87</volume><fpage>587</fpage><lpage>593</lpage></mixed-citation></ref><ref id="CR131"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kokko</surname><given-names>EG</given-names></name><name><surname>Conner</surname><given-names>RL</given-names></name><name><surname>Lee</surname><given-names>B</given-names></name><name><surname>Kuzyk</surname><given-names>AD</given-names></name><name><surname>Kozu</surname><given-names>GC</given-names></name></person-group><article-title xml:lang="en">Quantification of common root rot symptoms in resistant and susceptible barley by image analysis</article-title><source>Can J Plant Pathol.</source><year>2000</year><volume>22</volume><fpage>38</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1080/07060660009501159</pub-id></mixed-citation></ref><ref id="CR132"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kora</surname><given-names>C</given-names></name><name><surname>McDonald</surname><given-names>MR</given-names></name><name><surname>Boland</surname><given-names>GJ</given-names></name></person-group><article-title xml:lang="en">Epidemiology of Sclerotinia rot of carrot caused by <italic>Sclerotinia sclerotiorum</italic></article-title><source>Can J Plant Pathol.</source><year>2005</year><volume>27</volume><fpage>245</fpage><lpage>258</lpage><pub-id pub-id-type="doi">10.1080/07060660509507222</pub-id></mixed-citation></ref><ref id="CR133"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kranz</surname><given-names>J</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Kranz</surname><given-names>J</given-names></name><name><surname>Rotem</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Measuring plant disease</article-title><source>Experimental techniques in plant disease epidemiology</source><year>1988</year><publisher-loc>New York</publisher-loc><publisher-name>Springer Verlag</publisher-name><fpage>35</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-95534-1_4</pub-id></mixed-citation></ref><ref id="CR134"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kruse</surname><given-names>OMO</given-names></name><name><surname>Prats-Montalbán</surname><given-names>JM</given-names></name><name><surname>Indahl</surname><given-names>UG</given-names></name><name><surname>Kvaal</surname><given-names>K</given-names></name><name><surname>Ferrer</surname><given-names>A</given-names></name><name><surname>Futsaether</surname><given-names>CM</given-names></name></person-group><article-title xml:lang="en">Pixel classification methods for identifying and quantifying leaf surface injury from digital images</article-title><source>Comput Electron Agric.</source><year>2014</year><volume>108</volume><fpage>155</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2014.07.010</pub-id></mixed-citation></ref><ref id="CR135"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuska</surname><given-names>M</given-names></name><name><surname>Wahabzada</surname><given-names>M</given-names></name><name><surname>Leucker</surname><given-names>M</given-names></name><name><surname>Dehne</surname><given-names>H-W</given-names></name><name><surname>Kersting</surname><given-names>K</given-names></name><name><surname>Oerke</surname><given-names>E-C</given-names></name><etal/></person-group><article-title xml:lang="en">Hyperspectral phenotyping on the microscopic scale: towards automated characterization of plant-pathogen interactions</article-title><source>Plant Methods.</source><year>2015</year><volume>11</volume><fpage>28</fpage><pub-id pub-id-type="pmid">25937826</pub-id><pub-id pub-id-type="pmcid">4416301</pub-id><pub-id pub-id-type="doi">10.1186/s13007-015-0073-7</pub-id></mixed-citation></ref><ref id="CR136"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuska</surname><given-names>MT</given-names></name><name><surname>Mahlein</surname><given-names>A-K</given-names></name></person-group><article-title xml:lang="en">Aiming at decision making in plant disease protection and phenotyping by the use of optical sensors</article-title><source>Eur J Plant Pathol.</source><year>2018</year><volume>152</volume><fpage>987</fpage><lpage>992</lpage><pub-id pub-id-type="doi">10.1007/s10658-018-1464-1</pub-id></mixed-citation></ref><ref id="CR137"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kutcher</surname><given-names>HR</given-names></name><name><surname>Turkington</surname><given-names>TK</given-names></name><name><surname>McLaren</surname><given-names>DL</given-names></name><name><surname>Irvine</surname><given-names>RB</given-names></name><name><surname>Brar</surname><given-names>GS</given-names></name></person-group><article-title xml:lang="en">Fungicide and cultivar management of leaf spot diseases of winter wheat in western Canada</article-title><source>Plant Dis.</source><year>2018</year><volume>102</volume><fpage>1828</fpage><lpage>1833</lpage><pub-id pub-id-type="pmid">30125191</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-12-17-1920-RE</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXivV2gsbc%3D</pub-id><pub-id pub-id-type="pmcid">30125191</pub-id></mixed-citation></ref><ref id="CR138"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuźniak</surname><given-names>E</given-names></name><name><surname>Świercz</surname><given-names>U</given-names></name><name><surname>Chojak</surname><given-names>J</given-names></name><name><surname>Sekulska-Nalewajko</surname><given-names>J</given-names></name><name><surname>Gocławski</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Automated image analysis for quantification of histochemical detection of reactive oxygen species and necrotic infection symptoms in plant leaves</article-title><source>J Plant Interact.</source><year>2014</year><volume>9</volume><fpage>167</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1080/17429145.2013.791729</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3sXlsl2jtbg%3D</pub-id></mixed-citation></ref><ref id="CR139"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kwack</surname><given-names>MS</given-names></name><name><surname>Kim</surname><given-names>EN</given-names></name><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Kim</surname><given-names>J-W</given-names></name><name><surname>Chun</surname><given-names>S-C</given-names></name><name><surname>Kim</surname><given-names>KD</given-names></name></person-group><article-title xml:lang="en">Digital image analysis to measure lesion area of cucumber anthracnose by <italic>Colletotrichum orbiculare</italic></article-title><source>J Gen Plant Pathol.</source><year>2005</year><volume>71</volume><fpage>418</fpage><lpage>421</lpage><pub-id pub-id-type="doi">10.1007/s10327-005-0233-0</pub-id></mixed-citation></ref><ref id="CR140"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laflamme</surname><given-names>B</given-names></name><name><surname>Middleton</surname><given-names>M</given-names></name><name><surname>Lo</surname><given-names>T</given-names></name><name><surname>Desveaux</surname><given-names>D</given-names></name><name><surname>Guttman</surname><given-names>DS</given-names></name></person-group><article-title xml:lang="en">Image-based quantification of plant immunity and disease</article-title><source>Mol Plant-Microbe Interact.</source><year>2016</year><volume>29</volume><fpage>919</fpage><lpage>924</lpage><pub-id pub-id-type="pmid">27996374</pub-id><pub-id pub-id-type="doi">10.1094/MPMI-07-16-0129-TA</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXpt1Cqurg%3D</pub-id><pub-id pub-id-type="pmcid">27996374</pub-id></mixed-citation></ref><ref id="CR141"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lamari</surname><given-names>L</given-names></name></person-group><source>ASSESS 2.0: image analysis software for plant disease quantification</source><year>2002</year><publisher-loc>St Paul</publisher-loc><publisher-name>APS Press</publisher-name></mixed-citation></ref><ref id="CR142"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Large</surname><given-names>EC</given-names></name></person-group><article-title xml:lang="en">Measuring plant disease</article-title><source>Annu Rev Phytopathol.</source><year>1966</year><volume>4</volume><fpage>9</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1146/annurev.py.04.090166.000301</pub-id></mixed-citation></ref><ref id="CR143"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larsolle</surname><given-names>A</given-names></name><name><surname>Muhammed</surname><given-names>HH</given-names></name></person-group><article-title xml:lang="en">Measuring crop status using multivariate analysis of hyperspectral field reflectance with application to disease severity and plant density</article-title><source>Precis Agric.</source><year>2007</year><volume>8</volume><fpage>37</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1007/s11119-006-9027-4</pub-id></mixed-citation></ref><ref id="CR144"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lelong</surname><given-names>CCD</given-names></name><name><surname>Burger</surname><given-names>P</given-names></name><name><surname>Jubelin</surname><given-names>G</given-names></name><name><surname>Roux</surname><given-names>BL</given-names></name><name><surname>Kabbe</surname><given-names>S</given-names></name><name><surname>Baret</surname><given-names>F</given-names></name></person-group><article-title xml:lang="en">Assessment of unmanned aerial vehicles imagery for quantitative monitoring of wheat crop in small plots</article-title><source>Sensors.</source><year>2008</year><volume>8</volume><fpage>3557</fpage><lpage>3585</lpage><pub-id pub-id-type="pmid">27879893</pub-id><pub-id pub-id-type="doi">10.3390/s8053557</pub-id></mixed-citation></ref><ref id="CR145"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leucker</surname><given-names>M</given-names></name><name><surname>Mahlein</surname><given-names>AK</given-names></name><name><surname>Steiner</surname><given-names>U</given-names></name><name><surname>Oerke</surname><given-names>EC</given-names></name></person-group><article-title xml:lang="en">Improvement of lesion phenotyping in Cercospora beticola – sugar beet interaction by hyperspectral imaging</article-title><source>Phytopathology</source><year>2016</year><volume>106</volume><fpage>177</fpage><lpage>184</lpage><pub-id pub-id-type="pmid">26506458</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-04-15-0100-R</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2sXlsF2msA%3D%3D</pub-id></mixed-citation></ref><ref id="CR146"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leucker</surname><given-names>M</given-names></name><name><surname>Wahabzada</surname><given-names>M</given-names></name><name><surname>Kersting</surname><given-names>K</given-names></name><name><surname>Peter</surname><given-names>M</given-names></name><name><surname>Beyer</surname><given-names>W</given-names></name><name><surname>Steiner</surname><given-names>U</given-names></name><etal/></person-group><article-title xml:lang="en">Hyperspectral imaging reveals the effect of sugar beet quantitative trait loci on Cercospora leaf spot resistance</article-title><source>Funct Plant Biol.</source><year>2017</year><volume>44</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1071/FP16121</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28XitFSmt7%2FJ</pub-id></mixed-citation></ref><ref id="CR147"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liang</surname><given-names>W</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>G</given-names></name><name><surname>Cao</surname><given-names>H-X</given-names></name></person-group><article-title xml:lang="en">Rice blast disease recognition using a deep convolutional neural network</article-title><source>Sci Rep.</source><year>2019</year><volume>9</volume><fpage>2869</fpage><pub-id pub-id-type="pmid">30814523</pub-id><pub-id pub-id-type="pmcid">6393546</pub-id><pub-id pub-id-type="doi">10.1038/s41598-019-38966-0</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXnslOlt7Y%3D</pub-id></mixed-citation></ref><ref id="CR148"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Likert</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">A technique for the measurement of attitudes</article-title><source>Arch Psychol.</source><year>1932</year><volume>140</volume><fpage>1</fpage><lpage>55</lpage></mixed-citation></ref><ref id="CR149"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindow</surname><given-names>SE</given-names></name></person-group><article-title xml:lang="en">Estimating disease severity of single plants</article-title><source>Phytopathology.</source><year>1983</year><volume>73</volume><fpage>1576</fpage><lpage>1581</lpage><pub-id pub-id-type="doi">10.1094/Phyto-73-1576</pub-id></mixed-citation></ref><ref id="CR150"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindow</surname><given-names>SE</given-names></name><name><surname>Webb</surname><given-names>RR</given-names></name></person-group><article-title xml:lang="en">Quantification of foliar plant disease symptoms by microcomputer-digitized video image analysis</article-title><source>Phytopathology.</source><year>1983</year><volume>73</volume><fpage>520</fpage><lpage>524</lpage><pub-id pub-id-type="doi">10.1094/Phyto-73-520</pub-id></mixed-citation></ref><ref id="CR151"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>W</given-names></name><name><surname>Cao</surname><given-names>X</given-names></name><name><surname>Fan</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Yan</surname><given-names>Z</given-names></name><name><surname>Luo</surname><given-names>Y</given-names></name><etal/></person-group><article-title xml:lang="en">Detecting wheat powdery mildew and predicting grain yield using unmanned aerial photography</article-title><source>Plant Dis.</source><year>2018</year><volume>102</volume><fpage>1981</fpage><lpage>1988</lpage><pub-id pub-id-type="pmid">30125137</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-12-17-1893-RE</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXjsFCnuro%3D</pub-id><pub-id pub-id-type="pmcid">30125137</pub-id></mixed-citation></ref><ref id="CR152"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lloret</surname><given-names>J</given-names></name><name><surname>Bosch</surname><given-names>I</given-names></name><name><surname>Sendra</surname><given-names>S</given-names></name><name><surname>Serrano</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">A wireless sensor network for vineyard monitoring that uses image processing</article-title><source>Sensors.</source><year>2011</year><volume>11</volume><fpage>6165</fpage><lpage>6196</lpage><pub-id pub-id-type="pmid">22163948</pub-id><pub-id pub-id-type="doi">10.3390/s110606165</pub-id><pub-id pub-id-type="pmcid">22163948</pub-id></mixed-citation></ref><ref id="CR153"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macedo-Cruz</surname><given-names>A</given-names></name><name><surname>Pajares</surname><given-names>G</given-names></name><name><surname>Santos</surname><given-names>M</given-names></name><name><surname>Vilegas-Romero</surname><given-names>I</given-names></name></person-group><article-title xml:lang="en">Digital image sensor-based assessment of the status of oat (<italic>Avena sativa</italic> L.) crops after frost damage</article-title><source>Sensors</source><year>2011</year><volume>11</volume><fpage>6015</fpage><lpage>6036</lpage><pub-id pub-id-type="pmid">22163940</pub-id><pub-id pub-id-type="doi">10.3390/s110606015</pub-id><pub-id pub-id-type="pmcid">22163940</pub-id></mixed-citation></ref><ref id="CR154"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Madden</surname><given-names>LV</given-names></name><name><surname>Hughes</surname><given-names>G</given-names></name><name><surname>van den Bosch</surname><given-names>F</given-names></name></person-group><source>The study of plant disease epidemics</source><year>2007</year><publisher-loc>St Paul</publisher-loc><publisher-name>APS Press</publisher-name></mixed-citation></ref><ref id="CR155"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahlein</surname><given-names>A-K</given-names></name></person-group><article-title xml:lang="en">Plant disease detection by imaging sensors—parallels and specific demands for precision agriculture and plant phenotyping</article-title><source>Plant Dis.</source><year>2016</year><volume>100</volume><fpage>241</fpage><lpage>251</lpage><pub-id pub-id-type="pmid">30694129</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-03-15-0340-FE</pub-id><pub-id pub-id-type="pmcid">30694129</pub-id></mixed-citation></ref><ref id="CR156"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Kuska</surname><given-names>MT</given-names></name><name><surname>Behmann</surname><given-names>J</given-names></name><name><surname>Polder</surname><given-names>G</given-names></name><name><surname>Walter</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Hyperspectral sensors and imaging technologies in phytopathology: state of the art</article-title><source>Annu Rev Phytopathol.</source><year>2018</year><volume>56</volume><fpage>535</fpage><lpage>558</lpage><pub-id pub-id-type="pmid">30149790</pub-id><pub-id pub-id-type="doi">10.1146/annurev-phyto-080417-050100</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXhsF2ltr%2FK</pub-id><pub-id pub-id-type="pmcid">30149790</pub-id></mixed-citation></ref><ref id="CR157"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Kuska</surname><given-names>MT</given-names></name><name><surname>Thomas</surname><given-names>S</given-names></name><name><surname>Wahabzada</surname><given-names>M</given-names></name><name><surname>Behmann</surname><given-names>J</given-names></name><name><surname>Rascher</surname><given-names>U</given-names></name><etal/></person-group><article-title xml:lang="en">Quantitative and qualitative phenotyping of disease resistance of crops by hyperspectral sensors: seamless interlocking of phytopathology, sensors, and machine learning is needed!</article-title><source>Curr Opin Plant Biol.</source><year>2019</year><volume>50</volume><fpage>156</fpage><lpage>162</lpage><pub-id pub-id-type="pmid">31387067</pub-id><pub-id pub-id-type="doi">10.1016/j.pbi.2019.06.007</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXhsFWjt7jE</pub-id><pub-id pub-id-type="pmcid">31387067</pub-id></mixed-citation></ref><ref id="CR158"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Oerke</surname><given-names>EC</given-names></name><name><surname>Steiner</surname><given-names>U</given-names></name><name><surname>Dehne</surname><given-names>HW</given-names></name></person-group><article-title xml:lang="en">Recent advances in sensing plant diseases for precision crop protection</article-title><source>Eur J Plant Pathol.</source><year>2012</year><volume>133</volume><fpage>197</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1007/s10658-011-9878-z</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38XkvVCrsbk%3D</pub-id></mixed-citation></ref><ref id="CR159"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Rumpf</surname><given-names>T</given-names></name><name><surname>Welke</surname><given-names>P</given-names></name><name><surname>Dehne</surname><given-names>H-W</given-names></name><name><surname>Plümer</surname><given-names>L</given-names></name><name><surname>Steiner</surname><given-names>U</given-names></name><etal/></person-group><article-title xml:lang="en">Development of spectral indices for detecting and identifying plant diseases</article-title><source>Remote Sens Environ.</source><year>2013</year><volume>128</volume><fpage>21</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2012.09.019</pub-id></mixed-citation></ref><ref id="CR160"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Steiner</surname><given-names>U</given-names></name><name><surname>Dehne</surname><given-names>H-W</given-names></name><name><surname>Oerke</surname><given-names>E-C</given-names></name></person-group><article-title xml:lang="en">Spectral signatures of sugar beet leaves for the detection and differentiation of diseases</article-title><source>Precis Agric.</source><year>2010</year><volume>11</volume><fpage>413</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1007/s11119-010-9180-7</pub-id></mixed-citation></ref><ref id="CR161"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Steiner</surname><given-names>U</given-names></name><name><surname>Hillnhütter</surname><given-names>C</given-names></name><name><surname>Dehne</surname><given-names>H-W</given-names></name><name><surname>Oerke</surname><given-names>E-C</given-names></name></person-group><article-title xml:lang="en">Hyperspectral imaging for small-scale analysis of symptoms caused by different sugar beet diseases</article-title><source>Plant Methods.</source><year>2012</year><volume>8</volume><issue>1</issue><fpage>3</fpage><pub-id pub-id-type="pmid">22273513</pub-id><pub-id pub-id-type="pmcid">3274483</pub-id><pub-id pub-id-type="doi">10.1186/1746-4811-8-3</pub-id></mixed-citation></ref><ref id="CR162"><mixed-citation publication-type="other">Manso GL, Knidel H, Krohling RA, Ventura JA. A smartphone application to detection and classification of coffee leaf miner and coffee leaf rust. arXiv. 2019; <ext-link xlink:href="https://arxiv.org/pdf/1904.00742v1.pdf" ext-link-type="uri">https://arxiv.org/pdf/1904.00742v1.pdf</ext-link>. (36 pages).</mixed-citation></ref><ref id="CR163"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin</surname><given-names>DP</given-names></name><name><surname>Rybicki</surname><given-names>EP</given-names></name></person-group><article-title xml:lang="en">Microcomputer-based quantification of maize streak virus symptoms in <italic>Zea mays</italic></article-title><source>Phytopathology.</source><year>1998</year><volume>88</volume><fpage>422</fpage><lpage>427</lpage><pub-id pub-id-type="pmid">18944921</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO.1998.88.5.422</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BD1cjjvVaiug%3D%3D</pub-id><pub-id pub-id-type="pmcid">18944921</pub-id></mixed-citation></ref><ref id="CR164"><mixed-citation publication-type="other">McBride GB. A proposal for strength-of-agreement criteria for Lin’s concordance correlation coefficient. NIWA Client Report. 2005:HAM2005–62 <ext-link xlink:href="https://www.medcalc.org/download/pdf/McBride2005.pdf" ext-link-type="uri">https://www.medcalc.org/download/pdf/McBride2005.pdf</ext-link>.</mixed-citation></ref><ref id="CR165"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merzlyak</surname><given-names>MN</given-names></name><name><surname>Gitelson</surname><given-names>AA</given-names></name><name><surname>Chivkunova</surname><given-names>OB</given-names></name><name><surname>Rakitin</surname><given-names>VY</given-names></name></person-group><article-title xml:lang="en">Non-destructive optical detection of pigment changes during leaf senescence and fruit ripening</article-title><source>Physiol Plant.</source><year>1999</year><volume>106</volume><fpage>135</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1034/j.1399-3054.1999.106119.x</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DyaK1MXktFKks78%3D</pub-id><comment>https://doi.org/10.1034/j.1399-3054.1999.106119.x</comment></mixed-citation></ref><ref id="CR166"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michereff</surname><given-names>SJ</given-names></name><name><surname>Noronha</surname><given-names>MA</given-names></name><name><surname>Lima</surname><given-names>GSA</given-names></name><name><surname>Albert</surname><given-names>ÍCL</given-names></name><name><surname>Melo</surname><given-names>EA</given-names></name><name><surname>Gusmão</surname><given-names>LO</given-names></name></person-group><article-title xml:lang="en">Diagrammatic scale to assess downy mildew severity in melon</article-title><source>Hortic Bras.</source><year>2009</year><volume>27</volume><fpage>76</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1590/S0102-05362009000100015</pub-id></mixed-citation></ref><ref id="CR167"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirik</surname><given-names>M</given-names></name><name><surname>Michels</surname><given-names>GJ</given-names></name><name><surname>Kassymzhanova-Mirik</surname><given-names>S</given-names></name><name><surname>Elliott</surname><given-names>NC</given-names></name><name><surname>Catana</surname><given-names>V</given-names></name><name><surname>Jones</surname><given-names>DB</given-names></name><etal/></person-group><article-title xml:lang="en">Using digital image analysis and spectral reflectance data to quantify damage by greenbug (Hemitera: Aphididae) in winter wheat</article-title><source>Comput Electron Agric.</source><year>2006</year><volume>51</volume><fpage>86</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2005.11.004</pub-id></mixed-citation></ref><ref id="CR168"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mishra</surname><given-names>P</given-names></name><name><surname>Nordon</surname><given-names>A</given-names></name><name><surname>Tschannerl</surname><given-names>J</given-names></name><name><surname>Lian</surname><given-names>G</given-names></name><name><surname>Redfern</surname><given-names>S</given-names></name><name><surname>Marshall</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Near-infrared hyperspectral imaging for non-destructive classification of commercial tea products</article-title><source>J Food Eng.</source><year>2018</year><volume>238</volume><fpage>70</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.jfoodeng.2018.06.015</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXht1SmsLnI</pub-id></mixed-citation></ref><ref id="CR169"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miyasaka</surname><given-names>SC</given-names></name><name><surname>McCulloch</surname><given-names>CE</given-names></name><name><surname>Nelson</surname><given-names>SC</given-names></name></person-group><article-title xml:lang="en">Taro germplasm evaluated for resistance to taro leaf blight</article-title><source>Hort Technol.</source><year>2012</year><volume>22</volume><fpage>838</fpage><lpage>849</lpage><pub-id pub-id-type="doi">10.21273/HORTTECH.22.6.838</pub-id></mixed-citation></ref><ref id="CR170"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>WC</given-names></name></person-group><article-title xml:lang="en">The measurement of plant disease in the field: preliminary report of a sub-committee of the Society's plant pathology committee</article-title><source>Trans Br Mycol Soc.</source><year>1943</year><volume>26</volume><fpage>28</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1016/S0007-1536(43)80008-5</pub-id></mixed-citation></ref><ref id="CR171"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mutka</surname><given-names>AM</given-names></name><name><surname>Bart</surname><given-names>RS</given-names></name></person-group><article-title xml:lang="en">Image-based phenotyping of plant disease symptoms</article-title><source>Front Plant Sci.</source><year>2015</year><volume>5</volume><fpage>734</fpage><pub-id pub-id-type="pmid">25601871</pub-id><pub-id pub-id-type="pmcid">4283508</pub-id><pub-id pub-id-type="doi">10.3389/fpls.2014.00734</pub-id></mixed-citation></ref><ref id="CR172"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mutka</surname><given-names>AM</given-names></name><name><surname>Fentress</surname><given-names>SJ</given-names></name><name><surname>Sher</surname><given-names>JW</given-names></name><name><surname>Berry</surname><given-names>JC</given-names></name><name><surname>Pretz</surname><given-names>C</given-names></name><name><surname>Nusinow</surname><given-names>DA</given-names></name><etal/></person-group><article-title xml:lang="en">Quantitative, image-based phenotyping methods provide insight into spatial and temporal dimensions of plant disease</article-title><source>Plant Physiol.</source><year>2016</year><volume>172</volume><fpage>650</fpage><lpage>660</lpage><pub-id pub-id-type="pmid">27443602</pub-id><pub-id pub-id-type="pmcid">5047107</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28XhvFaktbzM</pub-id></mixed-citation></ref><ref id="CR173"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mwebaze</surname><given-names>E</given-names></name><name><surname>Owomugisha</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Machine learning for plant disease incidence and severity measurements from leaf images</article-title><source>Proceedings of the 15th IEEE international conference on machine learning and applications (ICMLA), Anaheim, USA</source><year>2016</year><fpage>158</fpage><lpage>163</lpage></mixed-citation></ref><ref id="CR174"><mixed-citation publication-type="other">Nagasubramanian K, Jones S, Sarkar S, Singh AK, Singh A. Ganapathysubramanian B. Hyperspectral band selection using genetic algorithm and support vector machines for early identification of charcoal rot disease in soybean. arXiv. 2017; <ext-link xlink:href="https://arxiv.org/ftp/arxiv/papers/1710/1710.04681.pdf" ext-link-type="uri">https://arxiv.org/ftp/arxiv/papers/1710/1710.04681.pdf</ext-link>. (20 pages).</mixed-citation></ref><ref id="CR175"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagasubramanian</surname><given-names>K</given-names></name><name><surname>Jones</surname><given-names>S</given-names></name><name><surname>Singh</surname><given-names>AK</given-names></name><name><surname>Sarkar</surname><given-names>S</given-names></name><name><surname>Singh</surname><given-names>A</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Plant disease identification using explainable 3D deep learning on hyperspectral images</article-title><source>Plant Methods.</source><year>2019</year><volume>15</volume><fpage>98</fpage><pub-id pub-id-type="pmid">31452674</pub-id><pub-id pub-id-type="pmcid">6702735</pub-id><pub-id pub-id-type="doi">10.1186/s13007-019-0479-8</pub-id></mixed-citation></ref><ref id="CR176"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naik</surname><given-names>HS</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Lofquist</surname><given-names>A</given-names></name><name><surname>Assefa</surname><given-names>T</given-names></name><name><surname>Sarkar</surname><given-names>S</given-names></name><name><surname>Ackerman</surname><given-names>D</given-names></name><etal/></person-group><article-title xml:lang="en">A real-time phenotyping framework using machine learning for plant stress severity rating in soybean</article-title><source>Plant Methods.</source><year>2017</year><volume>13</volume><fpage>23</fpage><pub-id pub-id-type="pmid">28405214</pub-id><pub-id pub-id-type="pmcid">5385078</pub-id><pub-id pub-id-type="doi">10.1186/s13007-017-0173-7</pub-id></mixed-citation></ref><ref id="CR177"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newell</surname><given-names>LC</given-names></name><name><surname>Tysdal</surname><given-names>HM</given-names></name></person-group><article-title xml:lang="en">Numbering and note-taking systems for use in improvement of forage crops</article-title><source>J Amer Soc Agron.</source><year>1945</year><volume>37</volume><fpage>736</fpage><lpage>749</lpage><pub-id pub-id-type="doi">10.2134/agronj1945.00021962003700090007x</pub-id></mixed-citation></ref><ref id="CR178"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newton</surname><given-names>AC</given-names></name><name><surname>Hackett</surname><given-names>CA</given-names></name></person-group><article-title xml:lang="en">Subjective components of mildew assessment on spring barley</article-title><source>Eur J Plant Pathol.</source><year>1994</year><volume>100</volume><fpage>395</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1007/BF01874807</pub-id></mixed-citation></ref><ref id="CR179"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nilsson</surname><given-names>H-E</given-names></name></person-group><article-title xml:lang="en">Remote sensing and image analysis in plant pathology</article-title><source>Annu Rev Phytopathol.</source><year>1995</year><volume>15</volume><fpage>489</fpage><lpage>527</lpage><pub-id pub-id-type="doi">10.1146/annurev.py.33.090195.002421</pub-id></mixed-citation></ref><ref id="CR180"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nita</surname><given-names>M</given-names></name><name><surname>Ellis</surname><given-names>MA</given-names></name><name><surname>Madden</surname><given-names>LV</given-names></name></person-group><article-title xml:lang="en">Reliability and accuracy of visual estimation of Phomopsis leaf blight of strawberry</article-title><source>Phytopathology.</source><year>2003</year><volume>93</volume><fpage>995</fpage><lpage>1005</lpage><pub-id pub-id-type="pmid">18943866</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO.2003.93.8.995</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BD1cjkt1Kitw%3D%3D</pub-id><pub-id pub-id-type="pmcid">18943866</pub-id></mixed-citation></ref><ref id="CR181"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nutter</surname><given-names>FW</given-names><suffix>Jr</suffix></name><name><surname>Esker</surname><given-names>PD</given-names></name></person-group><article-title xml:lang="en">The role of psychophysics in phytopathology</article-title><source>Eur J Plant Pathol.</source><year>2006</year><volume>114</volume><fpage>199</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1007/s10658-005-4732-9</pub-id></mixed-citation></ref><ref id="CR182"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nutter</surname><given-names>FW</given-names><suffix>Jr</suffix></name><name><surname>Gleason</surname><given-names>ML</given-names></name><name><surname>Jenco</surname><given-names>JH</given-names></name><name><surname>Christians</surname><given-names>NC</given-names></name></person-group><article-title xml:lang="en">Assessing the accuracy, intra-rater repeatability, and inter-rater reliability of disease assessment systems</article-title><source>Phytopathology.</source><year>1993</year><volume>83</volume><fpage>806</fpage><lpage>812</lpage><pub-id pub-id-type="doi">10.1094/Phyto-83-806</pub-id></mixed-citation></ref><ref id="CR183"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nutter</surname><given-names>FW</given-names><suffix>Jr</suffix></name><name><surname>Litwiller</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">A computer program to generate standard area diagrams to aid raters in assessing disease severity</article-title><source>Phytopathology.</source><year>1998</year><volume>88</volume><fpage>S117</fpage><pub-id pub-id-type="doi">10.1094/PHYTO.1998.88.9.895</pub-id></mixed-citation></ref><ref id="CR184"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nutter</surname><given-names>FW</given-names><suffix>Jr</suffix></name><name><surname>Schultz</surname><given-names>PM</given-names></name></person-group><article-title xml:lang="en">Improving the accuracy and precision of disease assessments: selection of methods and use of computer-aided training programs</article-title><source>Can J Plant Pathol.</source><year>1995</year><volume>17</volume><fpage>174</fpage><lpage>184</lpage><pub-id pub-id-type="doi">10.1080/07060669509500709</pub-id></mixed-citation></ref><ref id="CR185"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nutter</surname><given-names>FW</given-names><suffix>Jr</suffix></name><name><surname>Teng</surname><given-names>PS</given-names></name><name><surname>Shokes</surname><given-names>FM</given-names></name></person-group><article-title xml:lang="en">Disease assessment terms and concepts</article-title><source>Plant Dis.</source><year>1991</year><volume>75</volume><fpage>1187</fpage><lpage>1188</lpage></mixed-citation></ref><ref id="CR186"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Neal</surname><given-names>ME</given-names></name><name><surname>Landis</surname><given-names>DA</given-names></name><name><surname>Isaacs</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">An inexpensive, accurate method for measuring leaf area and defoliation through digital image analysis</article-title><source>J Econ Entomol.</source><year>2002</year><volume>95</volume><fpage>1190</fpage><lpage>1194</lpage><pub-id pub-id-type="pmid">12539831</pub-id><pub-id pub-id-type="doi">10.1603/0022-0493-95.6.1190</pub-id><pub-id pub-id-type="pmcid">12539831</pub-id></mixed-citation></ref><ref id="CR187"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oerke</surname><given-names>E-C</given-names></name></person-group><article-title xml:lang="en">Crop losses to pests</article-title><source>J Agric Sci.</source><year>2006</year><volume>144</volume><fpage>31</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1017/S0021859605005708</pub-id></mixed-citation></ref><ref id="CR188"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oerke</surname><given-names>E-C</given-names></name><name><surname>Herzog</surname><given-names>K</given-names></name><name><surname>Toepfer</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Hyperspectral phenotyping of the reaction of grapevine genotypes to <italic>Plasmopara viticola</italic></article-title><source>J Exp Bot.</source><year>2016</year><volume>67</volume><fpage>5529</fpage><lpage>5543</lpage><pub-id pub-id-type="pmid">27567365</pub-id><pub-id pub-id-type="doi">10.1093/jxb/erw318</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28XhvFSksbbI</pub-id><pub-id pub-id-type="pmcid">27567365</pub-id></mixed-citation></ref><ref id="CR189"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Oerke</surname><given-names>E-C</given-names></name><name><surname>Steiner</surname><given-names>U</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Oerke</surname><given-names>E-C</given-names></name><name><surname>Gerhards</surname><given-names>R</given-names></name><name><surname>Menz</surname><given-names>G</given-names></name><name><surname>Sikora</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Potential of digital thermography for disease control</article-title><source>Precision crop protection-the challenge and use of heterogeneity</source><year>2010</year><publisher-loc>Dordrecht</publisher-loc><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-90-481-9277-9</pub-id></mixed-citation></ref><ref id="CR190"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olmstead</surname><given-names>JW</given-names></name><name><surname>Lang</surname><given-names>GA</given-names></name><name><surname>Grove</surname><given-names>GG</given-names></name></person-group><article-title xml:lang="en">Assessment of severity of powdery mildew infection of sweet cherry leaves by digital image analysis</article-title><source>Hortic Sci.</source><year>2001</year><volume>36</volume><fpage>107</fpage><lpage>111</lpage></mixed-citation></ref><ref id="CR191"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parker</surname><given-names>SR</given-names></name><name><surname>Shaw</surname><given-names>MW</given-names></name><name><surname>Royle</surname><given-names>DJ</given-names></name></person-group><article-title xml:lang="en">The reliability of visual estimates of disease severity on cereal leaves</article-title><source>Plant Pathol.</source><year>1995</year><volume>44</volume><fpage>856</fpage><lpage>864</lpage><pub-id pub-id-type="doi">10.1111/j.1365-3059.1995.tb02745.x</pub-id></mixed-citation></ref><ref id="CR192"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parker</surname><given-names>SR</given-names></name><name><surname>Shaw</surname><given-names>MW</given-names></name><name><surname>Royle</surname><given-names>DJ</given-names></name></person-group><article-title xml:lang="en">Reliable measurement of disease severity</article-title><source>Asp Appl Biol.</source><year>1995</year><volume>43</volume><fpage>205</fpage><lpage>214</lpage></mixed-citation></ref><ref id="CR193"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patil</surname><given-names>SB</given-names></name><name><surname>Bodhe</surname><given-names>SK</given-names></name></person-group><article-title xml:lang="en">Leaf disease severity measurement using image processing</article-title><source>Int J Engin Tech.</source><year>2011</year><volume>3</volume><fpage>297</fpage><lpage>301</lpage><pub-id pub-id-type="doi">10.7763/IJET.2011.V3.241</pub-id></mixed-citation></ref><ref id="CR194"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paul</surname><given-names>PA</given-names></name><name><surname>El-Allaf</surname><given-names>SM</given-names></name><name><surname>Lipps</surname><given-names>PE</given-names></name><name><surname>Madden</surname><given-names>LV</given-names></name></person-group><article-title xml:lang="en">Relationships between incidence and severity of Fusarium head blight on winter wheat in Ohio</article-title><source>Phytopathology.</source><year>2005</year><volume>95</volume><fpage>1049</fpage><lpage>1060</lpage><pub-id pub-id-type="pmid">18943303</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-95-1049</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BD1cjks1Wgug%3D%3D</pub-id><pub-id pub-id-type="pmcid">18943303</pub-id></mixed-citation></ref><ref id="CR195"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedroso</surname><given-names>C</given-names></name><name><surname>Lage</surname><given-names>DAC</given-names></name><name><surname>Henz</surname><given-names>GP</given-names></name><name><surname>Café-Filho</surname><given-names>AC</given-names></name></person-group><article-title xml:lang="en">Development and validation of a diagrammatic scale for estimation of anthracnose on sweet pepper fruits for epidemiological studies</article-title><source>J Plant Pathol.</source><year>2011</year><volume>93</volume><fpage>219</fpage><lpage>225</lpage></mixed-citation></ref><ref id="CR196"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peressotti</surname><given-names>E</given-names></name><name><surname>Duchêne</surname><given-names>E</given-names></name><name><surname>Merdinoglu</surname><given-names>D</given-names></name><name><surname>Mestre</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">A semiautomatic non-destructive method to quantify grapevine downy mildew sporulation</article-title><source>J Microbiol Methods.</source><year>2011</year><volume>84</volume><fpage>265</fpage><lpage>271</lpage><pub-id pub-id-type="pmid">21167874</pub-id><pub-id pub-id-type="doi">10.1016/j.mimet.2010.12.009</pub-id><pub-id pub-id-type="pmcid">21167874</pub-id></mixed-citation></ref><ref id="CR197"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pethybridge</surname><given-names>SJ</given-names></name><name><surname>Nelson</surname><given-names>SC</given-names></name></person-group><article-title xml:lang="en">Leaf doctor: a new portable application for quantifying plant disease severity</article-title><source>Plant Dis.</source><year>2015</year><volume>99</volume><fpage>1310</fpage><lpage>1316</lpage><pub-id pub-id-type="pmid">30690990</pub-id><pub-id pub-id-type="doi">10.1094/PDIS-03-15-0319-RE</pub-id><pub-id pub-id-type="pmcid">30690990</pub-id></mixed-citation></ref><ref id="CR198"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Price</surname><given-names>TV</given-names></name><name><surname>Gross</surname><given-names>R</given-names></name><name><surname>Wey</surname><given-names>JH</given-names></name><name><surname>Osborne</surname><given-names>CF</given-names></name></person-group><article-title xml:lang="en">A comparison of visual and digital image-processing methods in quantifying the severity of coffee leaf rust (<italic>Hemileia vastatrix</italic>)</article-title><source>Aust J Exp Agric.</source><year>1993</year><volume>33</volume><fpage>97</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1071/EA9930097</pub-id></mixed-citation></ref><ref id="CR199"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramcharan</surname><given-names>A</given-names></name><name><surname>McCloskey</surname><given-names>P</given-names></name><name><surname>Baronowski</surname><given-names>K</given-names></name><name><surname>Mbiliyni</surname><given-names>N</given-names></name><name><surname>Mrisho</surname><given-names>L</given-names></name><name><surname>Ndalawha</surname><given-names>M</given-names></name><etal/></person-group><article-title xml:lang="en">A mobile-based deep learning model for cassava disease diagnosis</article-title><source>Front Plant Sci.</source><year>2019</year><volume>10</volume><fpage>272</fpage><pub-id pub-id-type="pmid">30949185</pub-id><pub-id pub-id-type="pmcid">6436463</pub-id><pub-id pub-id-type="doi">10.3389/fpls.2019.00272</pub-id></mixed-citation></ref><ref id="CR200"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rioux</surname><given-names>RA</given-names></name><name><surname>Van Ryzin</surname><given-names>BJ</given-names></name><name><surname>Kerns</surname><given-names>JP</given-names></name></person-group><article-title xml:lang="en">Brachypodium: a potential model host for fungal pathogens of turfgrasses</article-title><source>Phytopathology.</source><year>2017</year><volume>107</volume><fpage>749</fpage><lpage>757</lpage><pub-id pub-id-type="pmid">28134592</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-08-16-0318-R</pub-id></mixed-citation></ref><ref id="CR201"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rouse</surname><given-names>JW</given-names></name><name><surname>Haas</surname><given-names>RH</given-names></name><name><surname>Schell</surname><given-names>JA</given-names></name><name><surname>Deering</surname><given-names>DW</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Freden</surname><given-names>SC</given-names></name><name><surname>Mercanti</surname><given-names>EP</given-names></name><name><surname>Becker</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Monitoring vegetation systems in the Great Plains with ERTS</article-title><source>Third earth resources technology satellite–1 syposium NASA, NASA SP-351, Washington DC</source><year>1974</year><fpage>309</fpage><lpage>317</lpage></mixed-citation></ref><ref id="CR202"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumpf</surname><given-names>T</given-names></name><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Steiner</surname><given-names>U</given-names></name><name><surname>Oerke</surname><given-names>E-C</given-names></name><name><surname>Dehne</surname><given-names>H-W</given-names></name><name><surname>Plümer</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Early detection and classification of plant diseases with support vector machines based on hyperspectral reflectance</article-title><source>Comput Electron Agric.</source><year>2010</year><volume>74</volume><fpage>91</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2010.06.009</pub-id></mixed-citation></ref><ref id="CR203"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sankaran</surname><given-names>S</given-names></name><name><surname>Mishra</surname><given-names>A</given-names></name><name><surname>Ehsani</surname><given-names>R</given-names></name><name><surname>Davis</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">A review of advanced techniques for detecting plant diseases</article-title><source>Comput Electron Agric.</source><year>2010</year><volume>72</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2010.02.007</pub-id></mixed-citation></ref><ref id="CR204"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savary</surname><given-names>S</given-names></name><name><surname>Bregaglio</surname><given-names>S</given-names></name><name><surname>Willocquet</surname><given-names>L</given-names></name><name><surname>Gustafson</surname><given-names>D</given-names></name><name><surname>Mason D’Croz</surname><given-names>D</given-names></name><name><surname>Sparks</surname><given-names>A</given-names></name><etal/></person-group><article-title xml:lang="en">Crop health and its global impacts on the components of food security</article-title><source>Food Secur.</source><year>2017</year><volume>9</volume><fpage>311</fpage><lpage>327</lpage><pub-id pub-id-type="doi">10.1007/s12571-017-0659-1</pub-id></mixed-citation></ref><ref id="CR205"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savary</surname><given-names>S</given-names></name><name><surname>Ficke</surname><given-names>A</given-names></name><name><surname>Aubertot</surname><given-names>J-N</given-names></name><name><surname>Hollier</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Crop losses due to diseases and their implications for global food production losses and food security</article-title><source>Food Secur.</source><year>2012</year><volume>4</volume><fpage>519</fpage><lpage>537</lpage><pub-id pub-id-type="doi">10.1007/s12571-012-0200-5</pub-id></mixed-citation></ref><ref id="CR206"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwanck</surname><given-names>AA</given-names></name><name><surname>Del Ponte</surname><given-names>EM</given-names></name></person-group><article-title xml:lang="en">Accuracy and reliability of severity estimates using linear or logarithmic disease diagram sets in true colour or black and white: a study case for rice brown spot</article-title><source>J Phytopathol.</source><year>2014</year><volume>162</volume><fpage>670</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1111/jph.12246</pub-id></mixed-citation></ref><ref id="CR207"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seelig</surname><given-names>H-D</given-names></name><name><surname>Hoehn</surname><given-names>A</given-names></name><name><surname>Stodieck</surname><given-names>LS</given-names></name><name><surname>Klaus</surname><given-names>DM</given-names></name><name><surname>Adams</surname><given-names>WW</given-names><suffix>III</suffix></name><name><surname>Emery</surname><given-names>WJ</given-names></name></person-group><article-title xml:lang="en">The assessment of leaf water content using leaf reflectance ratios in the visible, near-, and short-wave-infrared</article-title><source>Int J Remote Sens.</source><year>2008</year><volume>29</volume><fpage>3701</fpage><lpage>3713</lpage><pub-id pub-id-type="doi">10.1080/01431160701772500</pub-id></mixed-citation></ref><ref id="CR208"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shah</surname><given-names>DA</given-names></name><name><surname>Madden</surname><given-names>LV</given-names></name></person-group><article-title xml:lang="en">Nonparametric analysis of ordinal data in designed factorial experiments</article-title><source>Phytopathology.</source><year>2004</year><volume>94</volume><fpage>33</fpage><lpage>43</lpage><pub-id pub-id-type="pmid">18943817</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO.2004.94.1.33</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BD1cjks1ertQ%3D%3D</pub-id></mixed-citation></ref><ref id="CR209"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherwood</surname><given-names>RT</given-names></name><name><surname>Berg</surname><given-names>CC</given-names></name><name><surname>Hoover</surname><given-names>MR</given-names></name><name><surname>Zeiders</surname><given-names>KE</given-names></name></person-group><article-title xml:lang="en">Illusions in visual assessment of Stagonospora leaf spot of orchard grass</article-title><source>Phytopathology.</source><year>1983</year><volume>73</volume><fpage>173</fpage><lpage>177</lpage><pub-id pub-id-type="doi">10.1094/Phyto-73-173</pub-id></mixed-citation></ref><ref id="CR210"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shrivastava</surname><given-names>S</given-names></name><name><surname>Singh</surname><given-names>SK</given-names></name><name><surname>Hooda</surname><given-names>DS</given-names></name></person-group><article-title xml:lang="en">Color sensing and image processing-based automatic soybean plant foliar disease severity detection and estimation</article-title><source>Multimed Tools Appl.</source><year>2015</year><volume>74</volume><fpage>11467</fpage><lpage>11484</lpage><pub-id pub-id-type="doi">10.1007/s11042-014-2239-0</pub-id><comment>https://doi.org/10.1007/s11042-014-2239-0</comment></mixed-citation></ref><ref id="CR211"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sibiya</surname><given-names>M</given-names></name><name><surname>Sumbwanyambe</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">An algorithm for severity estimation of plant leaf diseases by the use of colour threshold image segmentation and fuzzy logic inference: a proposed algorithm to update a “leaf doctor” application</article-title><source>AgriEngineering.</source><year>2019</year><volume>1</volume><fpage>205</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.3390/agriengineering1020015</pub-id></mixed-citation></ref><ref id="CR212"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silvertown</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">A new dawn for citizen science</article-title><source>Trends Ecol Evol.</source><year>2009</year><volume>24</volume><fpage>467</fpage><lpage>471</lpage><pub-id pub-id-type="pmid">19586682</pub-id><pub-id pub-id-type="doi">10.1016/j.tree.2009.03.017</pub-id></mixed-citation></ref><ref id="CR213"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simko</surname><given-names>I</given-names></name><name><surname>Jimenez-Berni</surname><given-names>JA</given-names></name><name><surname>Sirault</surname><given-names>XRR</given-names></name></person-group><article-title xml:lang="en">Phenomic approaches and tools for phytopathologists</article-title><source>Phytopathology.</source><year>2017</year><volume>107</volume><fpage>6</fpage><lpage>17</lpage><pub-id pub-id-type="pmid">27618193</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-02-16-0082-RVW</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXjs1yktr0%3D</pub-id></mixed-citation></ref><ref id="CR214"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>A</given-names></name><name><surname>Ganapathysubramanian</surname><given-names>B</given-names></name><name><surname>Singh</surname><given-names>AK</given-names></name><name><surname>Sarkar</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Machine learning for high-throughput stress phenotyping in plants</article-title><source>Trends Plant Sci.</source><year>2016</year><volume>21</volume><issue>2</issue><fpage>110</fpage><lpage>124</lpage><pub-id pub-id-type="pmid">26651918</pub-id><pub-id pub-id-type="doi">10.1016/j.tplants.2015.10.015</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXhvVykurvJ</pub-id></mixed-citation></ref><ref id="CR215"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Škaloudová</surname><given-names>B</given-names></name><name><surname>Křivan</surname><given-names>V</given-names></name><name><surname>Zemek</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Computer-assisted estimation of leaf damage caused by spider mites</article-title><source>Comput Electron Agric.</source><year>2006</year><volume>53</volume><fpage>81</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1016/j.compag.2006.04.002</pub-id></mixed-citation></ref><ref id="CR216"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spolti</surname><given-names>P</given-names></name><name><surname>Schneider</surname><given-names>L</given-names></name><name><surname>Sanhueza</surname><given-names>RMV</given-names></name><name><surname>Batzer</surname><given-names>JC</given-names></name><name><surname>Gleason</surname><given-names>ML</given-names></name><name><surname>Del Ponte</surname><given-names>EM</given-names></name></person-group><article-title xml:lang="en">Improving sooty blotch and flyspeck severity estimation on apple fruit with the aid of standard area diagrams</article-title><source>Eur J Plant Pathol.</source><year>2011</year><volume>129</volume><fpage>21</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1007/s10658-010-9636-7</pub-id></mixed-citation></ref><ref id="CR217"><mixed-citation publication-type="other">Steddom K, McMullen M, Schatz B, Rush CM. Comparing image format and resolution for assessment of foliar diseases of wheat. Plant Health Prog. 2005; <ext-link xlink:href="10.1094/PHP-2005-0516-01-RS" ext-link-type="doi">https://doi.org/10.1094/PHP-2005-0516-01-RS</ext-link>.</mixed-citation></ref><ref id="CR218"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stevens</surname><given-names>SS</given-names></name></person-group><article-title xml:lang="en">On the theory of scales of measurement</article-title><source>Science.</source><year>1946</year><volume>103</volume><fpage>677</fpage><lpage>680</lpage><pub-id pub-id-type="pmid">20984256</pub-id><pub-id pub-id-type="doi">10.1126/science.103.2684.677</pub-id></mixed-citation></ref><ref id="CR219"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stewart</surname><given-names>EL</given-names></name><name><surname>Hagerty</surname><given-names>CH</given-names></name><name><surname>Mikaberidze</surname><given-names>A</given-names></name><name><surname>Mundt</surname><given-names>CC</given-names></name><name><surname>Zhong</surname><given-names>Z</given-names></name><name><surname>McDonald</surname><given-names>BA</given-names></name></person-group><article-title xml:lang="en">An improved method for measuring quantitative resistance to the wheat pathogen <italic>Zymoseptoria tritici</italic> using high-throughput automated image analysis</article-title><source>Phytopathology.</source><year>2016</year><volume>106</volume><fpage>782</fpage><lpage>788</lpage><pub-id pub-id-type="pmid">27050574</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-01-16-0018-R</pub-id></mixed-citation></ref><ref id="CR220"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stewart</surname><given-names>EL</given-names></name><name><surname>McDonald</surname><given-names>BA</given-names></name></person-group><article-title xml:lang="en">Measuring quantitative virulence in the wheat pathogen <italic>Zymoseptoria tritici</italic> using high-throughput automated image analysis</article-title><source>Phytopathology.</source><year>2014</year><volume>104</volume><fpage>985</fpage><lpage>992</lpage><pub-id pub-id-type="pmid">24624955</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-11-13-0328-R</pub-id></mixed-citation></ref><ref id="CR221"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strange</surname><given-names>RN</given-names></name><name><surname>Scott</surname><given-names>PR</given-names></name></person-group><article-title xml:lang="en">Plant disease: a threat to global food security</article-title><source>Annu Rev Phytopathol.</source><year>2005</year><volume>43</volume><fpage>83</fpage><lpage>116</lpage><pub-id pub-id-type="pmid">16078878</pub-id><pub-id pub-id-type="doi">10.1146/annurev.phyto.43.113004.133839</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD2MXhtVOksr3O</pub-id></mixed-citation></ref><ref id="CR222"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Strayer-Scherer</surname><given-names>A</given-names></name><name><surname>Liao</surname><given-names>YY</given-names></name><name><surname>Young</surname><given-names>M</given-names></name><name><surname>Ritchie</surname><given-names>L</given-names></name><name><surname>Vallad</surname><given-names>GE</given-names></name><name><surname>Santra</surname><given-names>S</given-names></name><etal/></person-group><article-title xml:lang="en">Advanced copper composites against copper-tolerant <italic>Xanthomonas perforans</italic> and tomato bacterial spot</article-title><source>Phytopathology.</source><year>2018</year><volume>108</volume><fpage>196</fpage><lpage>205</lpage><pub-id pub-id-type="pmid">28990482</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-06-17-0221-R</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXhtlOjt7Y%3D</pub-id></mixed-citation></ref><ref id="CR223"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugiura</surname><given-names>R</given-names></name><name><surname>Tsuda</surname><given-names>S</given-names></name><name><surname>Tamiya</surname><given-names>S</given-names></name><name><surname>Itoh</surname><given-names>A</given-names></name><name><surname>Nishiwaki</surname><given-names>K</given-names></name><name><surname>Murakami</surname><given-names>N</given-names></name><etal/></person-group><article-title xml:lang="en">Field phenotyping system for the assessment of potato late blight resistance using RGB imagery from an unmanned aerial vehicle</article-title><source>Biosyst Eng.</source><year>2016</year><volume>148</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1016/j.biosystemseng.2016.04.010</pub-id></mixed-citation></ref><ref id="CR224"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>H</given-names></name><name><surname>Wei</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Yang</surname><given-names>W</given-names></name></person-group><article-title xml:lang="en">A comparison of disease severity measurements using image analysis and visual estimates using a category scale for genetic analysis of resistance to bacterial spot in tomato</article-title><source>Eur J Plant Pathol.</source><year>2014</year><volume>139</volume><fpage>125</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1007/s10658-013-0371-8</pub-id></mixed-citation></ref><ref id="CR225"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suomalainen</surname><given-names>J</given-names></name><name><surname>Anders</surname><given-names>N</given-names></name><name><surname>Iqbal</surname><given-names>S</given-names></name><name><surname>Roerink</surname><given-names>G</given-names></name><name><surname>Franke</surname><given-names>J</given-names></name><name><surname>Wenting</surname><given-names>P</given-names></name><etal/></person-group><article-title xml:lang="en">A lightweight hyperspectral mapping system and photogrammetric processing chain for unmanned aerial vehicles</article-title><source>Remote Sens.</source><year>2014</year><volume>6</volume><fpage>11013</fpage><lpage>11030</lpage><pub-id pub-id-type="doi">10.3390/rs61111013</pub-id></mixed-citation></ref><ref id="CR226"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>S</given-names></name><name><surname>Behmann</surname><given-names>J</given-names></name><name><surname>Steier</surname><given-names>A</given-names></name><name><surname>Kraska</surname><given-names>T</given-names></name><name><surname>Muller</surname><given-names>O</given-names></name><name><surname>Rascher</surname><given-names>U</given-names></name><etal/></person-group><article-title xml:lang="en">Quantitative assessment of disease severity and rating of barley cultivars based on hyperspectral imaging in a non-invasive, automated phenotyping platform</article-title><source>Plant Methods.</source><year>2018</year><volume>14</volume><fpage>45</fpage><pub-id pub-id-type="pmid">29930695</pub-id><pub-id pub-id-type="pmcid">5994119</pub-id><pub-id pub-id-type="doi">10.1186/s13007-018-0313-8</pub-id></mixed-citation></ref><ref id="CR227"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>S</given-names></name><name><surname>Kuska</surname><given-names>MT</given-names></name><name><surname>Bohnenkamp</surname><given-names>D</given-names></name><name><surname>Brugger</surname><given-names>A</given-names></name><name><surname>Alisaac</surname><given-names>E</given-names></name><name><surname>Wahabzada</surname><given-names>M</given-names></name><etal/></person-group><article-title xml:lang="en">Benefits of hyperspectral imaging for plant disease detection and plant protection: a technical perspective</article-title><source>J Plant Dis Protect.</source><year>2018</year><volume>125</volume><fpage>5</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1007/s41348-017-0124-6</pub-id></mixed-citation></ref><ref id="CR228"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>S</given-names></name><name><surname>Wahabzada</surname><given-names>M</given-names></name><name><surname>Kuska</surname><given-names>MT</given-names></name><name><surname>Rascher</surname><given-names>U</given-names></name><name><surname>Mahlein</surname><given-names>A-K</given-names></name></person-group><article-title xml:lang="en">Observation of plant-pathogen interaction by simultaneous hyperspectral imaging reflection and transmission measurements</article-title><source>Funct Plant Biol.</source><year>2017</year><volume>44</volume><fpage>23</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1071/FP16127</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28XitFSmt7%2FI</pub-id></mixed-citation></ref><ref id="CR229"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomerlin</surname><given-names>JR</given-names></name><name><surname>Howell</surname><given-names>TA</given-names></name></person-group><article-title xml:lang="en">DISTRAIN: a computer program for training people to estimate disease severity on cereal leaves</article-title><source>Plant Dis.</source><year>1988</year><volume>72</volume><fpage>455</fpage><lpage>459</lpage></mixed-citation></ref><ref id="CR230"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tucker</surname><given-names>CC</given-names></name><name><surname>Chakraborty</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Quantitative assessment of lesion characteristics and disease severity using digital image processing</article-title><source>J Phytopathol.</source><year>1997</year><volume>145</volume><fpage>273</fpage><lpage>278</lpage><pub-id pub-id-type="doi">10.1111/j.1439-0434.1997.tb00400.x</pub-id></mixed-citation></ref><ref id="CR231"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tucker</surname><given-names>CJ</given-names></name><name><surname>Dregne</surname><given-names>HE</given-names></name><name><surname>Newcomb</surname><given-names>WW</given-names></name></person-group><article-title xml:lang="en">Expansion and contraction of the Sahara Desert from 1980 to 1990</article-title><source>Science.</source><year>1991</year><volume>253</volume><fpage>299</fpage><lpage>301</lpage><pub-id pub-id-type="pmid">17794695</pub-id><pub-id pub-id-type="doi">10.1126/science.253.5017.299</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BC3cvjsVGrtA%3D%3D</pub-id><pub-id pub-id-type="pmcid">17794695</pub-id></mixed-citation></ref><ref id="CR232"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vale</surname><given-names>FXR</given-names></name><name><surname>Fernandes-Filho</surname><given-names>EI</given-names></name><name><surname>Liberato</surname><given-names>JR</given-names></name></person-group><article-title xml:lang="en">QUANT: a software for plant disease severity assessment. P 105</article-title><source>Proceedings of the 8th International Congress of Plant Pathology, 2-7 February 2003, Christchurch, New Zealand</source><year>2003</year><publisher-loc>Sydney</publisher-loc><publisher-name>Published by Horticulture Australia</publisher-name></mixed-citation></ref><ref id="CR233"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vieira</surname><given-names>RF</given-names></name><name><surname>Paula Júnior</surname><given-names>TJ</given-names></name><name><surname>Carneiro</surname><given-names>JES</given-names></name><name><surname>Teixeira</surname><given-names>H</given-names></name><name><surname>Queiroz</surname><given-names>TFN</given-names></name></person-group><article-title xml:lang="en">Management of white mold in type III common bean with plant spacing and fungicide</article-title><source>Trop Plant Pathol.</source><year>2012</year><volume>37</volume><fpage>95</fpage><lpage>101</lpage></mixed-citation></ref><ref id="CR234"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virlet</surname><given-names>N</given-names></name><name><surname>Sabermanesh</surname><given-names>K</given-names></name><name><surname>Sadeghi-Tehran</surname><given-names>P</given-names></name><name><surname>Hawkesford</surname><given-names>MJ</given-names></name></person-group><article-title xml:lang="en">Field Scanalyzer: an automated robotic field phenotyping platform for detailed crop monitoring</article-title><source>Funct Plant Biol.</source><year>2017</year><volume>44</volume><fpage>143</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1071/FP16163</pub-id></mixed-citation></ref><ref id="CR235"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wahabzada</surname><given-names>M</given-names></name><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Bauckhage</surname><given-names>C</given-names></name><name><surname>Steiner</surname><given-names>U</given-names></name><name><surname>Oerke</surname><given-names>E-C</given-names></name><name><surname>Kersting</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Metro maps of plant disease dynamics--automated mining of differences using hyperspectral images</article-title><source>PLoS One.</source><year>2015</year><volume>10</volume><fpage>e0116902</fpage><pub-id pub-id-type="pmid">25621489</pub-id><pub-id pub-id-type="pmcid">4306502</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0116902</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXht12itL3F</pub-id></mixed-citation></ref><ref id="CR236"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wahabzada</surname><given-names>M</given-names></name><name><surname>Mahlein</surname><given-names>A-K</given-names></name><name><surname>Bauckhage</surname><given-names>C</given-names></name><name><surname>Steiner</surname><given-names>U</given-names></name><name><surname>Oerke</surname><given-names>E-C</given-names></name><name><surname>Kersting</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Plant phenotyping using probabilistic topic models: uncovering the hyperspectral language of plants</article-title><source>Sci Rep.</source><year>2016</year><volume>6</volume><fpage>22482</fpage><pub-id pub-id-type="pmid">26957018</pub-id><pub-id pub-id-type="pmcid">4783663</pub-id><pub-id pub-id-type="doi">10.1038/srep22482</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC28XktVaitbo%3D</pub-id></mixed-citation></ref><ref id="CR237"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walter</surname><given-names>A</given-names></name><name><surname>Liebisch</surname><given-names>F</given-names></name><name><surname>Hund</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Plant phenotyping: from bean weighing to image analysis</article-title><source>Plant Methods.</source><year>2015</year><volume>11</volume><fpage>14</fpage><pub-id pub-id-type="pmid">25767559</pub-id><pub-id pub-id-type="pmcid">4357161</pub-id><pub-id pub-id-type="doi">10.1186/s13007-015-0056-8</pub-id></mixed-citation></ref><ref id="CR238"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>G</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Automatic image-based plant disease severity estimation using deep learning</article-title><source>Comput intell Neurosci.</source><year>2017</year><volume>2017</volume><fpage>2917536</fpage><pub-id pub-id-type="pmid">28757863</pub-id><pub-id pub-id-type="pmcid">5516765</pub-id><comment>https://doi.org/10.1155/2017/2917536</comment></mixed-citation></ref><ref id="CR239"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Qin</surname><given-names>F</given-names></name><name><surname>Ruan</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>R</given-names></name><name><surname>Liu</surname><given-names>Q</given-names></name><etal/></person-group><article-title xml:lang="en">Identification and severity determination of wheat stripe rust and wheat leaf rust based on hyperspectral data acquired using a black-paper-based measuring method</article-title><source>PLoS One</source><year>2016</year><volume>11</volume><fpage>e0154648</fpage><pub-id pub-id-type="pmid">27128464</pub-id><pub-id pub-id-type="pmcid">4851363</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0154648</pub-id></mixed-citation></ref><ref id="CR240"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wendel</surname><given-names>A</given-names></name><name><surname>Underwood</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Illumination compensation in ground based hyperspectral imaging</article-title><source>ISPRS J Photogramm Remote Sens.</source><year>2017</year><volume>129</volume><fpage>162</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1016/j.isprsjprs.2017.04.010</pub-id></mixed-citation></ref><ref id="CR241"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>West</surname><given-names>J</given-names></name><name><surname>Bravo</surname><given-names>C</given-names></name><name><surname>Oberti</surname><given-names>R</given-names></name><name><surname>Lemaire</surname><given-names>D</given-names></name><name><surname>Moshou</surname><given-names>D</given-names></name><name><surname>McCartney</surname><given-names>HA</given-names></name></person-group><article-title xml:lang="en">The potential of optical canopy measurement for targeted control of field crop diseases</article-title><source>Annu Rev Phytopathol.</source><year>2003</year><volume>41</volume><fpage>593</fpage><lpage>614</lpage><pub-id pub-id-type="pmid">12730386</pub-id><pub-id pub-id-type="doi">10.1146/annurev.phyto.41.121702.103726</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BD3sXptFWltr8%3D</pub-id></mixed-citation></ref><ref id="CR242"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiesner-Hanks</surname><given-names>T</given-names></name><name><surname>Stewart</surname><given-names>EL</given-names></name><name><surname>Kaczmar</surname><given-names>N</given-names></name><name><surname>DeChant</surname><given-names>C</given-names></name><name><surname>Wu</surname><given-names>H</given-names></name><name><surname>Nelson</surname><given-names>RJ</given-names></name><etal/></person-group><article-title xml:lang="en">Image set for deep learning: field images of maize annotated with disease symptoms</article-title><source>BMC Res Notes.</source><year>2018</year><volume>11</volume><fpage>440</fpage><pub-id pub-id-type="pmid">29970178</pub-id><pub-id pub-id-type="pmcid">6030791</pub-id><pub-id pub-id-type="doi">10.1186/s13104-018-3548-6</pub-id></mixed-citation></ref><ref id="CR243"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wijekoon</surname><given-names>CP</given-names></name><name><surname>Goodwin</surname><given-names>PH</given-names></name><name><surname>Hsiang</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">Quantifying fungal infection of plant leaves by digital image analysis using Scion image software</article-title><source>J Microbiol Methods.</source><year>2008</year><volume>74</volume><fpage>94</fpage><lpage>101</lpage><pub-id pub-id-type="pmid">18466990</pub-id><pub-id pub-id-type="doi">10.1016/j.mimet.2008.03.008</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BD1czpsFKhsg%3D%3D</pub-id></mixed-citation></ref><ref id="CR244"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>W</given-names></name><name><surname>Yu</surname><given-names>K</given-names></name><name><surname>Pauls</surname><given-names>KP</given-names></name><name><surname>Navabi</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Application of image analysis in studies of quantitative disease resistance, exemplified using common bacterial blight–common bean pathosystem</article-title><source>Phytopathology.</source><year>2012</year><volume>102</volume><fpage>434</fpage><lpage>442</lpage><pub-id pub-id-type="pmid">22204655</pub-id><pub-id pub-id-type="doi">10.1094/PHYTO-06-11-0175</pub-id></mixed-citation></ref><ref id="CR245"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>W</given-names></name><name><surname>Haynes</surname><given-names>KG</given-names></name><name><surname>Qu</surname><given-names>X</given-names></name></person-group><article-title xml:lang="en">Characterization of early blight resistance in potato cultivars</article-title><source>Plant Dis.</source><year>2019</year><volume>103</volume><fpage>629</fpage><lpage>637</lpage><pub-id pub-id-type="doi">10.1094/PDIS-05-18-0794-RE</pub-id></mixed-citation></ref><ref id="CR246"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yadav</surname><given-names>NVS</given-names></name><name><surname>de Vos</surname><given-names>SM</given-names></name><name><surname>Bock</surname><given-names>CH</given-names></name><name><surname>Wood</surname><given-names>BW</given-names></name></person-group><article-title xml:lang="en">Development and validation of standard area diagrams to aid assessment of pecan scab symptoms on fruit</article-title><source>Plant Pathol.</source><year>2013</year><volume>62</volume><fpage>325</fpage><lpage>335</lpage><pub-id pub-id-type="doi">10.1111/j.1365-3059.2012.02641.x</pub-id></mixed-citation></ref><ref id="CR247"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>D</given-names></name><name><surname>Zhou</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Lan</surname><given-names>Y</given-names></name><name><surname>Xu</surname><given-names>C</given-names></name><name><surname>Liang</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Detection of rice sheath blight using an unmanned aerial system with high-resolution color and multispectral imaging</article-title><source>PLoS One.</source><year>2018</year><volume>13</volume><fpage>e0187470</fpage><pub-id pub-id-type="pmid">29746473</pub-id><pub-id pub-id-type="pmcid">5945033</pub-id><pub-id pub-id-type="doi">10.1371/journal.pone.0187470</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXit1ektb3P</pub-id></mixed-citation></ref><ref id="CR248"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J-H</given-names></name><name><surname>Kong</surname><given-names>F-T</given-names></name><name><surname>Wu</surname><given-names>J-Z</given-names></name><name><surname>Han</surname><given-names>S-Q</given-names></name><name><surname>Zhai</surname><given-names>Z-F</given-names></name></person-group><article-title xml:lang="en">Automatic image segmentation method for cotton leaves with disease under natural environment</article-title><source>J Integr Agric.</source><year>2018</year><volume>17</volume><fpage>1800</fpage><lpage>1814</lpage><pub-id pub-id-type="doi">10.1016/S2095-3119(18)61915-X</pub-id></mixed-citation></ref><ref id="CR249"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>You</surname><given-names>Z</given-names></name><name><surname>Wu</surname><given-names>X</given-names></name></person-group><article-title xml:lang="en">Plant disease leaf image segmentation based on superpixel clustering and EM algorithm</article-title><source>Neural Comput &amp; Applic.</source><year>2019</year><volume>31</volume><fpage>S1225</fpage><lpage>S1232</lpage><pub-id pub-id-type="doi">10.1007/s00521-017-3067-8</pub-id></mixed-citation></ref><ref id="CR250"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Y</given-names></name><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>Qin</surname><given-names>F</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Ma</surname><given-names>Z</given-names></name><name><surname>Zhao</surname><given-names>L</given-names></name><etal/></person-group><article-title xml:lang="en">Application of near-infrared spectroscopy to quantitatively determine relative content of <italic>Puccnia striiformis</italic> f. sp. <italic>tritici</italic> DNA in wheat leaves in incubation period</article-title><source>J Spectrosc</source><year>2017</year><volume>2017</volume><fpage>9740295</fpage><comment>https://doi.org/10.1155/2017/9740295</comment></mixed-citation></ref><ref id="CR251"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>Q</given-names></name><name><surname>Huang</surname><given-names>W</given-names></name><name><surname>Cui</surname><given-names>X</given-names></name><name><surname>Shi</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">New spectral index for detecting wheat yellow rust using Sentinel-2 multispectral imagery</article-title><source>Sensors.</source><year>2018</year><volume>18</volume><fpage>868</fpage><pub-id pub-id-type="doi">10.3390/s18030868</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXisVWgurrM</pub-id></mixed-citation></ref><ref id="CR252"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Z</given-names></name><name><surname>Zang</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>P</given-names></name><name><surname>Luo</surname><given-names>X</given-names></name></person-group><article-title xml:lang="en">Rice plant-hopper infestation detection and classification algorithms based on fractal dimension values and fuzzy C-means</article-title><source>Math Comput Model.</source><year>2013</year><volume>58</volume><fpage>701</fpage><lpage>709</lpage><pub-id pub-id-type="doi">10.1016/j.mcm.2011.10.028</pub-id></mixed-citation></ref><ref id="CR253"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>H</given-names></name><name><surname>Chu</surname><given-names>B</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name><name><surname>Jiang</surname><given-names>L</given-names></name><name><surname>He</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Hyperspectral imaging for presymptomatic detection of tobacco disease with successive projections algorithm and machine-learning classifiers</article-title><source>Sci Rep.</source><year>2017</year><volume>7</volume><fpage>4125</fpage><pub-id pub-id-type="pmid">28646177</pub-id><pub-id pub-id-type="pmcid">5482814</pub-id><pub-id pub-id-type="doi">10.1038/s41598-017-04501-2</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXhtlKgtL%2FL</pub-id></mixed-citation></ref></ref-list></ref-list></back></article></records><facets><facet name="subject"><facet-value count="1">Life Sciences</facet-value><facet-value count="1">Plant Pathology</facet-value><facet-value count="1">Plant Sciences</facet-value></facet><facet name="keyword"><facet-value count="1">Accuracy</facet-value><facet-value count="1">Artificial intelligence</facet-value><facet-value count="1">Assessment</facet-value><facet-value count="1">Deep learning</facet-value><facet-value count="1">Digital technologies</facet-value><facet-value count="1">Disease severity</facet-value><facet-value count="1">Machine learning</facet-value><facet-value count="1">Mobile device</facet-value><facet-value count="1">Phenotyping</facet-value><facet-value count="1">Precision</facet-value><facet-value count="1">Precision agriculture</facet-value><facet-value count="1">Sensor</facet-value></facet><facet name="pub"><facet-value count="1">Phytopathology Research</facet-value></facet><facet name="year"><facet-value count="1">2020</facet-value></facet><facet name="country"><facet-value count="1">Brazil</facet-value><facet-value count="1">Germany</facet-value><facet-value count="1">United States</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
