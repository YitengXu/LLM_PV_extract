<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1038/s41467-020-19117-w</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="research-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">41467</journal-id><journal-id journal-id-type="doi">10.1038/41467.2041-1723</journal-id><journal-title-group><journal-title>Nature Communications</journal-title><abbrev-journal-title abbrev-type="publisher">Nat Commun</abbrev-journal-title></journal-title-group><issn pub-type="epub">2041-1723</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s41467-020-19117-w</article-id><article-id pub-id-type="manuscript">19117</article-id><article-id pub-id-type="doi">10.1038/s41467-020-19117-w</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/33/34/2810</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/624/1075/1076</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/624/1075/1077</subject></subj-group><subj-group subj-group-type="SubjectPath"><subject>/639/624/1075/187</subject></subj-group><subj-group subj-group-type="TechniquePath"><subject>/132</subject></subj-group><subj-group subj-group-type="TechniquePath"><subject>/119</subject></subj-group><subj-group subj-group-type="TechniquePath"><subject>/123</subject></subj-group><subj-group subj-group-type="NatureArticleTypeID"><subject>article</subject></subj-group></article-categories><title-group><article-title xml:lang="en">An all-photonic focal-plane wavefront sensor</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="Au1"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8352-7515</contrib-id><name><surname>Norris</surname><given-names>Barnaby R. M.</given-names></name><address><email>barnaby.norris@sydney.edu.au</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="corresp" rid="IDs4146702019117w_cor1">a</xref></contrib><contrib contrib-type="author" id="Au2"><name><surname>Wei</surname><given-names>Jin</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author" id="Au3"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3797-2028</contrib-id><name><surname>Betters</surname><given-names>Christopher H.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author" id="Au4"><name><surname>Wong</surname><given-names>Alison</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au5"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5606-3874</contrib-id><name><surname>Leon-Saval</surname><given-names>Sergio G.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.1013.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 834X</institution-id><institution content-type="org-division">Sydney Institute for Astronomy, School of Physics</institution><institution content-type="org-name">University of Sydney</institution></institution-wrap><addr-line content-type="street">Physics Road</addr-line><addr-line content-type="postcode">2006</addr-line><addr-line content-type="city">Sydney</addr-line><addr-line content-type="state">NSW</addr-line><country country="AU">Australia</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.1013.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 834X</institution-id><institution content-type="org-division">Sydney Astrophotonic Instrumentation Laboratories</institution><institution content-type="org-name">University of Sydney</institution></institution-wrap><addr-line content-type="street">Physics Road</addr-line><addr-line content-type="postcode">2006</addr-line><addr-line content-type="city">Sydney</addr-line><addr-line content-type="state">NSW</addr-line><country country="AU">Australia</country></aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.1013.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 834X</institution-id><institution content-type="org-division">AAO-USyd, School of Physics</institution><institution content-type="org-name">University of Sydney</institution></institution-wrap><addr-line content-type="street">Physics Road</addr-line><addr-line content-type="postcode">2006</addr-line><addr-line content-type="city">Sydney</addr-line><addr-line content-type="state">NSW</addr-line><country country="AU">Australia</country></aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.1013.3</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 834X</institution-id><institution content-type="org-division">Institute of Photonics and Optical Science, School of Physics</institution><institution content-type="org-name">University of Sydney</institution></institution-wrap><addr-line content-type="street">Physics Road</addr-line><addr-line content-type="postcode">2006</addr-line><addr-line content-type="city">Sydney</addr-line><addr-line content-type="state">NSW</addr-line><country country="AU">Australia</country></aff></contrib-group><author-notes><corresp id="IDs4146702019117w_cor1"><label>a</label><email>barnaby.norris@sydney.edu.au</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>21</day><month>10</month><year>2020</year></pub-date><pub-date date-type="collection" publication-format="electronic"><month>12</month><year>2020</year></pub-date><volume>11</volume><issue seq="5335">1</issue><elocation-id>5335</elocation-id><history><date date-type="registration"><day>1</day><month>10</month><year>2020</year></date><date date-type="received"><day>27</day><month>3</month><year>2020</year></date><date date-type="accepted"><day>24</day><month>9</month><year>2020</year></date><date date-type="online"><day>21</day><month>10</month><year>2020</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2020</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">Adaptive optics (AO) is critical in astronomy, optical communications and remote sensing to deal with the rapid blurring caused by the Earth’s turbulent atmosphere. But current AO systems are limited by their wavefront sensors, which need to be in an optical plane non-common to the science image and are insensitive to certain wavefront-error modes. Here we present a wavefront sensor based on a photonic lantern fibre-mode-converter and deep learning, which can be placed at the same focal plane as the science image, and is optimal for single-mode fibre injection. By measuring the intensities of an array of single-mode outputs, both phase and amplitude information on the incident wavefront can be reconstructed. We demonstrate the concept with simulations and an experimental realisation wherein Zernike wavefront errors are recovered from focal-plane measurements to a precision of 5.1 × 10<sup>−3</sup> <italic>π</italic> radians root-mean-squared-error.</p></abstract><abstract xml:lang="en" id="Abs2" abstract-type="ShortSummary"><p id="Par2">Adaptive optics wavefront sensors need to be in a pupil plane and are insensitive to certain wavefront-error modes. The authors present a wavefront sensor based on a photonic lantern fibre-mode-converter and deep learning, which can be placed at the same focal plane accessing nondegenerate wavefront information and reconstructing the wavefront.</p></abstract><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Nature Research</meta-value></custom-meta><custom-meta><meta-name>volume-issue-count</meta-name><meta-value>1</meta-value></custom-meta><custom-meta><meta-name>issue-article-count</meta-name><meta-value>5336</meta-value></custom-meta><custom-meta><meta-name>issue-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>issue-pricelist-year</meta-name><meta-value>2020</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-holder</meta-name><meta-value>The Author(s)</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-year</meta-name><meta-value>2020</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>No</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2020</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>10</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>1</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>volume-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>NonStandardArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>false</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/41467_2020_Article_19117.pdf</meta-value></custom-meta><custom-meta><meta-name>pdf-type</meta-name><meta-value>Typeset</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>issue-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>OriginalPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Science, Humanities and Social Sciences, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Science, Humanities and Social Sciences, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Science, multidisciplinary</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Science (multidisciplinary)</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par3">Due to the blurring caused by the Earth’s atmosphere as starlight passes through it, adaptive optics has become central to the advance of modern astronomy, including the imaging of extra-solar planets, newly-forming planetary systems, dying stars and active galactic nuclei. It also offers key advantages in fields where any type of distorted media hinders the detection and/or manipulation of the desired optical signal such as free-space optical communications, remote sensing, in-vivo imaging and manipulation of living cells.</p><p id="Par4">Excellent reviews of adaptive optics systems are given in<sup><xref ref-type="bibr" rid="CR1">1</xref></sup> and<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. In an adaptive optics system, a deformable mirror (DM) situated at the telescope pupil plane is used to rapidly apply corrections to the incident wavefront, cancelling out the effect of atmospheric turbulence. Modern DMs consist of thousands of electrically driven actuators, each applying a small deformation to the mirror surface on time scales of milliseconds. The performance of this method thus largely depends on how accurately the current state of the wavefront is known—a task accomplished (in conjunction with various reconstruction algorithms) by the system’s wavefront sensor (WFS).</p><p id="Par5">While the goal of the AO system is to produce the optimal image in the instrument’s focal-plane, the current state of the wavefront can not easily be determined from this focal-plane image alone. This is because the measured image (obtained by an imaging detector such as a CCD or CMOS chip) contains information only on the intensity of the beam, and is missing the phase information. But phase information is crucial in measuring the incident wavefront. For this reason, AO systems have conventionally used a separate WFS, positioned in a separate pupil plane (usually reimaged via a dichroic beamsplitter) rather than at the image plane. There exist several designs for these pupil-plane WFSs, such as the Shack–Hartmann WFS<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, the pyramid WFS<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> and the curvature WFS<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>.</p><p id="Par6">Systems solely using pupil-plane WFSs have some important disadvantages. Firstly, they are subject to non-common path aberrations—differences between the wavefront seen by the WFS and that used to make the image, due to the non-common optical components traversed by the wavefront-sensing and science beams<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. Since these aberrations are not seen by the WFS, they are not corrected, and this is currently the main limiting factor in the performance of high-contrast Extreme-AO systems in astronomy<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. It can take the form of both low-order aberrations (particularly harmful when a coronagraph is used) and high-order ones, which can produce static and quasi-static speckle. The latter is particularly insidious since it slowly varies depending on telescope pointing and other parameters, so can not easily be calibrated for.</p><p id="Par7">Another major disadvantage is that there exist some highly detrimental aberrations to which pupil-plane WFSs are insensitive, specifically the so called Low Wind Effect (LWE) or Island Effect<sup><xref ref-type="bibr" rid="CR7">7</xref>–<xref ref-type="bibr" rid="CR10">10</xref></sup>. This arises due to phase discontinuities across the secondary-mirror support structure in the telescope pupil, exacerbated by thermal effects that these structures create when the wind is low. Since this takes the form of a sudden step in phase across a region obscured (by the mirror support structures) in the pupil plane, they are virtually invisible to a pupil-plane WFS. However, they have an extremely strong effect in the image plane, and are also a limiting factor in the performance of adaptive optics systems.</p><p id="Par8">For these reasons, a focal-plane WFS (FP-WFS) has been long desired. As mentioned, a simple image will not do, since this does not contain any phase information. This missing information results in an ambiguity in any inferred wavefront determination. However various ingenious methods have been devised to address this, each with their own advantages and limitations. Phase diversity methods<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> generally rely on a set of two simultaneous images, taken with different aberrations (for example, both an in-focus and defocused image), allowing the ambiguity to be broken. However this requires some physical method to produce these two images, and also (due to the highly nonlinear relationships involved) relies on computationally expensive iterative algorithms that preclude real-time operation. An analytic solution (Linearized Analytic Phase Diversity) has been developed to allow real-time operation<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup> but this relies on a linear approximation, requiring the magnitude of phase aberrations be small (&lt;&lt;1 radian), a condition that aberrations such as the LWE does not necessarily fulfil. Other methods, such as the Fast &amp; Furious method<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> avoid the need for a simultaneous, aberrated image by using knowledge of the DM state, but also rely on a linear approximation. The Zernike Asymmetric Pupil Wavefront Sensor<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> is based on a kernel-phase analysis of the focal-plane image, and addresses the lack of phase information by inserting an asymmetric obstruction in the telescope pupil. It also relies on a linear approximation. Another class of methods rely on actively modulating the DM to generate ‘probe’ speckles, which are then modulated in an iterative fashion to break phase ambiguity<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>.</p><p id="Par9">Furthermore, all these FP-WFS have a major disadvantage—they assume that an imaging detector of some sort, with sufficient readout speed, is present at the focal plane. However for advanced exoplanet applications a spectrum of the exoplanet is desired, to allow characterisation of the composition of exoplanet atmospheres, mapping via doppler shift from planet rotation and even the detection of biological signatures<sup><xref ref-type="bibr" rid="CR17">17</xref>–<xref ref-type="bibr" rid="CR20">20</xref></sup>. This requires that rather than using an imaging detector, the planet image be fed to a high-dispersion spectrograph, either via injection into an optical fibre located at the image plane or by conventional optical means.</p><p id="Par10">In this paper, we present a type of FP-WFS that directly measures the phase as well as intensity of the image, without any linear approximations or active modulation. Leveraging photonic technologies as well as machine learning, the Photonic Lantern Wavefront Sensor (PL-WFS) uses a monolithic photonic mode converter known as a photonic lantern (PL) to determine the complex amplitude of the telescope point-spread function (PSF), via the conversion of multi-modal light into a set of single-mode outputs, as depicted in Fig. <xref rid="Fig1" ref-type="fig">1</xref> (top). The desired wavefront information can be determined by simply measuring the intensity of each of the single-mode outputs, which are also ideal for injection into a high-dispersion, diffraction-limited spectrograph, ideal for exoplanet characterisation<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>. In previous efforts a PL was simulated to measure the tip and tilt of an injected beam<sup><xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR23">23</xref></sup>, but now higher order terms describing the shape of the wavefront can be actually measured.<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><title>Non-degenerate response of the photonic lantern wavefront sensor to focal plane phase.</title><p><bold>a</bold> Schematics of a multi-core photonic lantern showing how the phase and intensity of the input field into the multimode fibre end-face evolve into an array of uncoupled single-mode cores with different intensities. <bold>b</bold> The results of three RSoft simulations demonstrating the concept of the photonic lantern wavefront sensor, and its ability to measure both amplitude and phase. The first column shows the phase of the wavefront, and the second and third columns show the intensity and phase of the resulting PSF respectively. The fourth column shows the intensities of the 19 single-mode outputs of the photonic lantern, when the corresponding PSF is injected. In the first example (first row) a flat wavefront is used. In the second and third rows, astigmatism with an amplitude of 0.8 radians, but with opposite signs, is introduced. This results in identical intensity structure in the image plane (2nd column), and so could not be distinguished with an imaging sensor. However the (usually un-measured) phase in the focal plane (3rd column) shows the difference between the two astigmatism terms, which is successfully measured by the photonic lantern (as shown by the different set of outputs from the lantern, in the 4th column). Simulations are performed at a wavelength of 1550 nm. Intensities are plotted with a square-root stretch to better show faint detail.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2020_19117_Fig1_HTML.png"/></fig></p><p id="Par11">Since the relationships between input phase and output intensities is non-linear, a deep neural network is used to perform the reconstruction. These deep learning methods<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> have recently exploded in popularity across many fields of science and engineering. In essence, a neural network learns the relationship between the inputs (in this case wavefront phase) and outputs (in this case the intensities of the single-mode core lantern outputs) of some system. Then, given a new, previously unseen set of outputs, it can infer what the input is. The use of simple neural networks for multimode fibre (MMF) applications has been investigated for several decades, including for image categorisation<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> and information transition<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. However recent advances in computational power and deep learning methods have allowed more complex applications to MMFs, such as convolutional neural networks, to be investigated<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>. Another advantage of such methods is that they can perform the required inferences extremely quickly, with currently available frameworks able to perform highly complex, true non-linear inferences with sub-millisecond latency<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Numerical simulation and theory</title><p id="Par12">Since the modes excited within a MMF are a function of the electric field at the input, by measuring the relative power in each mode at the fibre’s output it is in principle possible to reconstruct spatial information describing the input beam. Although power mixes between the various modes of the fibre as it propagates, as long as the fibre remains unperturbed (e.g. by strain or temperature) then the relationship between the input and output mode fields can be determined. This principle has allowed the development of basic imaging applications, wherein an image projected into the input face of the fibre is reconstructed by imaging the output mode field<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. Although a simple intensity image of the PSF does not contain the necessary information to reconstruct the wavefront, the combination of modes excited within a MMF is a function of both the phase and the amplitude of the incoming light. Hence if the power in each mode of the fibre is known, it should be possible to infer the complex wavefront of an injected PSF.</p><p id="Par13">In standard astronomical fibre-based spectroscopy, the PSF of the telescope while observing a star is indeed injected into a MMF. However reconstructing the complex wavefront by simply imaging the output of the MMF is difficult for a number of reasons. Firstly, the relationship between the modes at the input and output (the transfer function) is not constant, since the fibre, existing in the relatively hostile environment of a working observatory, will be subjected to various changes in strain and temperature. Secondly, in astronomical applications the light levels involved are extremely low, and so imaging the output mode field onto the many (read-noise limited) pixels of a CCD or CMOS detector—operated at 1000s of frames/second—is problematic. Thirdly, the decomposition of a mode field image into a set of coefficients of each mode is a complicated, computationally expensive and delicate task, not suited to the high degree of robustness and low latency required in a working observatory. Finally, if the output light from the fibre is allowed to propagate in free space to a camera it is difficult to effectively use the same light (at another wavelength) for science measurements, such as in a high-resolution spectrograph.</p><p id="Par14">These issues can be addressed by taking advantage of a photonic mode converter known as a PL<sup><xref ref-type="bibr" rid="CR30">30</xref>–<xref ref-type="bibr" rid="CR32">32</xref></sup>. A PL acts as an interface between a MMF and multiple single-mode fibres. By way of an adiabatic taper transition, light contained within the MMF is efficiently transferred into a discrete array of single-mode outputs as seen in Fig. <xref rid="Fig1" ref-type="fig">1</xref> (top). The transition is efficient as long as the number of output fibres is equal to (or greater than) the number of modes supported in the multimode region. The first generation of lanterns were made by tapering down a bundle of single-mode fibres, all placed within the lower refractive-index preform, until their claddings and preform merged into a composite waveguide to become the core and cladding of a new MMF<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. More recently, PLs have been demonstrated using a multi-core fibre (MCF)—a single fibre containing many uncoupled single-mode cores, each effectively acting as its own single-mode fibre—by placing it within a low refractive index capillary and tapering that down to form a single multimode core region<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> (Fig. <xref rid="Fig1" ref-type="fig">1</xref> (top)). This allows PLs with up to hundreds of output cores (and hence modes) to be manufactured<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>, and the entire PL can fit entirely within a standard fibre connector. Crucially, the monolithic nature of the device where the mode conversion occurs (typically 20–60 mm in length) means that, once manufactured, the relationship between the modes excited in the multimode region and the distribution of light in the uncoupled single-mode outputs is deterministic and unchanging.</p><p id="Par15">In the PL-WFS, the telescope PSF is injected directly into the multimode region of a PL. The PL then converts the multiple modes in the MMF into an array of uncoupled single-mode outputs, with the distribution of flux between the outputs determined by the corresponding power in each mode at the input. Once in the form of single-mode cores, the information is robust—it is encoded in only the intensity of each core, which is essentially unaffected by small perturbations. Moreover, when using a MCF, any wavelength-dependant loss and behaviour due to moderate bending and perturbation of the fibre will be the same across all cores. In the design presented here, the output of the lantern is in the form of a MCF. The distribution of power between modes can now be measured via single-pixel measurements of the flux in each waveguide, at a location remote from the focal plane. This enables the use of sensitive detectors (such as avalanche photodiodes) or wavelength dispersion onto an imaging detector to provide additional information.</p><p id="Par16">In the end we have a stable system where we have <italic>n</italic> intensity measurements (for an <italic>n</italic> mode PL), which is a function of both the amplitude and phase of the telescope PSF. This transfer function can not be easily predetermined in manufacture due to fabrication imperfections, but it is fixed. If it can be learned, then it is possible to determine the phase and amplitude of the incident wavefront (to a degree of complexity determined by the number of modes measured). The learning of this transfer function and the subsequent prediction of the wavefront is made more difficult by the fact that (other than at very small wavefront errors) the relationship is non-linear, and so a conventional matrix-based approach is insufficient. Thus to perform this inference, a neural network is used, as described in the laboratory demonstration section.</p><p id="Par17">To validate the approach, a series of simulations were performed. First, a wavefront containing Zernike aberrations is produced and the complex electric field of the resulting PSF is obtained. This is then input into a model of the PL built using the RSoft software from Synopsis. Here, a numerical simulation is performed wherein the electric field is allowed to propagate from the multimode end to the single-mode outputs.</p><p id="Par18">The result of one simulation demonstrating this concept is shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref> (bottom), wherein the phase of the wavefront, the intensity and phase of the resulting PSF after focusing, and the intensity of the 19 single-mode core outputs of the PL are given. The results for three wavefronts are shown—one with a flat wavefront, and the other two with +0.8 radians and −0.8 radians of astigmatism respectively. It is important to note that, in the latter two cases, the intensity structure of the PSFs are identical, and so a conventional imaging sensor at the focal plane would not be able to distinguish them. However the necessary information is contained within the phase structure of the PSF, which is successfully measured by the PL and encoded in the intensity of its outputs.</p><p id="Par19">These numerical simulations also demonstrate the non-linear response of the lantern’s output intensities to wavefront phase. In Fig. <xref rid="Fig2" ref-type="fig">2</xref> a series of simulations are run where a defocus term of changing amplitude is applied, and the output intensities of the lantern plotted as a function of defocus amplitude. It is seen that the 19 output intensities are not a linear function of phase, suggesting that using a linear algorithm (such as used conventionally in adaptive optics) to reconstruct the input phase would perform poorly.<fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><title>Photonic lantern wavefront sensor’s non-degenerate response to a varying degree of defocus.</title><p>Results of simulations where a defocus term is applied and its amplitude scanned from −2 to +2 radians. In the top panel, the normalised output intensities of the the 19 single-mode outputs are plotted as a function of defocus amplitude (although only four separate trends are seen due to the symmetry of this aberration). In the lower three rows the pupil phase, PSF intensity and PL outputs are shown as per Fig. <xref rid="Fig1" ref-type="fig">1</xref>. It is seen that although positive and negative defocus terms of the same amplitude give identical PSFs, it is unambiguous in the measurements from the PL. However, it is also seen that there is not a simple linear relationship between the amplitude of the phase error and the intensity of the lantern outputs. Simulations are performed at a wavelength of 1550 nm. Intensities are plotted with a square-root stretch to better show faint detail.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2020_19117_Fig2_HTML.png"/></fig></p></sec><sec id="Sec4"><title>On sky application</title><p id="Par20">In one proposed on-sky application, the telescope PSF is focused onto the tip of the PL, and the emerging single-mode, MCF routed to a suitable detector location. In the most basic setup, the MCF output is re-imaged onto a sensitive high-speed array detector, such as an EMCCD or sCMOS camera. Optionally, a low-dispersion prism can be inserted to allow low-resolution spectral information to be obtained, potentially useful for more advanced wavefront control and telemetry algorithms, as well as science. The output of the MCF can be spectrally dispersed with no additional reformatting or slit, using the so-called photonic ‘TIGER’ configuration<sup><xref ref-type="bibr" rid="CR35">35</xref>–<xref ref-type="bibr" rid="CR37">37</xref></sup>. The output of this camera is then fed to the real-time computer of the adaptive optics system, where the incident wavefront error is inferred (using a simple neural network) and the appropriate correction applied to the DM.</p><p id="Par21">Rather than acting as a stand-alone WFS, the same fibre can feed a high-dispersion single-mode spectrograph for science measurements. This offers some major advantages over a standard multimode-fibre-fed spectrograph, as described by various authors (e.g.<sup><xref ref-type="bibr" rid="CR38">38</xref>–<xref ref-type="bibr" rid="CR42">42</xref></sup>), outweighing the cost (and potentially extra detector noise) arising from the extra pixels required. By converting the multimode light of the telescope PSF into a set of single-modes, the scaling relation between telescope aperture and the size of the spectrograph optics is broken. This vastly reduced size results in an instrument with far more stability (crucial for high-dispersion spectroscopy) and also allows multiple instances of the spectrograph to be easily replicated to allow a large number of objects to be simultaneously observed. Moreover, the spatial filtering intrinsic to a single-mode fibre removes the modal noise that limits the spectral stability of conventional spectrographs<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>. Photonic lantern enabled single-mode spectrographs are the focus of ongoing efforts and technology demonstrators (e.g.<sup><xref ref-type="bibr" rid="CR44">44</xref>–<xref ref-type="bibr" rid="CR46">46</xref></sup>). Furthermore this technique has been successfully employed in other light-starved applications with high-stability requirements, such as Raman spectroscopy<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>.</p><p id="Par22">When the same lantern and fibre is used both as a WFS and to feed the spectrograph, a truly zero non-common-path design is realised. In this case, it is likely that a separate dispersing element and detector will be used for the science spectrograph than for the wavefront sensing portion. This is because very high dispersion spectrographs need very large detectors with very long integration times to reach the required signal/noise ratio, while the WFS needs to operate at a high framerate. To enable this, a dichroic mirror can be placed within the re-imaging optics after the termination of the MCF, directing longer wavelength light to the appropriate dispersion and detection modules for science. However, a new generation of fast, low-noise infrared detectors using e-APD technology are now available<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>, which may remove this requirement. One limitation of utilising a dichroic to split the light is the introduction of differential chromatic features between the WFS and science light (a problem not encountered in an imaging (rather than spectroscopic) FP-WFS application since the same imaging detector is used for all signals). If the effect proves to be large, then mitigation methods include trading photon-noise for differential chromaticity by using a grey beamsplitter instead, or performing PL-WFS measurements at both longer and shorter wavelengths than the science observation and interpolating the correction via a model.</p><p id="Par23">Also, it is straightforward to build a multi-object WFS (e.g. for use in a multi-conjugate adaptive optics system<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>) by simply adding more lantern/fibre units, and imaging the output cores from multiple MCFs onto a single larger detector or even multiple detectors. In the case of a multi-object galaxy survey, for example, the existing fibre positioning system could easily place multiple WFSs where desired, since they have the same form factor as the existing MMF infrastructure.</p><p id="Par24">Another application is in the case of coronagraphic imaging. While the light from the region beyond the coronagraphic mask proceeds as usual to an imaging instrument, the (usually neglected) light reflected off the coronagraphic focal-plane mask or Lyot-stop could be redirected to the PL-WFS. The neural network architecture described here would be able to handle the distortion created by redirecting the light in this manner, since this is just a modification to the transfer function already being learned. This way multi-wavelength focal-plane wavefront sensing could still be performed while long-exposure science integrations take place.</p><p id="Par25">In which of these configurations the PL-WFS is deployed depends on the science case. When the science object is not well spatially separated from the star, such as with radial-velocity measurements, transit spectroscopy, characterisation of circumstellar dust, etc., measuring the science data directly from the PL via high dispersion spectroscopy is ideal. For cases where the science object is well separated (such as a planet at several <italic>λ</italic>/<italic>D</italic> separation), the planet would likely be outside the sensor’s field of view, and the PL-WFS would be deployed purely as a focal plane WFS to optimise the performance of coronagraphic imaging or post-coronagraphic spectroscopy.</p><p id="Par26">The number of modes supported in the multimode input of the PL is determined by its diameter. Since the PL-WFS is at the focal plane, its core diameter, and hence number of spatial modes, corresponds directly to its field of view. The number of single-mode outputs of the PL sets the limit on the number of spatial modes that can be sensed. The device demonstrated here uses a relatively small number of outputs (19) and hence number of modes, but this can be extended to higher order modes by increasing the number of outputs on the device. Currently, devices with up to 511 outputs<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> are being produced. Since the outputs of the PL are orthogonal, the number of measurable spatial modes scales linearly with the number of outputs, however the optimal basis to be used for probing and/or reconstructing wave fronts with such a device is the topic of future work.</p><p id="Par27">Even a low mode-count device such as the current 19 output PL-WFS is extremely useful when used in the focal plane, since non-common-path-aberration is strongly dominated by low-order terms, with their amplitude very quickly diminishing as spatial frequency increases<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. Moreover, island modes/LWE modes are well represented by a low order mode set<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. Nonetheless, higher order non-common-path aberrations are also problematic (such as those arising from polishing error, sharp diffraction features, and other quasi-static aberrations), so the achievable Strehl ratio will be ultimately limited by the number of modes supported by the sensor.</p></sec><sec id="Sec5"><title>Laboratory demonstration</title><p id="Par28">To validate the ability of the PL-WFS to determine the wavefront phase from the focal plane, a laboratory experiment was performed and the ability to recover the incident wavefront errors from the PL outputs was demonstrated. The experimental testbed provided the ability to inject a PSF arising from an arbitrary wavefront (created using a spatial-light modulator (SLM)) into a PL, and measure the 19 output intensities. The experimental layout is shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>; see ‘Methods’ for a detailed description. A set of images produced by the back-reflection imaging system, showing the input face of the lantern and the back-reflected PSFs, are shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>.<fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><title>Diagram of the laboratory setup used for testing the photonic lantern wavefront sensor.</title><p>A collimated 685 nm laser (LASER) is passed through a linear polariser (POL) and via a fold mirror (MIR) onto a spatial light modulator (SLM), with a neutral density filter (ND) used to attenuate the beam. A wavefront constructed from a chosen set of Zernike terms is created by the SLM and focused to an image and injected by a microscope objective (L3) into the multimode end of the photonic lantern (PL). The intensity of the 19 outputs is then transmitted via multicore fibre (MCF) measured by a camera (CAM3) via lens L2. The raw PSF is also imaged via beamsplitter BS and lens L1 onto camera CAM1. The back-reflection off the fibre tip is imaged via the same beamsplitter and separate imaging system (L2, CAM2) to aid with alignment. Inset: illustration of the principle of the photonic lantern WFS. The incident aberrated wavefront is focused to an image at the focal plane, where the multimode end of the photonic lantern is placed. The complex wavefront determines the combination of modes excited within the multimode region, which are then translated via an adiabatic taper transition into an array of single-mode outputs, the intensities of which encode the complex wavefront information.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2020_19117_Fig3_HTML.png"/></fig><fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><title>Near-field image of the photonic lantern’s multimode end face.</title><p>The dotted line marks the outer extent of the fibre core, which has radius of ~3 <italic>λ</italic>/<italic>D</italic>. <bold>a</bold> The lantern is back-illuminated by injecting light into the multi-core outputs (with random intensity distribution), exciting some combination of the fibre’s modes, visible here. <bold>b</bold> Back-reflected image of the multimode fibre when no aberrations are applied. <bold>c</bold> Back-reflected image of the multimode fibre when several aberrations are applied.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2020_19117_Fig4_HTML.png"/></fig></p><p id="Par29">As seen in the numerical simulation and theory section, the relationship between the input wavefront phase and the output intensities is not linear (or even monotonic for large phase errors). This means that reconstructing the input wavefront from the output intensities using a linear algorithm, such as the SVD-based approach conventionally used in adaptive optics, is not optimal. To address this, a multi-layer neural network was implemented, and various architectures tested. It was then trained and validated using laboratory data produced using the aforementioned laboratory setup. As a point of comparison, a traditional linear, singular-value-decomposition (SVD) based approach was also tested. See ‘Methods’ for further details.</p><p id="Par30">For each laboratory measurement, a combination of the first 9 (non-piston) Zernike terms are simultaneously applied to the SLM, each with an amplitude randomly chosen between approximately −0.12 <italic>π</italic> and 0.12 <italic>π</italic> radians. After these aberrations are combined the resulting phase error for each measurement has a peak-to-valley amplitude of approximately <italic>π</italic> radians. This is a limit imposed by the maximum retardance the SLM can produce within its linear range.</p><p id="Par31">The 19 output intensities from the PL are then recorded, and the images of the PSF and back-reflection from the fibre are also saved for reference. This is then repeated for the desired number of samples. For the results in this paper, a data set of ~60,000 measurements was taken, which would take of order 30 sec to acquire with a contemporary extreme AO system running at kHz speeds. Of these data, 20% are reserved as validation samples and the rest are used as training samples. To evaluate the performance of the network, the 19 output fluxes for previously unseen laboratory test data were given to the neural network and the wavefront coefficients predicted, and the mean-squared error between the predicted coefficients and the true coefficients calculated.</p><p id="Par32">The neural network was able to reconstruct the incident wavefront error to varying degrees of accuracy depending on the model architecture chosen; a few representative models and their root-mean-squared-errors are given in Table <xref rid="Tab1" ref-type="table">1</xref>. It was clear that a non-linear architecture is needed. The best performing network (using the non-linear, ReLU activation function) yielded a root mean squared error (RMSE) of just 5.1 × 10<sup>−3</sup> <italic>π</italic> radians, while the traditional linear approach (using the singular value decomposition method) gave a much worse RMSE of 3.0 × 10<sup>−2</sup> <italic>π</italic> radians.</p><p id="Par33">It was also found that a deep network (i.e. including hidden layers) was required for optimum performance. The best performing network mentioned above (RMSE = 5.1 × 10<sup>−3</sup> <italic>π</italic>) consisted of three layers arranged in a ‘funnel’ configuration, with each layer having 2000, 1050 and 100 units respectively. A single layered network (with 2000 units) shows worse performance, with an RMSE of 7.6 × 10<sup>−3</sup> <italic>π</italic>. Furthermore, it was found that while performance was sensitive to the number of units in the first layer(s) and the number of layers, it was quite insensitive to the number of units in the final layer(s); increasing the number of units in the final layer beyond 100 had little effect. Increasing the number of hidden layers beyond 3, or the number of units in the first layer beyond 2000, also gave rapidly diminishing returns. Regularisation using dropout was also tested, but had little effect except for with very large networks (&gt;3000 units in the first layer, or &gt;3 layers), but which still offered no improvement over the smaller networks described above. These values are produced from a model trained on the complete set of data (48,000 individual measurements). But useful results are found even with much less data; training with 4800 measurements gives an RMSE of 9.3 × 10<sup>−3</sup> <italic>π</italic> and with only 480 measurements gives an RMSE of 2.0 × 10<sup>−2</sup> <italic>π</italic> radians.<table-wrap id="Tab1"><label>Table 1</label><caption xml:lang="en"><p>The performance of several different neural network architectures (selected from a larger hyperparameter scan) in predicting the incident wavefront error from the 19 PL output fluxes, quantified by the root-mean-squared-error (in <italic>π</italic> radians) of the predictions using test data. A deep, funnel-shaped network gives the lowest error. The ability of a neural network to handle non-linearity is clearly advantageous. See text for details.</p></caption><table frame="hsides" rules="groups"><thead><tr><th><p>Activation</p></th><th><p>Neurons in</p></th><th><p>Neurons in</p></th><th><p>No. of</p></th><th><p>RMS error</p></th></tr><tr><th/><th><p>first layer</p></th><th><p>final layer</p></th><th><p>hidden layers</p></th><th><p> ×10<sup>−3</sup> <italic>π</italic> radians</p></th></tr></thead><tbody><tr><td><p>Non-linear</p></td><td><p>2000</p></td><td><p>100</p></td><td><p>2</p></td><td><p>5.1</p></td></tr><tr><td><p>(ReLU)</p></td><td><p>2000</p></td><td><p>2000</p></td><td><p>2</p></td><td><p>5.1</p></td></tr><tr><td/><td><p>2000</p></td><td><p>100</p></td><td><p>1</p></td><td><p>5.9</p></td></tr><tr><td/><td><p>200</p></td><td><p>30</p></td><td><p>6</p></td><td><p>6.4</p></td></tr><tr><td/><td><p>2000</p></td><td><p>–</p></td><td><p>0</p></td><td><p>7.6</p></td></tr><tr><td/><td><p>100</p></td><td><p>100</p></td><td><p>3</p></td><td><p>7.6</p></td></tr><tr><td/><td><p>100</p></td><td><p>–</p></td><td><p>0</p></td><td><p>17</p></td></tr><tr><td><p>Linear</p></td><td><p>–</p></td><td><p>–</p></td><td><p>–</p></td><td><p>30</p></td></tr></tbody></table></table-wrap></p><p id="Par34"> Figure <xref rid="Fig5" ref-type="fig">5</xref> shows the results of the wavefront reconstruction (in terms of the 9 labelled Zernike modes) for laboratory data using the best model architecture. Data for 40 randomly selected samples are shown, with the reconstructed wavefront coefficients overplotted on the true values. It is seen that for all terms the reconstructed values align extremely well with the true values, with little deviation. Interestingly the tip and tilt terms show the poorest performance. This is believed to be due to drift in the alignment of the laboratory setup (due to thermal drift) as training data was acquired, leading to positional modes being poorly learned.<fig id="Fig5"><label>Fig. 5</label><caption xml:lang="en"><title>Results of laboratory tests of the photonic lantern wavefront sensor.</title><p>Shown here are the predicted Zernike coefficients (crosses) and the true values (black lines) for a randomly selected set of 40 measurements. Red points are predictions from a model trained with 48,000 measurements, green points with 4800 measurements and blue with 480 measurements. The difference between the predicted and true values is plotted at the bottom of each panel. Each measurement consists of a combination of the first 10 Zernike terms each with a randomly chosen amplitude between approximately −0.12<italic>π</italic> and 0.12<italic>π</italic> radians applied to the SLM. Resulting combined wavefronts for each measurement have peak-to-valley amplitudes of order <italic>π</italic> radians (limited by SLM hardware). Predictions are performed by the neural network described in the text, using the 19 output intensities of the lantern. The neural network accurately predicts the Zernike terms of the wavefront injected into the lantern, with a root-mean-squared-error of 5.1 × 10<sup>−3</sup> <italic>π</italic> radians.</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/41467_2020_19117_Fig5_HTML.png"/></fig></p><p id="Par35">This experiment was performed with a narrow-band light source (bandwidth 1.2 nm), while in astronomy a much broader bandwidth would be desired for increased photon efficiency. As described previously, the anticipated implementation would be spectrally dispersed, either at high spectral resolution for simultaneous science spectroscopy or at low resolution for wavefront-sensing only. As an individual spectral channel becomes broader (beyond that seen in this experiment), the light’s coherence, and hence the degree of modulation of the PL outputs, decreases. This would be expected to lead to a gradual limitation in sensitivity, and the optimal balance between channel width, read noise (from increased spectral dispersion) and total bandwidth is the subject of future analysis.</p></sec></sec><sec id="Sec6" sec-type="discussion"><title>Discussion</title><p id="Par36">The photonic lantern WFS (PL-WFS) represents a type of WFS, which addresses several of the limitations of current adaptive optics systems. Placing the WFS at the focal plane, rather than at a non-common pupil plane, has been long desired in adaptive optics as it eliminates non-common path error and is sensitive to wavefront errors not visible in the pupil plane (such as island modes). However the image at the focal plane does not contain sufficient information for wavefront reconstruction, since it contains only intensity information and lacks the phase component, leading to degeneracies. Other FP-WFS designs rely on introducing further perturbations to the wavefront to break degeneracies, linear approximations (so unsuited to large phase error) or slow, non-real time methods. They also are poorly suited to injecting the image into single mode fibres, extremely important for major science goals such as spectrographic characterisation of exoplanet atmosphere.</p><p id="Par37">The PL-WFS addressees these limitations by placing the multimode region of a PL at the focal plane, which deterministically remaps the combination of mode-fields in the multimode region to a set of intensities produced at several single-mode outputs. Since the modes excited in the multimode region are a function of both the amplitude and the phase of the incident wavefront, non-degenerate wavefront information is contained and the wavefront can be reconstructed. Furthermore, since the light is optimally injected into single-mode fibres, it is ideal for subsequent connection to a single-mode spectrograph. To deal with the non-linear relationship between phase and intensity in this device, a neural network is employed.</p><p id="Par38">Simulations validate the principle of the device, and laboratory demonstrations confirm its operation. In laboratory tests, wavefront errors with P-V amplitude of  ~<italic>π</italic> radians constructed using the first 9 (non-piston) Zernike terms are introduced, and are then accurately reconstructed from a focal plane measurement using the PL-WFS, to a precision of 5.1 × 10<sup>−3</sup> <italic>π</italic> radians root-mean-squared-error.</p><p id="Par39">The next steps are to use the device in a closed-loop configuration wherein wavefront errors are corrected in real-time, and introduce wavefront errors using a basis more similar to that of a turbulent media (such as a Kolmogorov phase screen). Following that, the device can be tested in an on-sky deployment at an astronomical telescope. Eventually the PL-WFS will form a key component in the increasingly complex set of sensors within a modern adaptive optics system, paving the way for advanced imaging and characterisation of exoplanets, their atmospheres and surface composition, and the detection of biological signatures.</p></sec><sec id="Sec7" sec-type="methods"><title>Methods</title><sec id="Sec8"><title>Laboratory procedure</title><p id="Par40">The experimental layout is shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, which allows the PSF produced by an arbitrary wavefront to be injected into the PL, and its output fluxes measured. Also, to aid in the alignment of the lantern, a back-reflection imaging system was implemented wherein the end of the multimode region is directly imaged via the same lens as that used for injection, with the incident PSF visible via its reflection off the polished end of the fibre. An example of these images is given in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. For these images, light was simultaneously injected into the single-mode outputs of the lantern, to excite a combination of modes in the multimode region. The superposition of these modes are seen in the left panel of the figure as the speckle-like background pattern in the fibre core. A separate focal plane camera was also implemented to independently verify the PSF of the system for a given SLM-induced wavefront.</p><p id="Par41">A 685 nm laser with measured bandwidth 1.2 nm is injected into a single-mode fibre and collimated by an off-axis parabolic mirror, followed by a 4 mm diameter pupil stop. The beam passes through a linear polariser (the SLM operates in a single linear polarisation) and onto the SLM via a fold mirror. From the SLM it passes through a neutral density filter to the beam-splitter cube (non-polarising, R:T 50:50). Here the reflected 50% of the beam is focused onto to the imaging camera (FLIR Grasshopper3 - CAM1) via an f = 200 mm doublet lens to provide a PSF reference, while the transmitted beam is focused onto the tip of the multimode region of the PL via a 10× microscope objective lens.</p><p id="Par42">The PL used here is made using a visible wavelength MCF with 19 uncoupled cores with a 3.7 <italic>μ</italic>m core diameter, NA of 0.14, and core-to-core separation of 35 <italic>μ</italic>, instead of a bundle of SMFs<sup><xref ref-type="bibr" rid="CR31">31</xref>,<xref ref-type="bibr" rid="CR32">32</xref></sup>, that is tapered with a low-index glass capillary (fluorine doped fused silica) jacket to produce a 22 <italic>μ</italic>m MM input with an NA of 0.145. This is equivalent to an angular ‘field-of-view’ with radius of ~3 <italic>λ</italic>/<italic>D</italic>. The PL is then housed within a standard SMA fibre connector. The lantern is mounted on a 3-axis stage to align it with the PSF. The output of the multicore fibre is then imaged onto a separate camera (FLIR Chameleon3 - CAM3) via an f = 200 mm doublet lens, to record the flux in each of the 19 single-mode outputs. Meanwhile, the back-reflected light from the MMF tip (arising from the Fresnel reflection of the non-AR coated fibre) passes back through the microscope objective and is focused onto another camera (FLIR Blackfly - CAM2) via a reverse pass through the same beamsplitter cube, to aid with alignment.</p><p id="Par43">Each measurement of the multicore outputs was performed with 10 co-adds of 20 ms integrations, with this relatively long total integration time required to smooth out the ripple caused by the SLM’s refresh rate. To limit the effect of drifting alignment, the experimental setup was placed in a temperature-stabilised room, maintaining the temperature to within  ±0.1 <sup>∘</sup>C. All wavefront modulation and data capture is performed via Matlab.</p></sec><sec id="Sec9"><title>Data analysis</title><p id="Par44">The neural network was implemented using Keras<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>, using the Tensorflow backend<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>. The loss function used was the mean squared error of the predicted coefficients, and using a ReLU activation function and Adam optimizer. A range of architectures for the neural network was explored, with hyperparameter exploration and optimisation performed using Talos<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>.</p><p id="Par45">In addition to the neural network, a linear, SVD based approach (traditionally used in adaptive optics)<sup><xref ref-type="bibr" rid="CR2">2</xref></sup> was tested as a point of comparison. Here, a matrix is constructed mapping the input wavefront coefficients to the output intensities using the training data, and then a pseudo-inverse of the matrix is create using a SVD, with suitable regularisation. This pseudo-inverse matrix is then used to predict the wavefront coefficients from any set of previously unseen output fluxes.</p></sec></sec></body><back><ack><title>Acknowledgements</title><p>We would like to thank Prof. Birks and Dr. Gris-Sanchez from the University of Bath for facilitating the fibre fabrication and the use of the fibre drawing tower. S.G.L-S would like to thank A/Prof Amezcua-Correa from the College of Optics and Photonics (CREOL) at the University of Central Florida for the inspiring conversations about this research and possible applications outside astronomy.</p></ack><sec sec-type="author-contribution"><title>Author contributions</title><p>B.R.M.N. and S.L-S. developed and led the project. C.H.B. designed and fabricated the multicore photonic lantern and S.L-S. designed and fabricated the multicore fibre. J.W. conducted the laboratory experiments with assistance from B.R.M.N., C.H.B. and S.L-S. B.R.M.N. developed and applied the deep learning network and algorithms. B.R.M.N., A.W. and J.W. analysed the data. B.R.M.N. wrote the paper with contributions from all the authors. S.L-S. and B.R.M.N. supervised the study.</p></sec><sec sec-type="data-availability"><title>Data availability</title><p>The data produced in this study are available from the corresponding author upon reasonable request.</p></sec><sec sec-type="ethics-statement"><sec id="FPar1" sec-type="COI-statement"><title>Competing interests</title><p id="Par46">The authors declare no competing interests.</p></sec></sec><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davies</surname><given-names>R</given-names></name><name><surname>Kasper</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Adaptive Optics for Astronomy</article-title><source>Annu. Rev. Astron. Astrophys.</source><year>2012</year><volume>50</volume><fpage>305</fpage><lpage>351</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2012ARA&amp;A..50..305D</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC38Xhs1ynsbfP</pub-id><pub-id pub-id-type="doi">10.1146/annurev-astro-081811-125447</pub-id></mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guyon</surname><given-names>O</given-names></name></person-group><article-title xml:lang="en">Extreme Adaptive Optics</article-title><source>Annu. Rev. Astron. Astrophys.</source><year>2018</year><volume>56</volume><fpage>315</fpage><lpage>355</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018ARA&amp;A..56..315G</pub-id><pub-id pub-id-type="doi">10.1146/annurev-astro-081817-052000</pub-id></mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Platt</surname><given-names>BC</given-names></name><name><surname>Shack</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">History and principles of shack-hartmann wavefront sensing</article-title><source>J. Refractive Surg.</source><year>2001</year><volume>17</volume><fpage>S573</fpage><lpage>S577</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BD3Mrjs1Snsw%3D%3D</pub-id><pub-id pub-id-type="doi">10.3928/1081-597X-20010901-13</pub-id></mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ragazzoni</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Pupil plane wavefront sensing with an oscillating prism</article-title><source>J. Mod. Opt.</source><year>1996</year><volume>43</volume><fpage>289</fpage><lpage>293</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">1996JMOp...43..289R</pub-id><pub-id pub-id-type="doi">10.1080/09500349608232742</pub-id></mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roddier</surname><given-names>F</given-names></name></person-group><article-title xml:lang="en">Curvature sensing and compensation: a new concept in adaptive optics</article-title><source>Appl. Opt.</source><year>1988</year><volume>27</volume><fpage>1223</fpage><lpage>1225</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">1988ApOpt..27.1223R</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BC3cvosFGitQ%3D%3D</pub-id><pub-id pub-id-type="doi">10.1364/AO.27.001223</pub-id></mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sauvage</surname><given-names>J-F</given-names></name><name><surname>Fusco</surname><given-names>T</given-names></name><name><surname>Rousset</surname><given-names>G</given-names></name><name><surname>Petit</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Calibration and precompensation of noncommon path aberrations for extreme adaptive optics</article-title><source>J. Optical Soc. Am. A</source><year>2007</year><volume>24</volume><fpage>2334</fpage><lpage>2346</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2007JOSAA..24.2334S</pub-id><pub-id pub-id-type="doi">10.1364/JOSAA.24.002334</pub-id></mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>N’Diaye</surname><given-names>M</given-names></name><etal/></person-group><article-title xml:lang="en">Calibration of the island effect: experimental validation of closed-loop focal plane wavefront control on Subaru/SCExAO</article-title><source>Astron. Astrophys.</source><year>2018</year><volume>610</volume><fpage>A18</fpage><pub-id pub-id-type="doi">10.1051/0004-6361/201731985</pub-id></mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Sauvage, J.-F. et al. <italic>Tackling down the low wind effect on SPHERE instrument</italic>, volume 9909 of <italic>Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series</italic>, 990916 (2016).</mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="other">Milli, J. et al. Low wind effect on VLT/SPHERE: impact, mitigation strategy, and results. In <italic>Proc. SPIE</italic>, volume 10703 of <italic>Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series</italic>, 107032A (2018).</mixed-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="other">Vievard, S. et al. Overview of focal plane wavefront sensors to correct for the Low Wind Effect on SUBARU/SCExAO. <italic>arXiv e-prints</italic><ext-link xlink:href="https://arxiv.org/abs/1912.10179" ext-link-type="uri">https://arxiv.org/abs/1912.10179</ext-link> (2019).</mixed-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonsalves</surname><given-names>RA</given-names></name></person-group><article-title xml:lang="en">Phase Retrieval And Diversity In Adaptive Optics</article-title><source>Optical Eng.</source><year>1982</year><volume>21</volume><fpage>829</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">1982OptEn..21..829G</pub-id><pub-id pub-id-type="doi">10.1117/12.7972989</pub-id></mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mocœur</surname><given-names>I</given-names></name><name><surname>Mugnier</surname><given-names>LM</given-names></name><name><surname>Cassaing</surname><given-names>F</given-names></name></person-group><article-title xml:lang="en">Analytical solution to the phase-diversity problem for real-time wavefront sensing</article-title><source>Opt. Lett.</source><year>2009</year><volume>34</volume><fpage>3487</fpage><lpage>3489</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2009OptL...34.3487M</pub-id><pub-id pub-id-type="doi">10.1364/OL.34.003487</pub-id></mixed-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vievard</surname><given-names>S</given-names></name><name><surname>Cassaing</surname><given-names>F</given-names></name><name><surname>Mugnier</surname><given-names>LM</given-names></name><name><surname>Bonnefois</surname><given-names>A</given-names></name><name><surname>Montri</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Real-time full alignment and phasing of multiple-aperture imagers using focal-plane sensors on unresolved objects</article-title><source>SPIE</source><year>2018</year><volume>10698</volume><fpage>106986F</fpage></mixed-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Korkiakoski</surname><given-names>V</given-names></name><etal/></person-group><article-title xml:lang="en">Fast &amp; Furious focal-plane wavefront sensing</article-title><source>Appl. Opt.</source><year>2014</year><volume>53</volume><fpage>4565</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2014ApOpt..53.4565K</pub-id><pub-id pub-id-type="doi">10.1364/AO.53.004565</pub-id></mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martinache</surname><given-names>F</given-names></name></person-group><article-title xml:lang="en">The Asymmetric Pupil Fourier Wavefront Sensor</article-title><source>PASP</source><year>2013</year><volume>125</volume><fpage>422</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2013PASP..125..422M</pub-id><pub-id pub-id-type="doi">10.1086/670670</pub-id></mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martinache</surname><given-names>F</given-names></name><etal/></person-group><article-title xml:lang="en">On-Sky Speckle Nulling Demonstration at Small Angular Separation with SCExAO</article-title><source>PASP</source><year>2014</year><volume>126</volume><fpage>565</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2014PASP..126..565M</pub-id><pub-id pub-id-type="doi">10.1086/677141</pub-id></mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snellen</surname><given-names>I</given-names></name><etal/></person-group><article-title xml:lang="en">Combining high-dispersion spectroscopy with high contrast imaging: probing rocky planets around our nearest neighbors</article-title><source>Astron. Astrophys.</source><year>2015</year><volume>576</volume><fpage>A59</fpage><pub-id pub-id-type="doi">10.1051/0004-6361/201425018</pub-id></mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J</given-names></name><etal/></person-group><article-title xml:lang="en">Detecting Water in the Atmosphere of HR 8799 c with L-band High-dispersion Spectroscopy Aided by Adaptive Optics</article-title><source>AJ</source><year>2018</year><volume>156</volume><fpage>272</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018AJ....156..272W</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1MXhsFaju7fN</pub-id><pub-id pub-id-type="doi">10.3847/1538-3881/aae47b</pub-id></mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crossfield</surname><given-names>IJM</given-names></name><etal/></person-group><article-title xml:lang="en">A global cloud map of the nearest known brown dwarf</article-title><source>Nature</source><year>2014</year><volume>505</volume><fpage>654</fpage><lpage>656</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2014Natur.505..654C</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2cXhsFejuro%3D</pub-id><pub-id pub-id-type="doi">10.1038/nature12955</pub-id></mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seager</surname><given-names>S</given-names></name><name><surname>Deming</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Exoplanet Atmospheres</article-title><source>ARAA</source><year>2010</year><volume>48</volume><fpage>631</fpage><lpage>672</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2010ARA&amp;A..48..631S</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC3cXhtlWhtbrE</pub-id><pub-id pub-id-type="doi">10.1146/annurev-astro-081309-130837</pub-id></mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Betters, C. H., Murray, A., Bland-Hawthorn, J. &amp; Leon-Saval, S. G. Precision radial velocities with inexpensive compact spectrographs. In Evans, C. J., Simard, L. &amp; Takami, H. (eds), <italic>Ground-based and Airborne Instrumentation for Astronomy VI</italic>, Vol 9908, 367–374 (International Society for Optics and Photonics, SPIE, 2016).</mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Corrigan, M. et al. <italic>Wavefront sensing using a photonic lantern</italic>, volume 9909 of <italic>Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series</italic>, 990969 (2016).</mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Corrigan, M. K., Morris, T. J., Harris, R. J. &amp; Anagnos, T. Demonstration of a photonic lantern low order wavefront sensor using an adaptive optics testbed. In Close, L. M., Schreiber, L. &amp; Schmidt, D. (eds), <italic>Adaptive Optics Systems VI</italic>, Vol 10703, 1313–1320 (International Society for Optics and Photonics, SPIE, 2018).</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lecun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Deep learning</article-title><source>Nature</source><year>2015</year><volume>521</volume><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2015Natur.521..436L</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC2MXht1WlurzP</pub-id><pub-id pub-id-type="doi">10.1038/nature14539</pub-id></mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aisawa</surname><given-names>S</given-names></name><name><surname>Noguchi</surname><given-names>K</given-names></name><name><surname>Matsumoto</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">Remote image classification through multimode optical fiber using a neural network</article-title><source>Opt. Lett.</source><year>1991</year><volume>16</volume><fpage>645</fpage><lpage>647</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">1991OptL...16..645A</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BD1Mnkt1ektA%3D%3D</pub-id><pub-id pub-id-type="doi">10.1364/OL.16.000645</pub-id></mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marusarz</surname><given-names>RK</given-names></name><name><surname>Sayeh</surname><given-names>MR</given-names></name></person-group><article-title xml:lang="en">Neural Network-Based Multimode Fiber-Optic Information Transmission</article-title><source>Appl. Opt.</source><year>2001</year><volume>40</volume><fpage>219</fpage><lpage>227</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2001ApOpt..40..219M</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BD1c7psl2rtQ%3D%3D</pub-id><pub-id pub-id-type="doi">10.1364/AO.40.000219</pub-id></mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rahmani</surname><given-names>B</given-names></name><name><surname>Loterie</surname><given-names>D</given-names></name><name><surname>Konstantinou</surname><given-names>G</given-names></name><name><surname>Psaltis</surname><given-names>D</given-names></name><name><surname>Moser</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Multimode optical fiber transmission with a deep learning network</article-title><source>Light. Sci. Appl.</source><year>2018</year><volume>7</volume><fpage>69</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2018LSA.....7...69R</pub-id><pub-id pub-id-type="doi">10.1038/s41377-018-0074-1</pub-id></mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">NVIDIA. Data center deep learning product performance. <ext-link xlink:href="https://developer.nvidia.com/deep-learning-performance-training-inference" ext-link-type="uri">https://developer.nvidia.com/deep-learning-performance-training-inference</ext-link> (2020).</mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Čižmár</surname><given-names>T</given-names></name><name><surname>Dholakia</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Exploiting multimode waveguides for pure fibre-based imaging</article-title><source>Nat. Commun.</source><year>2012</year><volume>3</volume><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2012NatCo...3.1027C</pub-id><pub-id pub-id-type="doi">10.1038/ncomms2024</pub-id></mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leon-Saval</surname><given-names>SG</given-names></name><name><surname>Birks</surname><given-names>TA</given-names></name><name><surname>Bland-Hawthorn</surname><given-names>J</given-names></name><name><surname>Englund</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Multimode fiber devices with single-mode performance</article-title><source>Opt. Lett.</source><year>2005</year><volume>30</volume><fpage>2545</fpage><lpage>2547</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2005OptL...30.2545L</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BD2Mrjtlymtg%3D%3D</pub-id><pub-id pub-id-type="doi">10.1364/OL.30.002545</pub-id></mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leon-Saval</surname><given-names>SG</given-names></name><name><surname>Argyros</surname><given-names>A</given-names></name><name><surname>Bland -Hawthorn</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Photonic lanterns</article-title><source>Nanophotonics</source><year>2013</year><volume>2</volume><fpage>429</fpage><lpage>440</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2013Nanop...2..429L</pub-id><pub-id pub-id-type="doi">10.1515/nanoph-2013-0035</pub-id></mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Birks</surname><given-names>TA</given-names></name><name><surname>Gris-Sánchez</surname><given-names>I</given-names></name><name><surname>Yerolatsitis</surname><given-names>S</given-names></name><name><surname>Leon-Saval</surname><given-names>SG</given-names></name><name><surname>Thomson</surname><given-names>RR</given-names></name></person-group><article-title xml:lang="en">The photonic lantern</article-title><source>Adv. Opt. Photonics</source><year>2015</year><volume>7</volume><fpage>107</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2015AdOP....7..107B</pub-id><pub-id pub-id-type="doi">10.1364/AOP.7.000107</pub-id></mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Birks</surname><given-names>TA</given-names></name><name><surname>Mangan</surname><given-names>BJ</given-names></name><name><surname>Díez</surname><given-names>A</given-names></name><name><surname>Cruz</surname><given-names>JL</given-names></name><name><surname>Murphy</surname><given-names>DF</given-names></name></person-group><article-title xml:lang="en">Photonic lantern” spectral filters in multi-core Fiber</article-title><source>Opt. Express</source><year>2012</year><volume>20</volume><fpage>13996</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2012OExpr..2013996B</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DC%2BC38jjt1ejsg%3D%3D</pub-id><pub-id pub-id-type="doi">10.1364/OE.20.013996</pub-id></mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leon-Saval</surname><given-names>SG</given-names></name><etal/></person-group><article-title xml:lang="en">Divide and conquer: an efficient solution to highly multimoded photonic lanterns from multicore fibres</article-title><source>Opt. Express</source><year>2017</year><volume>25</volume><fpage>17530</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2017OExpr..2517530L</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXltlGqs70%3D</pub-id><pub-id pub-id-type="doi">10.1364/OE.25.017530</pub-id></mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="other">Leon-Saval, S. G., Betters, C. H. and Bland -Hawthorn, J. <italic>The Photonic TIGER: a multicore fiber-fed spectrograph</italic>, volume 8450 of <italic>Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series</italic>, 84501K (2012).</mixed-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="other">Betters, C. H. et al. PIMMS échelle: the next generation of compact diffraction limited spectrographs for arbitrary input beams. In <italic>Ground-based and Airborne Instrumentation for Astronomy V</italic>, Vol 9147 of <italic>Proc. SPIE</italic>, 91471I (2014).</mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Betters</surname><given-names>CH</given-names></name><name><surname>Bland-Hawthorn</surname><given-names>J</given-names></name><name><surname>Sukkarieh</surname><given-names>S</given-names></name><name><surname>Gris-Sanchez</surname><given-names>I</given-names></name><name><surname>Leon-Saval</surname><given-names>SG</given-names></name></person-group><article-title xml:lang="en">A multi-core fibre photonic lantern-based spectrograph for raman spectroscopy</article-title><source>IEEE Photonics Technol. Lett.</source><year>2020</year><volume>32</volume><fpage>395</fpage><lpage>398</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2020IPTL...32..395B</pub-id><pub-id pub-id-type="doi">10.1109/LPT.2020.2976599</pub-id></mixed-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="other">Bland-Hawthorn, J. et al. PIMMS: photonic integrated multimode microspectrograph. In <italic>Ground-based and Airborne Instrumentation for Astronomy III</italic>, Vol 7735 of <italic>Proc. SPIE</italic>, 77350N (2010).</mixed-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Betters</surname><given-names>CH</given-names></name><name><surname>Leon-Saval</surname><given-names>SG</given-names></name><name><surname>Robertson</surname><given-names>JG</given-names></name><name><surname>Bland-Hawthorn</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Beating the classical limit: a diffraction-limited spectrograph for an arbitrary input beam</article-title><source>Opt. Express</source><year>2013</year><volume>21</volume><fpage>26103</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2013OExpr..2126103B</pub-id><pub-id pub-id-type="doi">10.1364/OE.21.026103</pub-id></mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>RJ</given-names></name><etal/></person-group><article-title xml:lang="en">Photonic spatial reformatting of stellar light for diffraction-limited spectroscopy</article-title><source>MNRAS</source><year>2015</year><volume>450</volume><fpage>428</fpage><lpage>434</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2015MNRAS.450..428H</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXltleitLs%3D</pub-id><pub-id pub-id-type="doi">10.1093/mnras/stv410</pub-id></mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jovanovic</surname><given-names>N</given-names></name><name><surname>Schwab</surname><given-names>C</given-names></name><name><surname>Cvetojevic</surname><given-names>N</given-names></name><name><surname>Guyon</surname><given-names>O</given-names></name><name><surname>Martinache</surname><given-names>F</given-names></name></person-group><article-title xml:lang="en">Enhancing Stellar Spectroscopy with Extreme Adaptive Optics and Photonics</article-title><source>PASP</source><year>2016</year><volume>128</volume><fpage>121001</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2016PASP..128l1001J</pub-id><pub-id pub-id-type="doi">10.1088/1538-3873/128/970/121001</pub-id></mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="other">Crepp, J. R. et al. iLocater: a diffraction-limited Doppler spectrometer for the Large Binocular Telescope. In <italic>Proc. SPIE</italic>, Vol 9908 of <italic>Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series</italic>, 990819 (2016).</mixed-citation></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baudrand</surname><given-names>J</given-names></name><name><surname>Walker</surname><given-names>GAH</given-names></name></person-group><article-title xml:lang="en">Modal noise in high-resolution, fiber-fed spectra: a study and simple cure</article-title><source>PASP</source><year>2001</year><volume>113</volume><fpage>851</fpage><lpage>858</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2001PASP..113..851B</pub-id><pub-id pub-id-type="doi">10.1086/322143</pub-id></mixed-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feger</surname><given-names>T</given-names></name><etal/></person-group><article-title xml:lang="en">Attaining m s<sup>−1</sup> level intrinsic Doppler precision with RHEA, a low-cost single-mode spectrograph</article-title><source>Exp. Astron.</source><year>2016</year><volume>42</volume><fpage>285</fpage><lpage>300</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2016ExA....42..285F</pub-id><pub-id pub-id-type="doi">10.1007/s10686-016-9510-5</pub-id></mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gatkine</surname><given-names>P</given-names></name><name><surname>Veilleux</surname><given-names>S</given-names></name><name><surname>Hu</surname><given-names>Y</given-names></name><name><surname>Bland -Hawthorn</surname><given-names>J</given-names></name><name><surname>Dagenais</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Arrayed waveguide grating spectrometers for astronomical applications: new results</article-title><source>Opt. Express</source><year>2017</year><volume>25</volume><fpage>17918</fpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2017OExpr..2517918G</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXltlKjsb0%3D</pub-id><pub-id pub-id-type="doi">10.1364/OE.25.017918</pub-id></mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jovanovic</surname><given-names>N</given-names></name><etal/></person-group><article-title xml:lang="en">Demonstration of an efficient, photonic-based astronomical spectrograph on an 8-m telescope</article-title><source>Opt. Express</source><year>2017</year><volume>25</volume><fpage>17753</fpage><lpage>17766</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2017OExpr..2517753J</pub-id><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:CAS:528:DC%2BC1cXltlGru7Y%3D</pub-id><pub-id pub-id-type="doi">10.1364/OE.25.017753</pub-id></mixed-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="other">Finger, G. et al. <italic>SAPHIRA detector for infrared wavefront sensing</italic>, volume 9148 of <italic>Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series</italic>, 914817 (2014).</mixed-citation></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marchetti</surname><given-names>E</given-names></name><etal/></person-group><article-title xml:lang="en">On-sky Testing of the Multi-Conjugate Adaptive Optics Demonstrator</article-title><source>Messenger</source><year>2007</year><volume>129</volume><fpage>8</fpage><lpage>13</lpage><pub-id pub-id-type="other" assigning-authority="NASA Astrophysics Data System">2007Msngr.129....8M</pub-id></mixed-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="other">Chollet, F. et al. Keras. <ext-link xlink:href="https://keras.io" ext-link-type="uri">https://keras.io</ext-link> (2015).</mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="other">Abadi, M. et al. TensorFlow: large-scale machine learning on heterogeneous systems (2015). Software available from <ext-link xlink:href="http://tensorflow.org" ext-link-type="uri">http://tensorflow.org</ext-link>.</mixed-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="other">Talos. Autonomio talos [computer software]. <ext-link xlink:href="http://github.com/autonomio/talos" ext-link-type="uri">http://github.com/autonomio/talos</ext-link>. (2019).</mixed-citation></ref></ref-list></ref-list><notes notes-type="Misc"><p><bold>Peer review information</bold><italic>Nature Communications</italic> thanks Robert Harris and the other, anonymous, reviewers for their contribution to the peer review of this work.</p></notes><notes notes-type="Misc"><p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Science, Humanities and Social Sciences, multidisciplinary</facet-value><facet-value count="1">Science, multidisciplinary</facet-value></facet><facet name="keyword"/><facet name="pub"><facet-value count="1">Nature Communications</facet-value></facet><facet name="year"><facet-value count="1">2020</facet-value></facet><facet name="country"><facet-value count="1">Australia</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
