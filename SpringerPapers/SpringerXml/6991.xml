<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1007/s10479-022-04857-3</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="research-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">10479</journal-id><journal-id journal-id-type="doi">10.1007/10479.1572-9338</journal-id><journal-title-group><journal-title>Annals of Operations Research</journal-title><abbrev-journal-title abbrev-type="publisher">Ann Oper Res</abbrev-journal-title></journal-title-group><issn pub-type="ppub">0254-5330</issn><issn pub-type="epub">1572-9338</issn><publisher><publisher-name>Springer US</publisher-name><publisher-loc>New York</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s10479-022-04857-3</article-id><article-id pub-id-type="manuscript">4857</article-id><article-id pub-id-type="doi">10.1007/s10479-022-04857-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Research</subject></subj-group></article-categories><title-group><article-title xml:lang="en">Incorporating causality in energy consumption forecasting using deep neural networks</article-title></title-group><contrib-group><contrib contrib-type="author" id="Au1"><name><surname>Sharma</surname><given-names>Kshitij</given-names></name><address><email>kshitij.sharma@ntnu.no</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au2"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5547-9990</contrib-id><name><surname>Dwivedi</surname><given-names>Yogesh K.</given-names></name><address><email>y.k.dwivedi@swansea.ac.uk</email></address><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="corresp" rid="IDs10479022048573_cor2">b</xref></contrib><contrib contrib-type="author" id="Au3"><name><surname>Metri</surname><given-names>Bhimaraya</given-names></name><address><email>director@iimnagpur.ac.in</email></address><xref ref-type="aff" rid="Aff4">4</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.5947.f</institution-id><institution-id institution-id-type="ISNI">0000 0001 1516 2393</institution-id><institution content-type="org-division">Department of Computer Science</institution><institution content-type="org-name">Norwegian University of Science and Technology</institution></institution-wrap><addr-line content-type="city">Trondheim</addr-line><country country="NO">Norway</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.4827.9</institution-id><institution-id institution-id-type="ISNI">0000 0001 0658 8800</institution-id><institution content-type="org-division">Emerging Markets Research Centre (EMaRC), School of Management</institution><institution content-type="org-name">Swansea University</institution></institution-wrap><addr-line content-type="street">Room #323, Bay Campus, Fabian Bay</addr-line><addr-line content-type="postcode">SA1 8EN</addr-line><addr-line content-type="city">Swansea</addr-line><country country="GB">Wales, UK</country></aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.444681.b</institution-id><institution-id institution-id-type="ISNI">0000 0004 0503 4808</institution-id><institution content-type="org-division">Department of Management, Symbiosis Institute of Business Management</institution><institution content-type="org-name">Pune &amp; Symbiosis International (Deemed University)</institution></institution-wrap><addr-line content-type="city">Pune</addr-line><addr-line content-type="state">Maharashtra</addr-line><country country="IN">India</country></aff><aff id="Aff4"><label>4</label><institution-wrap><institution content-type="org-name">Indian Institute of Management Nagpur</institution></institution-wrap><addr-line content-type="city">Nagpur</addr-line><country country="IN">India</country></aff></contrib-group><author-notes><corresp id="IDs10479022048573_cor2"><label>b</label><email>y.k.dwivedi@swansea.ac.uk</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>30</day><month>7</month><year>2022</year></pub-date><fpage>1</fpage><lpage>36</lpage><history><date date-type="registration"><day>23</day><month>6</month><year>2022</year></date><date date-type="accepted"><day>22</day><month>6</month><year>2022</year></date><date date-type="online"><day>30</day><month>7</month><year>2022</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2022</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">Forecasting energy demand has been a critical process in various decision support systems regarding consumption planning, distribution strategies, and energy policies. Traditionally, forecasting energy consumption or demand methods included trend analyses, regression, and auto-regression. With advancements in machine learning methods, algorithms such as support vector machines, artificial neural networks, and random forests became prevalent. In recent times, with an unprecedented improvement in computing capabilities, deep learning algorithms are increasingly used to forecast energy consumption/demand. In this contribution, a relatively novel approach is employed to use long-term memory. Weather data was used to forecast the energy consumption from three datasets, with an additional piece of information in the deep learning architecture. This additional information carries the causal relationships between the weather indicators and energy consumption. This architecture with the causal information is termed as entangled long short term memory. The results show that the entangled long short term memory outperforms the state-of-the-art deep learning architecture (bidirectional long short term memory). The theoretical and practical implications of these results are discussed in terms of decision-making and energy management systems.
</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Deep neural networks</kwd><kwd>Energy consumption</kwd><kwd>Forecasting</kwd><kwd>Machine learning</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Springer</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>No</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>ContentOnly</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2022</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>6</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>23</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>NonStandardArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>ContentOnly</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>true</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/10479_2022_Article_4857.pdf</meta-value></custom-meta><custom-meta><meta-name>pdf-type</meta-name><meta-value>Typeset</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>OriginalPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Business and Management</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Operations Research/Decision Theory</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Combinatorics</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Theory of Computation</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Business and Management</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Time-series forecasting is one of the most important quantitative models in which historical observations of the same variable are collected and analysed to develop a model that captures the underlying data generating process. Then the model is used to predict the future. In operation research (OR), such methods are used for volatility prediction (Vidal &amp; Kristjanpoller, <xref ref-type="bibr" rid="CR155">2020</xref>), risk assessment (Du et al., <xref ref-type="bibr" rid="CR36">2020</xref>), supply chain management (Pacella &amp; Papadia, <xref ref-type="bibr" rid="CR118">2021</xref>), price forecasting (Demir et al., <xref ref-type="bibr" rid="CR32">2021</xref>), demand and supply forecasting (Chen et al., <xref ref-type="bibr" rid="CR22">2020</xref>; Chen &amp; Lu, <xref ref-type="bibr" rid="CR25">2021</xref>; Du et al., <xref ref-type="bibr" rid="CR35">2021</xref>; van Steenbergen &amp; Mes, <xref ref-type="bibr" rid="CR153">2020</xref>; Zhang et al., <xref ref-type="bibr" rid="CR168">2021</xref>) and so on. There are multiple methods used in time series analysis that can be divided into three broad categories: 1) classical statistical modelling and forecasting (e.g., ARIMA, GARCH); 2) machine learning and deep learning; and 3) hybrid approaches. This paper used a novel method called "Entangled Recurrent Neural Network" (E-RNNs) for time series prediction (proposed by Yoon &amp; van der Schaar, <xref ref-type="bibr" rid="CR164">2017</xref>). Thus, contributing to the deep learning-based methods for time series prediction in OR. As an application of the method, this paper forecasts the energy demands in the different regions.</p><p id="Par3">Energy demand forecasting is becoming increasingly crucial for planning for energy consumption, formulation of distribution strategies, and recommending modern energy policies (Bhattacharyya &amp; Timilsina, <xref ref-type="bibr" rid="CR15">2009</xref>). Energy is one of the most vital resources for developing and sustaining that development in any country (Suganthi &amp; Samuel, <xref ref-type="bibr" rid="CR145">2012</xref>). This is true for all the sectors that are social, economic, and environmental. Energy is also a crucial part of multiple industries such as production, agriculture, health, and education. Therefore, it is important to have an efficient energy demand management system for allocating the available resources properly and effectively. Energy demand and supply can also be seen as the macro supply chain operations, with the energy companies and distributors as the main body. For example, Bagchi et al. (<xref ref-type="bibr" rid="CR12">2022</xref>) showed how energy usage could be employed to achieve a better energy mix to, in turn, obtain the much-desired decoupling of growth and sustainable development in developing countries. Moreover, because of the widespread impact of energy consumption, the decision-making in this sector might involve multiple stakeholders, a multitude of uncertainty, and risk inflicting sources (Dorsman et al., <xref ref-type="bibr" rid="CR34">2021</xref>). The decision-making in the energy sector can also be different based on the time frame (long, medium, and short term) and area scopes (country, region, city, buildings). Such decisions can also affect the financial aspects of the organizations because the energy investments have capital intensive nature. Furthermore, with the increasing world population (that is estimated at 8.5 billion by 2030; United Nations, 2015), the energy demand will also increase. This increase in demand can only be met by using efficient energy planning and sustainable energy policies, both of which depend on a reliable energy demand forecasting system. Energy demand and supply can also be seen as the macro supply chain operations, with the energy companies and distributors as the main body. Therefore, accurate forecasting of the energy demand does not only have societal impacts but also can have financial impacts. Therefore, accurate forecasting of energy demand or consumption is the desired outcome of the applied methods. One of the most prominent states of the art methods of forecasting the energy demand is using recurrent neural networks.</p><p id="Par4">Recurrent neural networks (RNNs) are the most used deep architectures for solving time-series-based prediction and/or regression tasks. They have been applied in a variety of domains. For example, speech recognition (Zhang et al., <xref ref-type="bibr" rid="CR167">2020</xref>), traffic forecasting (Zhang et al., <xref ref-type="bibr" rid="CR167">2020</xref>), language translation (Vathsala &amp; Holi, <xref ref-type="bibr" rid="CR154">2020</xref>), and risk scoring (Clements et al., <xref ref-type="bibr" rid="CR28">2020</xref>). There are two main variants of RNNs used in the state-of-the-art research, such as standard RNNs (Rumelhart et al., <xref ref-type="bibr" rid="CR129">1988</xref>) and bi-directional RNNs (Schuster &amp; Paliwal, <xref ref-type="bibr" rid="CR131">1997</xref>). Standard RNNs can propagate the error in only one direction and, therefore, cannot use future inputs for current prediction. On the other hand, using causal predictions with bi-directional RNNs converts them into standard RNNs (Yoon &amp; van der Schaar, <xref ref-type="bibr" rid="CR164">2017</xref>). Yoon and van der Schaar (<xref ref-type="bibr" rid="CR164">2017</xref>) addressed this limitation of Bi-directional RNNs for causal prediction by proposing a novel RNN architecture called Entangled RNN (E-RNN). By stacking an additional forward hidden layer on top of the Bi-RNN structure, the causal prediction of E-RNN is dependent on all the previous backward hidden states. E-RNN can be used in a plethora of applications, ranging from medicine to finance. Importantly, E-RNN can be combined with various state-of-the-art RNN techniques such as multilayer (Parlos et al., <xref ref-type="bibr" rid="CR120">1994</xref>), dropout (Srivastava et al., <xref ref-type="bibr" rid="CR142">2014</xref>), LSTM (Hochreiter &amp; Schmidhuber, <xref ref-type="bibr" rid="CR62">1997</xref>), and GRU (Chung et al., <xref ref-type="bibr" rid="CR27">2015</xref>) and leads to performance gains, without the need for any additional assumptions. Entangled Recurrent Neural Networks have been used in multiple domains such as face image sequencing (Oh et al., <xref ref-type="bibr" rid="CR112">2021</xref>), load forecasting (Sriram et al., <xref ref-type="bibr" rid="CR141">2018</xref>), and other power system applications (Sriram, <xref ref-type="bibr" rid="CR140">2020</xref>). However, as aforementioned, to the best of the authors’ knowledge, E-RNNs have not been used in the domain of OR, especially in energy demand forecasting.</p><p id="Par5">In this contribution, the relation between the weather conditions that are already used for forecasting purposes in energy consumption is used (Ghalehkhondabi et al., <xref ref-type="bibr" rid="CR53">2017</xref>). The causal link between energy consumption and weather conditions might improve upon the state-of-the-art forecasting accuracies. Once the demand forecasting based on the proposed causal relation and using E-RNNs is obtained, the E-RNNs’ performance is compared against the other state-of-the-art RNN techniques such as multilayer multivariate bi-bidirectional LSTM (Chung et al., <xref ref-type="bibr" rid="CR27">2015</xref>; Hochreiter &amp; Schmidhuber, <xref ref-type="bibr" rid="CR62">1997</xref>; Parlos et al., <xref ref-type="bibr" rid="CR120">1994</xref>; Srivastava et al., <xref ref-type="bibr" rid="CR142">2014</xref>). Specifically, this paper addresses the following research question:</p><p><bold>How much does the causal information between the weather conditions and the energy demand improves the energy demand forecasting using deep learning networks?</bold></p><p id="Par6">To address the aforementioned research question, the proposed method is applied to three datasets where additional information about the causal relations is used. These causal relations are between the weather conditions and the energy consumption in the training phase of the algorithm to forecast the energy consumption. These results will be compared against a multivariate bidirectional LSTM using just the weather conditions to forecast the energy consumption. Such a comparison will establish the role of causal relations in the forecasting of energy consumption. The current research in this field supports the use of deep learning methods for forecasting, but there is little to no knowledge about the role played by the factors causing the energy use in the different geopolitical landscapes such as a whole country, a region within a country, cities, and a standalone building. The causal relation also changes based on how wide the area has been considered for exploration. Therefore, it is necessary to study and understand the importance of the causal relationship between weather factors and energy consumption, especially when it comes to time-series prediction and forecasting.</p><p id="Par7">The remainder of the paper is organized as follows. The second section presents an overview of deep learning applications in OR, the role of energy demand forecasting in OR, and deep learning applications for energy forecasting. The third section presents the methodology, including the description of the datasets brief introduction to LSTMs, and the proposed method. The fourth section presents the results, and the fifth section discusses the results and presents the implications. Finally, the sixth section concludes the paper.</p></sec><sec id="Sec3"><title>Related work</title><sec id="Sec4"><title>Deep learning applications in operation research</title><p id="Par8">Over the past few years, innovations in business analytics and operations management are becoming necessary factors for the success of the ventures (Lim et al., <xref ref-type="bibr" rid="CR96">2013</xref>; Mortenson et al., <xref ref-type="bibr" rid="CR108">2015</xref>; Ranyard et al., <xref ref-type="bibr" rid="CR127">2015</xref>). During these years, deep learning has been used in a variety of operations research applications. For example, supply chain management (Kilimci et al., <xref ref-type="bibr" rid="CR82">2019</xref>; Pacella &amp; Papadia, <xref ref-type="bibr" rid="CR118">2021</xref>; Punia et al., <xref ref-type="bibr" rid="CR123">2020</xref>), understanding/predicting financial risk behaviour (Geng et al., <xref ref-type="bibr" rid="CR52">2015</xref>; Kim et al., <xref ref-type="bibr" rid="CR83">2020a</xref>, <xref ref-type="bibr" rid="CR85">2020b</xref>; Xu &amp; He, <xref ref-type="bibr" rid="CR163">2020</xref>) price and price movement forecasting (Sen &amp; Mehtab, <xref ref-type="bibr" rid="CR174">2021</xref>; Shahi et al., <xref ref-type="bibr" rid="CR134">2020</xref>), fault diagnosis (Kumar et al., <xref ref-type="bibr" rid="CR90">2016</xref>), maintenance prediction (Kumar et al., <xref ref-type="bibr" rid="CR91">2018</xref>) and asset management for maintenance prediction (Chen et al., <xref ref-type="bibr" rid="CR23">2021</xref>) and sustainability performance prediction (Rajesh, <xref ref-type="bibr" rid="CR125">2020</xref>). In the following paragraphs, a brief overview is provided about each of these sub-fields and how deep learning methods are applied within the sub-fields.</p><p id="Par9">Organizations use supply chain forecasting as part of their supply chain management to fulfil the requirements of short-term and long-run aggregate forecasting. Such forecasting aids in the decision-making at strategic and tactical levels. In recent times applications of and improvements upon existing deep learning networks have been frequently utilized for this purpose. For example, Kilimci et al. (<xref ref-type="bibr" rid="CR82">2019</xref>) used a decision integration strategy empowered using a combination of support vector regression and a deep learning network to forecast the demand in the Turkish market. Pacella and Papadia (<xref ref-type="bibr" rid="CR118">2021</xref>) used LSTMs to forecast the demand of products in the supply chain to form a better and more accurate basis for the respective replenishment systems. Xu and He (<xref ref-type="bibr" rid="CR163">2020</xref>) used a deep belief network to forecast the financial credit risk, as a crucial part of the supply chain finance, to maintain the sustainable profit growth for financial organizations. Along with demand forecasting, sales prediction is also important in the supply chain management to make sure that the stores do not sell overstock, avoid understocking, reduce losses and minimize waste. In this vein, Husna et al. (<xref ref-type="bibr" rid="CR68">2021</xref>) used LSTM and convolutional neural networks to forecast the sales of grocery stores. Other examples of sales forecasting in the different sectors include fashion retail (Giri et al., <xref ref-type="bibr" rid="CR56">2019</xref>; Loureiro et al., <xref ref-type="bibr" rid="CR99">2018</xref>), e-commerce (Pan &amp; Zhou, <xref ref-type="bibr" rid="CR119">2020</xref>; Qi et al., <xref ref-type="bibr" rid="CR124">2019</xref>), pharmaceuticals (Chang et al., <xref ref-type="bibr" rid="CR20">2017</xref>; Ferreira et al., <xref ref-type="bibr" rid="CR48">2018</xref>) to mention a few.</p><p id="Par10">There are several examples where improvements upon existing deep learning methods were proposed. For example, Punia et al. (<xref ref-type="bibr" rid="CR123">2020</xref>) proposed a novel and improved cross-temporal deep learning architecture to forecast all levels (e.g., individual stock units, product groups, online and offline channels) of a retail supply chain. In another example, Kegenbekov and Jackson (<xref ref-type="bibr" rid="CR81">2021</xref>) used an adaptive deep reinforcement learning method to achieve synchronization between the inbound and outbound flows in an organization. In all these examples mentioned above, the models incorporating deep learning methods outperform various traditional methods. These traditional methods include basic machine learning algorithms (Husna et al., <xref ref-type="bibr" rid="CR68">2021</xref>; Kilimci et al., <xref ref-type="bibr" rid="CR82">2019</xref>; Xu &amp; He, <xref ref-type="bibr" rid="CR163">2020</xref>), statistical methods (Pacella &amp; Papadia, <xref ref-type="bibr" rid="CR118">2021</xref>; Xu &amp; He, <xref ref-type="bibr" rid="CR163">2020</xref>), and sometimes even pre-existing deep learning methods (Punia et al., <xref ref-type="bibr" rid="CR123">2020</xref>). Another facet of deep learning applications for supply chain management is for verifying, generating, and augmenting supply chain maps. For this purpose, Wichmann et al. (<xref ref-type="bibr" rid="CR160">2020</xref>) used natural language processing and LSTM to automatically extract the buyer–seller relations from texts and then use the features to generate basic supply chain maps and verify/augment existing ones. More recently, Guan and Yu (<xref ref-type="bibr" rid="CR58">2021</xref>) used the features from the resource distribution allocation index and a deep learning network to inform the design of the supply chain resource distribution allocation model.</p><p id="Par11">For predicting financial risk behaviour, deep learning has been used at various stages of an artificial intelligence pipeline. In other words, deep learning has been used not only at the prediction stage of a process but also at earlier stages as well, such as during the feature extraction and selection phases. For example, Kim et al., (<xref ref-type="bibr" rid="CR83">2020a</xref>, <xref ref-type="bibr" rid="CR85">2020b</xref>) used deep learning to extract features from structured data for retail traders to identify/predict risk-related behaviour. Kim et al., (<xref ref-type="bibr" rid="CR83">2020a</xref>, <xref ref-type="bibr" rid="CR85">2020b</xref>) showed that the features extracted using deep learning methods provided better prediction outcomes than the traditional methods. Similarly, Geng et al. (<xref ref-type="bibr" rid="CR52">2015</xref>) used deep neural networks to extract features from the data collected about customers to predict the bankruptcy chances of the customers. Another financial risk venture for deep learning algorithms is in the direction of volatility. Liu (<xref ref-type="bibr" rid="CR98">2019</xref>) showed that the LSTM-RNN-based methods outperformed one of the most popular techniques (GARCH, Pérez-Cruz et al., <xref ref-type="bibr" rid="CR122">2003</xref>) for volatility prediction. Similar results and trends were reported by Xiong et al. (<xref ref-type="bibr" rid="CR162">2015</xref>) in the case of volatility prediction and comparison with GARCH. Chatzis et al. (<xref ref-type="bibr" rid="CR21">2018</xref>) used deep learning methods to forecast the stock market crisis and showed the prevalence of such methods over the classical methods. Along with similar trends, Moews et al. (<xref ref-type="bibr" rid="CR105">2019</xref>) reported better performances shown by deep learning models when compared to traditional machine learning models. Eachempati et al. (<xref ref-type="bibr" rid="CR37">2021</xref>) have also shown that the deep neural networks outperform the traditional methods of predicting the accounting disclosure, another type of financial behaviour that has gained considerable attraction from the deep learning applications (Almagtome, <xref ref-type="bibr" rid="CR6">2021</xref>). Another aspect of risk behaviour that was detected using such techniques is the detection of fraudulent reviews for online marketing websites (Kumar et al., <xref ref-type="bibr" rid="CR89">2022a</xref>, <xref ref-type="bibr" rid="CR88">2022b</xref>). Kumar et al., (<xref ref-type="bibr" rid="CR89">2022a</xref>, <xref ref-type="bibr" rid="CR88">2022b</xref>) examined the different pre-processing and feature engineering techniques to extract both reviews and review-centric features and showed that unifying these features in ML classifiers resulted in better detection of fraudulent reviews than the contemporary methods. Furthermore, using deep learning techniques and text mining Huang et al. (<xref ref-type="bibr" rid="CR66">2022</xref>) provided a more accurate estimate of financial distress for beneficiaries and investors than classical machine learning algorithms.</p><p id="Par12">Concerning the stock market prices, deep learning has attracted a multitude of efforts in the direction of stock price forecasting. To compare the different deep learning models such as LSTM and GRU, Shahi et al. (<xref ref-type="bibr" rid="CR134">2020</xref>) showed that there was no significant difference while using the models, but when the authors added additional sentiment data to forecast the stock prices, the performance was significantly increased. The high predictive performance of deep and extreme machine learning algorithms for stock price prediction was also reported by Balaji et al. (<xref ref-type="bibr" rid="CR175">2018</xref>), Sen and Mehtab (<xref ref-type="bibr" rid="CR174">2021</xref>), and Liu et al. (<xref ref-type="bibr" rid="CR97">2022</xref>). Furthermore, Wang and Fan (<xref ref-type="bibr" rid="CR158">2021</xref>) show that by incorporating complex non-linear relations into the architecture of the deep learning networks, one can achieve high stock price prediction capacity. Sirignano and Cont (<xref ref-type="bibr" rid="CR138">2019</xref>) used a deep temporal network and trained it on all the stock data that they obtained and showed that this model outperformed individually trained models. Li and Pan (<xref ref-type="bibr" rid="CR95">2022</xref>) proposed an ensemble deep learning model for predicting stock prices using the current affairs of the companies. ) used a generative adversarial network for stock market price movement prediction. Another set of efforts used sentiment analysis of Twitter data for stock price prediction (Darapaneni et al., <xref ref-type="bibr" rid="CR29">2022</xref>; Jing et al.,
<xref ref-type="bibr" rid="CR75">2021</xref>; Mohan et al., <xref ref-type="bibr" rid="CR106">2019</xref>; Rao &amp; Srivastava, <xref ref-type="bibr" rid="CR128">2012</xref>; Shivaprasad and Shetty, <xref ref-type="bibr" rid="CR137">2017</xref>; Swathi et al., <xref ref-type="bibr" rid="CR147">2022</xref>; Yusof et al., <xref ref-type="bibr" rid="CR165">2018</xref>). Sirignano and Cont (<xref ref-type="bibr" rid="CR138">2019</xref>) further claim that the "general" model can also be used for "transfer" learning purposes. A sub-application of stock price prediction is predicting the stock price movements and price formulation. For example, Tsantekidis et al. (<xref ref-type="bibr" rid="CR150">2017</xref>) used stochastic deep learning networks to forecast the price movement from the large-scale high-frequency data. In the same vein, Zhao and Chen (<xref ref-type="bibr" rid="CR169">2021</xref>) integrated ARIMA, convolutional neural networks, and long-short term memory to detect non-linear temporal patterns and predict the stock price movement. For deeper reviews on the applications of the deep learning algorithms in the domain of finance, see the surveys done by Ozbayoglu et al. (<xref ref-type="bibr" rid="CR115">2020</xref>) and Sezer et al. (<xref ref-type="bibr" rid="CR133">2020</xref>).</p></sec><sec id="Sec5"><title>Energy demand/consumption forecasting</title><p id="Par13">Energy demand forecasting/prediction is not a new problem. However, as mentioned in the introduction that it has become, over the years, an important problem to solve from an OR perspective. In the following, a few examples are described of how the past researchers have addressed the problem of energy demand/consumption forecasting/prediction. For comprehensive and in-depth reviews, see, Ghalehkhondabi et al. (<xref ref-type="bibr" rid="CR53">2017</xref>), Islam et al. (<xref ref-type="bibr" rid="CR71">2020</xref>), and Suganthi and Samuel (<xref ref-type="bibr" rid="CR145">2012</xref>). The examples covered in this brief overview, methods to forecast/predict the energy demand/consumption, are from basic time-series, regression and econometric analysis, ARMIA and GARCH models, basic machine learning, and deep learning methods.</p><p id="Par14">Time series models are concerned with trend analysis, Markov models, and spectrum analysis. Ediger and Tatlıdil (<xref ref-type="bibr" rid="CR38">2002</xref>) analysed the cyclic patterns in the energy consumption data to forecast the energy demands in Turkey. Aydin (<xref ref-type="bibr" rid="CR10">2014</xref>) used distribution analysis (t- and F-distributions) to forecast the demand for energy from fossil fuels globally. Aydin (<xref ref-type="bibr" rid="CR11">2015</xref>) used a similar analysis to model the trends of coal-based energy demands in countries such as India, the United States, Japan, South Africa, and Thailand. Farajian et al. (<xref ref-type="bibr" rid="CR46">2018</xref>) used the Box-Jenkins method for trend analysis to provide the agriculture energy demands in Iran over a 24-year period. Morakinyo et al. (<xref ref-type="bibr" rid="CR107">2019</xref>) used the trend analysis to predict the energy consumption on the extreme weather days to delineate the effect of the extremely hot or extremely cold days. Tian et al. (<xref ref-type="bibr" rid="CR149">2022</xref>) conducted a similar analysis as Morakinyo et al. (<xref ref-type="bibr" rid="CR107">2019</xref>) with additional regional climate models to predict the energy consumption during the extreme weather days in various regions of Canada.</p><p id="Par15">Efforts from a regression analysis point of view have used different variables to predict the energy demands of households, buildings, and regions. For example, Harold et al. (<xref ref-type="bibr" rid="CR59">2017</xref>) used the income elasticity of households and quantile regressions to predict the energy consumption, with the aim of informing the use of constant mean elasticity for policy purposes. Maaouane et al. (<xref ref-type="bibr" rid="CR102">2021</xref>) used the import, export, and energy efficiency measures information to predict the energy demands in the industrial sector. Catalina et al. (<xref ref-type="bibr" rid="CR18">2013</xref>) used the global heat loss coefficient of buildings, the indoor set point, the sol–air temperature difference, and the south equivalent surface to predict the heating energy consumption. Many studies have considered whether factors as independent variables in regression analysis to predict the energy demands. For example, Braun et al. (<xref ref-type="bibr" rid="CR17">2014</xref>) used humidity and temperature to predict the energy demands of supermarkets in the UK. Fumo and Biswas (<xref ref-type="bibr" rid="CR51">2015</xref>) used indoor and outdoor temperature and solar radiation to predict the energy consumption of residential buildings. Tso and Guan (<xref ref-type="bibr" rid="CR151">2014</xref>) also predicted the residential energy demands using the house size, housing type, heating requirement, and amount of air-conditioning use and a multiple regression model.</p><p id="Par16">Econometric models use the correlations between the energy demand and the macro-economic variables to predict/forecast the energy demands/consumption. One of the methods for incorporating the macro-economic variables in the analysis is to use the causal analysis. For example, Kayhan et al. (<xref ref-type="bibr" rid="CR80">2010</xref>) used the causality between economic growth and energy consumption to forecast the energy demands in Romanian households. In another study, Sentürk and Sataf (<xref ref-type="bibr" rid="CR132">2015</xref>) used the GDP and other socio-econometric information from the World Economic Forum for seven countries (Turkey, Kazakhstan, Azerbaijan, Kyrgyzstan, Uzbekistan, Turkmenistan, and Tajikistan) to predict the overall energy consumption in those countries. Ozturk et al. (<xref ref-type="bibr" rid="CR116">2010</xref>) used similar information to analyse the causality between the GDP and the energy consumption for 51 countries and showed that for the low-income counties, the GDP Granger caused the energy consumption; while for the middle-income countries, there was a bi-directional causality. Other examples of studies using economic growth to cointegrate/predict energy consumption at a large scale could be found in Sentürk and Sataf (<xref ref-type="bibr" rid="CR132">2015</xref>).</p><p id="Par17">The next category of tools used is the models with auto-regressive components, that is, auto-regressive moving average (ARMA), auto-regressive integrated moving average (ARIMA), and generalized autoregressive conditional heteroskedasticity (GARCH). ARIMA and/or ARMA models are used to extract the historical trends in the time-series data and use this information for forecasting purposes (Erdogdu, <xref ref-type="bibr" rid="CR42">2007</xref>; Ho &amp; Xie, <xref ref-type="bibr" rid="CR61">1998</xref>; Huang &amp; Shih, <xref ref-type="bibr" rid="CR67">2003</xref>; Vo et al, <xref ref-type="bibr" rid="CR156">2021</xref>; Wang et al., <xref ref-type="bibr" rid="CR157">2019</xref>). The only difference between the two models is that, unlike ARMA models, the ARIMA models can be used only with stationary time-series (Valipour et al., <xref ref-type="bibr" rid="CR152">2013</xref>). On the other hand, GARCH models have similar functionality as ARMA/ARIMA models with one key difference (Bauwens et al., <xref ref-type="bibr" rid="CR14">2006</xref>; Engle, <xref ref-type="bibr" rid="CR41">2001</xref>). While ARMA/ARIMA models utilize the conditional mean of the time series to forecast the values, GARCH models use the conditional variances in the time series to perform similar forecasts. These models are especially useful when there is heterogeneity in the time series (Bauwens et al., <xref ref-type="bibr" rid="CR14">2006</xref>; Engle, <xref ref-type="bibr" rid="CR41">2001</xref>). Examples of studies using ARMA/ARIMA models for predicting the future energy demands include Li and Li (<xref ref-type="bibr" rid="CR93">2017</xref>) predicting the future energy consumption in the Shandong province in China; Ozturk and Ozturk (<xref ref-type="bibr" rid="CR117">2018</xref>) predicting the coal, oil, natural gas, and renewable energy consumption in Turkey. Furthermore, Eerdogdu (<xref ref-type="bibr" rid="CR42">2007</xref>) also used cointegratison analysis with ARIMA to predict total energy consumption in Turkey, while ) used ARIMA models to predict agricultural loads at small scales. Other similar efforts include predicting energy consumption in Morocco (Kafazi et al., <xref ref-type="bibr" rid="CR77">2016</xref>), Ghana (Sarkodie, <xref ref-type="bibr" rid="CR130">2017</xref>), Afghanistan (Mitkov et al., <xref ref-type="bibr" rid="CR104">2019</xref>), India, China, and the USA (Jiang et al., <xref ref-type="bibr" rid="CR74">2018</xref>), and Middle Africa (Wang et al., <xref ref-type="bibr" rid="CR159">2018</xref>). In the case of using GARCH for prediction purposes in the energy sector, the primary use cases of this method if predicting the volatility of the energy market and load forecasting. For example, Efimova and Serletis (<xref ref-type="bibr" rid="CR40">2014</xref>) use the extreme weather conditions, geopolitical tensions, and de-regularised markets along with GARCH models to forecast the volatility in the energy market; while Ergen and Rizvanoghlu (<xref ref-type="bibr" rid="CR43">2016</xref>) used GARCH and the historical changes due to weather and demand abnormalities to forecast the volatility in the natural gas energy demand. Fałdziński et al. (<xref ref-type="bibr" rid="CR45">2020</xref>) used GARCH and SVM to forecast the volatility in the demands of multiple energy sources (e.g., oil, gas, gasoline). Concerning load forecasting, Hor et al. (<xref ref-type="bibr" rid="CR63">2006</xref>) used GARCH not only for the load forecast daily but also to estimate the maximum daily demand with high accuracy. Similarly, Iwafune et al. (<xref ref-type="bibr" rid="CR72">2014</xref>) used GARCH to forecast a building's energy load in short-term usage. For a comparison of time-series-based methods for energy demand forecasting, see Okawu et al. (<xref ref-type="bibr" rid="CR113">2019</xref>).</p><p id="Par18">Another category of studies to forecast the energy demands is concerned with the basic machine learning algorithms. For example, Eseye and Lehtonen (<xref ref-type="bibr" rid="CR44">2020</xref>) used Artificial Neural Networks (ANN) and Support Vector Machines (SVM) with the weather, occupancy, and heat requirement data, to predict the energy consumption for residential buildings in Finland. Pelka (<xref ref-type="bibr" rid="CR121">2021</xref>) also used SVM and ARIMA models to predict the mid-term energy consumption in European countries. Wu and Shen (<xref ref-type="bibr" rid="CR161">2018</xref>) use a swarm optimization-based SVM to predict the natural gas consumption. Johannesen et al. (<xref ref-type="bibr" rid="CR76">2019</xref>) compared different machine learning algorithms for different time units and concluded that random forest regressors were the best performing for the long-term forecasting problems, while K-Nearest neighbour based regressors were the most efficient for the short term forecasts. Ahmad and Chen (<xref ref-type="bibr" rid="CR4">2019</xref>) used Random Forest with non-linear auto-regression techniques to predict the energy demands during the different seasons and with the aim of having a more accurate grid-based distribution scheme than before. Wang et al. (<xref ref-type="bibr" rid="CR159">2018</xref>) also used Random Forests to predict short-term energy demands for building in Florida.) compared future energy predictions using the ARIMA and Random Forest models, and the results show that Random forest was better performing for the long-term prediction between the two models. Other examples of using basic machine learning algorithms include Murat and Ceylan (<xref ref-type="bibr" rid="CR109">2006</xref>) using ANN to predict the energy demand in the transport sector; Kankal and Uzlu (<xref ref-type="bibr" rid="CR79">2017</xref>) also using ANN for long-term energy demand forecast in Turkey; Ferlito et al. (<xref ref-type="bibr" rid="CR47">2015</xref>) using ANN to forecast a building's energy consumption; Lu et al. (<xref ref-type="bibr" rid="CR100">2021</xref>) using SVM for forecasting the energy consumption in the USA; Ghazal et al. (<xref ref-type="bibr" rid="CR54">2022</xref>) using IoT data and fusion of SVM algorithms to predict the industrial energy consumption and; Jana and Ghosh (<xref ref-type="bibr" rid="CR73">2022</xref>) using discrete wavelet transform and ensemble machine learning algorithms to forecast natural gas prices and demand. Forouzandeh et al. (<xref ref-type="bibr" rid="CR50">2022</xref>) also used ensemble machine learning algorithms to predict room energy demand. For a comprehensive review of studies using artificial neural networks and support vector machines for energy demand forecasting, see Ahmad et al. (<xref ref-type="bibr" rid="CR3">2014</xref>).</p><p id="Par19">Finally, the most recent set of studies (as is clear from the advancement of the methods and computing power in the last decade) concern the methods related to deep learning for forecasting the energy requirements in various sectors (e.g., household, industries), at various time scales (e.g., short-term, mid-term, long-term), and for the different area-scope (e.g., buildings, regions, countries). For example, Hrnjica and Mehr (<xref ref-type="bibr" rid="CR65">2020</xref>) used the time-series decomposition and Recurrent Neural Networks (RNN) to predict the energy demand in Northern Nicosia, Cyprus. Real et al. (<xref ref-type="bibr" rid="CR31">2020</xref>) used a combination of Convolutional Neural Networks (CNN) and ANN for load forecasting in French grids. Ishaq and Kwon (<xref ref-type="bibr" rid="CR70">2021</xref>) used an Ensemble of deep network architectures to forecast short-term energy demands for local Korean buildings. Somu and Ramamritham (<xref ref-type="bibr" rid="CR139">2021</xref>) also predicted the future energy for a local building using combinations of CNN and LSTM. Al Khafaf et al. (<xref ref-type="bibr" rid="CR5">2019</xref>) used LSTM to forecast energy demands in Victoria, Australia. Kim and Cho (<xref ref-type="bibr" rid="CR84">2019a</xref>, <xref ref-type="bibr" rid="CR86">2019b</xref>) also used LSTM and an auto-encounter for short-term forecasting of power demands in households. There have been a few studies where the traditional machine learning algorithm and deep learning algorithms were compared in terms of their forecasting accuracies. For example, Paterakis et al. (<xref ref-type="bibr" rid="CR176">2017</xref>) compared multiple layer perceptron against Random forest, SVM, and other regressors; Ağbulut (<xref ref-type="bibr" rid="CR2">2022</xref>) compared deep neural networks against SVM to predict the energy demands for the transport sector; Bakay and Ağbulut (<xref ref-type="bibr" rid="CR13">2021</xref>) compared deep neural networks against SVM and ANN to forecast electricity demands in Turkey; Shirzadi et al. (<xref ref-type="bibr" rid="CR136">2021</xref>) compared LSTMs against SVM and random forest to forecast long-term power demands in Ontario, Canada. In all these examples, the deep learning algorithms outperformed the basic machine learning algorithms. Another example of using deep networks in the energy sector is to perform the assets management for the electrical grid companies (Kala et al., <xref ref-type="bibr" rid="CR78">2020</xref>), where the authors showed that their proposed algorithm involves the faster regional convolutional neural networks outperformed the human-coding efforts for asset management. For a comprehensive review of deep learning for energy systems and building energy, please see, Forootan et al. (<xref ref-type="bibr" rid="CR49">2022</xref>) and Ardabili et al. (<xref ref-type="bibr" rid="CR9">2022</xref>), respectively. From the studies reported in this section, there is a lot of potential in using deep learning methods to forecast energy consumption as a process in Operations Research. This contribution aims to improve upon the existing deep learning algorithms to predict future energy demands/consumption by incorporating the causal relation between the weather information and the energy consumption over different area-scope (e.g., buildings, regions, countries).</p></sec></sec><sec id="Sec6" sec-type="methods"><title>Methodology</title><sec id="Sec7"><title>Granger causality</title><p id="Par20">Granger causality (Granger, <xref ref-type="bibr" rid="CR57">1969</xref>) tests for the ability of one time series to predict another one – in the present case, whether information flow provides sufficient information to predict 1) user focus size, 2) cognitive load, and 3) user attention flow. Granger causality investigates bi-directional, simultaneous, and continuous relationships and has been employed in several studies in OR (e.g., Ghouali et al., <xref ref-type="bibr" rid="CR55">2014</xref>; Mian &amp; Liang, <xref ref-type="bibr" rid="CR103">2010</xref>; Tang &amp; Chrsquo, <xref ref-type="bibr" rid="CR148">2011</xref>; Zhang &amp; Xu, <xref ref-type="bibr" rid="CR166">2015</xref>). The basic definition of Granger causality has two assumptions (Granger, <xref ref-type="bibr" rid="CR57">1969</xref>). First, it assumes that the cause occurs prior to the effect. Second, the cause contains information about the effect that is more important than the history of the effect itself. Although Granger causality is defined for linear and stationary time-series contexts, variations for non-linear (Ancona et al., <xref ref-type="bibr" rid="CR7">2004</xref>; Chen et al., <xref ref-type="bibr" rid="CR26">2004</xref>) and non-stationary (Ding et al., <xref ref-type="bibr" rid="CR33">2000</xref>; Hesse et al., <xref ref-type="bibr" rid="CR60">2003</xref>) data exist.</p><p id="Par21">The main idea behind Granger’s definition of causality is that if the lag (past values) of variable one predicts the current value of variable two in a better manner than the lags (past values) of the variable two itself, it can be inferred that variable one causes variable two. To arrive at such an inference, there is a simple method to be followed. Considering the case of two variables, <italic>X</italic> and <italic>Y</italic>. To determine whether <italic>X</italic> Granger causes <italic>Y</italic> or the other way around, two models are created. The first model predicts the current value of <italic>Y</italic> using the past values of <italic>Y</italic>, while the second model predicts the current value of <italic>Y</italic> using the past values of <italic>X</italic>. Then, the quality of the prediction for both models is compared; if the second model outperforms the first model, it can be inferred that <italic>X</italic> Granger causes <italic>Y</italic>.</p><p id="Par22">To conduct the data analysis, there are a number of statistical steps. First is data treatment, which is to divide the dataset comprising of weather information and energy consumption into 48 h windows for further analyses. Then the stationary nature of the time series is tested: a Ljung-Box test is used to determine whether there are significant non-zero correlation coefficients at lags 1–15. Small p-values suggest that the time series data is stationary. Further, the optimum value for the ‘lag’ is identified as the number of previous data points considered for modelling the causality. The value is identified based on the Akaike information criterion (AIC) value of the model. Different models are created with different values of lag that must be considered for the Granger causality consideration and select the model with the lowest AIC value.</p><p id="Par23">Next, Granger Causality (Granger, <xref ref-type="bibr" rid="CR57">1969</xref>) is tested to examine the causality between the different variable pairs (humidity – energy consumption; information flow – energy consumption; information flow – energy consumption; wind speed – energy consumption). As aforementioned, the basic principle of Granger causality is to compare two models to test whether <italic>x causes y</italic>. The first model predicts the value of <italic>y</italic> at time <italic>t</italic> using the previous <italic>n</italic> values of <italic>y</italic>. The second model predicts the value of <italic>y</italic> at time <italic>t</italic> using the previous <italic>n</italic> values of both <italic>x</italic> and <italic>y</italic>. The comparison of the two models can tell whether the history of <italic>x</italic> contains more information about <italic>y</italic> than the history of <italic>y</italic> itself. If this is the case, then it can be said that <italic>x Granger causes y</italic>.<disp-formula id="Equa"><alternatives><mml:math display="block" id="Equa_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>11</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>12</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mn>22</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Equa_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \begin{aligned} &amp; y(t) = \sum\limits_{j = 1}^{p} {\alpha_{11j} x(t - j) + \alpha_{12j} y(t - j) + \varepsilon_{1} t} \\ &amp; y(t) = \sum\limits_{j = 1}^{p} {\alpha_{22j} y(t - j) + \varepsilon_{2} t} \\ \end{aligned} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equa.gif"/></alternatives></disp-formula>where <italic>p</italic> model order, maximum lag included in the model, <italic>α</italic> coefficients matrix, the contribution of each lag value to the predicted value, ε residual, prediction error.</p><p id="Par24">One might argue about the choice of the method to analyse the causality between the different pairs of measurements. This paper uses the definition of causality provided by Granger. There are three other methods that could be used to show the causality between different variables: 1) Structured Equation Modelling (SEM, (Edwards &amp; Bagozzi, <xref ref-type="bibr" rid="CR39">2000</xref>)) 2) Cross-convergent mapping (CCM, (Sugihara et al., <xref ref-type="bibr" rid="CR146">2012</xref>)) and 3) conducting an intervention experiment where the hypothesized cause is controlled and the hypothesized 'effect' is measured (Shadish et al., <xref ref-type="bibr" rid="CR177">2002</xref>). SEM does not necessarily contain the information required to consider a causal relationship. Statistically speaking, testing an SEM is not a test for causality. There is a certain mathematical formulation under which SEM can be used for causal inference (Steyer, <xref ref-type="bibr" rid="CR143">2013</xref>; Steyer et al., <xref ref-type="bibr" rid="CR144">2002</xref>); however, the solutions are not available commercially. Bollen and Pearl (<xref ref-type="bibr" rid="CR16">2013</xref>) provide a detailed account describing how SEM should not be used for modelling causal relations between variables. The second method, that is, CCM, is useful only in the cases where the time series is stationary (i.e., the mean and variance of the variable do not change over time) and non-linear (i.e., there is no autocorrelation in the time series). Eye-tracking data is stationary (as revealed by the Ljung-Box test) but auto-correlated (where users look at current time instances vastly depending on where they were looking at previous instances). Therefore CCM is not an adequate method for such data. In the case of identifying causal relations between two variables through an experimental or pseudo-experimental setup, such setups are typically costly or require an extensive duration to identify the cause-effect relationship between the two variables in question (Chambliss &amp; Schutt, <xref ref-type="bibr" rid="CR19">2018</xref>). Moreover, it has also been shown that for longer time-series data, the Granger causality outperforms other contemporary methods (Zou &amp; Feng, <xref ref-type="bibr" rid="CR172">2009</xref>).</p><p id="Par25">In this contribution, four casualties for each dataset (and sub-datasets) are computed for a time window of 48 h with a one-hour shift between two consecutive windows: (1) pressure "Granger causing" demand; (2) wind speed "Granger causing" demand; (3) temperature "Granger causing" demand, and (4) humidity "Granger causing" demand. Once the F-values for all four causal relations are available over time, this is used as additional information for forecasting using entangled LSTM.</p></sec><sec id="Sec8"><title>Entangled LSTM</title><sec id="Sec9"><title>LSTM</title><p id="Par26">A single LSTM cell is comprised of four components:<list list-type="order"><list-item><p id="Par27">Forget gate (f): this is a neural network with a sigmoid activation function. This gate is responsible for what information is propagated to the next time step and what information is discarded. Depending on the previously hidden state h<sub>t-1</sub> and the current input x<sub>t</sub>, the forget gate assigns a value between zero and one to every element in the previous cell state C<sub>t-1</sub>. For all the elements that are assigned a value of one, the information is retained, and for all the elements that are assigned a value of zero are discarded. For all the elements that are assigned a value between zero and one, the value decides how much information is to be retained.</p></list-item><list-item><p id="Par28">Input gate (I): this is also a neural network that uses a sigmoid activation function. To make the decision about what new information is to be stored in the cell state (explained next), there are two different operations:<list list-type="alpha-lower"><list-item><p id="Par29">The input gate decides which values will be updated.</p></list-item><list-item><p id="Par30">Using a tanh activation function, a set of candidate values is created (<inline-formula id="IEq1"><alternatives><mml:math id="IEq1_Math"><mml:mover accent="true"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:math><tex-math id="IEq1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{{C_{t} }}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_IEq1.gif"/></alternatives></inline-formula>). Once <inline-formula id="IEq2"><alternatives><mml:math id="IEq2_Math"><mml:mover accent="true"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:math><tex-math id="IEq2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{{C_{t} }}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_IEq2.gif"/></alternatives></inline-formula> and I<sub>t</sub> are computed, the input given to the cell state can be decided.</p></list-item></list></p></list-item><list-item><p id="Par31">Cell State (C<sub>t</sub>): this functions as the memory of the LSTM. Due to the cell states, LSTMs usually outperform basic recurrent neural networks. For every time window, the C<sub>t-1</sub> is combined with the forget gate, and it is determined what information is propagated to the next time step and what information is discarded. The retained information is then combined with I<sub>t</sub> and <inline-formula id="IEq3"><alternatives><mml:math id="IEq3_Math"><mml:mover accent="true"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:math><tex-math id="IEq3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{{C_{t} }}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_IEq3.gif"/></alternatives></inline-formula> to create the new cell state that will be the new memory of the LSTM.</p></list-item><list-item><p id="Par32">Output gate (O): this is another neural network that uses a sigmoid activation function. The cell state computed from the previous step is passed through a hyperbolic function (tanh), and this creates the cell values that are filtered between -1 and 1.</p></list-item></list></p><p id="Par33">The schema in Fig. <xref rid="Fig1" ref-type="fig">1</xref> shows the various gates and their arrangement;
<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><p>One LSTM cell with all the components marked with red boxes. (Color figure online)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10479_2022_4857_Fig1_HTML.png" id="MO1"/></fig></p><p id="Par34">For each gate, the following are the variables (set of weights and biases):<list list-type="order"><list-item><p id="Par35">W<sub>f</sub> and b<sub>f</sub> are the Forget gate weight and bias, respectively.</p></list-item><list-item><p id="Par36">W<sub>i</sub> and b<sub>i</sub> are the Input gate weight and bias, respectively.</p></list-item><list-item><p id="Par37">W<sub>c</sub> and b<sub>c</sub> are the Candidate cell state weight and bias, respectively.</p></list-item><list-item><p id="Par38">W<sub>o</sub> and b<sub>o</sub> are the Output gate weight and bias, respectively.</p></list-item><list-item><p id="Par39">W<sub>v</sub> and b<sub>v</sub> are the Weight and bias associated with the Softmax layer, respectively.</p></list-item><list-item><p id="Par40">f<sub>t</sub>, i<sub>t</sub>, Ct, and o<sub>t</sub> are the Output of the activation functions for the forget, input, cell, and output gates, respectively.</p></list-item><list-item><p id="Par41">a<sub>f</sub>, a<sub>i</sub>, a<sub>c</sub>, and a<sub>o</sub> are the Input to the activation functions to the forget, input, cell, and output gates, respectively.</p></list-item><list-item><p id="Par42">CF is the cost function with respect to which the derivatives are calculated.</p></list-item></list> For each gate, the following equations show how the activation of each gate is calculated.<list list-type="order"><list-item><p id="Par44">Forget gate: <inline-formula id="IEq4"><alternatives><mml:math id="IEq4_Math"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mspace width="0.277778em"/><mml:mspace width="0.277778em"/><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a_{f} = W_{f} .Z_{t} + b_{f} \;\;f_{t} = sigmoid\left( {a_{f} } \right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_IEq4.gif"/></alternatives></inline-formula></p></list-item><list-item><p id="Par45">Input gate: <inline-formula id="IEq5"><alternatives><mml:math id="IEq5_Math"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mspace width="0.277778em"/><mml:mspace width="0.277778em"/><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a_{i} = W_{i} .Z_{t} + b_{i} \;\;i_{t} = sigmoid\left( {a_{i} } \right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_IEq5.gif"/></alternatives></inline-formula></p></list-item><list-item><p id="Par46">Input gate: <inline-formula id="IEq6"><alternatives><mml:math id="IEq6_Math"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mspace width="0.277778em"/><mml:mspace width="0.277778em"/><mml:mover accent="true"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a_{c} = W_{c} .Z_{t} + b_{c} \;\; \widetilde{{C_{t} }} = tanh\left( {a_{c} } \right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_IEq6.gif"/></alternatives></inline-formula></p></list-item><list-item><p id="Par47">Cell state: <inline-formula id="IEq7"><alternatives><mml:math id="IEq7_Math"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⊕</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true">~</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="IEq7_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C_{t} = f_{t} \otimes C_{t - 1} \oplus i_{t} \otimes \widetilde{{C_{t} }}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_IEq7.gif"/></alternatives></inline-formula></p></list-item><list-item><p id="Par48">Hidden state: <inline-formula id="IEq8"><alternatives><mml:math id="IEq8_Math"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="IEq8_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_{t} = o_{t} \otimes tanh(C_{t} ) $$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_IEq8.gif"/></alternatives></inline-formula></p></list-item><list-item><p id="Par49">Output Eq. 1: <inline-formula id="IEq9"><alternatives><mml:math id="IEq9_Math"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>V</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="IEq9_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V_{t} = W_{V} .h_{t} + b_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_IEq9.gif"/></alternatives></inline-formula></p></list-item><list-item><p id="Par50">Output Eq. 2: <inline-formula id="IEq10"><alternatives><mml:math id="IEq10_Math"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq10_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widehat{{y_{t} }} = softmax\left( {V_{t} } \right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_IEq10.gif"/></alternatives></inline-formula></p></list-item><list-item><p id="Par51">Output gate: <inline-formula id="IEq11"><alternatives><mml:math id="IEq11_Math"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mspace width="0.277778em"/><mml:mspace width="0.277778em"/><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq11_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a_{f} = W_{f} .Z_{t} + b_{f} \;\;f_{t} = sigmoid\left( {a_{f} } \right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_IEq11.gif"/></alternatives></inline-formula></p></list-item></list></p><p id="Par52">The outcome of all the gates is derived in a similar manner, and here the forget gate calculations are explained as an example. There is a fixed path from the activation of the forget gate to the cost function that is shown as the following:<disp-formula id="Equb"><alternatives><mml:math display="block" id="Equb_Math"><mml:mrow><mml:msub><mml:mtext>f</mml:mtext><mml:mtext>t</mml:mtext></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mtext>C</mml:mtext><mml:mtext>t</mml:mtext></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:msub><mml:mtext>h</mml:mtext><mml:mtext>t</mml:mtext></mml:msub><mml:mo stretchy="false">→</mml:mo><mml:mtext>CF</mml:mtext></mml:mrow></mml:math><tex-math id="Equb_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\text{f}}_{{\text{t}}} \to {\text{C}}_{{\text{t}}} \to {\text{h}}_{{\text{t}}} \to {\text{CF}} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equb.gif"/></alternatives></disp-formula></p><p id="Par53">The following is how the derivative is calculated for the cost function with respect to the forget gate.<disp-formula id="Equc"><alternatives><mml:math display="block" id="Equc_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equc_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{df_{t} }} = \frac{dCF}{{dh_{t} }} * \frac{{dh_{t} }}{{dC_{t} }} * \frac{{dC_{t} }}{{df_{t} }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equc.gif"/></alternatives></disp-formula></p><p id="Par54">All the derivatives of the cost function with respect to the cell state and hidden state are calculated in the same manner. Input to each LSTM is the previous cell state and the concatenated previous hidden state and current input. For simplicity [h<sub>t-1</sub>, x<sub>t</sub>]  Z<sub>t</sub><disp-formula id="Equd"><alternatives><mml:math display="block" id="Equd_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="Equd_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{dC_{t - 1} }} = \frac{dCF}{{dC_{t} }} * \frac{{dC_{t} }}{{dC_{t - 1} }} = \frac{dCF}{{dC_{t} }} * f_{t} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equd.gif"/></alternatives></disp-formula><disp-formula id="Eque"><alternatives><mml:math display="block" id="Eque_Math"><mml:mrow><mml:mtable><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mo>=</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>Z</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><tex-math id="Eque_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \begin{aligned} &amp; \frac{dCF}{{dZ_{t} }} = \frac{dCF}{{da_{f} }} * \frac{{da_{f} }}{{dZ_{t} }} + \frac{dCF}{{da_{i} }} * \frac{{da_{i} }}{{dZ_{t} }} + \frac{dCF}{{da_{o} }} * \frac{{da_{o} }}{{dZ_{t} }} + \frac{dCF}{{da_{c} }} * \frac{{da_{c} }}{{dZ_{t} }} \\ &amp; \quad \quad \quad \quad = W_{f}^{T} * \frac{{da_{f} }}{{dZ_{t} }} + W_{i}^{T} * \frac{{da_{i} }}{{dZ_{t} }} + W_{o}^{T} * \frac{{da_{o} }}{{dZ_{t} }} + W_{c}^{T} * \frac{{da_{c} }}{{dZ_{t} }} \\ \end{aligned} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Eque.gif"/></alternatives></disp-formula></p><p id="Par55">The forget gate:<disp-formula id="Equf"><alternatives><mml:math display="block" id="Equf_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equf_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{df_{t} }} = \frac{dCF}{{dh_{t} }} * \frac{{dh_{t} }}{{dC_{t} }} * \frac{{dC_{t} }}{{df_{t} }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equf.gif"/></alternatives></disp-formula></p><p id="Par56">But,<disp-formula id="Equg"><alternatives><mml:math display="block" id="Equg_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equg_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{dC_{t} }} = \frac{dCF}{{dh_{t} }} * \frac{{dh_{t} }}{{dC_{t} }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equg.gif"/></alternatives></disp-formula></p><p id="Par57">So,<disp-formula id="Equh"><alternatives><mml:math display="block" id="Equh_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equh_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{df_{t} }} = \frac{dCF}{{dC_{t} }} * \frac{{dC_{t} }}{{df_{t} }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equh.gif"/></alternatives></disp-formula><disp-formula id="Equi"><alternatives><mml:math display="block" id="Equi_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⊕</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equi_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{df_{t} }} = \frac{dCF}{{dC_{t} }} * \frac{{d \left( {f_{t} \otimes C_{t - 1} \oplus i_{t} \otimes \hat{C}_{t} } \right)}}{{df_{t} }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equi.gif"/></alternatives></disp-formula><disp-formula id="Equj"><alternatives><mml:math display="block" id="Equj_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="Equj_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{df_{t} }} = \frac{dCF}{{dC_{t} }} * C_{t} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equj.gif"/></alternatives></disp-formula></p><p id="Par58">And,<disp-formula id="Equk"><alternatives><mml:math display="block" id="Equk_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equk_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{da_{f} }} = \frac{dCF}{{df_{t} }} * \frac{{df_{t} }}{{da_{f} }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equk.gif"/></alternatives></disp-formula><disp-formula id="Equl"><alternatives><mml:math display="block" id="Equl_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equl_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{da_{f} }} = \frac{dCF}{{dC_{t} }} * C_{t - 1} * f_{t} \left( {1 - f_{t} } \right) $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equl.gif"/></alternatives></disp-formula></p><p id="Par59">The other derivatives can be computed with respect to the inputs and outputs of the cost function. For example, for the input gate,<disp-formula id="Equm"><alternatives><mml:math display="block" id="Equm_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="Equm_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{di_{t} }} = \frac{dCF}{{dC_{t} }} * \hat{C}_{t} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equm.gif"/></alternatives></disp-formula><disp-formula id="Equn"><alternatives><mml:math display="block" id="Equn_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equn_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{da_{i} }} = \frac{dCF}{{dC_{t} }} * \hat{C}_{t} * i_{t} \left( {1 - i_{t} } \right) $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equn.gif"/></alternatives></disp-formula></p><p id="Par60">For the Cell State:<disp-formula id="Equo"><alternatives><mml:math display="block" id="Equo_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:msup><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mfenced close=")" open="("><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equo_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{dC_{t} }} = \frac{dCF}{{dh_{t} }} * O_{t} * \left( {1 - tanh^{2} \left( {C_{t} } \right)} \right) $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equo.gif"/></alternatives></disp-formula><disp-formula id="Equp"><alternatives><mml:math display="block" id="Equp_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="Equp_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{d \hat{C}_{t} }} = \frac{{dC_{t} }}{{d \hat{C}_{t} }} * i_{t} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equp.gif"/></alternatives></disp-formula><disp-formula id="Equq"><alternatives><mml:math display="block" id="Equq_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equq_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{da_{c} }} = \frac{dCF}{{dC_{t} }} * i_{t} * \left( {1 - \hat{C}_{t}^{2} } \right) $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equq.gif"/></alternatives></disp-formula></p><p id="Par61">Output gate:<disp-formula id="Equr"><alternatives><mml:math display="block" id="Equr_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equr_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{dO_{t} }} = \frac{dCF}{{dh_{t} }} * tanh (C_{t} ) $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equr.gif"/></alternatives></disp-formula><disp-formula id="Equs"><alternatives><mml:math display="block" id="Equs_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mfenced><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equs_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{da_{o} }} = \frac{dCF}{{dh_{t} }} * tanh \left( {C_{t} } \right) * O_{t} \left( {1 - O_{t} } \right) $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equs.gif"/></alternatives></disp-formula>and finally, the hidden state:<disp-formula id="Equt"><alternatives><mml:math display="block" id="Equt_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>V</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equt_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{dh_{t} }} = \frac{dCF}{{dV_{t} }} * \frac{{d \left( {W_{V} * h_{t} } \right)}}{{dh_{t} }} = W_{V}^{T} * \frac{dCF}{{dV_{t} }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equt.gif"/></alternatives></disp-formula></p><p id="Par62">The weights for all the gates.</p><p id="Par63">Forget gate:<disp-formula id="Equu"><alternatives><mml:math display="block" id="Equu_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equu_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{dW_{f} }} = \frac{dCF}{{da_{i} }} * \frac{{da_{f} }}{{dW_{f} }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equu.gif"/></alternatives></disp-formula></p><p id="Par64">Input gate:<disp-formula id="Equv"><alternatives><mml:math display="block" id="Equv_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equv_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{dW_{i} }} = \frac{dCF}{{da_{i} }} * \frac{{da_{i} }}{{dW_{i} }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equv.gif"/></alternatives></disp-formula></p><p id="Par65">Output:<disp-formula id="Equw"><alternatives><mml:math display="block" id="Equw_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equw_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{dW_{V} }} = \frac{dCF}{{dV_{t} }} * \frac{{dV_{t} }}{{dW_{V} }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equw.gif"/></alternatives></disp-formula></p><p id="Par66">Output gate:<disp-formula id="Equx"><alternatives><mml:math display="block" id="Equx_Math"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">dCF</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow/><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>a</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equx_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{dCF}{{dW_{o} }} = \frac{dCF}{{da_{o} }} * \frac{{da_{o} }}{{dW_{o} }} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equx.gif"/></alternatives></disp-formula></p></sec><sec id="Sec10"><title>Bi-directional-LSTM</title><p id="Par67">Bi-directional LSTM, or Bi-LSTM, functions on a very simple principle. In Bi-LSTMs, there are just two LSTMs put together. The first LSTM runs on the exact input sequence that is provided by the dataset. The second LSTM runs in the reversed order of the input sequence as the first LSTM. This improves the LSTM by using both the temporal directions: past and future. The forward layer is responsible for the positive time (forward states or the future), and the backward state is responsible for the negative time (backward state or the past). It has been shown in various contexts that Bi-LSTM outperforms the simple LSTM. For example, Sun et al. (<xref ref-type="bibr" rid="CR178">2018</xref>) reported better prediction from using Bi-LSTM as compared to LSTM while predicting the blood glucose levels. Shahid et al. (<xref ref-type="bibr" rid="CR179">2020</xref>) also reported better prediction quality from Bi-LSTM than LSTM while predicting the COVID-19 infections. In terms of energy consumption prediction, Le et al. (<xref ref-type="bibr" rid="CR180">2019</xref>) showed better performance of Bi-LSTM than regular LSTM. Moreover, Kim and Cho (<xref ref-type="bibr" rid="CR84">2019a</xref>, <xref ref-type="bibr" rid="CR86">2019b</xref>) also show better energy consumption forecasting in specific regions while using Bi-LSTMS than regular LSTMs, whereas Ma et al. (<xref ref-type="bibr" rid="CR181">2020</xref>) showed similar results while predicting the future energy consumption of individual buildings. Other examples where Bidirectional LSTMs outperformed LSTM in time-series forecasting/prediction tasks include crop detection (Crisóstomo et al., <xref ref-type="bibr" rid="CR182">2020</xref>), text mining (Alzaidy et al., <xref ref-type="bibr" rid="CR183">2019</xref>), news classification (Li et al., <xref ref-type="bibr" rid="CR94">2002</xref>), human activity classification (Shrestha et al., <xref ref-type="bibr" rid="CR184">2020</xref>) and sequence tagging (Huang et al., <xref ref-type="bibr" rid="CR185">2015</xref>).</p><p id="Par68">The main reason for Bi-LSTM outperforming the simple LSTM can be attributed to the fact that by using two hidden states for each time step, the information from the past and the future is preserved, which in turn provides a better approximation of the time series and encodes the contexts in a better manner than just a forward layer. Therefore, Bi-LSTMs provide better forecasting performance than regular LSTMs. One of the key operations in the Bi-LSTMs is the merging of the two layers, that is, forward and backward layers. This operation is necessary because without merging, it will not be possible to combine the outputs of these layers since they function independently of each other. There are four primary ways of merging the output of these two layers. (1) Sum: The outputs are added together. (2) Multiply: The outputs are multiplied together. (3) Concatenation: The outputs are concatenated together (the default), providing double the number of outputs to the next layer. (4) Average: The average of the outputs is taken. The sum and multiplication artificially increase the variance of the outputs, while the average reduces them. At the same time, the concatenation maintains the original variances of the outputs of the forward and backward layers. Therefore most of the contributions use the concatenation operation to merge the outputs of the forward and backward layers in the Bi-LSTMs.</p></sec><sec id="Sec11"><title>Entangled-LSTM</title><p id="Par69">In the Entangled-LSTM, an additional layer containing the causal information is stacked on top of the backward layer of Bi-LSTM. This layer is a traditional LSTM layer where the positive direction of time (i.e., the future) is maintained. It can be seen in Fig. <xref rid="Fig2" ref-type="fig">2</xref> that the forward hidden layer that is stacked on top of the backward hidden layer is used for propagating the backward hidden state to the current output. The following shows the update process of the hidden and current output states:<disp-formula id="Equy"><alternatives><mml:math display="block" id="Equy_Math"><mml:mrow><mml:mi>h</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>b</mml:mi><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mi>W</mml:mi><mml:mi>f</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>h</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>U</mml:mi><mml:mi>f</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equy_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ hf_{t} = tanh \left( {bf + Wf*hf_{t - 1} + Uf*x_{t} } \right) $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equy.gif"/></alternatives></disp-formula><disp-formula id="Equz"><alternatives><mml:math display="block" id="Equz_Math"><mml:mrow><mml:mi>h</mml:mi><mml:msub><mml:mi>b</mml:mi><mml:mi>τ</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>b</mml:mi><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mi>W</mml:mi><mml:mi>b</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>h</mml:mi><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>U</mml:mi><mml:mi>b</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>b</mml:mi><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mi>W</mml:mi><mml:mi>b</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>h</mml:mi><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>τ</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>U</mml:mi><mml:mi>b</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>τ</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equz_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ hb_{\tau } = \left\{ {\begin{array}{*{20}c} { tanh \left( {bb + Wb*hb_{i} + Ub*x_{t} } \right) it \tau = t} \\ { tanh \left( {bb + Wb*hb_{\tau + 1} + Ub*x_{\tau } } \right) otherwise} \\ \end{array} } \right. $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equz.gif"/></alternatives></disp-formula><disp-formula id="Equaa"><alternatives><mml:math display="block" id="Equaa_Math"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mi>W</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>U</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mi>h</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi>h</mml:mi><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equaa_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ h_{t} = tanh \left( {b + W*h_{t - 1} + U\left[ {hf_{t} ;hb_{t} } \right]} \right) $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equaa.gif"/></alternatives></disp-formula><disp-formula id="Equab"><alternatives><mml:math display="block" id="Equab_Math"><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="Equab_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ O_{t} = c + Vh_{t} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equab.gif"/></alternatives></disp-formula>where h, hf, and HB are the hidden states in simple, forward, and backward layers, respectively; b, bf and bb are the biases in the simple, forward, and backward layers, respectively; W, Wf, Wb, U, Uf, Ub are the weights for the respective networks.<fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><p>Bidirectional LSTM (left) and entangled LSTM (right). Dash line: Independent connection to o<sub>t</sub>, Thick blue line: New connections by Entangled-LSTM. (Color figure online)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10479_2022_4857_Fig2_HTML.png" id="MO2"/></fig></p><p id="Par70">The outcome of the output layer is dependent on the propagated hidden state, the current forward and backward states. The propagated hidden state is dependent on the previous propagated hidden state, which is dependent on three states: 1) the previous propagated hidden state, 2) the previous forward hidden state, and 3) the previous backward hidden state. This chain of dependencies shows that the output at any time t is dependent on the entire input, forward, backward and hidden states. Whereas, in the Bi-LSTM, the output at time t is dependent only on the entire input and forward states only. Figure <xref rid="Fig2" ref-type="fig">2</xref> shows the difference between the Bi-LSTM and entangled-LSTM schematically.</p></sec></sec><sec id="Sec12"><title>Datasets and pre-processing</title><p id="Par71">This paper used three datasets available online. Following is a brief description of the datasets and how they have been pre-processed to be used in this paper. These three datasets cover three different area scopes: the first dataset (Spain) is a country-wide dataset, the second dataset (Paraguay) is a region-specific dataset, and the third dataset (France) is for a specific building. For the convenience of expression, datasets 1, 2, and 3 are referred to as Spain, Paraguay, and France datasets, respectively, in the rest of this paper. The three datasets contain different amounts of data in terms of their time span. As reported next, the first dataset had 48 months of data, and the second and the third datasets have 3 and 29 months as the total duration of the recorded data, respectively. Therefore, for maintaining equal grounds for comparison across the three datasets, only the first 29 months of data from the first two datasets were used.</p><sec id="Sec13"><title>Dataset1: Spain</title><p id="Par72">This dataset<xref ref-type="fn" rid="Fn1">1</xref> contains four years (a total of 48 months) of electrical consumption, generation, pricing, and weather data for Spain. Consumption and generation data were retrieved from ENTSOE, a public portal for Transmission Service Operator (TSO) data. Settlement prices were obtained from the Spanish TSO Red Electric España. Weather data was purchased as part of a personal project from the Open Weather API for the five largest cities in Spain and made public on Kaggle. The dataset contains the following sources of energy: biomass, coal/lignite, coal gas, natural gas, coal, oil, shale oil, peat, geothermal, hydro, sea, nuclear, and other renewable. This detailed information was not present in all the datasets. Therefore, these diverse data sources were aggregated to reflect the total demand for every hour across four years. This dataset also contains hourly weather parameters from the five largest cities in Spain that are Madrid, Barcelona, Valencia, Seville, and Bilbao. Once again, for the analysis and consistency across the datasets, humidity, temperature, pressure, and wind speed were used as the weather parameters. Further, there was no specific energy data for the separate cities; therefore, for the purpose of this contribution, the granger causality was computed (explained in the next subsection) between the weather data from all the cities separately and virtually divided this dataset into five sub-datasets, one for each city.</p></sec><sec id="Sec14"><title>Dataset2: Paraguay</title><p id="Par74">This dataset<xref ref-type="fn" rid="Fn2">2</xref> contains the electricity consumption and the meteorological data of the Alto Parana region in Paraguay. Both datasets are from January 2017 to December 2020, a total of 36 months of a time period. The weather data contains temperature (Celsius), relative humidity (percentage), wind speed (km/h, kilometres per hour), and atmospheric pressure (hPa, hectopascal) at the station level with a frequency of every three hours. To be consistent with the other two datasets, the weather data was extrapolated to represent hourly data. A simple smoothing function was used to extrapolate the weather data. The window size for the smoothing function was 24 data points (3 days) with a shift of one data point between two consecutive windows. The electricity consumption data was recorded from 55 feeders in 15 substations in an hourly fashion. Once again, to maintain consistency, the data from the 55 feeders were combined into one by aggregating the consumed amount from all the substations. This was done because there was only one weather station form where the data was gathered, and there was no specific location provided for the weather station. Another way to process this dataset was similar to dataset1, where five sets of causal relations were computed (one for each city). However, this would not have been possible here because even computing 14 causalities would be cumbersome; and because the data is from a region and not a country, therefore aggregating the electricity consumption is the better choice.</p></sec><sec id="Sec15"><title>Dataset3: France</title><p id="Par76">This dataset<xref ref-type="fn" rid="Fn3">3</xref> contains the energy consumption and weather data from one Challenger building in Guyancourt, France. The dataset has 29 months of high-frequency energy consumption data, with the recording frequency being every 10 min. The energy consumption includes Heating and cooling, electrical consumption (indoor and outdoor comfort units), Lighting, plug load, blinds, sanitary consumption, air handling unit consumption, and total consumption. For maintaining consistency across the three datasets, the total energy consumption was used, which is the aggregate of all the individual energy consumptions. The data was aggregated in terms of temporal frequency. The energy consumption data were recorded every 10 min; therefore, to compute the hourly consumption, the data from one hour (six or fewer values in certain hours) was added. The weather data included daily degrees during the days, hourly humidity, hourly temperature, and daily sunshine hours. There was no pressure or wind speed data. However, the exact coordinates of the building were available. Therefore, it was possible to extract the missing information (hourly pressure and hourly wind speed) from online resources (e.g., scrapping certain web pages and some freely available data). It was possible to extract the missing information for the whole period represented in the dataset.</p></sec></sec><sec id="Sec16"><title>Training and testing setup</title><p id="Par78">To train, validate, and test the Bi-LSTM and Entangled-LSTM, the data from the first 29 months of the three datasets were used. This was done to have an accurate comparison among the three datasets because 29 months was the lowest of the durations across them. The input of the data for the Bi-LSTM contains the batch size (48 h, i.e., two days), number of time steps (120 h, i.e., five days), and the hidden size. The input data is then fed into three "stacked" layers of LSTM cells (of 50 lengths for the hidden size), and the LSTM network is shown as unrolled over all the time steps. The term "unrolled" means that the feedback loop of an LSTM cell is not shown. The loop is used for keeping the information persisting within the recurrent network. The output from these unrolled cells is the same as the input (batch size, number of time steps, hidden size). This output data is passed to the time distributed layer, which is the set of inputs that the model will learn from to predict the input data coming after. Finally, the output layer has a softmax activation applied to it. This output is compared to the training data for each batch, and the error and gradient are then backpropagated. The Entangled LSTM is created in the same manner as the Bi-LSTM except for one difference. In Entangled-LSTM, there is one additional layer containing the F-value of the causal relationship of humidity, pressure, temperature, and wind speed with energy consumption/demand. This additional layer is also trained with backpropagation.</p><p id="Par79">For training and validating both the models, 26 months of hourly data were used, and for the testing, the remaining three months of data were used. Hyndman and Koehler (<xref ref-type="bibr" rid="CR69">2006</xref>) and Davydenko and Fildes (<xref ref-type="bibr" rid="CR30">2013</xref>) have provided overviews of the metrics that could be used to evaluate the forecasts. In this contribution, the following three error metrics are used:</p><p id="Par80"><bold>Mean Absolute Error (MAE)</bold>: this is the mean of the absolute difference between the original and the predicted values.<disp-formula id="Equac"><alternatives><mml:math display="block" id="Equac_Math"><mml:mrow><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mo>∑</mml:mo><mml:mfenced close="|" open="|"><mml:mrow><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equac_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ MAE = \frac{1}{n} \sum \left| {e\left( t \right)} \right| $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equac.gif"/></alternatives></disp-formula><bold>Root Mean Squared Error (RMSE)</bold>: the is the square root of the mean of the squared difference between the original and the predicted values.<disp-formula id="Equad"><alternatives><mml:math display="block" id="Equad_Math"><mml:mrow><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mo>∑</mml:mo><mml:mi>e</mml:mi><mml:msup><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:math><tex-math id="Equad_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ RMSE = \sqrt {\frac{1}{n} \sum e\left( t \right)^{2} } $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equad.gif"/></alternatives></disp-formula><bold>Mean Absolute Percentage Error (MAPE)</bold>: this is the mean of the absolute error when the error is reported as a ratio of the original values.<disp-formula id="Equae"><alternatives><mml:math display="block" id="Equae_Math"><mml:mrow><mml:mi>M</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>100</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mo>∑</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:mrow><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:mfenced><mml:mrow><mml:mi>o</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equae_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ MAPE = \frac{100}{n} \sum \frac{{\left| {e\left( t \right)} \right|}}{o\left( t \right)} $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equae.gif"/></alternatives></disp-formula>where<disp-formula id="Equaf"><alternatives><mml:math display="block" id="Equaf_Math"><mml:mrow><mml:mi>e</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced><mml:mo>-</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced></mml:mrow></mml:math><tex-math id="Equaf_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ e\left( t \right) = orig\left( t \right) - pred\left( t \right) $$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10479_2022_4857_Article_Equaf.gif"/></alternatives></disp-formula> In all the above formulae, <italic>e(t)</italic> is the error for time <italic>t</italic>, orig(t) is the original value at time <italic>t</italic>, pred(t) is the predicted value at time <italic>t</italic>, and <italic>n</italic> is the number of data points used in the test set. Among the three metrics, MAE and RMSE are the two most user error metrics. But they are scale-dependent, which indicates a requirement for an additional scale-invariant evaluation metric. Therefore, the MAPE is used. MAPE is also good for comparing the error rates among different datasets because of its scale-invariant nature. In this paper, only the performances of the bidirectional-multivariate-LSTM and the causal-LSTM (which by extension is also bidirectional and multivariate) are compared.</p></sec></sec><sec id="Sec17" sec-type="results"><title>Results</title><sec id="Sec18"><title>Simulation results</title><p id="Par84">First of all, the results with simulated data will be presented. The purpose of this set of results is to show that if there are two-time series where one time series is perfectly causing the other time series, which of the two LSTM architectures (Bi-LSTM or Entangled-LSTM) would perform better. For this purpose, two time series were generated, where the time series one is perfectly causing the time series two, and the task is to forecast the values for the second time series. Next, both the LSTM architectures were trained and tested for the simulated dataset. Table <xref rid="Tab1" ref-type="table">1</xref> contains the outcome of the comparison. The entangled LSTM clearly outperforms the Bidirectional LSTM. This shows the theoretical confirmation of the proposed method. That is, adding the causal information in perfect causal conditions will provide better forecasting than the model without the causal information. It is clear that when one-time series "perfectly" causes another time series, the performance of Entangled LSTM is better than the Bi-directional LSTM.<table-wrap id="Tab1"><label>Table 1</label><caption xml:lang="en"><p>The testing performance from the two LSTM architectures for the simulated data where the causality is established</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="4"><p>Bidirectional LSTM</p></th><th align="left" colspan="4"><p>Entangled LSTM</p></th></tr><tr><th align="left"><p>Dataset</p></th><th align="left"><p>MAE</p></th><th align="left"><p>RMSE</p></th><th align="left"><p>MAPE</p></th><th align="left"><p>Dataset</p></th><th align="left"><p>MAE</p></th><th align="left"><p>RMSE</p></th><th align="left"><p>MAPE</p></th></tr></thead><tbody><tr><td align="left"><p>Simulated</p></td><td char="." align="char"><p>0.15</p></td><td char="." align="char"><p>0.12</p></td><td char="." align="char"><p>0.08</p></td><td align="left"><p>Simulated</p></td><td char="." align="char"><p>0.09</p></td><td char="." align="char"><p>0.06</p></td><td char="." align="char"><p>0.02</p></td></tr></tbody></table><table-wrap-foot><p>The MAE and RMSE are scale-dependent, and the MAPE is scale-independent. Therefore, for the purpose of understandability, the time series were normalized between 0 and 1</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec19"><title>Comparison of multivariate-bidirectional and multivariate entangled LSTMs</title><p id="Par85">The two LSTM architectures (bidirectional and entangled) are compared for the three datasets based on the different metrics (MAE, RMSE, MAPE). Figures <xref rid="Fig3" ref-type="fig">3</xref>, <xref rid="Fig4" ref-type="fig">4</xref>, and <xref rid="Fig5" ref-type="fig">5</xref> show the training and validation losses for Spain (different sub-datasets based on the cities), Paraguay, and France datasets. It can be clearly observed from the losses that both the architectures are not overfitting on any of the datasets. Moreover, the training losses (the blue curves in all the figures) fluctuate in the range of 0.05 to 0.10 before eventually stabilizing. On the other hand, the validation losses (the orange curves in all the figures) fluctuate in a smaller range (0.02 to 0.04) and stabilize. None of the plots (in Figs. <xref rid="Fig3" ref-type="fig">3</xref>, <xref rid="Fig4" ref-type="fig">4</xref>, and <xref rid="Fig5" ref-type="fig">5</xref>) have any alarming differences between the training and validation losses. Therefore, it can be concluded that there was no overfitting of the data in any of the three cases.<fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><p>The training (blue curves) and validation (orange curves) losses from the first dataset (Spain dataset and the five sub-datasets). (Color figure online)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10479_2022_4857_Fig3a_HTML.png" id="MO3"/><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10479_2022_4857_Fig3b_HTML.png" id="MO311"/></fig><fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><p>The training (blue curves) and validation (orange curves) losses from the first dataset (Paraguay dataset). (Color figure online)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10479_2022_4857_Fig4_HTML.png" id="MO4"/></fig><fig id="Fig5"><label>Fig. 5</label><caption xml:lang="en"><p>The training (blue curves) and validation (orange curves) losses from the third dataset (France dataset). (Color figure online)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10479_2022_4857_Fig5_HTML.png" id="MO5"/></fig></p><p id="Par86">As shown the Table <xref rid="Tab2" ref-type="table">2</xref>, the entangled LSTM outperforms the bidirectional LSTM for all three datasets. The minimum improvement is for the Paraguay dataset (MAPE difference is 2.07%), and the maximum improvement is for the France dataset (MAPE difference is 7.73%). The highest difference between the two architectures is for the France dataset. This could be because of the reason that in the France dataset, the weather information is the most accurate for the geographical location. Therefore, the causality computed between the weather indicators (pressure, temperature, humidity, wind speed) and the energy consumption of the building (the France dataset has the data from an individual building) captures the causal relation that is closest to the reality among all the datasets. On the other hand, the Paraguay dataset having the minimum improvement shows that the data from the single weather station in the whole region does not exemplify the weather conditions that are in general covered by the 14 substations from which the data was collected. Another reason for the Paraguay dataset corresponding to the minimum improvement could be the original frequency of the weather parameters. In the Paraguay dataset, the original weather parameters were recorded every three hours, and the weather data was extrapolated to obtain the hourly frequencies for all the four weather parameters used in the paper. This could be the reason why the variability in the weather data in the Paraguay dataset was lower than in the other two datasets, and therefore, the causation with the energy data was not as informative as it was in the other two cases.<table-wrap id="Tab2"><label>Table 2</label><caption xml:lang="en"><p>The testing performance from the two LSTM architectures. As it is evident that the MAE and RMSE are scale-dependent, and the MAPE is scale-independent</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="4"><p>Bidirectional LSTM</p></th><th align="left" colspan="4"><p>Entangled LSTM</p></th></tr><tr><th align="left"><p>Dataset</p></th><th align="left"><p>MAE</p></th><th align="left"><p>RMSE</p></th><th align="left"><p>MAPE</p></th><th align="left"><p>Dataset</p></th><th align="left"><p>MAE</p></th><th align="left"><p>RMSE</p></th><th align="left"><p>MAPE</p></th></tr></thead><tbody><tr><td align="left"><p>Spain (Barcelona)</p></td><td char="." align="char"><p>3358.60</p></td><td char="." align="char"><p>3929.88</p></td><td char="." align="char"><p>12.55</p></td><td align="left"><p>Spain (Barcelona)</p></td><td char="." align="char"><p>2692.17</p></td><td char="." align="char"><p>3317.99</p></td><td char="." align="char"><p>10.14</p></td></tr><tr><td align="left"><p>Spain (Bilbao)</p></td><td char="." align="char"><p>3278.86</p></td><td char="." align="char"><p>3873.20</p></td><td char="." align="char"><p>12.49</p></td><td align="left"><p>Spain (Bilbao)</p></td><td char="." align="char"><p>2462.59</p></td><td char="." align="char"><p>2840.11</p></td><td char="." align="char"><p>9.84</p></td></tr><tr><td align="left"><p>Spain (Madrid)</p></td><td char="." align="char"><p>3583.12</p></td><td char="." align="char"><p>4243.87</p></td><td char="." align="char"><p>13.31</p></td><td align="left"><p>Spain (Madrid)</p></td><td char="." align="char"><p>2848.33</p></td><td char="." align="char"><p>3252.92</p></td><td char="." align="char"><p>10.45</p></td></tr><tr><td align="left"><p>Spain (Seville)</p></td><td char="." align="char"><p>3472.90</p></td><td char="." align="char"><p>3917.47</p></td><td char="." align="char"><p>12.89</p></td><td align="left"><p>Spain (Seville)</p></td><td char="." align="char"><p>2283.42</p></td><td char="." align="char"><p>2708.95</p></td><td char="." align="char"><p>8.83</p></td></tr><tr><td align="left"><p>Spain (Valencia)</p></td><td char="." align="char"><p>3885.11</p></td><td char="." align="char"><p>4523.322</p></td><td char="." align="char"><p>15.05</p></td><td align="left"><p>Spain (Valencia)</p></td><td char="." align="char"><p>2117.02</p></td><td char="." align="char"><p>2473.69</p></td><td char="." align="char"><p>8.14</p></td></tr><tr><td align="left"><p>Paraguay</p></td><td char="." align="char"><p>2651.78</p></td><td char="." align="char"><p>3099.92</p></td><td char="." align="char"><p>10.36</p></td><td align="left"><p>Paraguay</p></td><td char="." align="char"><p>2101.28</p></td><td char="." align="char"><p>2798.55</p></td><td char="." align="char"><p>8.29</p></td></tr><tr><td align="left"><p>France</p></td><td char="." align="char"><p>1962.67</p></td><td char="." align="char"><p>2311.56</p></td><td char="." align="char"><p>17.80</p></td><td align="left"><p>France</p></td><td char="." align="char"><p>1066.35</p></td><td char="." align="char"><p>1454.34</p></td><td char="." align="char"><p>10.07</p></td></tr></tbody></table></table-wrap></p><p id="Par87">Another important aspect that can be observed is the differences between the bidirectional LSTM and entangled LSTM for the Sub-datasets of the Spain dataset. These sub-datasets are treated as independent datasets, and indeed there is no specific trend revealed from the presented forecasting and analysis. The order of the cities in terms of size of the population is Madrid, Barcelona, Valencia, Seville, and Bilbao, while their respective improvements from bidirectional to entangled LSTM are 2.86%, 2.41%, 6.91%, 4.04%, 2.65%. As a post-hoc prediction, the energy consumption data was divided in a way that the proportion of the energy consumed reflected the ratio of these cities' populations to the Spanish population. There was no significant difference in the results with either of the two methods. This shows that including the causal information is even more important in cases like the Spain dataset. In the following, an explanation is provided. Looking at the MAPE of the two methods, Valencia has the worst forecasting performance, and Bilbao has the best MAPE, looking at the bidirectional LSTM. This would indicate that adding the causal information plays a role in improving the forecasts. The MAPE for Valencia with entangled LSTM was cut down to half of what it was with bidirectional LSTM, while the MAPE for Bilbao was also reduced by almost a quarter with entangled LSTM.</p><p id="Par88">In a nutshell, it is evident that adding the causal information for forecasting the energy consumption/demand improves the forecasting accuracy. This is shown across all three datasets. The range in MAPE for the entangled LSTM is 2.31% which, considering the variation in the three datasets, is neither alarming nor significant, especially because the three datasets cover large variations in terms of their area scope. As aforementioned, the Spain dataset covers national consumption while Paraguay and the France dataset cover regional and individual building consumption, respectively. This, combined With the proof that none of the models have overfitted in the training and validation phases, the generalizability of this method can be assumed.</p></sec><sec id="Sec20"><title>Comparison of univariate-bidirectional and univariate entangled LSTMs</title><p id="Par89">The results from the previous multivariate forecasting show that using Granger's definition of causality and modelling the causal relationship between the two-time series can provide better forecasting results than simply using one or more time series to forecast another time series. Next, the comparison of univariate forecasting using bidirectional and Entangled LSTMs, was performed. For comparing the univariate forecasting quality, only MAPE was used because the other two metrics (i.e., MAE and RMSE) are scale-dependent and will follow the same trend as the MAPE. There are two key aspects that can be observed in Table <xref rid="Tab3" ref-type="table">3</xref>. First, the univariate results are underperforming when compared to the multivariate results. This depicts the importance of considering the multiple weather features. Second, for all the univariate results, the Entangled LSTM outperforms the Bidirectional LSTM. This is another proof that incorporating causal relation between the weather features and the energy consumption is beneficial for the forecasting of energy consumption. From the univariate forecasting, it is also clear that the temperature is the most important weather feature for forecasting. Using the temperature, in both the Entangled and Bidirectional LSTMs, the MAPE is the lowest for all the datasets (and data-subsets). In some cases, temperature features marginally outperform all the other features; however, it emerges as the best feature to be used in the forecasting, nonetheless. In summary, With these univariate forecasting results, it is shown that it is important not only to include multivariability in the LSTM but also causal relationships.<table-wrap id="Tab3"><label>Table 3</label><caption xml:lang="en"><p>The univariate testing performance, MAPE, from the two LSTM architectures using temperature, humidity, wind speed, and pressure, separately</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left" colspan="4"><p>Bidirectional LSTM</p></th><th align="left" colspan="4"><p>Entangled LSTM</p></th></tr><tr><th align="left"><p>Dataset</p></th><th align="left"><p>Temp</p></th><th align="left"><p>Humid</p></th><th align="left"><p>WS</p></th><th align="left"><p>Pres</p></th><th align="left"><p>Temp</p></th><th align="left"><p>Humid</p></th><th align="left"><p>WS</p></th><th align="left"><p>Pres</p></th></tr></thead><tbody><tr><td align="left"><p>Spain (Barcelona)</p></td><td char="." align="char"><p>11.25</p></td><td char="." align="char"><p>16.87</p></td><td char="." align="char"><p>17.76</p></td><td char="." align="char"><p>14.22</p></td><td char="." align="char"><p>10.10</p></td><td char="." align="char"><p>15.85</p></td><td char="." align="char"><p>17.76</p></td><td char="." align="char"><p>12.62</p></td></tr><tr><td align="left"><p>Spain (Bilbao)</p></td><td char="." align="char"><p>14.07</p></td><td char="." align="char"><p>18.70</p></td><td char="." align="char"><p>13.46</p></td><td char="." align="char"><p>14.28</p></td><td char="." align="char"><p>11.45</p></td><td char="." align="char"><p>13.63</p></td><td char="." align="char"><p>13.46</p></td><td char="." align="char"><p>12.37</p></td></tr><tr><td align="left"><p>Spain (Madrid)</p></td><td char="." align="char"><p>15.19</p></td><td char="." align="char"><p>18.10</p></td><td char="." align="char"><p>15.36</p></td><td char="." align="char"><p>16.39</p></td><td char="." align="char"><p>13.23</p></td><td char="." align="char"><p>14.49</p></td><td char="." align="char"><p>15.36</p></td><td char="." align="char"><p>14.79</p></td></tr><tr><td align="left"><p>Spain (Seville)</p></td><td char="." align="char"><p>14.41</p></td><td char="." align="char"><p>15.90</p></td><td char="." align="char"><p>19.14</p></td><td char="." align="char"><p>15.44</p></td><td char="." align="char"><p>12.02</p></td><td char="." align="char"><p>12.41</p></td><td char="." align="char"><p>19.14</p></td><td char="." align="char"><p>12.08</p></td></tr><tr><td align="left"><p>Spain (Valencia)</p></td><td char="." align="char"><p>15.76</p></td><td char="." align="char"><p>16.23</p></td><td char="." align="char"><p>18.03</p></td><td char="." align="char"><p>17.29</p></td><td char="." align="char"><p>11.84</p></td><td char="." align="char"><p>14.25</p></td><td char="." align="char"><p>18.03</p></td><td char="." align="char"><p>12.18</p></td></tr><tr><td align="left"><p>Paraguay</p></td><td char="." align="char"><p>14.03</p></td><td char="." align="char"><p>16.51</p></td><td char="." align="char"><p>16.80</p></td><td char="." align="char"><p>14.96</p></td><td char="." align="char"><p>16.18</p></td><td char="." align="char"><p>15.48</p></td><td char="." align="char"><p>16.80</p></td><td char="." align="char"><p>17.83</p></td></tr><tr><td align="left"><p>France</p></td><td char="." align="char"><p>20.16</p></td><td char="." align="char"><p>21.24</p></td><td char="." align="char"><p>22.98</p></td><td char="." align="char"><p>20.45</p></td><td char="." align="char"><p>20.07</p></td><td char="." align="char"><p>20.62</p></td><td char="." align="char"><p>22.98</p></td><td char="." align="char"><p>22.78</p></td></tr></tbody></table></table-wrap></p></sec><sec id="Sec21"><title>Comparing early predictions</title><p id="Par90">While the Entangled LSTM outperforms the Bidirectional LSTM in all the comparisons, it is also important to understand "how much data is needed to obtain reliable forecasts?” To answer this question, less data was used to forecast than what was available in the given datasets. For example, the results in Sect. <xref rid="Sec19" ref-type="sec">4.2</xref> are based on training the algorithms using the data from 29 months. In different experiments, the same forecasts were obtained using half data (14.5 months), third data (9.67 months), fourth data (7.25 months), sixth data (4.85 months), and eighth data (3.63 months). The purpose was to know at what proportion of the data the forecasting accuracy decreases to a level, as compared to the results from Sect. <xref rid="Sec19" ref-type="sec">4.2</xref>, that it ceases to be potentially useful. In all these cases, both the entangled and bidirectional LSTMs were compared. These results were also compared using the MAPE values of the forecasting performance. Figure <xref rid="Fig6" ref-type="fig">6</xref> shows the results. In all the cases (i.e., all the datasets and the data subsets), it is observed that when the data is reduced from half of the original training data length to a third of the data length, a considerable increment in the MAPE occurs. Moreover, with subsequent reductions in the data, further increments in the MAPE values can be seen for all the datasets. In all these experiments, there are two key takeaways. First, as aforementioned, given these three datasets, half of the dataset (14.5 months) is sufficient to obtain similar forecasting performance as with the full data (29 months). Second, in early predictions, as is seen with univariate and multivariate forecasting, the entangled LSTM outperforms the bidirectional LSTM. Another proof for the initial hypothesis is that incorporating the causal information in the deep network for forecasting the energy demand yields better results than simply using the weather features in a multivariate LSTM.<fig id="Fig6"><label>Fig. 6</label><caption xml:lang="en"><p>Results (MAPE values) for the early prediction experiments</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10479_2022_4857_Fig6_HTML.png" id="MO6"/></fig></p></sec><sec id="Sec22"><title>Comparing generalizability across datasets</title><p id="Par91">Finally, the two algorithms are compared on the scale of generalizability. To perform such a comparison, cross-training testing was used. In other words, the training of the forecasting algorithm was carried out using one dataset, and the trained model was tested on another dataset. For example, training on the Spain dataset (all cities combined) and testing on France and Paraguay datasets. In this manner, both the algorithms were tested if they could use the learned model to predict in an unseen environment. The algorithm is deemed to be pseudo-generalizable if the testing accuracy on another dataset is comparable to the testing accuracy on the same dataset. For example, in the case of training on Spain and testing on Paraguay datasets, it can be observed from Table <xref rid="Tab4" ref-type="table">4</xref> that both LSTM models produce similar MAPE as when they were tested on the Spain dataset. When Bidirectional LSTM is trained on the Spain dataset, the testing MAPE for the Spain dataset is 13.32, while on the Paraguay dataset, the MAPE was 16.21. On the other hand, when the entangled LSTM is trained on the Spain dataset, the testing MAPE for the Spain dataset is 9.28, while on the Paraguay dataset, the MAPE is 11.21. In both cases, the algorithms can be considered generalizable. This difference is greater in the opposite case (i.e., when the training is done on the Paraguay dataset). However, the Entangled LSTM seems to be more generalizable than the Bidirectional LSTM. In the end, both algorithms do not seem to generalize for the France dataset. It is shown that when the algorithms are trained using the country-wide dataset (Spain), they generalize on the region-based dataset (Paraguay) but not on a building-specific dataset (France). Moreover, the region-based dataset does not generalize for the building-based dataset; also, the algorithms do not generalize or generalize to a smaller extent when they are trained on a smaller area and tested on a larger area (i.e., trained on region or building based data and tested on country or region based data, respectively). These results can be explained by the fact that the larger the area in the trained dataset, the higher the variance in the model, and therefore they generalize on specific cases, but the opposite is not possible. Another aspect worth mentioning about the results from Table <xref rid="Tab4" ref-type="table">4</xref> is that the MAPE differences are lower in Entangled LSTM than those for the bidirectional LSTM. This can be explained based on the fact that the causal relationship between the weather and the energy consumption across countries might be more generalizable than the temporal nature of the weather conditions across different countries. This might be why the Entangle LSTM achieves better generalizability than the Bidirectional LSTM.<table-wrap id="Tab4"><label>Table 4</label><caption xml:lang="en"><p>Results (MAPE values) from cross-training testing (i.e., training on one dataset and testing on another one)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2"><p>Bidirectional LSTM</p></th><th align="left" colspan="3"><p>Testing dataset</p></th></tr><tr><th align="left"><p>Spain</p></th><th align="left"><p>Paraguay</p></th><th align="left"><p>France</p></th></tr></thead><tbody><tr><td align="left"><p>Training dataset</p></td><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left"><p>Spain</p></td><td align="left"><p>13.32</p></td><td align="left"><p>16.21</p></td><td align="left"><p>23.91</p></td></tr><tr><td align="left"><p>Paraguay</p></td><td align="left"><p>16.32</p></td><td align="left"><p>10.36</p></td><td align="left"><p>24.53</p></td></tr><tr><td align="left"><p>France</p></td><td align="left"><p>26.23</p></td><td align="left"><p>26.56</p></td><td align="left"><p>17.80</p></td></tr></tbody></table><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2"><p>Entangled LSTM</p></th><th align="left" colspan="3"><p>Testing dataset</p></th></tr><tr><th align="left"><p>Spain</p></th><th align="left"><p>Paraguay</p></th><th align="left"><p>France</p></th></tr></thead><tbody><tr><td align="left"><p>Training dataset</p></td><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left"><p>Spain</p></td><td align="left"><p>9.28</p></td><td align="left"><p>11.12</p></td><td align="left"><p>18.93</p></td></tr><tr><td align="left"><p>Paraguay</p></td><td align="left"><p>11.92</p></td><td align="left"><p>8.29</p></td><td align="left"><p>19.21</p></td></tr><tr><td align="left"><p>France</p></td><td align="left"><p>21.53</p></td><td align="left"><p>19.24</p></td><td align="left"><p>10.07</p></td></tr></tbody></table></table-wrap></p></sec></sec><sec id="Sec23" sec-type="discussion"><title>Discussion</title><sec id="Sec24"><title>Implications for theory</title><p id="Par92">Causal analysis has lately become one of the major and important components for improving modern processes, and a few examples include Capability Maturity Model Integration (CMMI), Six Sigma, and Lean. Incorporating the causal analysis is also becoming more important for the organizations than before to obtain high levels of process maturation. This is evident because of two facts. First, CMMI has assigned the Causal Analysis and Resolution at the Maturity Level five. Second, Six Sigma programs also often embed causal analysis in a curriculum that is of more challenging statistical levels. Identifying causal relationships in the data helps the systems to predict future events in a more robust manner than those done using just the correlations and regressions (Kleinberg, <xref ref-type="bibr" rid="CR87">2013</xref>). One of the key goals of causal analysis is to aid organizations in making better decisions (Zheng et al., <xref ref-type="bibr" rid="CR170">2020</xref>). Causal relations can provide better support in decision-making due to the following two reasons. First, by analysing causalities in a particular data set, one can not only gain a deeper understanding of the relationship between pairs of time series and provide better predictions, but one can also analyse the effects of certain past events or decisions on the future predictions and outcomes. Second, based on the known causal relations, one can forecast the effect before it takes place and simulates the effects of certain decision-making activities. Encoding the intricacies of the relationships in the given datasets using the causal analysis might be the root cause of the results that were obtained. This contribution shows how to improve the time series forecasting using by adding the causal information (entangled LSTM) to the basic forecasting model (bidirectional LSTM).</p><p id="Par93">Furthermore, it is also backed by a few theoretical frameworks that the causal information should be used in the decision making. One of the most prominent ones is the Expected Utility Theory (von Neumann &amp; Morgenstern, <xref ref-type="bibr" rid="CR187">1944</xref>; Savage, <xref ref-type="bibr" rid="CR188">1954</xref>). This theory has two assumptions, and incorporating the causal relation between the weather information and the energy demands shows how these two assumptions are satisfied. Especially because the results show an improvement in forecasting capabilities when the casual information is incorporated into the deep learning network as compared to when the causal information is absent from the forecasting problem. The first assumption is that each outcome has a corresponding utility to the decision-maker. In the presented case, this is the amount of energy consumed. The second assumption is that each outcome is assigned a probability. That is, each outcome is uncertain because there is always a lack of knowledge and evidence for an outcome to take place given a particular event or action. The theory also dictates that the outcome should maximize the expected utility. This lack of knowledge can be taken care of by using the causal relationship between the events and the outcomes. In this case, the energy consumption is the outcome, and the weather information creates the event. Therefore, it is intuitive to consider the causal relationship between energy consumption and weather data to effectively predict energy consumption. The results confirm the theory, where the entangled LSTM produces better forecasts than the bidirectional LSTM in all the cases, by showing that the power of causality in the predictor makes up for the lack of knowledge about the relation between an event (weather condition) and outcome (energy consumption). The inclusion of causal information is also supported by the causal decision theory (Joyce, <xref ref-type="bibr" rid="CR189">1999</xref>; Lewis, <xref ref-type="bibr" rid="CR173">1981</xref>; Maher, <xref ref-type="bibr" rid="CR190">1987</xref>; Nozick, <xref ref-type="bibr" rid="CR191">1993</xref>; Skyrms, <xref ref-type="bibr" rid="CR192">1982</xref>), which extends the Expected Utility Theory by dictating that knowing the outcomes of one must be aware of the causal relationship between an event and outcomes.</p></sec><sec id="Sec25"><title>Implications for practice</title><p id="Par94">Deep learning architectures encode the representation of the input data at multiple levels of abstraction using their multiple processing layers (LeCun et al., <xref ref-type="bibr" rid="CR92">2015</xref>). These encodings then can and are used to generate better predictions and forecasts than the other basic machine learning and statistical methods (Husna et al., <xref ref-type="bibr" rid="CR68">2021</xref>; Kilimci et al., <xref ref-type="bibr" rid="CR82">2019</xref>; Xu &amp; He, <xref ref-type="bibr" rid="CR163">2020</xref>). It has been shown that predictive analysis brings competitive advantages to organizations (Ransbotham et al., <xref ref-type="bibr" rid="CR126">2017</xref>), and by extension, using deep learning to obtain better predictions can improve the advantageous positions for these organizations. Most of the predictions and/or forecasts aid in the decision making for different operations such as supply chain management (Husna et al., <xref ref-type="bibr" rid="CR68">2021</xref>; Pacella &amp; Papadia, <xref ref-type="bibr" rid="CR118">2021</xref>; Punia et al., <xref ref-type="bibr" rid="CR123">2020</xref>), digital marketing (Pan &amp; Zhou, <xref ref-type="bibr" rid="CR119">2020</xref>; Qi et al., <xref ref-type="bibr" rid="CR124">2019</xref>), and financial decision making (Abu-Mostafa &amp; Atiya, <xref ref-type="bibr" rid="CR1">1996</xref>; Geng et al., <xref ref-type="bibr" rid="CR52">2015</xref>; Kim et al., <xref ref-type="bibr" rid="CR83">2020a</xref>, <xref ref-type="bibr" rid="CR85">2020b</xref>; Xu &amp; He, <xref ref-type="bibr" rid="CR163">2020</xref>). With the current availability of the data in huge quantities, traditional machine learning algorithms tend to saturate their training and risk overfitting and specificity to one case. On the other hand, because of their complex structures and multiple weights to be trained, deep learning architectures can handle this large amount of data in a manner that is beneficial for various operations in organizations. Another advantage of deep learning algorithms is that they do not need extensive pre-processing and feature engineering because such algorithms are known to function well with noisy and unstructured or semi-structured datasets. Most of the contributions cited in the related work section of this paper do not use many pre-processing and/or feature engineering schemes. This also gives an additional advantage to the organizations in faster decision-making. Two other virtues of deep learning algorithms that help organizations to invest less time in data-driven decision-making are: 1) the less requirement of human intervention during the training phase of deep learning algorithms, and 2) the support for parallel and distributed processing. The first one refers to the self-learning capabilities of the deep learning algorithms using the error-backpropagation through its multiple layers and therefore requiring less human intervention as compared to the traditional machine learning algorithms. Moreover, the second advantage is mostly due to the advancements in computing technology that allows the deep networks to be trained at scale and thus proving to be a big aid in fast data-driven decision support systems. With this contribution, by improving upon the state-of-the-art bidirectional LSTM networks mainly because of the use of causal information, the case of using deep learning architectures for operations research is emphasized.</p><p id="Par95">The terms of the presented results (MAPE from entangled-LSTM), which are in the range of 0.08 and 0.11, stand comparable to some of the state-of-the-art contributions (Hrnjica &amp; Mehr, <xref ref-type="bibr" rid="CR65">2020</xref> report in the range 0.06—0.11 and Al Khafaf et al., <xref ref-type="bibr" rid="CR5">2019</xref> report an average MAPE of 0.16); and better than others (Ishaq &amp; Kwon, <xref ref-type="bibr" rid="CR70">2021</xref>: 0.35 and Somu &amp; Ramamritham, <xref ref-type="bibr" rid="CR139">2021</xref>: 0.26); only Real et al. (<xref ref-type="bibr" rid="CR31">2020</xref>) have reported a better MAPE range of 0.02—0.06. Considering that the better prediction of future energy consumption might lead to improving energy management processes and systems, this contribution also has certain implications for energy management systems. Efficient energy management is becoming a necessary process both at the supplier (i.e., smart grids) and consumer levels (i.e., energy management in smart homes). A smart grid energy management system contains multiple modules, among which the load and demand forecasting modules are also included (Chen et al., <xref ref-type="bibr" rid="CR24">2011</xref>). Effective forecasting systems can also support the real-time energy management systems in creating efficient load-balancing, operating routines, and minimizing operational costs (Luna et al., <xref ref-type="bibr" rid="CR101">2017</xref>). Moreover, better energy consumption forecasting can optimize the peak shavings for the utility grids and maximize the revenue for the grid (Shen et al., <xref ref-type="bibr" rid="CR135">2016</xref>). Finally, using highly accurate forecasts, it could be possible to minimize the power peaks and fluctuations while the grids are exchanging energy with each other or with the main grid (Arcos-Aviles et al., <xref ref-type="bibr" rid="CR8">2017</xref>). In terms of the consumer side of the energy supply chain, better energy forecasts can lead to better planning for optimizing smart home appliances (Hossen et al., <xref ref-type="bibr" rid="CR64">2018</xref>). Better energy consumption forecasts can have a major impact on the home energy management systems, which in turn can have a huge impact on the energy conservation, reliability, economics, and efficiency of the energy usage (Zhou et al., <xref ref-type="bibr" rid="CR171">2016</xref>). Whenever there is an option to choose between more than one source of energy, an efficient and individualized energy consumption forecast can also enable smart home energy management to switch among the multiple energy sources in a cost-effective manner (Olatomiwa et al., <xref ref-type="bibr" rid="CR114">2016</xref>).</p></sec><sec id="Sec26"><title>Limitations and future work</title><p id="Par96">Our contribution extends state the art in energy demand forecasting by incorporating the causal relationships between the weather parameters and the energy consumption at three different levels, that is, country, a specific region, and individual building. However, there were certain issues that limited the extent of this work and simultaneously opened new avenues for exploration. For example, in this paper, all the causal information that was available in the data was added, that is, the pressure causes consumption/demand, the humidity causes consumption/demand, the temperature causes consumption/demand, and the wind speed causes consumption/demand. Although each of these causalities seems intuitive to be added to the forecasting model, not all might have the same amount of mutual information with the actual demand. Therefore, it is important to explore which ones or which combinations would provide the most appropriate amount of information for the desired increase in the forecasting capability. Furthermore, the datasets in Spain and Paraguay were limited by the amount of information provided. For example, the Spain dataset had the national energy demand, but the weather information was about the five largest cities in the country. It is safe to assume that the five largest cities can control a big proportion of energy consumed. However, it is a limitation in terms of analyses performed in this paper. On the other hand, in the Paraguay datasets, this problem was inverted. That is, local energy consumption data was available, but the weather information was centralised. Once again, it is not a completely valid assumption that the weather parameters would remain the same across a big region, but it is safe to assume that feeders in the high to medium vicinity of the weather station would be parameterised better by the causal relationship in the aggregate energy consumption data. In the future, it should be aimed to obtain the data such that the geographical spread of the two data streams is better matched than the two datasets. Different sources of energy (available in the Spain dataset) and the different modalities of usage (available in the France dataset) were not considered, where the causal relationship among each of these could have with the weather indicators. This choice was made to have one common analysis across the three datasets to showcase the generalizability of the proposed approach. However, exploring the different causal relationships between various energy usages and modalities with the weather conditions might also provide a better forecast for individual cases. Finally, for consistency of analysis across the three datasets, only four parameters were used to indicate weather conditions, that is, humidity, pressure, temperature, and wind speed. In the future, rainfall, snowfall, and wind direction, among other additional weather parameters, can also be considered.</p><p id="Par97">From the current results presented in this paper, several venues emerge that could bring novel knowledge in the field of forecasting energy demand or consumption. First, at the forecasting level, exploring the multivariate nature of the causal relationships between the weather conditions and the energy consumption could improve the forecasting performance; because the interaction effects between the weather conditions would also be exploited in such a manner. Second, on a higher level, implementing and controlling the energy production using such methods (on a small scale) would provide an opportunity to study the effectiveness of the forecasting algorithm in the real-life scenarios because, with the current contribution, the practical nature of such an improved consumption forecasting could not be studied. Third, as it is with any dep learning application, the transparency and explainability of the algorithms are not up to the standards in some other industry sectors; therefore, after knowing that causality plays a significant role in the forecasting processes, the explanation for "how the forecasting works" could be provided to users at various levels, such as customers, managers, and policymakers.</p></sec></sec><sec id="Sec27" sec-type="conclusions"><title>Conclusions</title><p id="Par98">In a nutshell, this paper presents a deep learning method to forecast energy consumption using not only the weather data but also the causal relationship between the weather indicators and the energy consumption. For the casual modelling, the definition of causality between the two-time series provided by Granger was used. This method was applied to three freely available datasets and showed that in all the cases, that is, a country, a specific region, and an individual building, augmenting the forecasting model by the causal information also augments the forecasting performance. This contribution extends the state-of-the-art in four ways.<list list-type="order"><list-item><p id="Par99">This paper proposes the inclusion of causal relations in the deep learning frameworks for forecasting the energy demand/consumption.</p></list-item><list-item><p id="Par100">Extending the LSTM architecture by using the causal information about how weather conditions cause the changes in the energy consumption provides better forecasting results.</p></list-item><list-item><p id="Par101">Using the causal relations within the LSTM framework also provides better early prediction. That is, it requires less amount of data to achieve a similar level of forecasting performance as it would have been required by a setup without the casual information.</p></list-item><list-item><p id="Par102">By using cross-training–testing routines, this paper also shows the higher generalizability of the proposed method than the contemporary methods.</p></list-item></list></p><p id="Par103">The theoretical and practical implications of the results are also provided, both of which indicate that including the causal information does not only confirm certain widely accepted theoretical frameworks but also provides better energy management opportunities both at the supplier (i.e., smart grids) and the consumer (i.e., smart homes) levels.</p></sec></body><back><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abu-Mostafa</surname><given-names>YS</given-names></name><name><surname>Atiya</surname><given-names>AF</given-names></name></person-group><article-title xml:lang="en">Introduction to Financial Forecasting</article-title><source>Applied Intelligence</source><year>1996</year><volume>6</volume><issue>3</issue><fpage>205</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1007/BF00126626</pub-id></mixed-citation></ref><ref id="CR2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ağbulut</surname><given-names>Ü</given-names></name></person-group><article-title xml:lang="en">Forecasting of transportation-related energy demand and CO2 emissions in Turkey with different machine learning algorithms</article-title><source>Sustainable Production and Consumption</source><year>2022</year><volume>29</volume><fpage>141</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1016/j.spc.2021.10.001</pub-id></mixed-citation></ref><ref id="CR3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahmad</surname><given-names>AS</given-names></name><name><surname>Hassan</surname><given-names>MY</given-names></name><name><surname>Abdullah</surname><given-names>MP</given-names></name><name><surname>Rahman</surname><given-names>HA</given-names></name><name><surname>Hussin</surname><given-names>F</given-names></name><name><surname>Abdullah</surname><given-names>H</given-names></name><name><surname>Saidur</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">A review on applications of ANN and SVM for building electrical energy consumption forecasting</article-title><source>Renewable and Sustainable Energy Reviews</source><year>2014</year><volume>33</volume><fpage>102</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1016/j.rser.2014.01.069</pub-id></mixed-citation></ref><ref id="CR4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahmad</surname><given-names>T</given-names></name><name><surname>Chen</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Nonlinear autoregressive and random forest approaches to forecasting electricity load for utility energy management systems</article-title><source>Sustainable Cities and Society</source><year>2019</year><volume>45</volume><fpage>460</fpage><lpage>473</lpage><pub-id pub-id-type="doi">10.1016/j.scs.2018.12.013</pub-id></mixed-citation></ref><ref id="CR5"><mixed-citation publication-type="other">Al Khafaf, N., Jalili, M., &amp; Sokolowski, P. (2019). Application of deep learning long short-term memory in energy demand forecasting. In <italic>International conference on engineering applications of neural networks</italic> (pp. 31–42). Springer, Cham.</mixed-citation></ref><ref id="CR6"><mixed-citation publication-type="other">Almagtome, A. H. (2021). Artificial Intelligence Applications in Accounting and Financial Reporting Systems: An International Perspective. In <italic>Handbook of Research on Applied AI for International Business and Marketing Applications</italic> (pp. 540–558). IGI Global.</mixed-citation></ref><ref id="CR183"><mixed-citation publication-type="other">Alzaidy, R., Caragea, C., &amp; Giles, C. L. (2019). Bi-LSTM-CRF sequence labeling for keyphrase extraction from scholarly documents. In
<italic>The world wide web conference</italic> (pp. 2551–2557).</mixed-citation></ref><ref id="CR7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ancona</surname><given-names>N</given-names></name><name><surname>Marinazzo</surname><given-names>D</given-names></name><name><surname>Stramaglia</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Radial basis function approach to nonlinear Granger causality of time series</article-title><source>Physical Review E</source><year>2004</year><volume>70</volume><issue>5</issue><pub-id pub-id-type="doi">10.1103/PhysRevE.70.056221</pub-id></mixed-citation></ref><ref id="CR8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arcos-Aviles</surname><given-names>D</given-names></name><name><surname>Pascual</surname><given-names>J</given-names></name><name><surname>Guinjoan</surname><given-names>F</given-names></name><name><surname>Marroyo</surname><given-names>L</given-names></name><name><surname>Sanchis</surname><given-names>P</given-names></name><name><surname>Marietta</surname><given-names>MP</given-names></name></person-group><article-title xml:lang="en">Low complexity energy management strategy for grid profile smoothing of a residential grid-connected microgrid using generation and demand forecasting</article-title><source>Applied Energy</source><year>2017</year><volume>205</volume><fpage>69</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1016/j.apenergy.2017.07.123</pub-id></mixed-citation></ref><ref id="CR9"><mixed-citation publication-type="other">Ardabili, S. F., Abdilalizadeh, L., Mako, C., Torok, B., &amp; Mosavi, A. (2022). Systematic review of deep learning and machine learning for building energy.</mixed-citation></ref><ref id="CR10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aydin</surname><given-names>GÖKHAN</given-names></name></person-group><article-title xml:lang="en">Production modeling in the oil and natural gas industry: An application of trend analysis</article-title><source>Petroleum Science and Technology</source><year>2014</year><volume>32</volume><issue>5</issue><fpage>555</fpage><lpage>564</lpage><pub-id pub-id-type="doi">10.1080/10916466.2013.825271</pub-id></mixed-citation></ref><ref id="CR11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aydin</surname><given-names>GÖKHAN</given-names></name></person-group><article-title xml:lang="en">The Application of trend analysis for coal demand modeling</article-title><source>Energy Sources, Part B: Economics, Planning, and Policy</source><year>2015</year><volume>10</volume><issue>2</issue><fpage>183</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1080/15567249.2013.813611</pub-id></mixed-citation></ref><ref id="CR12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagchi</surname><given-names>P</given-names></name><name><surname>Sahu</surname><given-names>SK</given-names></name><name><surname>Kumar</surname><given-names>A</given-names></name><name><surname>Tan</surname><given-names>KH</given-names></name></person-group><article-title xml:lang="en">Analysis of carbon productivity for firms in the manufacturing sector of India</article-title><source>Technological Forecasting and Social Change</source><year>2022</year><volume>178</volume><pub-id pub-id-type="doi">10.1016/j.techfore.2022.121606</pub-id></mixed-citation></ref><ref id="CR13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bakay</surname><given-names>MS</given-names></name><name><surname>Ağbulut</surname><given-names>Ü</given-names></name></person-group><article-title xml:lang="en">Electricity production based forecasting of greenhouse gas emissions in Turkey with deep learning, support vector machine and artificial neural network algorithms</article-title><source>Journal of Cleaner Production</source><year>2021</year><volume>285</volume><pub-id pub-id-type="doi">10.1016/j.jclepro.2020.125324</pub-id></mixed-citation></ref><ref id="CR175"><mixed-citation publication-type="other">Balaji, A. J., Ram, D. H., &amp; Nair, B. B. (2018). Applicability of deep learning models for stock price forecasting an empirical study on BANKEX data. <italic>Procedia Computer Science</italic>, <italic>143</italic>, 947–953.</mixed-citation></ref><ref id="CR14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bauwens</surname><given-names>L</given-names></name><name><surname>Laurent</surname><given-names>S</given-names></name><name><surname>Rombouts</surname><given-names>JV</given-names></name></person-group><article-title xml:lang="en">Multivariate GARCH models: A survey</article-title><source>Journal of Applied Econometrics</source><year>2006</year><volume>21</volume><issue>1</issue><fpage>79</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1002/jae.842</pub-id></mixed-citation></ref><ref id="CR15"><mixed-citation publication-type="other">Bhattacharyya, S. C., &amp; Timilsina, G. R. (2009). Energy demand models for policy formulation: a comparative study of energy demand models. World Bank Policy Research Working Paper, (4866).</mixed-citation></ref><ref id="CR16"><mixed-citation publication-type="other">Bollen, K. A., &amp; Pearl, J. (2013). Eight myths about causality and structural equation models. In <italic>Handbook of causal analysis for social research</italic> (pp. 301–328). Springer, Dordrecht.</mixed-citation></ref><ref id="CR17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braun</surname><given-names>MR</given-names></name><name><surname>Altan</surname><given-names>H</given-names></name><name><surname>Beck</surname><given-names>SBM</given-names></name></person-group><article-title xml:lang="en">Using regression analysis to predict the future energy consumption of a supermarket in the UK</article-title><source>Applied Energy</source><year>2014</year><volume>130</volume><fpage>305</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1016/j.apenergy.2014.05.062</pub-id></mixed-citation></ref><ref id="CR18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Catalina</surname><given-names>T</given-names></name><name><surname>Iordache</surname><given-names>V</given-names></name><name><surname>Caracaleanu</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Multiple regression model for fast prediction of the heating energy demand</article-title><source>Energy and Buildings</source><year>2013</year><volume>57</volume><fpage>302</fpage><lpage>312</lpage><pub-id pub-id-type="doi">10.1016/j.enbuild.2012.11.010</pub-id></mixed-citation></ref><ref id="CR19"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chambliss</surname><given-names>DF</given-names></name><name><surname>Schutt</surname><given-names>RK</given-names></name></person-group><source>Making sense of the social world: Methods of investigation</source><year>2018</year><publisher-loc>Thousand Oaks</publisher-loc><publisher-name>Sage Publications</publisher-name></mixed-citation></ref><ref id="CR20"><mixed-citation publication-type="other">Chang, O., Naranjo, I., Guerron, C., Criollo, D., Guerron, J., &amp; Mosquera, G. (2017). A deep learning algorithm to forecast sales of pharmaceutical products. no. August.</mixed-citation></ref><ref id="CR21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chatzis</surname><given-names>SP</given-names></name><name><surname>Siakoulis</surname><given-names>V</given-names></name><name><surname>Petropoulos</surname><given-names>A</given-names></name><name><surname>Stavroulakis</surname><given-names>E</given-names></name><name><surname>Vlachogiannakis</surname><given-names>N</given-names></name></person-group><article-title xml:lang="en">Forecasting stock market crisis events using deep and statistical machine learning techniques</article-title><source>Expert Systems with Applications</source><year>2018</year><volume>112</volume><fpage>353</fpage><lpage>371</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2018.06.032</pub-id></mixed-citation></ref><ref id="CR22"><mixed-citation publication-type="other">Chen, H., Rossi, R. A., Mahadik, K., &amp; Eldardiry, H. (2020). A context integrated relational spatio-temporal model for demand and supply forecasting. <italic>arXiv preprint </italic><ext-link xlink:href="http://arxiv.org/abs/2009.12469" ext-link-type="uri">arXiv:2009.12469</ext-link>.</mixed-citation></ref><ref id="CR23"><mixed-citation publication-type="other">Chen, J., Lim, C. P., Tan, K. H., Govindan, K., &amp; Kumar, A. (2021). Artificial intelligence-based human-centric decision support framework: an application to predictive maintenance in asset management under pandemic environments. <italic>Annals of Operations Research</italic>, 1–24.</mixed-citation></ref><ref id="CR24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Duan</surname><given-names>S</given-names></name><name><surname>Cai</surname><given-names>T</given-names></name><name><surname>Liu</surname><given-names>B</given-names></name><name><surname>Hu</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Smart energy management system for optimal microgrid economic operation</article-title><source>IET Renewable Power Generation</source><year>2011</year><volume>5</volume><issue>3</issue><fpage>258</fpage><lpage>267</lpage><pub-id pub-id-type="doi">10.1049/iet-rpg.2010.0052</pub-id></mixed-citation></ref><ref id="CR25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>IF</given-names></name><name><surname>Lu</surname><given-names>CJ</given-names></name></person-group><article-title xml:lang="en">Demand forecasting for multichannel fashion retailers by integrating clustering and machine learning algorithms</article-title><source>Processes</source><year>2021</year><volume>9</volume><issue>9</issue><fpage>1578</fpage><pub-id pub-id-type="doi">10.3390/pr9091578</pub-id></mixed-citation></ref><ref id="CR26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Rangarajan</surname><given-names>G</given-names></name><name><surname>Feng</surname><given-names>J</given-names></name><name><surname>Ding</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Analyzing multiple nonlinear time series with extended Granger causality</article-title><source>Physics Letters A</source><year>2004</year><volume>324</volume><issue>1</issue><fpage>26</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1016/j.physleta.2004.02.032</pub-id></mixed-citation></ref><ref id="CR27"><mixed-citation publication-type="other">Chung, J., Gulcehre, C., Cho, K., &amp; Bengio, Y. (2015). Gated feedback recurrent neural networks. In <italic>International conference on machine learning</italic> (pp. 2067–2075).</mixed-citation></ref><ref id="CR28"><mixed-citation publication-type="other">Clements, J. M., Xu, D., Yousefi, N., &amp; Efimov, D. (2020). Sequential deep learning for credit risk monitoring with tabular financial data. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/2012.15330" ext-link-type="uri">arXiv:2012.15330</ext-link>.</mixed-citation></ref><ref id="CR182"><mixed-citation publication-type="other">Crisóstomo de Castro Filho, H., Abílio de Carvalho Júnior, O., Ferreira de Carvalho, O. L., Pozzobon de Bem, P., dos Santos de Moura, R., Olino de Albuquerque, A., &amp; Trancoso Gomes, R. A. (2020). Rice crop detection using LSTM, Bi-LSTM, and machine learning models from sentinel-1 time series. <italic>Remote Sensing</italic>, <italic>12</italic>(16), 2655.</mixed-citation></ref><ref id="CR29"><mixed-citation publication-type="other">Darapaneni, N., Paduri, A. R., Sharma, H., Manjrekar, M., Hindlekar, N., Bhagat, P., &amp; Agarwal, Y. (2022). Stock price prediction using sentiment analysis and deep learning for Indian markets. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/2204.05783" ext-link-type="uri">arXiv:2204.05783</ext-link>.</mixed-citation></ref><ref id="CR30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davydenko</surname><given-names>A</given-names></name><name><surname>Fildes</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Measuring forecasting accuracy: The case of judgmental adjustments to SKU-level demand forecasts</article-title><source>International Journal of Forecasting</source><year>2013</year><volume>29</volume><issue>3</issue><fpage>510</fpage><lpage>522</lpage><pub-id pub-id-type="doi">10.1016/j.ijforecast.2012.09.002</pub-id></mixed-citation></ref><ref id="CR31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Del Real</surname><given-names>AJ</given-names></name><name><surname>Dorado</surname><given-names>F</given-names></name><name><surname>Durán</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Energy demand forecasting using deep learning: Applications for the French grid</article-title><source>Energies</source><year>2020</year><volume>13</volume><issue>9</issue><fpage>2242</fpage><pub-id pub-id-type="doi">10.3390/en13092242</pub-id></mixed-citation></ref><ref id="CR32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demir</surname><given-names>S</given-names></name><name><surname>Mincev</surname><given-names>K</given-names></name><name><surname>Kok</surname><given-names>K</given-names></name><name><surname>Paterakis</surname><given-names>NG</given-names></name></person-group><article-title xml:lang="en">Data augmentation for time series regression: Applying transformations, autoencoders and adversarial networks to electricity price forecasting</article-title><source>Applied Energy</source><year>2021</year><volume>304</volume><pub-id pub-id-type="doi">10.1016/j.apenergy.2021.117695</pub-id></mixed-citation></ref><ref id="CR33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>M</given-names></name><name><surname>Bressler</surname><given-names>SL</given-names></name><name><surname>Yang</surname><given-names>W</given-names></name><name><surname>Liang</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Short-window spectral analysis of cortical event-related potentials by adaptive multivariate autoregressive modeling: Data preprocessing, model validation, and variability assessment</article-title><source>Biological Cybernetics</source><year>2000</year><volume>83</volume><issue>1</issue><fpage>35</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1007/s004229900137</pub-id></mixed-citation></ref><ref id="CR34"><mixed-citation publication-type="other">Dorsman, A. B., Atici, K. B., Ulucan, A., &amp; Karan, M. B. (2021). Introduction: Applied operations research and financial modeling in energy. In <italic>Applied operations research and financial modelling in energy</italic> (pp. 1–6). Springer, Cham.</mixed-citation></ref><ref id="CR35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>B</given-names></name><name><surname>Zhou</surname><given-names>Q</given-names></name><name><surname>Guo</surname><given-names>J</given-names></name><name><surname>Guo</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Deep learning with long short-term memory neural networks combining wavelet transform and principal component analysis for daily urban water demand forecasting</article-title><source>Expert Systems with Applications</source><year>2021</year><volume>171</volume><pub-id pub-id-type="doi">10.1016/j.eswa.2021.114571</pub-id></mixed-citation></ref><ref id="CR36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Du</surname><given-names>Z</given-names></name><name><surname>Ge</surname><given-names>L</given-names></name><name><surname>Ng</surname><given-names>AHM</given-names></name><name><surname>Zhu</surname><given-names>Q</given-names></name><name><surname>Horgan</surname><given-names>FG</given-names></name><name><surname>Zhang</surname><given-names>Q</given-names></name></person-group><article-title xml:lang="en">Risk assessment for tailings dams in Brumadinho of Brazil using InSAR time series approach</article-title><source>Science of the Total Environment</source><year>2020</year><volume>717</volume><pub-id pub-id-type="doi">10.1016/j.scitotenv.2020.137125</pub-id></mixed-citation></ref><ref id="CR37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eachempati</surname><given-names>P</given-names></name><name><surname>Srivastava</surname><given-names>PR</given-names></name><name><surname>Kumar</surname><given-names>A</given-names></name><name><surname>Tan</surname><given-names>KH</given-names></name><name><surname>Gupta</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Validating the impact of accounting disclosures on stock market: A deep neural network approach</article-title><source>Technological Forecasting and Social Change</source><year>2021</year><volume>170</volume><pub-id pub-id-type="doi">10.1016/j.techfore.2021.120903</pub-id></mixed-citation></ref><ref id="CR38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ediger</surname><given-names>VŞ</given-names></name><name><surname>Tatlıdil</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Forecasting the primary energy demand in Turkey and analysis of cyclic patterns</article-title><source>Energy Conversion and Management</source><year>2002</year><volume>43</volume><issue>4</issue><fpage>473</fpage><lpage>487</lpage><pub-id pub-id-type="doi">10.1016/S0196-8904(01)00033-4</pub-id></mixed-citation></ref><ref id="CR39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edwards</surname><given-names>JR</given-names></name><name><surname>Bagozzi</surname><given-names>RP</given-names></name></person-group><article-title xml:lang="en">On the nature and direction of relationships between constructs and measures</article-title><source>Psychological Methods</source><year>2000</year><volume>5</volume><issue>2</issue><fpage>155</fpage><pub-id pub-id-type="doi">10.1037/1082-989X.5.2.155</pub-id></mixed-citation></ref><ref id="CR40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Efimova</surname><given-names>O</given-names></name><name><surname>Serletis</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Energy markets volatility modelling using GARCH</article-title><source>Energy Economics</source><year>2014</year><volume>43</volume><fpage>264</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1016/j.eneco.2014.02.018</pub-id></mixed-citation></ref><ref id="CR41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engle</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">GARCH 101: The use of ARCH/GARCH models in applied econometrics</article-title><source>Journal of Economic Perspectives</source><year>2001</year><volume>15</volume><issue>4</issue><fpage>157</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1257/jep.15.4.157</pub-id></mixed-citation></ref><ref id="CR42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erdogdu</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Electricity demand analysis using cointegration and ARIMA modelling: A case study of Turkey</article-title><source>Energy Policy</source><year>2007</year><volume>35</volume><issue>2</issue><fpage>1129</fpage><lpage>1146</lpage><pub-id pub-id-type="doi">10.1016/j.enpol.2006.02.013</pub-id></mixed-citation></ref><ref id="CR43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ergen</surname><given-names>I</given-names></name><name><surname>Rizvanoghlu</surname><given-names>I</given-names></name></person-group><article-title xml:lang="en">Asymmetric impacts of fundamentals on the natural gas futures volatility: An augmented GARCH approach</article-title><source>Energy Economics</source><year>2016</year><volume>56</volume><fpage>64</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1016/j.eneco.2016.02.022</pub-id></mixed-citation></ref><ref id="CR44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eseye</surname><given-names>AT</given-names></name><name><surname>Lehtonen</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Short-term forecasting of heat demand of buildings for efficient and optimal energy management based on integrated machine learning models</article-title><source>IEEE Transactions on Industrial Informatics</source><year>2020</year><volume>16</volume><issue>12</issue><fpage>7743</fpage><lpage>7755</lpage><pub-id pub-id-type="doi">10.1109/TII.2020.2970165</pub-id></mixed-citation></ref><ref id="CR45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fałdziński</surname><given-names>M</given-names></name><name><surname>Fiszeder</surname><given-names>P</given-names></name><name><surname>Orzeszko</surname><given-names>W</given-names></name></person-group><article-title xml:lang="en">Forecasting volatility of energy commodities: Comparison of GARCH models with support vector regression</article-title><source>Energies</source><year>2020</year><volume>14</volume><issue>1</issue><fpage>1</fpage><lpage>1</lpage><pub-id pub-id-type="doi">10.3390/en14010006</pub-id></mixed-citation></ref><ref id="CR46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farajian</surname><given-names>L</given-names></name><name><surname>Moghaddasi</surname><given-names>R</given-names></name><name><surname>Hosseini</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Agricultural energy demand modeling in Iran: Approaching to a more sustainable situation</article-title><source>Energy Reports</source><year>2018</year><volume>4</volume><fpage>260</fpage><lpage>265</lpage><pub-id pub-id-type="doi">10.1016/j.egyr.2018.03.002</pub-id></mixed-citation></ref><ref id="CR47"><mixed-citation publication-type="other">Ferlito, S., Atrigna, M., Graditi, G., De Vito, S., Salvato, M., Buonanno, A., &amp; Di Francia, G. (2015). Predictive models for building's energy consumption: An Artificial Neural Network (ANN) approach. In <italic>2015 xviii aisem annual conference</italic> (pp. 1–4). IEEE.</mixed-citation></ref><ref id="CR48"><mixed-citation publication-type="other">Ferreira, R., Braga, M., &amp; Alves, V. (2018, March). Forecast in the pharmaceutical area–statistic models vs deep learning. In <italic>World conference on information systems and technologies</italic> (pp. 165–175). Springer, Cham.</mixed-citation></ref><ref id="CR49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Forootan</surname><given-names>MM</given-names></name><name><surname>Larki</surname><given-names>I</given-names></name><name><surname>Zahedi</surname><given-names>R</given-names></name><name><surname>Ahmadi</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Machine learning and deep learning in energy systems: A review</article-title><source>Sustainability</source><year>2022</year><volume>14</volume><issue>8</issue><fpage>4832</fpage><pub-id pub-id-type="doi">10.3390/su14084832</pub-id></mixed-citation></ref><ref id="CR50"><mixed-citation publication-type="other">Forouzandeh, N., Zomorodian, Z. S., Shaghaghian, Z., &amp; Tahsildoost, M. (2022). Room energy demand and thermal comfort predictions in early stages of design based on the machine learning methods. <italic>Intelligent Buildings International</italic>, 1–18.</mixed-citation></ref><ref id="CR51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fumo</surname><given-names>N</given-names></name><name><surname>Biswas</surname><given-names>MR</given-names></name></person-group><article-title xml:lang="en">Regression analysis for prediction of residential energy consumption</article-title><source>Renewable and Sustainable Energy Reviews</source><year>2015</year><volume>47</volume><fpage>332</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1016/j.rser.2015.03.035</pub-id></mixed-citation></ref><ref id="CR52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geng</surname><given-names>R</given-names></name><name><surname>Bose</surname><given-names>I</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name></person-group><article-title xml:lang="en">Prediction of financial distress: An empirical study of listed Chinese companies using data mining</article-title><source>European Journal of Operational Research</source><year>2015</year><volume>241</volume><issue>1</issue><fpage>236</fpage><lpage>247</lpage><pub-id pub-id-type="doi">10.1016/j.ejor.2014.08.016</pub-id></mixed-citation></ref><ref id="CR53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghalehkhondabi</surname><given-names>I</given-names></name><name><surname>Ardjmand</surname><given-names>E</given-names></name><name><surname>Weckman</surname><given-names>GR</given-names></name><name><surname>Young</surname><given-names>WA</given-names></name></person-group><article-title xml:lang="en">An overview of energy demand forecasting methods published in 2005–2015</article-title><source>Energy Systems</source><year>2017</year><volume>8</volume><issue>2</issue><fpage>411</fpage><lpage>447</lpage><pub-id pub-id-type="doi">10.1007/s12667-016-0203-y</pub-id></mixed-citation></ref><ref id="CR54"><mixed-citation publication-type="other">Ghazal, T. M., Noreen, S., Said, R. A., Khan, M. A., Siddiqui, S. Y., Abbas, S., &amp; Ahmad, M. (2022). Energy demand forecasting using fused machine learning approaches.</mixed-citation></ref><ref id="CR55"><mixed-citation publication-type="other">Ghouali, S., Feham, M., &amp; Ghouali, Y. Z. (2014). The direction of information between cardiorespiratory hemodynamic signals: test analysis using granger causality. <italic>GSTF Journal of Mathematics, Statistics &amp; Operations Research</italic>, 2(2).</mixed-citation></ref><ref id="CR56"><mixed-citation publication-type="other">Giri, C., Thomassey, S., Balkow, J., &amp; Zeng, X. (2019). Forecasting new apparel sales using deep learning and nonlinear neural network regression. In 2019 <italic>International Conference on Engineering, Science, and Industrial Applications</italic> (<italic>ICESI</italic>) (pp. 1–6). IEEE.</mixed-citation></ref><ref id="CR57"><mixed-citation publication-type="other">Granger, C. W. (1969). Investigating causal relations by econometric models and cross-spectral methods. <italic>Econometrica: Journal of the Econometric Society</italic>, 424–438.</mixed-citation></ref><ref id="CR58"><mixed-citation publication-type="other">Guan, Y., &amp; Yu, L. (2021). Design of supply chain resource distribution allocation model based on deep learning. In <italic>International conference on multimedia technology and enhanced learning</italic> (pp. 321–332). Springer, Cham.</mixed-citation></ref><ref id="CR59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harold</surname><given-names>J</given-names></name><name><surname>Cullinan</surname><given-names>J</given-names></name><name><surname>Lyons</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">The income elasticity of household energy demand: A quantile regression analysis</article-title><source>Applied Economics</source><year>2017</year><volume>49</volume><issue>54</issue><fpage>5570</fpage><lpage>5578</lpage><pub-id pub-id-type="doi">10.1080/00036846.2017.1313952</pub-id></mixed-citation></ref><ref id="CR60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hesse</surname><given-names>W</given-names></name><name><surname>Möller</surname><given-names>E</given-names></name><name><surname>Arnold</surname><given-names>M</given-names></name><name><surname>Schack</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">The use of time-variant EEG Granger causality for inspecting directed interdependencies of neural assemblies</article-title><source>Journal of Neuroscience Methods</source><year>2003</year><volume>124</volume><issue>1</issue><fpage>27</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1016/S0165-0270(02)00366-7</pub-id></mixed-citation></ref><ref id="CR61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ho</surname><given-names>SL</given-names></name><name><surname>Xie</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">The use of ARIMA models for reliability forecasting and analysis</article-title><source>Computers &amp; Industrial Engineering</source><year>1998</year><volume>35</volume><issue>1–2</issue><fpage>213</fpage><lpage>216</lpage><pub-id pub-id-type="doi">10.1016/S0360-8352(98)00066-7</pub-id></mixed-citation></ref><ref id="CR62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Long short-term memory</article-title><source>Neural Computation</source><year>1997</year><volume>9</volume><issue>8</issue><fpage>1735</fpage><lpage>1780</lpage><pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id></mixed-citation></ref><ref id="CR63"><mixed-citation publication-type="other">Hor, C. L., Watson, S. J., &amp; Majithia, S. (2006). Daily load forecasting and maximum demand estimation using ARIMA and GARCH. In <italic>2006 International conference on probabilistic methods applied to power systems</italic> (pp. 1–6). IEEE.</mixed-citation></ref><ref id="CR64"><mixed-citation publication-type="other">Hossen, T., Nair, A. S., Noghanian, S., &amp; Ranganathan, P. (2018). Optimal operation of smart home appliances using deep learning. In <italic>2018 North American Power Symposium (NAPS)</italic> (pp. 1–6). IEEE.</mixed-citation></ref><ref id="CR65"><mixed-citation publication-type="other">Hrnjica, B., &amp; Mehr, A. D. (2020). Energy demand forecasting using deep learning. In Smart cities performability, cognition, &amp; security (pp. 71–104). Springer, Cham.</mixed-citation></ref><ref id="CR185"><mixed-citation publication-type="other">Huang, Z., Xu, W., &amp; Yu, K. (2015). Bidirectional LSTM-CRF models for sequence tagging. arXiv preprint. http://arXiv:1508.01991.</mixed-citation></ref><ref id="CR66"><mixed-citation publication-type="other">Huang, B., Yao, X., Luo, Y., &amp; Li, J. (2022). Improving financial distress prediction using textual sentiment of annual reports. <italic>Annals of Operations Research</italic>, 1–28.</mixed-citation></ref><ref id="CR67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>SJ</given-names></name><name><surname>Shih</surname><given-names>KR</given-names></name></person-group><article-title xml:lang="en">Short-term load forecasting via ARMA model identification including non-Gaussian process considerations</article-title><source>IEEE Transactions on Power Systems</source><year>2003</year><volume>18</volume><issue>2</issue><fpage>673</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1109/TPWRS.2003.811010</pub-id></mixed-citation></ref><ref id="CR68"><mixed-citation publication-type="other">Husna, A., Amin, S. H., &amp; Shah, B. (2021). Demand forecasting in supply chain management using different deep learning methods. In Demand <italic>forecasting and order planning in supply chains and humanitarian logistics</italic> (pp. 140–170). IGI Global.</mixed-citation></ref><ref id="CR69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyndman</surname><given-names>RJ</given-names></name><name><surname>Koehler</surname><given-names>AB</given-names></name></person-group><article-title xml:lang="en">Another look at measures of forecast accuracy</article-title><source>International Journal of Forecasting</source><year>2006</year><volume>22</volume><issue>4</issue><fpage>679</fpage><lpage>688</lpage><pub-id pub-id-type="doi">10.1016/j.ijforecast.2006.03.001</pub-id></mixed-citation></ref><ref id="CR70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ishaq</surname><given-names>M</given-names></name><name><surname>Kwon</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Short-term energy forecasting framework using an ensemble deep learning approach</article-title><source>IEEE Access</source><year>2021</year><volume>9</volume><fpage>94262</fpage><lpage>94271</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2021.3093053</pub-id></mixed-citation></ref><ref id="CR71"><mixed-citation publication-type="other">Islam, M. A., Che, H. S., Hasanuzzaman, M., &amp; Rahim, N. A. (2020). Energy demand forecasting. In <italic>Energy for sustainable development</italic> (pp. 105–123). Academic Press.</mixed-citation></ref><ref id="CR72"><mixed-citation publication-type="other">Iwafune, Y., Yagita, Y., Ikegami, T., &amp; Ogimoto, K. (2014). Short-term forecasting of residential building load for distributed energy management. In <italic>2014 IEEE international energy conference (ENERGYCON)</italic> (pp. 1197–1204). IEEE.</mixed-citation></ref><ref id="CR73"><mixed-citation publication-type="other">Jana, R. K., &amp; Ghosh, I. (2022). A residual driven ensemble machine learning approach for forecasting natural gas prices: Analyses for pre-and during-COVID-19 phases. <italic>Annals of Operations Research</italic>, 1–22.</mixed-citation></ref><ref id="CR74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>F</given-names></name><name><surname>Yang</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Comparison of forecasting India’s energy demand using an MGM, ARIMA model, MGM-ARIMA model, and BP neural network model</article-title><source>Sustainability</source><year>2018</year><volume>10</volume><issue>7</issue><fpage>2225</fpage><pub-id pub-id-type="doi">10.3390/su10072225</pub-id></mixed-citation></ref><ref id="CR75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jing</surname><given-names>N</given-names></name><name><surname>Wu</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">A hybrid model integrating deep learning with investor sentiment analysis for stock price prediction</article-title><source>Expert Systems with Applications</source><year>2021</year><volume>178</volume><pub-id pub-id-type="doi">10.1016/j.eswa.2021.115019</pub-id></mixed-citation></ref><ref id="CR76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johannesen</surname><given-names>NJ</given-names></name><name><surname>Kolhe</surname><given-names>M</given-names></name><name><surname>Goodwin</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Relative evaluation of regression tools for urban area electrical energy demand forecasting</article-title><source>Journal of Cleaner Production</source><year>2019</year><volume>218</volume><fpage>555</fpage><lpage>564</lpage><pub-id pub-id-type="doi">10.1016/j.jclepro.2019.01.108</pub-id></mixed-citation></ref><ref id="CR189"><mixed-citation publication-type="other">Joyce, J. M. (1999). <italic>The foundations of causal decision theory</italic>. Cambridge University Press.</mixed-citation></ref><ref id="CR77"><mixed-citation publication-type="other">Kafazi, I., Bannari, R., &amp; Abouabdellah, A. (2016). Modeling and forecasting energy demand. In <italic>2016 international renewable and sustainable energy conference (IRSEC)</italic> (pp. 746–750). IEEE.</mixed-citation></ref><ref id="CR78"><mixed-citation publication-type="other">Kala, J. R., Kre, D. M., Gnassou, A. N. G., Kala, J. R. K., Akpablin, Y. M. A., &amp; Coulibaly, T. (2020). Assets management on electrical grid using Faster-RCNN. <italic>Annals of Operations</italic><italic>Research</italic>, 1–14.</mixed-citation></ref><ref id="CR79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kankal</surname><given-names>M</given-names></name><name><surname>Uzlu</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Neural network approach with teaching–learning-based optimization for modeling and forecasting long-term electric energy demand in Turkey</article-title><source>Neural Computing and Applications</source><year>2017</year><volume>28</volume><issue>1</issue><fpage>737</fpage><lpage>747</lpage><pub-id pub-id-type="doi">10.1007/s00521-016-2409-2</pub-id></mixed-citation></ref><ref id="CR80"><mixed-citation publication-type="other">Kayhan, S., Adiguzel, U., Bayat, T., &amp; Lebe, F. (2010). Causality relationship between real GDP and electricity consumption in Romania (2001). <italic>Romanian Journal of Economic Forecasting</italic>, 169.</mixed-citation></ref><ref id="CR81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kegenbekov</surname><given-names>Z</given-names></name><name><surname>Jackson</surname><given-names>I</given-names></name></person-group><article-title xml:lang="en">Adaptive supply chain: Demand-supply synchronization using deep reinforcement learning</article-title><source>Algorithms</source><year>2021</year><volume>14</volume><issue>8</issue><fpage>240</fpage><pub-id pub-id-type="doi">10.3390/a14080240</pub-id></mixed-citation></ref><ref id="CR82"><mixed-citation publication-type="other">Kilimci, Z. H., Akyuz, A. O., Uysal, M., Akyokus, S., Uysal, M. O., Atak Bulbul, B., &amp; Ekmis, M. A. (2019). An improved demand forecasting model using deep learning approach and proposed decision integration strategy for supply chain. <italic>Complexity</italic>, 2019.</mixed-citation></ref><ref id="CR83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>A</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Lessmann</surname><given-names>S</given-names></name><name><surname>Ma</surname><given-names>T</given-names></name><name><surname>Sung</surname><given-names>MC</given-names></name><name><surname>Johnson</surname><given-names>JE</given-names></name></person-group><article-title xml:lang="en">Can deep learning predict risky retail investors? A case study in financial risk behavior forecasting</article-title><source>European Journal of Operational Research</source><year>2020</year><volume>283</volume><issue>1</issue><fpage>217</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.ejor.2019.11.007</pub-id></mixed-citation></ref><ref id="CR84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>JY</given-names></name><name><surname>Cho</surname><given-names>SB</given-names></name></person-group><article-title xml:lang="en">Electric energy consumption prediction by deep learning with state explainable autoencoder</article-title><source>Energies</source><year>2019</year><volume>12</volume><issue>4</issue><fpage>739</fpage><pub-id pub-id-type="doi">10.3390/en12040739</pub-id></mixed-citation></ref><ref id="CR85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>M</given-names></name><name><surname>Ryu</surname><given-names>J</given-names></name><name><surname>Cha</surname><given-names>D</given-names></name><name><surname>Sim</surname><given-names>MK</given-names></name></person-group><article-title xml:lang="en">Stock price prediction using sentiment analysis: From</article-title><source>The Journal of Society for e-Business Studies</source><year>2020</year><volume>25</volume><issue>4</issue><fpage>61</fpage><lpage>75</lpage></mixed-citation></ref><ref id="CR86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>TY</given-names></name><name><surname>Cho</surname><given-names>SB</given-names></name></person-group><article-title xml:lang="en">Predicting residential energy consumption using CNN-LSTM neural networks</article-title><source>Energy</source><year>2019</year><volume>182</volume><fpage>72</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1016/j.energy.2019.05.230</pub-id></mixed-citation></ref><ref id="CR87"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kleinberg</surname><given-names>S</given-names></name></person-group><source>Causality, probability, and time</source><year>2013</year><publisher-name>Cambridge University Press</publisher-name></mixed-citation></ref><ref id="CR88"><mixed-citation publication-type="other">Kumar, A., Gopal, R. D., Shankar, R., &amp; Tan, K. H. (2022b). Fraudulent review detection model focusing on emotional expressions and explicit aspects: Investigating the potential of feature engineering. <italic>Decision Support Systems</italic>, 113728.</mixed-citation></ref><ref id="CR89"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>A</given-names></name><name><surname>Alsadoon</surname><given-names>A</given-names></name><name><surname>Prasad</surname><given-names>PWC</given-names></name><name><surname>Abdullah</surname><given-names>S</given-names></name><name><surname>Rashid</surname><given-names>TA</given-names></name><name><surname>Pham</surname><given-names>DTH</given-names></name><name><surname>Nguyen</surname><given-names>TQV</given-names></name></person-group><article-title xml:lang="en">Generative adversarial network (GAN) and enhanced root mean square error (ERMSE): Deep learning for stock price movement prediction</article-title><source>Multimedia Tools and Applications</source><year>2022</year><volume>81</volume><issue>3</issue><fpage>3995</fpage><lpage>4013</lpage><pub-id pub-id-type="doi">10.1007/s11042-021-11670-w</pub-id></mixed-citation></ref><ref id="CR90"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>A</given-names></name><name><surname>Shankar</surname><given-names>R</given-names></name><name><surname>Choudhary</surname><given-names>A</given-names></name><name><surname>Thakur</surname><given-names>LS</given-names></name></person-group><article-title xml:lang="en">A big data MapReduce framework for fault diagnosis in cloud-based manufacturing</article-title><source>International Journal of Production Research</source><year>2016</year><volume>54</volume><issue>23</issue><fpage>7060</fpage><lpage>7073</lpage><pub-id pub-id-type="doi">10.1080/00207543.2016.1153166</pub-id></mixed-citation></ref><ref id="CR91"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>A</given-names></name><name><surname>Shankar</surname><given-names>R</given-names></name><name><surname>Thakur</surname><given-names>LS</given-names></name></person-group><article-title xml:lang="en">A big data driven sustainable manufacturing framework for condition-based maintenance prediction</article-title><source>Journal of Computational Science</source><year>2018</year><volume>27</volume><fpage>428</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1016/j.jocs.2017.06.006</pub-id></mixed-citation></ref><ref id="CR180"><mixed-citation publication-type="other">Le, T., Vo, M. T., Vo, B., Hwang, E., Rho, S., &amp; Baik, S. W. (2019). Improving electric energy consumption prediction using CNN and Bi-LSTM. <italic>Applied Sciences</italic>, <italic>9</italic>(20), 4237.</mixed-citation></ref><ref id="CR92"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LeCun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Deep learning</article-title><source>Nature</source><year>2015</year><volume>521</volume><issue>7553</issue><fpage>436</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id></mixed-citation></ref><ref id="CR173"><mixed-citation publication-type="other">Lewis, D. (1981). Causal decision theory. <italic>Australasian Journal of Philosophy</italic>, <italic>59</italic>(1), 5–30.</mixed-citation></ref><ref id="CR93"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Comparison of forecasting energy consumption in Shandong, China Using the ARIMA model, GM model, and ARIMA-GM model</article-title><source>Sustainability</source><year>2017</year><volume>9</volume><issue>7</issue><fpage>1181</fpage><pub-id pub-id-type="doi">10.3390/su9071181</pub-id></mixed-citation></ref><ref id="CR94"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>T</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Zhu</surname><given-names>S</given-names></name><name><surname>Ogihara</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">A survey on wavelet applications in data mining</article-title><source>ACM SIGKDD Explorations Newsletter</source><year>2002</year><volume>4</volume><issue>2</issue><fpage>49</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1145/772862.772870</pub-id></mixed-citation></ref><ref id="CR95"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Pan</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">A novel ensemble deep learning model for stock prediction based on stock prices and news</article-title><source>International Journal of Data Science and Analytics</source><year>2022</year><volume>13</volume><issue>2</issue><fpage>139</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1007/s41060-021-00279-9</pub-id></mixed-citation></ref><ref id="CR96"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>EP</given-names></name><name><surname>Chen</surname><given-names>H</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Business intelligence and analytics: Research directions</article-title><source>ACM Transactions on Management Information Systems (TMIS)</source><year>2013</year><volume>3</volume><issue>4</issue><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1145/2407740.2407741</pub-id></mixed-citation></ref><ref id="CR97"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Q</given-names></name><name><surname>Tao</surname><given-names>Z</given-names></name><name><surname>Tse</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Stock market prediction with deep learning: The case of China</article-title><source>Finance Research Letters</source><year>2022</year><volume>46</volume><pub-id pub-id-type="doi">10.1016/j.frl.2021.102209</pub-id></mixed-citation></ref><ref id="CR98"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Novel volatility forecasting using deep learning–long short term memory recurrent neural networks</article-title><source>Expert Systems with Applications</source><year>2019</year><volume>132</volume><fpage>99</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2019.04.038</pub-id></mixed-citation></ref><ref id="CR99"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loureiro</surname><given-names>AL</given-names></name><name><surname>Miguéis</surname><given-names>VL</given-names></name><name><surname>da Silva</surname><given-names>LF</given-names></name></person-group><article-title xml:lang="en">Exploring the use of deep neural networks for sales forecasting in fashion retail</article-title><source>Decision Support Systems</source><year>2018</year><volume>114</volume><fpage>81</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1016/j.dss.2018.08.010</pub-id></mixed-citation></ref><ref id="CR100"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>H</given-names></name><name><surname>Ma</surname><given-names>X</given-names></name><name><surname>Ma</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">A hybrid multi-objective optimizer-based model for daily electricity demand prediction considering COVID-19</article-title><source>Energy</source><year>2021</year><volume>219</volume><pub-id pub-id-type="doi">10.1016/j.energy.2020.119568</pub-id></mixed-citation></ref><ref id="CR101"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luna</surname><given-names>AC</given-names></name><name><surname>Meng</surname><given-names>L</given-names></name><name><surname>Diaz</surname><given-names>NL</given-names></name><name><surname>Graells</surname><given-names>M</given-names></name><name><surname>Vasquez</surname><given-names>JC</given-names></name><name><surname>Guerrero</surname><given-names>JM</given-names></name></person-group><article-title xml:lang="en">Online energy management systems for microgrids: Experimental validation and assessment framework</article-title><source>IEEE Transactions on Power Electronics</source><year>2017</year><volume>33</volume><issue>3</issue><fpage>2201</fpage><lpage>2215</lpage><pub-id pub-id-type="doi">10.1109/TPEL.2017.2700083</pub-id></mixed-citation></ref><ref id="CR181"><mixed-citation publication-type="other">Ma, J., Cheng, J. C., Jiang, F., Chen, W., Wang, M., &amp; Zhai, C. (2020). A bi-directional missing data imputation scheme based on LSTM and transfer learning for building energy data. <italic>Energy and Buildings</italic>, <italic>216</italic>, 109941.</mixed-citation></ref><ref id="CR102"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maaouane</surname><given-names>M</given-names></name><name><surname>Zouggar</surname><given-names>S</given-names></name><name><surname>Krajačić</surname><given-names>G</given-names></name><name><surname>Zahboune</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Modelling industry energy demand using multiple linear regression analysis based on consumed quantity of goods</article-title><source>Energy</source><year>2021</year><volume>225</volume><pub-id pub-id-type="doi">10.1016/j.energy.2021.120270</pub-id></mixed-citation></ref><ref id="CR190"><mixed-citation publication-type="other">Maher, P. (1987). Causality in the logic of decision. <italic>Theory and Decision</italic>, <italic>22</italic>(2), 155–172.</mixed-citation></ref><ref id="CR103"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mian</surname><given-names>DU</given-names></name><name><surname>Liang</surname><given-names>GU</given-names></name></person-group><article-title xml:lang="en">Study on the causal relationship between proportion of blockholder and corporate performance——Based on panel-data granger causality tests of listed companies in China</article-title><source>Forecasting</source><year>2010</year><volume>29</volume><issue>3</issue><fpage>50</fpage><lpage>54</lpage></mixed-citation></ref><ref id="CR104"><mixed-citation publication-type="other">Mitkov, A., Noorzad, N., Gabrovska-Evstatieva, K., &amp; Mihailov, N. (2019). Forecasting the energy consumption in Afghanistan with the ARIMA model. In <italic>2019 16th conference on electrical machines, drives and power systems (ELMA)</italic> (pp. 1–4). IEEE.</mixed-citation></ref><ref id="CR105"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moews</surname><given-names>B</given-names></name><name><surname>Herrmann</surname><given-names>JM</given-names></name><name><surname>Ibikunle</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Lagged correlation-based deep learning for directional trend change prediction in financial time series</article-title><source>Expert Systems with Applications</source><year>2019</year><volume>120</volume><fpage>197</fpage><lpage>206</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2018.11.027</pub-id></mixed-citation></ref><ref id="CR106"><mixed-citation publication-type="other">Mohan, S., Mullapudi, S., Sammeta, S., Vijayvergia, P., &amp; Anastasiu, D. C. (2019). Stock price prediction using news sentiment analysis. In <italic>2019 IEEE fifth international conference on big data computing service and applications (BigDataService)</italic> (pp. 205–208). IEEE.</mixed-citation></ref><ref id="CR107"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morakinyo</surname><given-names>TE</given-names></name><name><surname>Ren</surname><given-names>C</given-names></name><name><surname>Shi</surname><given-names>Y</given-names></name><name><surname>Lau</surname><given-names>KKL</given-names></name><name><surname>Tong</surname><given-names>HW</given-names></name><name><surname>Choy</surname><given-names>CW</given-names></name><name><surname>Ng</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Estimates of the impact of extreme heat events on cooling energy demand in Hong Kong</article-title><source>Renewable Energy</source><year>2019</year><volume>142</volume><fpage>73</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1016/j.renene.2019.04.077</pub-id></mixed-citation></ref><ref id="CR108"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mortenson</surname><given-names>MJ</given-names></name><name><surname>Doherty</surname><given-names>NF</given-names></name><name><surname>Robinson</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Operational research from taylorism to terabytes: A research agenda for the analytics age</article-title><source>European Journal of Operational Research</source><year>2015</year><volume>241</volume><issue>3</issue><fpage>583</fpage><lpage>595</lpage><pub-id pub-id-type="doi">10.1016/j.ejor.2014.08.029</pub-id></mixed-citation></ref><ref id="CR109"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murat</surname><given-names>YS</given-names></name><name><surname>Ceylan</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Use of artificial neural networks for transport energy demand modeling</article-title><source>Energy Policy</source><year>2006</year><volume>34</volume><issue>17</issue><fpage>3165</fpage><lpage>3172</lpage><pub-id pub-id-type="doi">10.1016/j.enpol.2005.02.010</pub-id></mixed-citation></ref><ref id="CR110"><mixed-citation publication-type="other">Noureen, S., Atique, S., Roy, V., &amp; Bayne, S. (2019a). Analysis and application of seasonal ARIMA model in energy demand forecasting: A case study of small scale agricultural load. In <italic>2019a IEEE 62nd international midwest symposium on circuits and systems (MWSCAS)</italic> (pp. 521–524). IEEE.</mixed-citation></ref><ref id="CR111"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noureen</surname><given-names>S</given-names></name><name><surname>Atique</surname><given-names>S</given-names></name><name><surname>Roy</surname><given-names>V</given-names></name><name><surname>Bayne</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">A comparative forecasting analysis of arima model vs random forest algorithm for a case study of small-scale industrial load</article-title><source>International Research Journal of Engineering and Technology</source><year>2019</year><volume>6</volume><issue>09</issue><fpage>1812</fpage><lpage>1821</lpage></mixed-citation></ref><ref id="CR191"><mixed-citation publication-type="other">Nozick, R. (1993). <italic>The Nature of Rationality</italic>. Princeton: Princeton University Press.</mixed-citation></ref><ref id="CR112"><mixed-citation publication-type="other">Oh, G., Jeong, E., &amp; Lim, S. (2021). Causal affect prediction model using a facial image sequence. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/2107.03886" ext-link-type="uri">arXiv:2107.03886</ext-link>.</mixed-citation></ref><ref id="CR113"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okakwu</surname><given-names>IK</given-names></name><name><surname>Oluwasogo</surname><given-names>ES</given-names></name><name><surname>Ibhaze</surname><given-names>AE</given-names></name><name><surname>Imoize</surname><given-names>AL</given-names></name></person-group><article-title xml:lang="en">A comparative study of time series analysis for forecasting energy demand in Nigeria</article-title><source>Nigerian Journal of Technology</source><year>2019</year><volume>38</volume><issue>2</issue><fpage>465</fpage><lpage>469</lpage><pub-id pub-id-type="doi">10.4314/njt.v38i2.24</pub-id></mixed-citation></ref><ref id="CR114"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olatomiwa</surname><given-names>L</given-names></name><name><surname>Mekhilef</surname><given-names>S</given-names></name><name><surname>Ismail</surname><given-names>MS</given-names></name><name><surname>Moghavvemi</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Energy management strategies in hybrid renewable energy systems: A review</article-title><source>Renewable and Sustainable Energy Reviews</source><year>2016</year><volume>62</volume><fpage>821</fpage><lpage>835</lpage><pub-id pub-id-type="doi">10.1016/j.rser.2016.05.040</pub-id></mixed-citation></ref><ref id="CR115"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ozbayoglu</surname><given-names>AM</given-names></name><name><surname>Gudelek</surname><given-names>MU</given-names></name><name><surname>Sezer</surname><given-names>OB</given-names></name></person-group><article-title xml:lang="en">Deep learning for financial applications: A survey</article-title><source>Applied Soft Computing</source><year>2020</year><volume>93</volume><pub-id pub-id-type="doi">10.1016/j.asoc.2020.106384</pub-id></mixed-citation></ref><ref id="CR116"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ozturk</surname><given-names>I</given-names></name><name><surname>Aslan</surname><given-names>A</given-names></name><name><surname>Kalyoncu</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Energy consumption and economic growth relationship: Evidence from panel data for low and middle income countries</article-title><source>Energy Policy</source><year>2010</year><volume>38</volume><issue>8</issue><fpage>4422</fpage><lpage>4428</lpage><pub-id pub-id-type="doi">10.1016/j.enpol.2010.03.071</pub-id></mixed-citation></ref><ref id="CR117"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ozturk</surname><given-names>S</given-names></name><name><surname>Ozturk</surname><given-names>F</given-names></name></person-group><article-title xml:lang="en">Forecasting energy consumption of Turkey by Arima model</article-title><source>Journal of Asian Scientific Research</source><year>2018</year><volume>8</volume><issue>2</issue><fpage>52</fpage><pub-id pub-id-type="doi">10.18488/journal.2.2018.82.52.60</pub-id></mixed-citation></ref><ref id="CR118"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pacella</surname><given-names>M</given-names></name><name><surname>Papadia</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Evaluation of deep learning with long short-term memory networks for time series forecasting in supply chain management</article-title><source>Procedia CIRP</source><year>2021</year><volume>99</volume><fpage>604</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1016/j.procir.2021.03.081</pub-id></mixed-citation></ref><ref id="CR119"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>H</given-names></name><name><surname>Zhou</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Study on convolutional neural network and its application in data mining and sales forecasting for E-commerce</article-title><source>Electronic Commerce Research</source><year>2020</year><volume>20</volume><issue>2</issue><fpage>297</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1007/s10660-020-09409-0</pub-id></mixed-citation></ref><ref id="CR120"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parlos</surname><given-names>AG</given-names></name><name><surname>Chong</surname><given-names>KT</given-names></name><name><surname>Atiya</surname><given-names>AF</given-names></name></person-group><article-title xml:lang="en">Application of the recurrent multilayer perceptron in modeling complex process dynamics</article-title><source>IEEE Transactions on Neural Networks</source><year>1994</year><volume>5</volume><issue>2</issue><fpage>255</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1109/72.279189</pub-id></mixed-citation></ref><ref id="CR176"><mixed-citation publication-type="other">Paterakis, N. G., Mocanu, E., Gibescu, M., Stappers, B., &amp; van Alst, W. (2017). Deep learning versus traditional machine learning methods for aggregated energy demand prediction. In <italic>2017 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)</italic> (pp. 1–6). IEEE.</mixed-citation></ref><ref id="CR121"><mixed-citation publication-type="other">Pełka, P. (2021). Pattern-based forecasting of monthly electricity demand using support vector machine. <italic>In 2021 International joint conference on neural networks (IJCNN)</italic> (pp. 1–8). IEEE.</mixed-citation></ref><ref id="CR122"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pérez-Cruz</surname><given-names>F</given-names></name><name><surname>Afonso-Rodriguez</surname><given-names>JA</given-names></name><name><surname>Giner</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Estimating GARCH models using support vector machines</article-title><source>Quantitative Finance</source><year>2003</year><volume>3</volume><issue>3</issue><fpage>163</fpage><pub-id pub-id-type="doi">10.1088/1469-7688/3/3/302</pub-id></mixed-citation></ref><ref id="CR123"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Punia</surname><given-names>S</given-names></name><name><surname>Singh</surname><given-names>SP</given-names></name><name><surname>Madaan</surname><given-names>JK</given-names></name></person-group><article-title xml:lang="en">A cross-temporal hierarchical framework and deep learning for supply chain forecasting</article-title><source>Computers &amp; Industrial Engineering</source><year>2020</year><volume>149</volume><pub-id pub-id-type="doi">10.1016/j.cie.2020.106796</pub-id></mixed-citation></ref><ref id="CR124"><mixed-citation publication-type="other">Qi, Y., Li, C., Deng, H., Cai, M., Qi, Y., &amp; Deng, Y. (2019). A deep neural framework for sales forecasting in e-commerce. In <italic>Proceedings of the 28th ACM international conference on information and knowledge management</italic> (pp. 299–308).</mixed-citation></ref><ref id="CR125"><mixed-citation publication-type="other">Rajesh, R. (2020). Sustainability performance predictions in supply chains: Grey and rough set theoretical approaches. <italic>Annals of Operations Research</italic>, 1–30.</mixed-citation></ref><ref id="CR126"><mixed-citation publication-type="other">Ransbotham, S., Kiron, D., Gerbert, P., &amp; Reeves, M. (2017). Reshaping business with artificial intelligence: Closing the gap between ambition and action. <italic>MIT Sloan Management Review</italic>, <italic>59</italic>(1).</mixed-citation></ref><ref id="CR127"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranyard</surname><given-names>JC</given-names></name><name><surname>Fildes</surname><given-names>R</given-names></name><name><surname>Hu</surname><given-names>TI</given-names></name></person-group><article-title xml:lang="en">Reassessing the scope of OR practice: The influences of problem structuring methods and the analytics movement</article-title><source>European Journal of Operational Research</source><year>2015</year><volume>245</volume><issue>1</issue><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1016/j.ejor.2015.01.058</pub-id></mixed-citation></ref><ref id="CR128"><mixed-citation publication-type="other">Rao, T., &amp; Srivastava, S. (2012). Analyzing stock market movements using twitter sentiment analysis.</mixed-citation></ref><ref id="CR129"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name><name><surname>Williams</surname><given-names>RJ</given-names></name></person-group><article-title xml:lang="en">Learning representations by back-propagating errors</article-title><source>Cognitive Modeling</source><year>1988</year><volume>5</volume><issue>3</issue><fpage>1</fpage></mixed-citation></ref><ref id="CR130"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sarkodie</surname><given-names>SA</given-names></name></person-group><article-title xml:lang="en">Estimating Ghana’s electricity consumption by 2030: An ARIMA forecast</article-title><source>Energy Sources, Part B: Economics, Planning, and Policy</source><year>2017</year><volume>12</volume><issue>10</issue><fpage>936</fpage><lpage>944</lpage><pub-id pub-id-type="doi">10.1080/15567249.2017.1327993</pub-id></mixed-citation></ref><ref id="CR188"><mixed-citation publication-type="other">Savage, L. J. (1954). <italic>The Foundations of Statistics</italic>. New York: Wiley.</mixed-citation></ref><ref id="CR131"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuster</surname><given-names>M</given-names></name><name><surname>Paliwal</surname><given-names>KK</given-names></name></person-group><article-title xml:lang="en">Bidirectional recurrent neural networks</article-title><source>IEEE Transactions on Signal Processing</source><year>1997</year><volume>45</volume><issue>11</issue><fpage>2673</fpage><lpage>2681</lpage><pub-id pub-id-type="doi">10.1109/78.650093</pub-id></mixed-citation></ref><ref id="CR174"><mixed-citation publication-type="other">Sen, J., &amp; Mehtab, S. (2021). Accurate stock price forecasting using robust and optimized deep learning models. In  <italic>2021 International Conference on Intelligent Technologies (CONIT)</italic> (pp. 1–9). IEEE.</mixed-citation></ref><ref id="CR132"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sentürk</surname><given-names>C</given-names></name><name><surname>Sataf</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">The determination of panel causality analysis on the relationship between economic growth and primary energy resources consumption of Turkey and Central Asian Turkish Republics</article-title><source>Procedia-Social and Behavioral Sciences</source><year>2015</year><volume>195</volume><fpage>393</fpage><lpage>402</lpage><pub-id pub-id-type="doi">10.1016/j.sbspro.2015.06.342</pub-id></mixed-citation></ref><ref id="CR133"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sezer</surname><given-names>OB</given-names></name><name><surname>Gudelek</surname><given-names>MU</given-names></name><name><surname>Ozbayoglu</surname><given-names>AM</given-names></name></person-group><article-title xml:lang="en">Financial time series forecasting with deep learning: A systematic literature review: 2005–2019</article-title><source>Applied Soft Computing</source><year>2020</year><volume>90</volume><pub-id pub-id-type="doi">10.1016/j.asoc.2020.106181</pub-id></mixed-citation></ref><ref id="CR177"><mixed-citation publication-type="other">Shadish, W. R., Cook, T. D., &amp; Campbell, D. T. (2002). <italic>Experimental and quasi-experimental designs for generalized causal inference</italic>. Houghton, Mifflin and Company.</mixed-citation></ref><ref id="CR134"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shahi</surname><given-names>TB</given-names></name><name><surname>Shrestha</surname><given-names>A</given-names></name><name><surname>Neupane</surname><given-names>A</given-names></name><name><surname>Guo</surname><given-names>W</given-names></name></person-group><article-title xml:lang="en">Stock price forecasting with deep learning: A comparative study</article-title><source>Mathematics</source><year>2020</year><volume>8</volume><issue>9</issue><fpage>1441</fpage><pub-id pub-id-type="doi">10.3390/math8091441</pub-id></mixed-citation></ref><ref id="CR179"><mixed-citation publication-type="other">Shahid, F., Zameer, A., &amp; Muneeb, M. (2020). Predictions for COVID-19 with deep learning models of LSTM, GRU and Bi-LSTM.
<italic>Chaos, Solitons &amp; Fractals</italic>, <italic>140</italic>, 110212.</mixed-citation></ref><ref id="CR135"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>J</given-names></name><name><surname>Jiang</surname><given-names>C</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Qian</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">A microgrid energy management system with demand response for providing grid peak shaving</article-title><source>Electric Power Components and Systems</source><year>2016</year><volume>44</volume><issue>8</issue><fpage>843</fpage><lpage>852</lpage><pub-id pub-id-type="doi">10.1080/15325008.2016.1138344</pub-id></mixed-citation></ref><ref id="CR136"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shirzadi</surname><given-names>N</given-names></name><name><surname>Nizami</surname><given-names>A</given-names></name><name><surname>Khazen</surname><given-names>M</given-names></name><name><surname>Nik-Bakht</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Medium-term regional electricity load forecasting through machine learning and deep learning</article-title><source>Designs</source><year>2021</year><volume>5</volume><issue>2</issue><fpage>27</fpage><pub-id pub-id-type="doi">10.3390/designs5020027</pub-id></mixed-citation></ref><ref id="CR137"><mixed-citation publication-type="other">Shivaprasad, T. K., &amp; Shetty, J. (2017). Sentiment analysis of product reviews: a review. In <italic>2017 International conference on inventive communication and computational technologies (ICICCT)</italic> (pp. 298–301). IEEE.</mixed-citation></ref><ref id="CR184"><mixed-citation publication-type="other">Shrestha, A., Li, H., Le Kernec, J., &amp; Fioranelli, F. (2020). Continuous human activity classification from FMCW radar with Bi-LSTM networks. <italic>IEEE Sensors Journal</italic>, <italic>20</italic>(22), 13607–13619.</mixed-citation></ref><ref id="CR138"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sirignano</surname><given-names>J</given-names></name><name><surname>Cont</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Universal features of price formation in financial markets: Perspectives from deep learning</article-title><source>Quantitative Finance</source><year>2019</year><volume>19</volume><issue>9</issue><fpage>1449</fpage><lpage>1459</lpage><pub-id pub-id-type="doi">10.1080/14697688.2019.1622295</pub-id></mixed-citation></ref><ref id="CR192"><mixed-citation publication-type="other">Skyrms, B. (1982). Causal decision theory. <italic>The Journal of Philosophy</italic>, <italic>79</italic>(11), 695–711.</mixed-citation></ref><ref id="CR139"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Somu</surname><given-names>N</given-names></name><name><surname>MR</surname><given-names>GR</given-names></name><name><surname>Ramamritham</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">A deep learning framework for building energy consumption forecast</article-title><source>Renewable and Sustainable Energy Reviews.</source><year>2021</year><volume>137</volume><fpage>110591</fpage><pub-id pub-id-type="doi">10.1016/j.rser.2020.110591</pub-id></mixed-citation></ref><ref id="CR140"><mixed-citation publication-type="other">Sriram, L. M. K. (2020). <italic>Causality theory and advanced machine learning in power systems applications</italic> (Doctoral dissertation, The Florida State University).</mixed-citation></ref><ref id="CR141"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sriram</surname><given-names>LMK</given-names></name><name><surname>Gilanifar</surname><given-names>M</given-names></name><name><surname>Zhou</surname><given-names>Y</given-names></name><name><surname>Ozguven</surname><given-names>EE</given-names></name><name><surname>Arghandeh</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Causal Markov Elman network for load forecasting in multinetwork systems</article-title><source>IEEE Transactions on Industrial Electronics</source><year>2018</year><volume>66</volume><issue>2</issue><fpage>1434</fpage><lpage>1442</lpage><pub-id pub-id-type="doi">10.1109/TIE.2018.2851977</pub-id></mixed-citation></ref><ref id="CR142"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srivastava</surname><given-names>N</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name><name><surname>Krizhevsky</surname><given-names>A</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Salakhutdinov</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Dropout: A simple way to prevent neural networks from overfitting</article-title><source>The Journal of Machine Learning Research</source><year>2014</year><volume>15</volume><issue>1</issue><fpage>1929</fpage><lpage>1958</lpage></mixed-citation></ref><ref id="CR143"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Steyer</surname><given-names>R</given-names></name></person-group><source>Wahrscheinlichkeit und Regression</source><year>2013</year><publisher-name>Springer-Verlag</publisher-name></mixed-citation></ref><ref id="CR144"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steyer</surname><given-names>R</given-names></name><name><surname>Nachtigall</surname><given-names>C</given-names></name><name><surname>Wüthrich-Martone</surname><given-names>O</given-names></name><name><surname>Kraus</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Causal regression models III: Covariates, conditional, and unconditional average causal effects</article-title><source>Methods of Psychological Research Online</source><year>2002</year><volume>7</volume><issue>1</issue><fpage>41</fpage><lpage>68</lpage></mixed-citation></ref><ref id="CR145"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suganthi</surname><given-names>L</given-names></name><name><surname>Samuel</surname><given-names>AA</given-names></name></person-group><article-title xml:lang="en">Energy models for demand forecasting—A review</article-title><source>Renewable and Sustainable Energy Reviews</source><year>2012</year><volume>16</volume><issue>2</issue><fpage>1223</fpage><lpage>1240</lpage><pub-id pub-id-type="doi">10.1016/j.rser.2011.08.014</pub-id></mixed-citation></ref><ref id="CR146"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugihara</surname><given-names>G</given-names></name><name><surname>May</surname><given-names>R</given-names></name><name><surname>Ye</surname><given-names>H</given-names></name><name><surname>Hsieh</surname><given-names>CH</given-names></name><name><surname>Deyle</surname><given-names>E</given-names></name><name><surname>Fogarty</surname><given-names>M</given-names></name><name><surname>Munch</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Detecting causality in complex ecosystems</article-title><source>Science</source><year>2012</year><volume>338</volume><issue>6106</issue><fpage>496</fpage><lpage>500</lpage><pub-id pub-id-type="doi">10.1126/science.1227079</pub-id></mixed-citation></ref><ref id="CR178"><mixed-citation publication-type="other">Sun, Q., Jankovic, M. V., Bally, L., &amp; Mougiakakou, S. G. (2018). Predicting blood glucose with an lstm and bi-lstm based deep neural network. In <italic>2018 14th symposium on neural networks and applications (NEUREL)</italic> (pp. 1–5). IEEE.</mixed-citation></ref><ref id="CR147"><mixed-citation publication-type="other">Swathi, T., Kasiviswanath, N., &amp; Rao, A. A. (2022). An optimal deep learning-based lstm for stock price prediction using twitter sentiment analysis. <italic>Applied Intelligence</italic>, 1–14.</mixed-citation></ref><ref id="CR148"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>CF</given-names></name><name><surname>Chrsquo</surname><given-names>KS</given-names></name></person-group><article-title xml:lang="en">The Granger causality between health expenditure and income in Southeast Asia economies</article-title><source>African Journal of Business Management</source><year>2011</year><volume>5</volume><issue>16</issue><fpage>6814</fpage><lpage>6824</lpage></mixed-citation></ref><ref id="CR149"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tian</surname><given-names>C</given-names></name><name><surname>Huang</surname><given-names>G</given-names></name><name><surname>Piwowar</surname><given-names>JM</given-names></name><name><surname>Yeh</surname><given-names>SC</given-names></name><name><surname>Lu</surname><given-names>C</given-names></name><name><surname>Duan</surname><given-names>R</given-names></name><name><surname>Ren</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Stochastic RCM-driven cooling and heating energy demand analysis for residential building</article-title><source>Renewable and Sustainable Energy Reviews</source><year>2022</year><volume>153</volume><pub-id pub-id-type="doi">10.1016/j.rser.2021.111764</pub-id></mixed-citation></ref><ref id="CR150"><mixed-citation publication-type="other">Tsantekidis, A., Passalis, N., Tefas, A., Kanniainen, J., Gabbouj, M., &amp; Iosifidis, A. (2017). Using deep learning to detect price change indications in financial markets. In <italic>2017 25th European signal processing conference (EUSIPCO)</italic> (pp. 2511–2515). IEEE.</mixed-citation></ref><ref id="CR151"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tso</surname><given-names>GK</given-names></name><name><surname>Guan</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">A multilevel regression approach to understand effects of environment indicators and household features on residential energy consumption</article-title><source>Energy</source><year>2014</year><volume>66</volume><fpage>722</fpage><lpage>731</lpage><pub-id pub-id-type="doi">10.1016/j.energy.2014.01.056</pub-id></mixed-citation></ref><ref id="CR152"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valipour</surname><given-names>M</given-names></name><name><surname>Banihabib</surname><given-names>ME</given-names></name><name><surname>Behbahani</surname><given-names>SMR</given-names></name></person-group><article-title xml:lang="en">Comparison of the ARMA, ARIMA, and the autoregressive artificial neural network models in forecasting the monthly inflow of Dez dam reservoir</article-title><source>Journal of Hydrology</source><year>2013</year><volume>476</volume><fpage>433</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1016/j.jhydrol.2012.11.017</pub-id></mixed-citation></ref><ref id="CR153"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Steenbergen</surname><given-names>RM</given-names></name><name><surname>Mes</surname><given-names>MR</given-names></name></person-group><article-title xml:lang="en">Forecasting demand profiles of new products</article-title><source>Decision Support Systems</source><year>2020</year><volume>139</volume><pub-id pub-id-type="doi">10.1016/j.dss.2020.113401</pub-id></mixed-citation></ref><ref id="CR154"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vathsala</surname><given-names>MK</given-names></name><name><surname>Holi</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">RNN based machine translation and transliteration for Twitter data</article-title><source>International Journal of Speech Technology</source><year>2020</year><volume>23</volume><issue>3</issue><fpage>499</fpage><lpage>504</lpage><pub-id pub-id-type="doi">10.1007/s10772-020-09724-9</pub-id></mixed-citation></ref><ref id="CR155"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vidal</surname><given-names>A</given-names></name><name><surname>Kristjanpoller</surname><given-names>W</given-names></name></person-group><article-title xml:lang="en">Gold volatility prediction using a CNN-LSTM approach</article-title><source>Expert Systems with Applications</source><year>2020</year><volume>157</volume><pub-id pub-id-type="doi">10.1016/j.eswa.2020.113481</pub-id></mixed-citation></ref><ref id="CR156"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vo</surname><given-names>TT</given-names></name><name><surname>Le</surname><given-names>PH</given-names></name><name><surname>Nguyen</surname><given-names>NT</given-names></name><name><surname>Nguyen</surname><given-names>TL</given-names></name><name><surname>Do</surname><given-names>NH</given-names></name></person-group><article-title xml:lang="en">Demand forecasting and inventory prediction for apparel product using the ARIMA and fuzzy EPQ model</article-title><source>Journal of Engineering Science &amp; Technology Review.</source><year>2021</year><volume>14</volume><issue>2</issue><fpage>80</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.25103/jestr.142.11</pub-id></mixed-citation></ref><ref id="CR187"><mixed-citation publication-type="other">von Neumann, J., &amp; Oskar, M. (1944). Theoo: of Games and Economic Behavior. Princeton: Princeton University Press. Second edition, 1947; third edition, 1953. Section 3, chapter I, reprinted in Alfred N. Page. (1968). Utility Theoov A Book of Readings. New York: Wiley, pp. 215–233.</mixed-citation></ref><ref id="CR157"><mixed-citation publication-type="other">Wang, L., Zhan, L., &amp; Li, R. (2019). Prediction of the energy demand trend in middle Africa—a comparison of MGM, MECM, ARIMA and BP mod.</mixed-citation></ref><ref id="CR158"><mixed-citation publication-type="other">Wang, G., &amp; Fan, Y. (2021). Research on stock price forecasting model based on deep learning. In <italic>2021 4th international conference on information systems and computer aided education</italic> (pp. 2946–2948).</mixed-citation></ref><ref id="CR159"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Zeng</surname><given-names>R</given-names></name><name><surname>Srinivasan</surname><given-names>RS</given-names></name><name><surname>Ahrentzen</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Random Forest based hourly building energy prediction</article-title><source>Energy and Buildings</source><year>2018</year><volume>171</volume><fpage>11</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1016/j.enbuild.2018.04.008</pub-id></mixed-citation></ref><ref id="CR160"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wichmann</surname><given-names>P</given-names></name><name><surname>Brintrup</surname><given-names>A</given-names></name><name><surname>Baker</surname><given-names>S</given-names></name><name><surname>Woodall</surname><given-names>P</given-names></name><name><surname>McFarlane</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Extracting supply chain maps from news articles using deep neural networks</article-title><source>International Journal of Production Research</source><year>2020</year><volume>58</volume><issue>17</issue><fpage>5320</fpage><lpage>5336</lpage><pub-id pub-id-type="doi">10.1080/00207543.2020.1720925</pub-id></mixed-citation></ref><ref id="CR161"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>YH</given-names></name><name><surname>Shen</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Grey-related least squares support vector machine optimization model and its application in predicting natural gas consumption demand</article-title><source>Journal of Computational and Applied Mathematics</source><year>2018</year><volume>338</volume><fpage>212</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1016/j.cam.2018.01.033</pub-id></mixed-citation></ref><ref id="CR162"><mixed-citation publication-type="other">Xiong, R., Nichols, E. P., &amp; Shen, Y. (2015). Deep learning stock volatility with google domestic trends. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/1512.04916" ext-link-type="uri">arXiv:1512.04916</ext-link>.</mixed-citation></ref><ref id="CR163"><mixed-citation publication-type="other">Xu, R. Z., &amp; He, M. K. (2020). Application of deep learning neural network in online supply chain financial credit risk assessment. In <italic>2020 international conference on computer information and big data applications (CIBDA)</italic> (pp. 224–232). IEEE.</mixed-citation></ref><ref id="CR164"><mixed-citation publication-type="other">Yoon, J., &amp; van der Schaar, M. (2017). E-RNN: Entangled recurrent neural networks for causal prediction. In <italic>Proc. ICML workshop principled approaches deep learn.</italic> (pp. 1–5).</mixed-citation></ref><ref id="CR165"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yusof</surname><given-names>NN</given-names></name><name><surname>Mohamed</surname><given-names>A</given-names></name><name><surname>Abdul-Rahman</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">A review of contextual information for context-based approach in sentiment analysis</article-title><source>International Journal of Machine Learning and Computing</source><year>2018</year><volume>8</volume><issue>4</issue><fpage>399</fpage><lpage>403</lpage></mixed-citation></ref><ref id="CR166"><mixed-citation publication-type="other">Zhang, L., &amp; Xu, Y. A. O. (2015). An improved method of granger causality test and application on the stock market risk transmission<italic>. Economic Computation &amp; Economic Cybernetics Studies &amp; Research</italic>, 49(2).</mixed-citation></ref><ref id="CR167"><mixed-citation publication-type="other">Zhang, Q., Lu, H., Sak, H., Tripathi, A., McDermott, E., Koo, S., &amp; Kumar, S. (2020). Transformer transducer: A streamable speech recognition model with transformer encoders and rnn-t loss. In <italic>ICASSP 2020–2020 IEEE international conference on acoustics, speech and signal processing (ICASSP)</italic> (pp. 7829–7833). IEEE.</mixed-citation></ref><ref id="CR168"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>G</given-names></name><name><surname>Muskat</surname><given-names>B</given-names></name><name><surname>Law</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Tourism demand forecasting: A decomposed deep learning approach</article-title><source>Journal of Travel Research</source><year>2021</year><volume>60</volume><issue>5</issue><fpage>981</fpage><lpage>997</lpage><pub-id pub-id-type="doi">10.1177/0047287520919522</pub-id></mixed-citation></ref><ref id="CR169"><mixed-citation publication-type="other">Zhao, Y., &amp; Chen, Z. (2021). Forecasting stock price movement: New evidence from a novel hybrid deep learning model. <italic>Journal of Asian Business and Economic Studies</italic>.</mixed-citation></ref><ref id="CR170"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>M</given-names></name><name><surname>Marsh</surname><given-names>JK</given-names></name><name><surname>Nickerson</surname><given-names>JV</given-names></name><name><surname>Kleinberg</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">How causal information affects decisions</article-title><source>Cognitive Research: Principles and Implications</source><year>2020</year><volume>5</volume><issue>1</issue><fpage>1</fpage><lpage>24</lpage></mixed-citation></ref><ref id="CR171"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>B</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Chan</surname><given-names>KW</given-names></name><name><surname>Cao</surname><given-names>Y</given-names></name><name><surname>Kuang</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name></person-group><article-title xml:lang="en">Smart home energy management systems: Concept, configurations, and scheduling strategies</article-title><source>Renewable and Sustainable Energy Reviews</source><year>2016</year><volume>61</volume><fpage>30</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1016/j.rser.2016.03.047</pub-id></mixed-citation></ref><ref id="CR172"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname><given-names>C</given-names></name><name><surname>Feng</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Granger causality vs. dynamic Bayesian network inference: A comparative study</article-title><source>BMC Bioinformatics</source><year>2009</year><volume>10</volume><issue>1</issue><fpage>1</fpage><lpage>17</lpage></mixed-citation></ref></ref-list></ref-list><fn-group><fn id="Fn1"><label>1</label><p id="Par73"><ext-link xlink:href="https://www.kaggle.com/nicholasjhana/energy-consumption-generation-prices-and-weather" ext-link-type="uri">https://www.kaggle.com/nicholasjhana/energy-consumption-generation-prices-and-weather</ext-link>.</p></fn><fn id="Fn2"><label>2</label><p id="Par75"><ext-link xlink:href="https://data.mendeley.com/datasets/hzfwzzsk8f/4" ext-link-type="uri">https://data.mendeley.com/datasets/hzfwzzsk8f/4</ext-link>.</p></fn><fn id="Fn3"><label>3</label><p id="Par77"><ext-link xlink:href="https://zenodo.org/record/3445332#.Ybcj6n3MJ24" ext-link-type="uri">https://zenodo.org/record/3445332#.Ybcj6n3MJ24</ext-link>.</p></fn></fn-group><notes notes-type="Misc"><title>Publisher's Note</title><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Business and Management</facet-value><facet-value count="1">Combinatorics</facet-value><facet-value count="1">Operations Research/Decision Theory</facet-value><facet-value count="1">Theory of Computation</facet-value></facet><facet name="keyword"><facet-value count="1">Deep neural networks</facet-value><facet-value count="1">Energy consumption</facet-value><facet-value count="1">Forecasting</facet-value><facet-value count="1">Machine learning</facet-value></facet><facet name="pub"><facet-value count="1">Annals of Operations Research</facet-value></facet><facet name="year"><facet-value count="1">2022</facet-value></facet><facet name="country"><facet-value count="1">India</facet-value><facet-value count="1">Norway</facet-value><facet-value count="1">United Kingdom</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
