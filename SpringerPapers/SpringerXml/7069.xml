<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1007/s40725-019-00094-3</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="review-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">40725</journal-id><journal-title-group><journal-title>Current Forestry Reports</journal-title><abbrev-journal-title abbrev-type="publisher">Curr Forestry Rep</abbrev-journal-title></journal-title-group><issn pub-type="epub">2198-6436</issn><publisher><publisher-name>Springer International Publishing</publisher-name><publisher-loc>Cham</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s40725-019-00094-3</article-id><article-id pub-id-type="manuscript">94</article-id><article-id pub-id-type="doi">10.1007/s40725-019-00094-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Remote Sensing (J Suarez, Section Editor)</subject></subj-group><subj-group subj-group-type="article-collection" specific-use="Regular"><subject>Topical Collection on Remote Sensing</subject></subj-group></article-categories><title-group><article-title xml:lang="en">Structure from Motion Photogrammetry in Forestry: a Review</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="Au1"><name><surname>Iglhaut</surname><given-names>Jakob</given-names></name><address><email>j.iglhaut.919076@swansea.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="corresp" rid="IDs40725019000943_cor1">a</xref></contrib><contrib contrib-type="author" id="Au2"><name><surname>Cabo</surname><given-names>Carlos</given-names></name><address><email>carloscabo.uniovi@gmail.com</email></address><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au3"><name><surname>Puliti</surname><given-names>Stefano</given-names></name><address><email>stefano.puliti@nibio.no</email></address><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author" id="Au4"><name><surname>Piermattei</surname><given-names>Livia</given-names></name><address><email>livia.piermattei@geo.tuwien.ac.at</email></address><xref ref-type="aff" rid="Aff5">5</xref><xref ref-type="aff" rid="Aff6">6</xref></contrib><contrib contrib-type="author" id="Au5"><name><surname>O’Connor</surname><given-names>James</given-names></name><address><email>james.oconnor@kingston.ac.uk</email></address><xref ref-type="aff" rid="Aff7">7</xref></contrib><contrib contrib-type="author" id="Au6"><name><surname>Rosette</surname><given-names>Jacqueline</given-names></name><address><email>j.a.rosette@swansea.ac.uk</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0658 8800</institution-id><institution-id institution-id-type="GRID">grid.4827.9</institution-id><institution content-type="org-division">Department of Geography</institution><institution content-type="org-name">Swansea University</institution></institution-wrap><addr-line content-type="street">Singleton Park</addr-line><addr-line content-type="postcode">SA2 8PP</addr-line><addr-line content-type="city">Swansea</addr-line><country country="GB">UK</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution content-type="org-name">CETEMAS, Centro Tecnológico y Forestal de la Madera, Área de Desarrollo Forestal Sostenible</institution></institution-wrap><addr-line content-type="street">Pumarabule, Carbayín Bajo s/n 33936</addr-line><addr-line content-type="city">Siero</addr-line><country country="ES">Spain</country></aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2164 6351</institution-id><institution-id institution-id-type="GRID">grid.10863.3c</institution-id><institution content-type="org-division">Department of Mining Exploitation and Prospecting, Polytechnic School of Mieres</institution><institution content-type="org-name">University of Oviedo</institution></institution-wrap><addr-line content-type="street">Campus de Mieres, C/Gonzalo Gutiérrez Quirós s/n</addr-line><addr-line content-type="postcode">33600</addr-line><addr-line content-type="city">Mieres</addr-line><country country="ES">Spain</country></aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 4910 9859</institution-id><institution-id institution-id-type="GRID">grid.454322.6</institution-id><institution content-type="org-division">Department of National Forest Inventory, Division of Forestry and Forest Resources</institution><institution content-type="org-name">Norwegian Institute of Bioeconomy Research (NIBIO)</institution></institution-wrap><addr-line content-type="postbox">P.O. Box 115</addr-line><addr-line content-type="postcode">1431</addr-line><addr-line content-type="city">Ås</addr-line><country country="NO">Norway</country></aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2348 4034</institution-id><institution-id institution-id-type="GRID">grid.5329.d</institution-id><institution content-type="org-division">Department of Geodesy and Geoinformation</institution><institution content-type="org-name">TU Wien</institution></institution-wrap><addr-line content-type="street">Gußhausstraße 27-29/E120</addr-line><addr-line content-type="postcode">1040</addr-line><addr-line content-type="city">Vienna</addr-line><country country="AT">Austria</country></aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 1245 5350</institution-id><institution-id institution-id-type="GRID">grid.440923.8</institution-id><institution content-type="org-name">Physical Geography Catholic University of Eichstätt-Ingolstadt</institution></institution-wrap><addr-line content-type="street">Ostenstraße 26</addr-line><addr-line content-type="postcode">85072</addr-line><addr-line content-type="city">Eichstätt</addr-line><country country="DE">Germany</country></aff><aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 0536 3773</institution-id><institution-id institution-id-type="GRID">grid.15538.3a</institution-id><institution content-type="org-division">Department of Natural and Built Environment</institution><institution content-type="org-name">Kingston University</institution></institution-wrap><addr-line content-type="street">Penrhyn Road, Kingston upon Thames</addr-line><addr-line content-type="postcode">KT2 1EE</addr-line><addr-line content-type="city">Surrey</addr-line><country country="GB">UK</country></aff></contrib-group><author-notes><corresp id="IDs40725019000943_cor1"><label>a</label><email>j.iglhaut.919076@swansea.ac.uk</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>16</day><month>7</month><year>2019</year></pub-date><pub-date date-type="pub" publication-format="print"><day>15</day><month>9</month><year>2019</year></pub-date><volume>5</volume><issue seq="5">3</issue><fpage>155</fpage><lpage>168</lpage><history><date date-type="registration"><day>26</day><month>6</month><year>2019</year></date><date date-type="online"><day>16</day><month>7</month><year>2019</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2019</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><sec id="ASec1"><title>Purpose of Review</title><p id="Par1">The adoption of Structure from Motion photogrammetry (SfM) is transforming the acquisition of three-dimensional (3D) remote sensing (RS) data in forestry. SfM photogrammetry enables surveys with little cost and technical expertise. We present the theoretical principles and practical considerations of this technology and show opportunities that SfM photogrammetry offers for forest practitioners and researchers.</p></sec><sec id="ASec2"><title>Recent Findings</title><p id="Par2">Our examples of key research indicate the successful application of SfM photogrammetry in forestry, in an operational context and in research, delivering results that are comparable to LiDAR surveys. Reviewed studies have identified possibilities for the extraction of biophysical forest parameters from airborne and terrestrial SfM point clouds and derived 2D data in area-based approaches (ABA) and individual tree approaches. Additionally, increases in the spatial and spectral resolution of sensors available for SfM photogrammetry enable forest health assessment and monitoring. The presented research reveals that coherent 3D data and spectral information, as provided by the SfM workflow, promote opportunities to derive both structural and physiological attributes at the individual tree crown (ITC) as well as stand levels.</p></sec><sec id="ASec3"><title>Summary</title><p id="Par3">We highlight the potential of using unmanned aerial vehicles (UAVs) and consumer-grade cameras for terrestrial SfM-based surveys in forestry. Offering several spatial products from a single sensor, the SfM workflow enables foresters to collect their own fit-for-purpose RS data. With the broad availability of non-expert SfM software, we provide important practical considerations for the collection of quality input image data to enable successful photogrammetric surveys.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>SfM</kwd><kwd>Point cloud</kwd><kwd>UAV</kwd><kwd>Close-range photogrammetry (CRP)</kwd><kwd>Forest inventory</kwd><kwd>Forest health</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution>Swansea University</institution></institution-wrap></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Springer</meta-value></custom-meta><custom-meta><meta-name>volume-issue-count</meta-name><meta-value>4</meta-value></custom-meta><custom-meta><meta-name>issue-article-count</meta-name><meta-value>6</meta-value></custom-meta><custom-meta><meta-name>issue-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-holder</meta-name><meta-value>Springer Nature Switzerland AG</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-year</meta-name><meta-value>2019</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>No</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2019</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>6</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>26</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>volume-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>ArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>Unnumbered</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>false</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/40725_2019_Article_94.pdf</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>issue-online-date-year</meta-name><meta-value>2019</meta-value></custom-meta><custom-meta><meta-name>issue-online-date-month</meta-name><meta-value>8</meta-value></custom-meta><custom-meta><meta-name>issue-online-date-day</meta-name><meta-value>23</meta-value></custom-meta><custom-meta><meta-name>issue-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>ReviewPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Environment</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Sustainable Development</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Environmental Management</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Nature Conservation</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Forestry</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Forestry Management</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Ecology</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Earth and Environmental Science</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta><notes notes-type="Misc"><p>This article is part of the Topical Collection on <italic>Remote Sensing</italic></p></notes></front><body><sec id="Sec1"><title>Introduction</title><p id="Par4">The use of remotely sensed (RS) data in forestry is motivated by efforts to increase cost efficiency, precision and timeliness of forest information [<xref ref-type="bibr" rid="CR1">1</xref>]. Differently, to traditional field-based sampling, the availability of full-coverage RS data enables the production of maps of key forestry variables, which are useful for forest management purposes. First examples of aerial imagery usage for forestry purposes date back to the beginning of the 1920s [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>]. Over the past century, there has been tremendous growth in the number of RS data sources available for the assessment and monitoring of forests. Three-dimensional (3D) RS data, which can describe tree or canopy height, have shown great potential for forest inventory [<xref ref-type="bibr" rid="CR4">4</xref>]. In the past 20 years, the use of airborne laser scanning (ALS) has been widely used for forest inventory purposes and has become the standard data source for operational forest inventories in many countries around the world [<xref ref-type="bibr" rid="CR5">5</xref>–<xref ref-type="bibr" rid="CR7">7</xref>]. Nevertheless, the acquisition of ALS data requires a degree of planning and investment, making these data sources cost-effective only on a relatively large scale [<xref ref-type="bibr" rid="CR8">8</xref>]. Up to the beginning of 2010, there were no cost-effective means of acquiring high-resolution 3D RS data for smaller areas, such as single forest properties or forest stands. Furthermore, in those cases, where ALS-based forest management is implemented, surveys are carried out infrequently, e.g. at intervals of 10–20 years [<xref ref-type="bibr" rid="CR5">5</xref>]. Hence, for some forest stands, the information may be too unreliable for decision-making. Timeliness is a key requirement to enable the adoption of precision forestry practices. This is especially true when the forest structure is changing rapidly, as is the case in fast-growing regeneration forests, or when growth is hindered by biotic or abiotic disturbances.</p><p id="Par5">Photogrammetric approaches to obtain 3D information on forest structure have become popular, offering substantial cost savings in the case of aerial photogrammetry compared with ALS [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>]. Photogrammetry is limited to the reconstruction of surfaces visible in the image data, providing ground information only where large vegetation gaps exist. However, photogrammetric data can be combined with pre-existing ground data, derived from light detection and ranging data (LiDAR) for example. This data synergy has been thoroughly discussed by Goodbody et al. [<xref ref-type="bibr" rid="CR11">11</xref>], indicating the potential for cost-efficient forest inventory updates. Similarly, Kangas et al. [<xref ref-type="bibr" rid="CR6">6</xref>] suggest an equal value of photogrammetric and ALS data in forest management planning, given that a ALS ground information is available from previous campaigns. Additional to the proven complementary use of LiDAR and photogrammetric data [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR12">12</xref>], recent attempts at deriving inventory relevant forest metrics from photogrammetric data alone show potential for aerial [<xref ref-type="bibr" rid="CR13">13</xref>•, <xref ref-type="bibr" rid="CR14">14</xref>] and terrestrial [<xref ref-type="bibr" rid="CR15">15</xref>•, <xref ref-type="bibr" rid="CR16">16</xref>] acquisitions. Further standalone use of photogrammetry was shown for forest health monitoring [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR18">18</xref>•, <xref ref-type="bibr" rid="CR19">19</xref>] species classification [<xref ref-type="bibr" rid="CR20">20</xref>] and biodiversity assessments [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>].</p><p id="Par6">In the last decade, a photogrammetric approach offering flexible and cost-effective acquisition of combined 3D and spectral RS data has found wide application and acceptance in physical geography [<xref ref-type="bibr" rid="CR23">23</xref>]: Structure from Motion (SfM), paired with multi-view stereo (MVS) algorithms (SfM-MVS, commonly abbreviated to just SfM). SfM is based on computer vision and facilitates the photogrammetric reconstruction from images alone. Contrary to traditional stereophotogrammetry, 3D information can be computed from overlapping images, without the need for prerequisite information on camera location and orientation, camera calibration and/or surveyed reference points in the scene. This allows the use of inexpensive imaging platforms, both for aerial or terrestrial applications.</p><p id="Par7">SfM photogrammetry has been comprehensively reviewed in the geosciences [<xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR25">25</xref>, <xref ref-type="bibr" rid="CR26">26</xref>••], where it has been gaining prominence for topographical surveys. We complement these findings with a summary of SfM photogrammetry use specific to forestry. We present an overview of the theoretical principles of a SfM-MVS workflow and its applications in forestry by reviewing a representative sample of key research in this field. Challenges and technical considerations are discussed, concluding with opportunities and practical implications for operational use of SfM by forest practitioners.</p><sec id="Sec2"><title>Structure from Motion: Theoretical Principles</title><p id="Par8">Traditional stereophotogrammetry methods are based on an analogy of the binocular human vision. Depth can be perceived from two points whose relative position is known. However, depth, volumes or 3D features can also be perceived from a single observing point if either the observer or the object is moving [<xref ref-type="bibr" rid="CR27">27</xref>, <xref ref-type="bibr" rid="CR28">28</xref>]. SfM is a photogrammetric technique that is based on both these principles: (i) the binocular vision and (ii) the changing vision of an object that is moving or observed from a moving point [<xref ref-type="bibr" rid="CR29">29</xref>]. SfM is used for estimating 3D models from sequences of overlapping 2D images. It gained popularity in recent years due to its ability to deal with sets of unordered and heterogeneous images without prior knowledge of the camera parameters [<xref ref-type="bibr" rid="CR30">30</xref>]. SfM differs from traditional photogrammetry mainly in three aspects: (i) features can be automatically identified and matched in images at differing scales, viewing angles and orientations, which is of particular benefit when small unstable platforms are considered; (ii) the equations used in the algorithm can be solved without information of camera positions or ground control points, although both can be added and used and (iii) camera calibration can be automatically solved or refined during the process. SfM can thus automatically deliver photogrammetric models without requiring rigorous homogeneity in overlapping images, camera poses and calibrations [<xref ref-type="bibr" rid="CR31">31</xref>–<xref ref-type="bibr" rid="CR33">33</xref>].</p><p id="Par9">‘SfM’ photogrammetry is commonly used to define the entire reconstruction workflow, from image set to dense point cloud; however, strictly speaking, SfM only refers to a specific step in the workflow that provides camera parameters and a sparse point cloud (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Although some studies use the sparse point cloud as a final product [<xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR34">34</xref>], in most cases, dense image matching algorithms, such as MVS, are used in a subsequent step to densify the point cloud. The whole process can thus be referred to as SfM-MVS. Figure <xref rid="Fig1" ref-type="fig">1</xref> contains a schematic workflow of the whole SfM-MVS process, and Fig. <xref rid="Fig2" ref-type="fig">2</xref> shows a graphic diagram of the main three steps.<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><p>Schematic workflow of the SfM-MVS process resulting in a dense point cloud from image sets. The point cloud is georeferenced by providing positional information for images and/or ground control points</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40725_2019_94_Fig1_HTML.png" id="MO1"/></fig><fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><p>The three key stages in a SfM-MVS workflow illustrated on two hypothetical images of a Canary Island pine forest: (1) keypoint identification and matching (e.g. SIFT), (2) SfM with camera parameters and a sparse point cloud as output and (3) the densified point cloud following MVS</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40725_2019_94_Fig2_HTML.png" id="MO2"/></fig></p><p id="Par10">The SfM-MVS process starts with the automatic extraction of keypoints (i.e. points or sets of pixels with distinctive contrast or texture) in the images. The keypoints are identified in all images and then tied (matched) across images where they appear. The scale-invariant feature transform (SIFT [<xref ref-type="bibr" rid="CR35">35</xref>]) and its variations are the most common algorithms for keypoint identification and matching in SfM [<xref ref-type="bibr" rid="CR26">26</xref>••]. SIFT produces numerical descriptors for each point in each image. These descriptors are invariant to scale and orientation, thus suitable for identifying points or objects in pictures taken from different perspectives and under different conditions. Then, coherence of keypoint matches is checked using a coarse reconstruction of the geometry of the images and the relative position of the keypoints on them (Figs. <xref rid="Fig1" ref-type="fig">1</xref> and <xref rid="Fig2" ref-type="fig">2</xref>).</p><p id="Par11">Given a sufficient number of images and keypoint matches, SfM performs bundle adjustments to simultaneously compute camera poses and parameters, and a sparse 3D point cloud of the scene (consisting of the position of keypoints matched in different images). The bundle adjustment is solved using (i) initialization values obtained from sequences of randomly selected matched keypoints and, complementarily, parameters from the cameras and poses and (ii) a non-linear refinement [<xref ref-type="bibr" rid="CR36">36</xref>]. Then, the outputs of SfM are scaled and georeferenced based on ground control points (GCPs) and/or data from navigation devices from the camera or its platform (Figs. <xref rid="Fig1" ref-type="fig">1</xref> and <xref rid="Fig2" ref-type="fig">2</xref>).</p><p id="Par12">The camera poses and parameters obtained from SfM are then applied to generate a densified point cloud using MVS algorithms. Prior to the MVS densification, and for computational efficiency or even viability, images are clustered based on their location [<xref ref-type="bibr" rid="CR37">37</xref>]. In this way, the dense point cloud of each cluster (i.e. group of images) is computed separately (Figs. <xref rid="Fig1" ref-type="fig">1</xref> and <xref rid="Fig2" ref-type="fig">2</xref>).</p><p id="Par13">A dense point cloud, with colour/spectral information derived from the input images, represents the primary output of the SfM-MVS workflow. Subsequent processing steps (for aerial surveys) typically involve the derivation of a digital surface model (DSM) and an orthomosaic. A canopy height model (CHM) can be attained by height normalization (i.e. conversion from height above sea level to height above ground) with a pre-existing digital terrain model (DTM). When SfM-derived surface data are height normalized in such a way, this offers the calculation of forest metrics like those commonly derived from ALS (e.g. height, timber volume, biomass). Additionally, image metrics like radiance/reflectance values and texture may be extracted [<xref ref-type="bibr" rid="CR13">13</xref>•, <xref ref-type="bibr" rid="CR18">18</xref>•, <xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>]. Finally, rasterization can offer opportunities to explore the sensed information in more depth when statistics are calculated for every cell (e.g. height percentiles, surface roughness, spectral indices) [<xref ref-type="bibr" rid="CR40">40</xref>–<xref ref-type="bibr" rid="CR42">42</xref>].</p></sec><sec id="Sec3"><title>SfM Photogrammetry in Practice</title><p id="Par14">With photogrammetry being a passive technique, results are highly influenced by the input image data. SfM photogrammetry, employing an automated process to identify and match features by computer vision, is fundamentally dependent on image quality. Sensors, settings and acquisition designs should be considered with great care.</p><p id="Par15">In every circumstance, the camera settings need to be considered to ensure optimal image data is acquired given a set of constraints, namely (i) those from the environment (lighting conditions), (ii) the platform (UAV, pole, tripod or handheld) and (iii) the camera and lens combination (the exposure triangle, focal length, sensor size). Acquiring high-quality image data has been discussed in O’Connor et al. [<xref ref-type="bibr" rid="CR43">43</xref>••] and Mosbrucker et al. [<xref ref-type="bibr" rid="CR44">44</xref>], with key rules-of-thumb including keeping the motion of the camera to a minimum, and increasing ISO (i.e. the sensors sensitivity) to account for potential underexposure (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). RAW image data is better to capture as it retains the raw pixel values acquired by the camera prior to quantization and compression [<xref ref-type="bibr" rid="CR45">45</xref>].<fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><p>Image quality issues illustrated by simulated degradations on UAV image: <bold>a</bold> adds motion blur, which has negative impacts on the quality of photogrammetric reproduction (Sieberth et al., 2014); <bold>b</bold> adds JPEG compression, which smoothes subtle contrast changes across an image; <bold>c</bold> adds noise, which can rapidly degrade image quality at high-ISO values; <bold>d</bold> adds overexposure, where the image sensor was exposed for too long a time and <bold>e</bold> underexposure, where the image sensor was exposed for too little time</p></caption><graphic specific-use="web" mime-subtype="JPEG" xlink:href="MediaObjects/40725_2019_94_Fig3_HTML.jpg" id="MO3"/></fig></p><p id="Par16">Image network geometry has an impact on the quality of reproduction, and for every survey, a ‘convergent’ imaging geometry should be sought that where the principal axis (perpendicular to the image sensor) of the images used converge so that systematic error is minimized [<xref ref-type="bibr" rid="CR46">46</xref>, <xref ref-type="bibr" rid="CR47">47</xref>]. In UAV imaging, James and Robson [<xref ref-type="bibr" rid="CR46">46</xref>] suggest surveying with gently banked turns when using fixed wing UAVs, in order to achieve this. With rotary UAVs, a similar result can be achieved by angling the camera on the gimbal on which it is mounted. For terrestrial imaging, a convergence of images on AOIs is advised, as presented in Mosbrucker et al. [<xref ref-type="bibr" rid="CR44">44</xref>].</p><p id="Par17">Within image acquisition and SfM photogrammetric workflows, users have many parameters which they can vary depending on the equipment and software used. For some, users can have near full control (e.g. the ‘exposure triangle’; ISO, shutter speed and aperture), though there are several which will only be estimated prior to performing a survey (such as the exact camera positions images will be acquired from). Other influential factors, which cannot be manipulated (e.g. light conditions), will have to be carefully considered when planning a SfM-based survey. The success of reconstruction is ultimately dependent on factors that can be broken down into five categories, as presented in Table <xref rid="Tab1" ref-type="table">1</xref>. The accuracy of the position and scale of a survey is then determined by the referencing approach (e.g. GCPs, direct georeferencing, manual scaling).<table-wrap id="Tab1"><label>Table 1</label><caption xml:lang="en"><p>Overview of variables influencing the results of a SfM survey</p></caption><table frame="hsides" rules="groups"><thead><tr><th><p>Domain</p></th><th><p>Variable</p></th><th><p>Recommendation</p></th></tr></thead><tbody><tr><td rowspan="4"><p>Scene</p></td><td><p>Texture</p></td><td><p>High surface contrast to allow for feature-point detection</p></td></tr><tr><td><p>Pattern repetition</p></td><td><p>Increase overlap and increase accuracy of geotags</p></td></tr><tr><td><p>Moving features</p></td><td><p>Avoid!</p></td></tr><tr><td><p>Occlusions</p></td><td><p>Increase overlap and viewing angles</p></td></tr><tr><td rowspan="3"><p>Lighting conditions</p></td><td><p>Sun angle</p></td><td><p>High! Solar noon is ideal</p></td></tr><tr><td><p>Weather</p></td><td><p>Overcast provides even lighting (ambient occlusion) for structural (RGB) surveys.</p><p>For spectral surveys little atmospheric influence may be required, clear skies.</p></td></tr><tr><td><p>Changing illumination</p></td><td><p>Avoid!</p></td></tr><tr><td rowspan="6"><p>Camera parameters</p></td><td><p>Focal length</p></td><td><p>Wide but not too wide to minimize distortions. 28–35 mm is a good basis (James et al. 2012)</p></td></tr><tr><td><p>Exposure ∆</p></td><td><p>Well exposed</p></td></tr><tr><td><p>- Aperture</p></td><td><p>Small for max DOF*, f/8 an advisable default</p></td></tr><tr><td><p>- Shutter speed</p></td><td><p>High for reduced motion blur*, ground speed (m/s) * exposure time (s) = blurred pixel</p></td></tr><tr><td><p>- ISO</p></td><td><p>Length</p><p>Low for min noise*, auto-ISO an advisable default</p><p>*Ideal scenario, but will always be a compromise between these three parameters</p></td></tr><tr><td><p>Pixel pitch</p></td><td><p>As high as is practical. Physical pixel size positively influences dynamic range and sensitivity</p></td></tr><tr><td rowspan="3"><p>Survey characteristics</p></td><td><p>Overlap</p></td><td><p>High (&gt; 80% forward and lateral) as rule of thumb for forests to increase redundancy and matchability in scenes with high pattern repetition, moving features and/or occlusions. As a rule of thumb, a UAV-SfM data acquisition should be planned so that each point will be visible at least in 4–5 images.</p></td></tr><tr><td><p>View angles</p></td><td><p>Convergent for reduction of systematic errors (RGB)</p><p>Parallel (Nadir) for spectral sensing (reflectance)</p></td></tr><tr><td><p>Survey range</p></td><td><p>With increasing distance to the object/scene (decreasing GSD) survey precision degrades. Increased GSD requires higher overlap.</p></td></tr><tr><td rowspan="4"><p>Processing parameters</p></td><td><p>SfM—matching</p><p>- Image scale</p></td><td><p>If matching is not successful at full image scale ½ or ¼ may promote matchability</p></td></tr><tr><td><p>- Keypoints</p></td><td><p>The number may be reduced for large datasets to reduce processing time</p></td></tr><tr><td><p>MVS—densification</p></td><td><p>Densification may not always be required at full image scale/maximum point cloud density</p></td></tr><tr><td><p>Secondary products</p></td><td><p>Multitude of algorithms for meshing, gridding etc. (results will depend on specific method)</p></td></tr></tbody></table></table-wrap></p><p id="Par18">To apply SfM photogrammetry in forestry, important aspects to a successful survey are as follows: (i) the scene is covered with overlapping images from multiple locations and angles (high overlap to increase redundancy and multiple viewing angles of the same object to reduce occlusions and systematic errors), (ii) any feature to be reconstructed should be visible in at least three images (five or six images for dense vegetation) and the angular divergence between neighbouring images between should not exceed 10–20°, (iii) the scene is sufficiently illuminated (constant lighting is preferable, e.g. overcast or cloud-free conditions) and (iv) object of interest is fixed (preferably no movement from branches in wind).</p></sec><sec id="Sec4"><title>The Current Status of SfM in Forestry</title><p id="Par19">With the ability to produce highly detailed 3D information from a set of images alone, SfM photogrammetry lays a powerful tool into the hands of anyone looking to collect their own fit-for-purpose RS data. Owing particularly to the potential of using off-the-shelf cameras and the availability of affordable user-friendly software, the application of SfM photogrammetry in physical geography has increased rapidly [<xref ref-type="bibr" rid="CR26">26</xref>••, <xref ref-type="bibr" rid="CR48">48</xref>]. With SfM photogrammetry being scale independent, images may be acquired from a multitude of platforms ranging from ground-based, handheld or pole-mounted options, to unmanned aerial vehicles (UAVs) and manned aircraft. UAVs have enabled geospatial data to be acquired in new ways. Flexibly deployed at scales from several hectares to square kilometres [<xref ref-type="bibr" rid="CR49">49</xref>], they allow forest practitioners to collect their own aerial information. In fact, there is an increasing interest in UAV forest surveys that can arguably be attributed to SfM-based photogrammetric processing [<xref ref-type="bibr" rid="CR26">26</xref>••].</p><p id="Par20">The rapid adoption of SfM photogrammetry is indicated by a growing number of scientific publications in forestry that utilize this photogrammetric technique. We conducted a search for peer-reviewed studies indexed by the Web of Knowledge database using the keywords ‘Structure from Motion’, ‘UAV’ and ‘Forestry’ (and their most common variations). The search results were manually filtered to retain only forestry-related studies applying a SfM-based workflow. We further categorized results into research on aerial and terrestrial inventory, forest health and proof-of-concept studies. These results are presented in Table <xref rid="Tab2" ref-type="table">2</xref> and reveal a steady rise of publications on forest remote sensing with SfM photogrammetry.<table-wrap id="Tab2"><label>Table 2</label><caption xml:lang="en"><p>Number of publications on SfM photogrammetry for forest/tree remote sensing per year with manually assigned sub-categories</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th><p>2010</p></th><th><p>2013</p></th><th><p>2014</p></th><th><p>2015</p></th><th><p>2016</p></th><th><p>2017</p></th><th><p>2018</p></th><th><p>02/2019</p></th></tr></thead><tbody><tr><td><p>SfM in forestry</p></td><td><p>1</p></td><td><p>3</p></td><td><p>3</p></td><td><p>11</p></td><td><p>18</p></td><td><p>31</p></td><td><p>66</p></td><td><p>4</p></td></tr><tr><td><p>- Airborne inventory</p></td><td><p>0</p></td><td><p>1</p></td><td><p>2</p></td><td><p>4</p></td><td><p>7</p></td><td><p>22</p></td><td><p>24</p></td><td><p>1</p></td></tr><tr><td><p>- Terrestrial inventory</p></td><td><p>0</p></td><td><p>0</p></td><td><p>0</p></td><td><p>1</p></td><td><p>4</p></td><td><p>2</p></td><td><p>10</p></td><td><p>0</p></td></tr><tr><td><p>- Forest health</p></td><td><p>0</p></td><td><p>0</p></td><td><p>0</p></td><td><p>2</p></td><td><p>4</p></td><td><p>1</p></td><td><p>7</p></td><td><p>1</p></td></tr><tr><td><p>- Proof-of-concept</p></td><td><p>1</p></td><td><p>2</p></td><td><p>1</p></td><td><p>4</p></td><td><p>3</p></td><td><p>6</p></td><td><p>15</p></td><td><p>2</p></td></tr></tbody></table><table-wrap-foot><p>Results presented are based on a manually filtered search in the scientific publications database Web of Knowledge using the search terms: TS = (‘Structure from Motion’ OR ‘Structure-from-Motion’ OR ‘SfM’ OR ‘sfm’ OR ‘structure from motion’ OR ‘structure-from-motion’ OR photogrammetry OR UAS OR SfM OR UAV OR RPAS OR drone OR CRP OR ‘unmanned aerial’ OR ‘Unmanned Aerial’) AND TS = (forest OR forestry OR tree). The date of this search was 21 February 2019</p></table-wrap-foot></table-wrap></p><p id="Par21">SfM photogrammetry applications aimed at forest inventory are currently the most studied (Table <xref rid="Tab2" ref-type="table">2</xref>). Here, a distinction between aerial and terrestrial approaches can be made. An aerial approach typically utilizes a canopy surface model derived from SfM and/or associated spectral properties to estimate inventory relevant parameters [<xref ref-type="bibr" rid="CR11">11</xref>]. Terrestrial acquisitions, also termed close-range photogrammetry (CRP), focus on the reconstruction of stems within sample plots or the reconstruction of individual trees [<xref ref-type="bibr" rid="CR15">15</xref>•].</p><p id="Par22">A further field of research is the assessment and monitoring of forest health condition. For SfM-based mapping of the canopy, hereby an aerial acquisition of image data, most commonly by UAV, with multispectral sensors prevails. Studies dealing with forest health often make use of the 3D information and derived 2D spectral products that SfM photogrammetry delivers [<xref ref-type="bibr" rid="CR18">18</xref>•, <xref ref-type="bibr" rid="CR50">50</xref>]. The following sections describe the research on SfM-based forest inventory and health assessments to date in more detail.</p></sec><sec id="Sec5"><title>Inventory</title><p id="Par23">Forest inventory holds a central role in all of the forest research. Sustainable management of forests relies on knowledge of their structure, distribution and dynamics over time [<xref ref-type="bibr" rid="CR51">51</xref>]. The collection of field data for inventory purposes is labour intensive, time-consuming and expensive, and cannot be applied to large areas, consequently drastically limiting the number of field inventories that can be afforded [<xref ref-type="bibr" rid="CR52">52</xref>, <xref ref-type="bibr" rid="CR53">53</xref>]. Efforts to improve on the efficiency of inventory practices therefore drive research in this field [<xref ref-type="bibr" rid="CR53">53</xref>]. Amongst RS technologies, SfM photogrammetry offers a low-cost and flexible approach to collect information on forest structure, thus naturally there has been an increase in interest to use such data for forest inventory.</p><p id="Par24">Within the context of forest inventory, the main use of SfM photogrammetry has been its application on UAV image data to produce wall-to-wall auxiliary information in a similar fashion to ALS data. As such, UAV-SfM data has been shown to be suitable for the estimation of inventory relevant biophysical parameters such as height, density and biomass [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR34">34</xref>, <xref ref-type="bibr" rid="CR54">54</xref>–<xref ref-type="bibr" rid="CR56">56</xref>]. Even though SfM has mostly been applied to aerial image data, in recent years, there has been an increasing effort in developing terrestrial SfM applications to replace or augment field data collections. The focus of studies incorporating CRP lies on estimating diameter at breast height (DBH), tree position and stem curves. The following sub-sections elaborate further on the developments up to today regarding aerial and terrestrial SfM and highlight some of the key work on using these photogrammetric data for inventory purposes.</p><sec id="Sec6"><title>Aerial Inventory</title><p id="Par25">The use of SfM techniques applied to aerial image data for forest inventory was pioneered by Dandois and Ellis in 2010 [<xref ref-type="bibr" rid="CR54">54</xref>]. These authors were the first to use a series of unordered but overlapping images acquired using a consumer-grade camera mounted on a kite to produce a dense 3D point cloud representing the forest canopy. A first attempt to model forest biophysical properties using UAV-SfM data was done by Dandois and Ellis in 2013 [<xref ref-type="bibr" rid="CR34">34</xref>] and Lisein et al. in 2013 [<xref ref-type="bibr" rid="CR55">55</xref>]. Both studies found that even though the results were not consistent in all the studied areas, there was a correlation between UAV-SfM data and variables such as dominant height (<italic>R</italic><sup>2</sup> = 0.07–0.91) or aboveground biomass (<italic>R</italic><sup>2</sup> = 0.27–0.73). A more comprehensive evaluation of the possibilities to use UAV-SfM for forest inventories came with the studies by Puliti et al. in 2015 [<xref ref-type="bibr" rid="CR12">12</xref>] and Tuominen et al. in 2015 [<xref ref-type="bibr" rid="CR56">56</xref>] who extended their evaluation to the range of biophysical variables commonly used in forest management. Their results in terms of RMSE% for dominant height (3.5%), Lorey’s height (13.3%–14.4%), stem density (38.6%), basal area (15.4–23.9%) and timber volume (14.9–26.1%) were found to be similar to errors associated with ALS-based forest inventories. While these two studies set an important benchmark, they were both conducted in even-aged managed boreal forests and thus provided limited information on how UAV-SfM may perform in different forest types and forest developmental stages.</p><p id="Par26">Since the early days of UAV-SfM, the rapid growth in computing capabilities, availability of UAVs and SfM software triggered increased interest in the scientific community (see Table <xref rid="Tab1" ref-type="table">1</xref>). This led to a widespread evaluation of UAV-SfM technology over a variety of forest types and forest developmental stages. UAV-SfM data has been consistently proven to be useful for forest inventories in a large variety of forest types, including temperate European beech forests in Italy [<xref ref-type="bibr" rid="CR13">13</xref>•], mangrove forests in Malaysia [<xref ref-type="bibr" rid="CR57">57</xref>], tropical forests in Guyana [<xref ref-type="bibr" rid="CR58">58</xref>], mixed conifer-broadleaved forest in Japan [<xref ref-type="bibr" rid="CR59">59</xref>], sparse sub-alpine coniferous forests in China [<xref ref-type="bibr" rid="CR60">60</xref>], tropical woodlands in Malawi [<xref ref-type="bibr" rid="CR41">41</xref>] and various plantations around the globe [<xref ref-type="bibr" rid="CR61">61</xref>–<xref ref-type="bibr" rid="CR63">63</xref>]. From these studies, a conclusion can be drawn that the accuracy of UAV-SfM models is consistent across many different forest types and on a similar scale to ALS models. All of the aforementioned studies dealt with mature to nearly mature forest, while there has been little effort dedicated to estimating biophysical variables for forests under regeneration [<xref ref-type="bibr" rid="CR64">64</xref>, <xref ref-type="bibr" rid="CR65">65</xref>, <xref ref-type="bibr" rid="CR66">66</xref>•]. Nevertheless, the use of UAV-SfM data for regeneration forests may outperform alternative data sources such as field assessments or the use of ALS data in terms of costs and accuracy. Goodbody et al. [<xref ref-type="bibr" rid="CR64">64</xref>] demonstrated the possibility to discriminate coniferous and deciduous species (overall accuracy of 86–95%). Puliti et al. [<xref ref-type="bibr" rid="CR66">66</xref>•] showed that UAV-SfM data could be used to accurately model stem density and height (RMSE% = 21.8% and 23.6%). Such results represent a substantial increase in accuracy over ALS forest inventories and field assessment. Furthermore, their study reported that data acquired using UAV-SfM techniques halved the amount of time required for traditional field surveys that are commonly performed in regeneration stands. Thus, the use of UAV-SfM for regeneration forest may be particularly interesting since it allows a simultaneous increase in the precision of the inventory while reducing its costs.</p><p id="Par27">Different methodological approaches have been applied to UAV-SfM data, similarly to ALS data. The methods can be categorized into area-based approaches (ABA) [<xref ref-type="bibr" rid="CR67">67</xref>] and individual tree crown (ITC) approaches [<xref ref-type="bibr" rid="CR68">68</xref>, <xref ref-type="bibr" rid="CR69">69</xref>]. While in the former case, the population units are represented by grid cells of area equal to that of the field plots; in the latter, they are polygons representing single-tree crowns. In both cases, the UAV-SfM data, corresponding either to the grid cells or the single-tree crowns, are then linked to a sample of field observations either for field plots or for single trees through models. These models are then applied to all the population units either for estimation of parameters for stand or forest level mapping. The results of ABA methods have been presented in the previous paragraph. The adoption of ITC approaches to UAV-SfM has been found to be useful for detecting single trees with 25–90% detection accuracy [<xref ref-type="bibr" rid="CR63">63</xref>, <xref ref-type="bibr" rid="CR70">70</xref>, <xref ref-type="bibr" rid="CR71">71</xref>], to classify them according to tree species with overall accuracies up to 95% [<xref ref-type="bibr" rid="CR71">71</xref>], and measuring their height with RMSEs in the range of 0.5–2.84 m [<xref ref-type="bibr" rid="CR55">55</xref>, <xref ref-type="bibr" rid="CR63">63</xref>]. In addition to rather large variability in the accuracy of some of these variables, the results of UAV-SfM ITC approaches vary according to forest types since they remain limited to the detection of the dominant tree layer, while smaller and dominated trees remain mostly undetected.</p></sec><sec id="Sec7"><title>Terrestrial Inventory</title><p id="Par28">Currently, terrestrial laser scanning (TLS) is the most accurate non-contact method of measurement to derive detailed forest inventory information at the plot level [<xref ref-type="bibr" rid="CR15">15</xref>•]. The main drawbacks of this technology are the high hardware costs [<xref ref-type="bibr" rid="CR53">53</xref>], and the time required for multiple scans mitigating occlusions along with post-processing to provide full coverage of a plot [<xref ref-type="bibr" rid="CR72">72</xref>]. Mobile laser scanning systems reduce acquisition time but high costs remain [<xref ref-type="bibr" rid="CR73">73</xref>].</p><p id="Par29">The deficiencies of traditional field data collection and the need for reducing the cost of alternative laser scanning solutions have encouraged the application of terrestrial photogrammetry for forest inventory. Efforts to utilize terrestrial photogrammetric point clouds for deriving forest parameters derive from the low-cost of the equipment for the data collection, the automated SfM-based data processing and the potentially simple and fast data acquisition [<xref ref-type="bibr" rid="CR74">74</xref>]. Requiring only a camera, typically handheld or mounted to a pole or tripod, terrestrial SfM photogrammetry makes such a system highly mobile, reducing the risk of occlusion yet providing a level of detail comparable to TLS [<xref ref-type="bibr" rid="CR75">75</xref>].</p><p id="Par30">Studies on terrestrial SfM for forestry purposes have become more frequent in the last years (Table <xref rid="Tab1" ref-type="table">1</xref>) and mainly focus on linear rather than volumetric tree metrics. Studies vary according to (i) the scale of application, i.e. at plot level and individual tree reconstruction; (ii) the measured forest parameters like tree position, DBH, height and stem curve; (iii) the resolution of the sensor, e.g. video, mobile phone and SLR camera; (iv) the camera configuration and photographic path and (v) the equipment used to acquire the images, e.g. pole, tripod, camera rig and backpack. Based on these aspects an overview of key work on terrestrial SfM applications together with the obtained accuracies, acquisition method and geo-referencing approach are provided.</p><p id="Par31">Most of the recent studies on photogrammetric measurements of forest parameters are based on the single-camera technique, according to which overlapping images are acquired around the plot (Fig. <xref rid="Fig4" ref-type="fig">4</xref>).<fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><p>Example of a terrestrial SfM survey [<xref ref-type="bibr" rid="CR51">51</xref>] in an open forest plot showing <bold>a</bold> the configuration of camera positions and orientations, dense point cloud and ground control points; <bold>b</bold> an example of an image and the dense point cloud from the same point of view and <bold>c</bold> the dense point cloud of a single stem without RGB colouring together with a 10-cm cross-section at 1.3 m (light blue point cloud)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/40725_2019_94_Fig4_HTML.png" id="MO4"/></fig></p><p id="Par32">Terrestrial photogrammetry has been evaluated in several studies in the past few years at plot scales [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR15">15</xref>•, <xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR74">74</xref>, <xref ref-type="bibr" rid="CR76">76</xref>–<xref ref-type="bibr" rid="CR78">78</xref>]. In these studies, DBH and tree locations were estimated in circular plots with diameters ranging from 12 to 30 m. The reported RMSE of the DBH ranged from 0.88 to 6.80 cm compared with either field or TLS DBH measurements. Tree detection ranged between 60 and 98%. Results were influenced by the complexity of the forest plot, the acquisition path and mode.</p><p id="Par33">The impact of photographic path on the accuracy of forest metrics derived from terrestrial SfM point clouds was firstly investigated by Liang et al. in 2014 and 2015 [<xref ref-type="bibr" rid="CR74">74</xref>, <xref ref-type="bibr" rid="CR75">75</xref>] followed by Mokroš et al. in 2018 [<xref ref-type="bibr" rid="CR78">78</xref>]. According to Mokroš et al. [<xref ref-type="bibr" rid="CR78">78</xref>], the optimal acquisition solution resulted in portrait images, stop and go shooting mode and a path leading around the plot with two diagonal paths through the plot. Differently, Liang et al. [<xref ref-type="bibr" rid="CR75">75</xref>] concluded that the image matching results of landscape images were optimal together with a photographing path based on inside and outside of an inner circle (Fig. <xref rid="Fig4" ref-type="fig">4</xref>). For complex forest plots, Piermattei et al. [<xref ref-type="bibr" rid="CR15">15</xref>•] found that the optimal acquisition path was a combination of the solution found by Liang et al. [<xref ref-type="bibr" rid="CR75">75</xref>] and Mokroš et al. [<xref ref-type="bibr" rid="CR78">78</xref>]: landscape images, stop and go mode around the plot pointing in, following by an inner circle pointing out of the plot and two diagonals. This solution allowed reconstruction of stems with an accuracy of few centimetres up to a few metres above ground. For low-density and medium-density forests, Liu et al. [<xref ref-type="bibr" rid="CR77">77</xref>] proposed a system that combines two pole-mounted cameras with a RTK GNSS for continuous capturing. Compared with total station measurements, their automatic determination of tree position, DBH and height achieved RMSEs of 0.16–0.2 m, 0.92–1.13 cm and 2.41–2.51 m respectively.</p><p id="Par34">Most investigations on the use of terrestrial SfM were performed reconstructing single trees (i.e. not the entire forest plot) [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR76">76</xref>, <xref ref-type="bibr" rid="CR79">79</xref>–<xref ref-type="bibr" rid="CR83">83</xref>]. In those studies, DBH was the most frequently estimated parameter and often compared with TLS data for accuracy assessment. Although sub-centimetre accuracy was achieved in all cases, the obtained RMSEs differed according to the approaches used, forest types and survey conditions, i.e. natural forest and controlled field settings.</p><p id="Par35">Not all the research studies report the time required for collecting the images. This can range from around 10 min to 2 h depending on the system used, parameters to be estimated, plot size and survey configuration, by excluding the time to acquire scaling measurements. However, the accuracy of the scaling factor is crucial for forest plot and individual tree reconstruction [<xref ref-type="bibr" rid="CR74">74</xref>]. To scale the photogrammetric point cloud, most of the studies used targets surveyed by total station, implying additional equipment needs to be carried into the field, consequently increasing the total acquisition time per plot and reducing the portability of the entire surveying system. Aside from systems requiring a GNSS solution [<xref ref-type="bibr" rid="CR77">77</xref>], currently, only Liang et al. [<xref ref-type="bibr" rid="CR74">74</xref>] tested natural reference objects, e.g. tree stems, for the determination of correct scale. Their results showed that both natural reference objects and artificial targets worked effectively.</p></sec></sec><sec id="Sec8"><title>Health Assessment and Monitoring</title><p id="Par36">As part of a sustainable forest management, assessment and monitoring of forest health condition play a crucial role. With threats to forest thought to increase globally [<xref ref-type="bibr" rid="CR84">84</xref>], the identification of declining forest health induced by biotic, abiotic and anthropogenic stress agents becomes imperative. RS approaches offer rapid, spatially inclusive and objective ways to monitor forest health when compared with field assessments. With the aim of identifying and observing stress in plants, multi- and hyperspectral sensors are capable of capturing information outside the visible spectrum, which allow for estimation of biochemical plant traits like chlorophyll, leaf pigments and canopy water content [<xref ref-type="bibr" rid="CR85">85</xref>]. Spatially continuous spectral mapping used to be exclusive to the manned airborne surveying domain. However, in recent years, lightweight sensors with discrete narrow spectral bands suitable for UAV mounting have become commercially available, allowing researchers to collect their own aerial spectral data [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR86">86</xref>–<xref ref-type="bibr" rid="CR88">88</xref>]. Such 2D spectral imagers may be used for SfM-based photogrammetric reconstruction and orthophoto generation similarly to RGB cameras, although they typically exhibit lower resolution.</p><p id="Par37">Opposed to the field of precision agriculture, where SfM-based processing of spectral image data is widely applied [<xref ref-type="bibr" rid="CR89">89</xref>], in forestry there currently are only a few examples where SfM-derived mapped spectral products have found the application. Early UAV/SfM-based studies of forest health made use of off-the-shelf RGB cameras, modified to capture near-infrared (NIR) images. Lehmann et al. [<xref ref-type="bibr" rid="CR19">19</xref>] and Michez et al. [<xref ref-type="bibr" rid="CR18">18</xref>•] used an object-based image analysis (OBIA) approach to segment and classify their scenes in order to identify declining tree health caused by biotic stress agents on both alder and oak. They achieved good overall classification accuracies (79.5–84.1% and 82.5–85% at their respective study sites) across five classes. However, they pointed out the limitations of NIR-modified RGB cameras, namely that visible and NIR spectra are not separable on the same sensor, spectral contamination due to broad and overlapping bands (see also Pauly [<xref ref-type="bibr" rid="CR90">90</xref>]) as well as the inability to correct for changing light conditions (as downwelling irradiance is not captured).</p><p id="Par38">Näsi et al. [<xref ref-type="bibr" rid="CR86">86</xref>] used hyperspectral image data combined with the SfM-derived DSM for bark beetle damage detection at the individual tree level, achieving an overall classification accuracy of 76% when distinguishing between healthy, infested and dead trees. In a follow -up study, Näsi et al. [<xref ref-type="bibr" rid="CR91">91</xref>] concluded that the individual tree-based approach, facilitated by the combination of 3D and spectral data, provides a promising and cost-efficient alternative to field-based assessments of pest infestation. Minařík and Langhammer [<xref ref-type="bibr" rid="CR92">92</xref>] also used a UAV-SfM-based mapping approach to map bark beetle forest disturbance and found that bands from the red edge and NIR part of the spectrum were most suited for stress detection. These findings go in line with the results from Dash et al. [<xref ref-type="bibr" rid="CR17">17</xref>], who assessed the potential of the commercially available multispectral sensor, the Micasense RedEdge (Micasense Inc., Seattle, WA, USA), for the detection of early signs of stress during a simulated disease outbreak in a pine plantation. In the applied random forest classification of time-series data, normalized difference vegetation index (NDVI) showed to be the best performing predictor variable to map physiological stress symptoms along with the declining tree health. Further, late examples of forest health monitoring are Baena et al. [<xref ref-type="bibr" rid="CR93">93</xref>] and Brovkina et al. [<xref ref-type="bibr" rid="CR50">50</xref>], both successfully applying an OBIA approach on SfM-mapped NIR image data stemming from a modified consumer RGB sensor to separate between dead and living trees.</p></sec></sec><sec id="Sec9" sec-type="discussion"><title>Discussion</title><p id="Par39">Used complementary to existing RS data (e.g. LiDAR) or by itself, SfM photogrammetry has shown great potential for forestry. Particularly attractive is the ability to use uncalibrated cameras paired with unstable or handheld platforms, enabling the use of low-cost and non-expert equipment. Ground and aerial SfM surveys can be carried out with high flexibility offering the option for increased frequency RS surveys to incorporate, e.g. phenological changes in the analysis [<xref ref-type="bibr" rid="CR59">59</xref>, <xref ref-type="bibr" rid="CR65">65</xref>, <xref ref-type="bibr" rid="CR71">71</xref>]. The implementation of SfM algorithms in modern photogrammetric software enables on-demand processing with little required user input. SfM photogrammetry thus presents a highly accessible and versatile solution to the acquisition of very high-resolution 3D data. In this regard, SfM empowers common forestry practitioners to produce real-time data analytics with the minimum investment required for hardware and software.</p><p id="Par40">Additional value in a SfM-based processing chain derives from the ability to provide multiple geospatial data products (i.e. 3D models and orthomosaics) from a single sensor. Spectral information is inherently linked to the reconstructed structural data and derived products as these are generated directly from the input imagery. Studies on forest health particularly highlight the benefits of using the fused structural and spectral information that SfM-based processing of UAV image data provides [<xref ref-type="bibr" rid="CR18">18</xref>•, <xref ref-type="bibr" rid="CR50">50</xref>].</p><p id="Par41">Point clouds generated from high-resolution images can exhibit point densities greater than LiDAR, providing higher detail information on the visible surface of forests. The increased spectral variation stemming from such high-resolution data may hereby provide another valuable source of information, namely texture, such as the case in an OBIA approach [<xref ref-type="bibr" rid="CR94">94</xref>]. Alongside the computational analysis, high-resolution SfM-generated models appear visually realistic, providing experts a near true depiction of the scene. Intuitive to understand, SfM models thus hold an important advantage over coarser remote sensing methods by enabling the rapid visual assessment and/or validation.</p><p id="Par42">As is the case with all RS data, these will only ever be an approximation of the Earth’s surface and some limitations always remain. With SfM photogrammetry being a new technology, the boundaries of these limitations are not fully tested yet. Some of the main challenges with SfM photogrammetry for forest applications that we are facing nowadays relate to the following:<list list-type="order"><list-item><p id="Par43">Reproducibility:</p><p id="Par44">With SfM photogrammetry enabling frequent surveys, variations in illumination, atmospheric and seasonal conditions are inevitable between acquisitions. Being a passive sensing technique, these variations are directly reflected on the data thus on the replicability of analyses. To ensure the use of SfM data on demand, allowing acquisitions at different times of the year, it is therefore crucial to develop protocols for varying conditional scenarios and models that account for variations in the data.</p></list-item><list-item><p id="Par45">Availability of accurate DTMs:</p><p id="Par46">Most airborne inventory studies presented here adopted highly accurate DTMs (e.g. ALS-based DTMs) to normalize UAV-SfM data and these are relatively rare around the globe, thus potentially limiting the area of application of UAV-SfM. To overcome this issue, some authors proposed the use of DTMs generated from the UAV-SfM data themselves [<xref ref-type="bibr" rid="CR41">41</xref>] or the use of coarse resolution global DTMs such as shuttle radar topography mission data (SRTM) [<xref ref-type="bibr" rid="CR41">41</xref>]. While the former type of DTM is obtainable only in open forests, the latter source was found to be unsuitable for estimation of aboveground biomass. A conceptually novel approach came with the study by Giannetti et al. [<xref ref-type="bibr" rid="CR13">13</xref>•] who, to overcome any of the abovementioned limitations, proposed the use of UAV-SfM data-derived variables without prior normalization (i.e. DTM-independent variables). Their results showed that models fitted raw UAV-SfM data alone predicted stem volume with similar accuracy to ALS data, even in the highly productive broadleaf forest in steep terrain. Despite such encouraging results, it remains fundamental to further apply the method by Giannetti et al. [<xref ref-type="bibr" rid="CR13">13</xref>•] in a wider variety of forest types and response variables. Furthermore, the greater complexity of DTM-independent variables over more traditional explanatory variables could limit the transferability of the models through space and time.</p></list-item><list-item><p id="Par47">Lack of acquisition and processing protocols:</p><p id="Par48">The success of a SfM-based photogrammetric acquisition is largely based on the sensor used, the photographic path and viewing angles along with the chosen image overlap as well as the composition of a scene. Adjustments to the acquisition approach to ensure quality data are currently undertaken based on the surveyor’s experience. Here protocols that enable certainty for SfM outputs across forest types and phenological stages, yet minimizing acquisition efforts, need to be established. Eltner et al. [<xref ref-type="bibr" rid="CR24">24</xref>] suggested a protocol for the collection of image data in geoscientific studies, which should be extended to take into account forestry-specific factors. Additional research is required on the parametrization of SfM-based photogrammetric software for vegetated scenes specifically. Processing protocols designed to deliver data adequate to the research question and to optimize processing speed are needed.</p></list-item><list-item><p id="Par49">Image matching issues:</p><p id="Par50">Forests may prove to be challenging scenes for the feature matching algorithms underlying a SfM workflow. Their fine uniform texture, repeating patterns and potential movement (e.g. branches in wind) can introduce uncertainty in matching, consequently leading to incomplete reconstruction and/or noisy point clouds. In such cases, the likelihood of identifying visual similarities in overlapping images is promoted by increasing the distance to the area of interest (AOI), thus increasing the number of features per image and decreasing perspective distortions. Coarser ground sampling distances (GSDs) and higher image overlaps were shown to positively influence image matching [<xref ref-type="bibr" rid="CR95">95</xref>, <xref ref-type="bibr" rid="CR96">96</xref>]. The overlap should thus be increased when decreasing the GSD (i.e. images with finer detail). Other potential mitigation strategies for reconstruction errors, like the use of high-accuracy position and orientation information for reduction of matching uncertainty, have yet to be studied.</p></list-item></list></p><p id="Par51">To widely employ SfM photogrammetry in operational forestry, future research needs to tackle the abovementioned hurdles. It is essential to develop a consensus on acquisition protocols and parametrization of SfM photogrammetry software that is set to answer specific research questions across forest types and environmental conditions. We have started to gain some understanding of how image quality, overlap, GSD and photographic path are influencing SfM-based reconstruction [<xref ref-type="bibr" rid="CR15">15</xref>•, <xref ref-type="bibr" rid="CR43">43</xref>••, <xref ref-type="bibr" rid="CR95">95</xref>–<xref ref-type="bibr" rid="CR97">97</xref>]. However, prior to processing, uncertainty remains in predicting the completeness of these photogrammetric models. More in-depth work on these influential parameters is needed in conjunction with the development of methods that allow for reliable quality estimation of SfM-based outputs. Towards the quantification of data quality, James et al. [<xref ref-type="bibr" rid="CR98">98</xref>] presented a method for estimating the precision of each point produced within the SfM pipeline by repeatedly running bundle adjustments on a set of input images. These ‘precision maps’ allow practitioners to describe the spatial variability of precision within SfM-derived products and gain insight into limitations in a given survey (such as image quality or control-point measurements). To our knowledge, ‘precision maps’ have not been applied in the context of forested scenes. In forestry, future studies would benefit from this method to objectively describe the data quality of SfM-derived products and thereby reduce uncertainty in subsequent analysis.</p></sec><sec id="Sec10" sec-type="conclusions"><title>Conclusions</title><p id="Par52">A camera and a computer are the basic requirements for SfM photogrammetry. With the examples given here, and in terms of what valuable data may be extracted from SfM-derived data by analysis, SfM photogrammetry shows great potential for forest practitioners and researchers. Adding the power of UAVs for the acquisition of aerial image data, the canopy of a forest can be mapped nearly in real time, responding rapidly to management needs. The temporal and spatial dimension that can be provided with SfM photogrammetry enables assessment and monitoring of forests in an economical way that has not existed before.</p><p id="Par53">However, constraints linked to the fundamental principles of SfM photogrammetry being a passive optical method will remain. Influencing factors like viewing geometry, lighting and the availability of static texture have to be carefully considered prior to every survey. We suggest that, in order to enable the collection of fit-for-purpose data with predictable quality, further work is needed on acquisition and processing protocols specific to forestry. Further progress in these areas will facilitate the move away from proof-of-concept studies and towards the operational application of SfM photogrammetry in forestry.</p></sec></body><back><sec><title>Funding</title><p>Jakob Iglhaut is funded by the Royal Society Research Grant RG140494. Stefano Puliti is funded by NIBIO.</p></sec><sec sec-type="ethics-statement"><title>Compliance with Ethical Standards</title><sec id="FPar1" sec-type="COI-statement"><title>Conflict of Interest</title><p id="Par54">Jakob Iglhaut, Carlos Cabo, Stefano Puliti, Livia Piermattei, James O’Connor, and Jacqueline Rosette declare that they have no conflict of interest.</p></sec><sec id="FPar2"><title>Human and Animal Rights and Informed Consent</title><p id="Par55">This article does not contain any studies with human or animal subjects performed by any of the authors.</p></sec></sec><ref-list id="Bib1"><title>References</title><ref-list id="BSec1"><title>Papers of particular interest, published recently, have been highlighted as: • Of importance •• Of major importance</title><ref id="CR1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mcroberts</surname><given-names>R</given-names></name><name><surname>Tomppo</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Remote sensing support for national forest inventories</article-title><source>Remote Sens Environ</source><year>2007</year><volume>110</volume><fpage>412</fpage><lpage>419</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2006.09.034</pub-id></mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wulder</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Optical remote-sensing techniques for the assessment of forest inventory and biophysical parameters</article-title><source>Prog Phys Geogr</source><year>1998</year><volume>22</volume><fpage>449</fpage><lpage>476</lpage><pub-id pub-id-type="doi">10.1177/030913339802200402</pub-id></mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">Korpela I. Individual tree measurements by means of digital aerial photogrammetry. Silva Fennica Monographs 2004;3:93.</mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>K</given-names></name><name><surname>Treitz</surname><given-names>P</given-names></name><name><surname>Wulder</surname><given-names>M</given-names></name><name><surname>St-Onge</surname><given-names>B</given-names></name><name><surname>Flood</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">LiDAR remote sensing of forest structure</article-title><source>Prog Phys Geogr Earth Environ</source><year>2003</year><volume>27</volume><fpage>88</fpage><lpage>106</lpage><pub-id pub-id-type="doi">10.1191/0309133303pp360ra</pub-id></mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Næsset</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Airborne laser scanning as a method in operational forest inventory: status of accuracy assessments accomplished in Scandinavia</article-title><source>Scand J For Res</source><year>2007</year><volume>22</volume><fpage>433</fpage><lpage>442</lpage><pub-id pub-id-type="doi">10.1080/02827580701672147</pub-id></mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Kangas A, Gobakken T, Puliti S, Hauglin M, Næsset E. Value of airborne laser scanning and digital aerial photogrammetry data in forest decision making. Silva Fennica 2018;52:1–19.</mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ginzler</surname><given-names>C</given-names></name><name><surname>Hobi</surname><given-names>ML</given-names></name></person-group><article-title xml:lang="en">Countrywide stereo-image matching for updating digital surface models in the framework of the swiss national forest inventory</article-title><source>Remote Sens</source><year>2015</year><volume>7</volume><fpage>4343</fpage><lpage>4370</lpage><pub-id pub-id-type="doi">10.3390/rs70404343</pub-id></mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Koch B. Remote sensing supporting national forest inventories. In Knowledge Reference for National Forest Assessments; FAO. 2013:1–18.</mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>JC</given-names></name><name><surname>Wulder</surname><given-names>MA</given-names></name><name><surname>Vastaranta</surname><given-names>M</given-names></name><name><surname>Coops</surname><given-names>NC</given-names></name><name><surname>Pitt</surname><given-names>D</given-names></name><name><surname>Woods</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">The utility of image-based point clouds for forest inventory: a comparison with airborne laser scanning</article-title><source>Forests</source><year>2013</year><volume>4</volume><fpage>518</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.3390/f4030518</pub-id></mixed-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leberl</surname><given-names>F</given-names></name><name><surname>Irschara</surname><given-names>A</given-names></name><name><surname>Pock</surname><given-names>T</given-names></name><name><surname>Meixner</surname><given-names>P</given-names></name><name><surname>Gruber</surname><given-names>M</given-names></name><name><surname>Scholz</surname><given-names>S</given-names></name><name><surname>Wiechert</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Point clouds: Lidar versus 3D vision</article-title><source>Photogramm Eng Remote Sens</source><year>2010</year><volume>76</volume><fpage>1123</fpage><lpage>1134</lpage><pub-id pub-id-type="doi">10.14358/PERS.76.10.1123</pub-id></mixed-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodbody</surname><given-names>TRH</given-names></name><name><surname>Coops</surname><given-names>NC</given-names></name><name><surname>White</surname><given-names>JC</given-names></name></person-group><article-title xml:lang="en">Digital aerial photogrammetry for updating area-based forest inventories: a review of opportunities, challenges, and future directions</article-title><source>Curr For Rep</source><year>2019</year><volume>5</volume><fpage>55</fpage><lpage>75</lpage><pub-id pub-id-type="doi">10.1007/s40725-019-00087-2</pub-id></mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Puliti</surname><given-names>S</given-names></name><name><surname>Ørka</surname><given-names>HO</given-names></name><name><surname>Gobakken</surname><given-names>T</given-names></name><name><surname>Naesset</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Inventory of small forest areas using an unmanned aerial system</article-title><source>Remote Sens</source><year>2015</year><volume>7</volume><fpage>9632</fpage><lpage>9654</lpage><pub-id pub-id-type="doi">10.3390/rs70809632</pub-id></mixed-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giannetti</surname><given-names>F</given-names></name><name><surname>Chirici</surname><given-names>G</given-names></name><name><surname>Gobakken</surname><given-names>T</given-names></name><name><surname>Næsset</surname><given-names>E</given-names></name><name><surname>Travaglini</surname><given-names>D</given-names></name><name><surname>Puliti</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">A new approach with DTM-independent metrics for forest growing stock prediction using UAV photogrammetric data</article-title><source>Remote Sens Environ</source><year>2018</year><volume>213</volume><fpage>195</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2018.05.016</pub-id><comment><bold>By omitting the prerequisite of DTM availability their approach indicates forward-looking potential for inventories based solely on SfM photogrammetry.</bold></comment></mixed-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mikita</surname><given-names>T</given-names></name><name><surname>Janata</surname><given-names>P</given-names></name><name><surname>Surový</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Forest stand inventory based on combined aerial and terrestrial close-range photogrammetry</article-title><source>Forests</source><year>2016</year><volume>7</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.3390/f7080165</pub-id></mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">• Piermattei L, Karel W, Wang D, Wieser M, Mokroš M, Koreň M, et al. Terrestrial Structure from Motion photogrammetry for deriving forest inventory data. Remote Sens. 2019. <ext-link xlink:href="10.3390/rs11080950" ext-link-type="doi">https://doi.org/10.3390/rs11080950</ext-link>. <bold>This paper deals with the detection of tree characteristics from close-range SfM photogrammetry and TLS in four case studies. The two techniques with respective acquisition and post-processing phases and their source requirements are discussed thoroughly.</bold></mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Mokroš M, Výbošťok J, Tomaštík J, Grznárová A, Valent P, Slavík M, et al. High precision individual tree diameter and perimeter estimation from close-range photogrammetry. Forests. 2018;9. <ext-link xlink:href="10.3390/f9110696" ext-link-type="doi">https://doi.org/10.3390/f9110696</ext-link>.</mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dash</surname><given-names>JP</given-names></name><name><surname>Watt</surname><given-names>MS</given-names></name><name><surname>Pearse</surname><given-names>GD</given-names></name><name><surname>Heaphy</surname><given-names>M</given-names></name><name><surname>Dungey</surname><given-names>HS</given-names></name></person-group><article-title xml:lang="en">Assessing very high resolution UAV imagery for monitoring forest health during a simulated disease outbreak</article-title><source>ISPRS J Photogramm Remote Sens</source><year>2017</year><volume>131</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1016/j.isprsjprs.2017.07.007</pub-id></mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michez</surname><given-names>A</given-names></name><name><surname>Piégay</surname><given-names>H</given-names></name><name><surname>Lisein</surname><given-names>J</given-names></name><name><surname>Claessens</surname><given-names>H</given-names></name><name><surname>Lejeune</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Classification of riparian forest species and health condition using multi-temporal and hyperspatial imagery from unmanned aerial system</article-title><source>Environ Monit Assess</source><year>2016</year><volume>188</volume><fpage>146</fpage><pub-id pub-id-type="doi">10.1007/s10661-015-4996-2</pub-id><comment><bold>A great example of forest health monitoring at the individual tree level based on SfM-derived structural, spectral and textural variables.</bold></comment></mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lehmann</surname><given-names>JRK</given-names></name><name><surname>Nieberding</surname><given-names>F</given-names></name><name><surname>Prinz</surname><given-names>T</given-names></name><name><surname>Knoth</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Analysis of unmanned aerial system-based CIR images in forestry-a new perspective to monitor pest infestation levels</article-title><source>Forests.</source><year>2015</year><volume>6</volume><fpage>594</fpage><lpage>612</lpage><pub-id pub-id-type="doi">10.3390/f6030594</pub-id></mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisein</surname><given-names>J</given-names></name><name><surname>Michez</surname><given-names>A</given-names></name><name><surname>Claessens</surname><given-names>H</given-names></name><name><surname>Lejeune</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Discrimination of deciduous tree species from time series of unmanned aerial system imagery</article-title><source>PLoS One</source><year>2015</year><volume>10</volume><fpage>1</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0141006</pub-id></mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alonzo</surname><given-names>M</given-names></name><name><surname>Andersen</surname><given-names>H-E</given-names></name><name><surname>Morton</surname><given-names>D</given-names></name><name><surname>Cook</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Quantifying boreal forest structure and composition using UAV structure from motion</article-title><source>Forests</source><year>2018</year><volume>9</volume><fpage>119</fpage><pub-id pub-id-type="doi">10.3390/f9030119</pub-id></mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Saarinen N, Vastaranta M, Näsi R, Rosnell T, Hakala T, Honkavaara E, et al. Assessing biodiversity in boreal forests with UAV-based photogrammetric point clouds and hyperspectral imaging. Remote Sens. 2018;10. <ext-link xlink:href="10.3390/rs10020338" ext-link-type="doi">https://doi.org/10.3390/rs10020338</ext-link>.</mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>MW</given-names></name><name><surname>Carrivick</surname><given-names>JL</given-names></name><name><surname>Quincey</surname><given-names>DJ</given-names></name></person-group><article-title xml:lang="en">Structure from motion photogrammetry in physical geography</article-title><source>Prog Phys Geogr</source><year>2015</year><volume>40</volume><fpage>247</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1177/0309133315615805</pub-id></mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eltner</surname><given-names>A</given-names></name><name><surname>Kaiser</surname><given-names>A</given-names></name><name><surname>Castillo</surname><given-names>C</given-names></name><name><surname>Rock</surname><given-names>G</given-names></name><name><surname>Neugirg</surname><given-names>F</given-names></name><name><surname>Abellán</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Image-based surface reconstruction in geomorphometry-merits, limits and developments</article-title><source>Earth Surf Dyn</source><year>2016</year><volume>4</volume><fpage>359</fpage><lpage>389</lpage><pub-id pub-id-type="doi">10.5194/esurf-4-359-2016</pub-id></mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bemis</surname><given-names>SP</given-names></name><name><surname>Micklethwaite</surname><given-names>S</given-names></name><name><surname>Turner</surname><given-names>D</given-names></name><name><surname>James</surname><given-names>MR</given-names></name><name><surname>Akciz</surname><given-names>S</given-names></name><name><surname>Thiele</surname><given-names>S</given-names></name><name><surname>Bangash</surname><given-names>HA</given-names></name></person-group><article-title xml:lang="en">Ground-based and UAV-based photogrammetry: a multi-scale, high-resolution mapping tool for structural geology and paleoseismology</article-title><source>J Struct Geol</source><year>2014</year><volume>69</volume><fpage>163</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1016/j.jsg.2014.10.007</pub-id></mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">•• Carrivick J, Smith MJ. Quincey D. Structure from motion in the geosciences. 2016. <bold>This book further elaborates on the concepts and methods of SfM photogrammetry applied in physical geography. Technical aspects are described with great clarity.</bold></mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bolles</surname><given-names>RC</given-names></name><name><surname>Baker</surname><given-names>HH</given-names></name><name><surname>Marimont</surname><given-names>DH</given-names></name></person-group><article-title xml:lang="en">Epipolar-plane image analysis: an approach to determining structure from motion</article-title><source>Int J Comput Vis</source><year>1987</year><volume>1</volume><fpage>7</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1007/BF00128525</pub-id></mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ullman</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">The interpretation of structure from motion</article-title><source>Proc R Soc Lond Ser B Biol Sci</source><year>1979</year><volume>203</volume><fpage>405</fpage><lpage>426</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DyaE1M7jslansQ%3D%3D</pub-id><pub-id pub-id-type="doi">10.1098/rspb.1979.0006</pub-id></mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koenderink</surname><given-names>JJ</given-names></name><name><surname>van Doorn</surname><given-names>AJ</given-names></name></person-group><article-title xml:lang="en">Affine structure from motion</article-title><source>J Opt Soc Am A</source><year>1991</year><volume>8</volume><fpage>377</fpage><lpage>385</lpage><pub-id pub-id-type="other" assigning-authority="ChemPort ( Chemical Abstract Service )">1:STN:280:DyaK3M7nvVGksg%3D%3D</pub-id><pub-id pub-id-type="doi">10.1364/JOSAA.8.000377</pub-id></mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westoby</surname><given-names>MJ</given-names></name><name><surname>Brasington</surname><given-names>J</given-names></name><name><surname>Glasser</surname><given-names>NF</given-names></name><name><surname>Hambrey</surname><given-names>MJ</given-names></name><name><surname>Reynolds</surname><given-names>JM</given-names></name></person-group><article-title xml:lang="en">“Structure-from-motion” photogrammetry: a low-cost, effective tool for geoscience applications</article-title><source>Geomorphology</source><year>2012</year><volume>179</volume><fpage>300</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1016/j.geomorph.2012.08.021</pub-id></mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fonstad</surname><given-names>MA</given-names></name><name><surname>Dietrich</surname><given-names>JT</given-names></name><name><surname>Courville</surname><given-names>BC</given-names></name><name><surname>Jensen</surname><given-names>JL</given-names></name><name><surname>Carbonneau</surname><given-names>PE</given-names></name></person-group><article-title xml:lang="en">Topographic structure from motion: a new development in photogrammetric measurement</article-title><source>Earth Surf Process Landf</source><year>2013</year><volume>38</volume><fpage>421</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1002/esp.3366</pub-id></mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="other">Micheletti N, Chandler JH, Lane SN. Structure from motion (SfM) photogrammetry. Br Soc Geomorphol. 2015.</mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skarlatos</surname><given-names>D</given-names></name><name><surname>Kiparissi</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Comparison of laser scanning, photogrammetry and Sfm-Mvs pipeline applied in structures and artificial surfaces</article-title><source>ISPRS Ann Photogramm Remote Sens Spat Inf Sci</source><year>2012</year><volume>I–3</volume><fpage>299</fpage><lpage>304</lpage><pub-id pub-id-type="doi">10.5194/isprsannals-I-3-299-2012</pub-id></mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dandois</surname><given-names>JP</given-names></name><name><surname>Ellis</surname><given-names>EC</given-names></name></person-group><article-title xml:lang="en">High spatial resolution three-dimensional mapping of vegetation spectral dynamics using computer vision</article-title><source>Remote Sens Environ</source><year>2013</year><volume>136</volume><fpage>259</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2013.04.005</pub-id></mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lowe</surname><given-names>DG</given-names></name></person-group><article-title xml:lang="en">Distinctive image features from Scale-Invariant Keypoints</article-title><source>Int J Comput Vis</source><year>2004</year><volume>60</volume><fpage>91</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1023/B:VISI.0000029664.99615.94</pub-id></mixed-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="other">Shum H-Y, Ke Q, Zhang Z. Efficient bundle adjustment with virtual key frames: a hierarchical approach to multi-frame structure from motion. In: Proceedings. 1999 IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. (Cat. No PR00149). IEEE Comput. Soc, pp 538–543.</mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahmadabadian</surname><given-names>AH</given-names></name><name><surname>Robson</surname><given-names>S</given-names></name><name><surname>Boehm</surname><given-names>J</given-names></name><name><surname>Shortis</surname><given-names>M</given-names></name><name><surname>Wenzel</surname><given-names>K</given-names></name><name><surname>Fritsch</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">A comparison of dense matching algorithms for scaled surface reconstruction using stereo camera rigs</article-title><source>ISPRS J Photogramm Remote Sens</source><year>2013</year><volume>78</volume><fpage>157</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1016/j.isprsjprs.2013.01.015</pub-id></mixed-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gini</surname><given-names>R</given-names></name><name><surname>Sona</surname><given-names>G</given-names></name><name><surname>Ronchetti</surname><given-names>G</given-names></name><name><surname>Passoni</surname><given-names>D</given-names></name><name><surname>Pinto</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Improving tree species classification using UAS multispectral images and texture measures</article-title><source>ISPRS Int J Geo-Information</source><year>2018</year><volume>7</volume><fpage>315</fpage><pub-id pub-id-type="doi">10.3390/ijgi7080315</pub-id></mixed-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Puliti S. Tree-stump detection, segmentation, classification, and measurement using unmanned aerial vehicle (UAV) imagery. Forests. 2018. <ext-link xlink:href="10.3390/f9030102" ext-link-type="doi">https://doi.org/10.3390/f9030102</ext-link>.</mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">Puliti S, Gobakken T, Ørka HO, Næsset E. Assessing 3D point clouds from aerial photographs for species-specific forest inventories. Scand J For Res. 2017;32:68–79.</mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kachamba</surname><given-names>D</given-names></name><name><surname>Ørka</surname><given-names>H</given-names></name><name><surname>Gobakken</surname><given-names>T</given-names></name><name><surname>Eid</surname><given-names>T</given-names></name><name><surname>Mwase</surname><given-names>W</given-names></name><name><surname>Kachamba</surname><given-names>DJ</given-names></name><name><surname>Ørka</surname><given-names>HO</given-names></name><name><surname>Gobakken</surname><given-names>T</given-names></name><name><surname>Eid</surname><given-names>T</given-names></name><name><surname>Mwase</surname><given-names>W</given-names></name></person-group><article-title xml:lang="en">Biomass estimation using 3D data from unmanned aerial vehicle imagery in a tropical woodland</article-title><source>Remote Sens</source><year>2016</year><volume>8</volume><fpage>968</fpage><pub-id pub-id-type="doi">10.3390/rs8110968</pub-id></mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="other">White JC, Wulder MA, Varhola A, Vastaranta M, Coops NC, Cook BD, et al. A best practices guide for generating forest inventory attributes from airborne laser scanning data using an area-based approach. Canadian Forest Service: Information Report. 2017. <ext-link xlink:href="10.5558/tfc2013-132" ext-link-type="doi">https://doi.org/10.5558/tfc2013-132</ext-link>.</mixed-citation></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Connor</surname><given-names>J</given-names></name><name><surname>Smith</surname><given-names>MJ</given-names></name><name><surname>James</surname><given-names>MR</given-names></name></person-group><article-title xml:lang="en">Cameras and settings for aerial surveys in the geosciences: optimising image data</article-title><source>Prog Phys Geogr</source><year>2017</year><volume>41</volume><fpage>325</fpage><lpage>344</lpage><pub-id pub-id-type="doi">10.1177/0309133317703092</pub-id><comment><bold>This paper gives a very clear introduction to aerial image capture. Foundational principles essential to capturing high quality imagery with digital sensors are provided. Cameras and settings are discussed with worked examples.</bold></comment></mixed-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mosbrucker</surname><given-names>AR</given-names></name><name><surname>Major</surname><given-names>JJ</given-names></name><name><surname>Spicer</surname><given-names>KR</given-names></name><name><surname>Pitlick</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Camera system considerations for geomorphic applications of SfM photogrammetry</article-title><source>Earth Surf Process Landf</source><year>2017</year><volume>42</volume><fpage>969</fpage><lpage>986</lpage><pub-id pub-id-type="doi">10.1002/esp.4066</pub-id></mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verhoeven</surname><given-names>GJJ</given-names></name></person-group><article-title xml:lang="en">It’s all about the format – unleashing the power of RAW aerial photography</article-title><source>Int J Remote Sens</source><year>2010</year><volume>31</volume><fpage>2009</fpage><lpage>2042</lpage><pub-id pub-id-type="doi">10.1080/01431160902929271</pub-id></mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>James</surname><given-names>MR</given-names></name><name><surname>Robson</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Mitigating systematic error in topographic models derived from UAV and ground-based image networks</article-title><source>Earth Surf Process Landf</source><year>2014</year><volume>39</volume><fpage>1413</fpage><lpage>1420</lpage><pub-id pub-id-type="doi">10.1002/esp.3609</pub-id></mixed-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wackrow</surname><given-names>R</given-names></name><name><surname>Chandler</surname><given-names>JH</given-names></name></person-group><article-title xml:lang="en">Minimising systematic error surfaces in digital elevation models using oblique convergent imagery</article-title><source>Photogramm Rec</source><year>2011</year><volume>26</volume><fpage>16</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1111/j.1477-9730.2011.00623.x</pub-id></mixed-citation></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>K</given-names></name><name><surname>Westoby</surname><given-names>MJ</given-names></name><name><surname>James</surname><given-names>MR</given-names></name></person-group><article-title xml:lang="en">Low-budget topographic surveying comes of age: structure from motion photogrammetry in geography and the geosciences</article-title><source>Prog Phys Geogr Earth Environ</source><year>2019</year><volume>43</volume><fpage>163</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1177/0309133319837454</pub-id></mixed-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>K</given-names></name><name><surname>Gaston</surname><given-names>KJ</given-names></name></person-group><article-title xml:lang="en">Lightweight unmanned aerial vehicles will revolutionize spatial ecology</article-title><source>Front Ecol Environ</source><year>2013</year><volume>11</volume><fpage>138</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1890/120150</pub-id></mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brovkina</surname><given-names>O</given-names></name><name><surname>Cienciala</surname><given-names>E</given-names></name><name><surname>Surový</surname><given-names>P</given-names></name><name><surname>Janata</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Unmanned aerial vehicles (UAV) for assessment of qualitative classification of Norway spruce in temperate forest stands</article-title><source>Geo-Spat Inf Sci</source><year>2018</year><volume>21</volume><fpage>12</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1080/10095020.2017.1416994</pub-id></mixed-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liang</surname><given-names>X</given-names></name><name><surname>Kukko</surname><given-names>A</given-names></name><name><surname>Hyyppä</surname><given-names>J</given-names></name><name><surname>Lehtomäki</surname><given-names>M</given-names></name><name><surname>Pyörälä</surname><given-names>J</given-names></name><name><surname>Yu</surname><given-names>X</given-names></name><name><surname>Kaartinen</surname><given-names>H</given-names></name><name><surname>Jaakkola</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">In-situ measurements from mobile platforms: an emerging approach to address the old challenges associated with forest inventories</article-title><source>ISPRS J Photogramm Remote Sens</source><year>2018</year><volume>143</volume><fpage>97</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1016/j.isprsjprs.2018.04.019</pub-id></mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thompson</surname><given-names>ID</given-names></name><name><surname>Maher</surname><given-names>SC</given-names></name><name><surname>Rouillard</surname><given-names>DP</given-names></name><name><surname>Fryxell</surname><given-names>JM</given-names></name><name><surname>Baker</surname><given-names>JA</given-names></name></person-group><article-title xml:lang="en">Accuracy of forest inventory mapping: some implications for boreal forest management</article-title><source>For Ecol Manag</source><year>2007</year><volume>252</volume><fpage>208</fpage><lpage>221</lpage><pub-id pub-id-type="doi">10.1016/j.foreco.2007.06.033</pub-id></mixed-citation></ref><ref id="CR53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>White</surname><given-names>JC</given-names></name><name><surname>Coops</surname><given-names>NC</given-names></name><name><surname>Wulder</surname><given-names>MA</given-names></name><name><surname>Vastaranta</surname><given-names>M</given-names></name><name><surname>Hilker</surname><given-names>T</given-names></name><name><surname>Tompalski</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Remote sensing technologies for enhancing forest inventories: a review</article-title><source>Can J Remote Sens</source><year>2016</year><volume>42</volume><fpage>619</fpage><lpage>641</lpage><pub-id pub-id-type="doi">10.1080/07038992.2016.1207484</pub-id></mixed-citation></ref><ref id="CR54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dandois</surname><given-names>JP</given-names></name><name><surname>Ellis</surname><given-names>EC</given-names></name></person-group><article-title xml:lang="en">Remote sensing of vegetation structure using computer vision</article-title><source>Remote Sens</source><year>2010</year><volume>2</volume><fpage>1157</fpage><lpage>1176</lpage><pub-id pub-id-type="doi">10.3390/rs2041157</pub-id></mixed-citation></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisein</surname><given-names>J</given-names></name><name><surname>Pierrot-Deseilligny</surname><given-names>M</given-names></name><name><surname>Bonnet</surname><given-names>S</given-names></name><name><surname>Lejeune</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">A photogrammetric workflow for the creation of a forest canopy height model from small unmanned aerial system imagery</article-title><source>Forests</source><year>2013</year><volume>4</volume><fpage>922</fpage><lpage>944</lpage><pub-id pub-id-type="doi">10.3390/f4040922</pub-id></mixed-citation></ref><ref id="CR56"><label>56.</label><mixed-citation publication-type="other">Tuominen S, Balazs A, Saari H, Pölönen I, Sarkeala J, Viitala R. Unmanned aerial system imagery and photogrammetric canopy height data in area-based estimation of forest variables. Silva Fenn. 2015. <ext-link xlink:href="10.14214/sf.1348" ext-link-type="doi">https://doi.org/10.14214/sf.1348</ext-link>.</mixed-citation></ref><ref id="CR57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otero</surname><given-names>V</given-names></name><name><surname>Van De Kerchove</surname><given-names>R</given-names></name><name><surname>Satyanarayana</surname><given-names>B</given-names></name><name><surname>Martínez-Espinosa</surname><given-names>C</given-names></name><name><surname>Bin</surname><given-names>FMA</given-names></name><name><surname>Bin</surname><given-names>IMR</given-names></name><name><surname>Sulong</surname><given-names>I</given-names></name><name><surname>Mohd-Lokman</surname><given-names>H</given-names></name><name><surname>Lucas</surname><given-names>R</given-names></name><name><surname>Dahdouh-Guebas</surname><given-names>F</given-names></name></person-group><article-title xml:lang="en">Managing mangrove forests from the sky: forest inventory using field data and unmanned aerial vehicle (UAV) imagery in the Matang Mangrove Forest Reserve, peninsular Malaysia</article-title><source>For Ecol Manag</source><year>2018</year><volume>411</volume><fpage>35</fpage><lpage>45</lpage><pub-id pub-id-type="doi">10.1016/j.foreco.2017.12.049</pub-id></mixed-citation></ref><ref id="CR58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roşca</surname><given-names>S</given-names></name><name><surname>Suomalainen</surname><given-names>J</given-names></name><name><surname>Bartholomeus</surname><given-names>H</given-names></name><name><surname>Herold</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Comparing terrestrial laser scanning and unmanned aerial vehicle structure from motion to assess top of canopy structure in tropical forests</article-title><source>Interface Focus</source><year>2018</year><volume>8</volume><fpage>20170038</fpage><pub-id pub-id-type="doi">10.1098/rsfs.2017.0038</pub-id></mixed-citation></ref><ref id="CR59"><label>59.</label><mixed-citation publication-type="other">Jayathunga S, Owari T, Tsuyuki S. Evaluating the performance of photogrammetric products using fixed-wing UAV imagery over a mixed conifer-broadleaf forest: comparison with airborne laser scanning. Remote Sens. 2018;10. <ext-link xlink:href="10.3390/rs10020187" ext-link-type="doi">https://doi.org/10.3390/rs10020187</ext-link>.</mixed-citation></ref><ref id="CR60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Ma</surname><given-names>M</given-names></name><name><surname>Lin</surname><given-names>Y</given-names></name><name><surname>Lin</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Ma</surname><given-names>M</given-names></name><name><surname>Lin</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Aboveground tree biomass estimation of sparse subalpine coniferous forest with UAV oblique photography</article-title><source>Remote Sens</source><year>2018</year><volume>10</volume><fpage>1849</fpage><pub-id pub-id-type="doi">10.3390/rs10111849</pub-id></mixed-citation></ref><ref id="CR61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname><given-names>P</given-names></name><name><surname>Sankey</surname><given-names>T</given-names></name><name><surname>Moore</surname><given-names>M</given-names></name><name><surname>Thode</surname><given-names>A</given-names></name><name><surname>Shin</surname><given-names>P</given-names></name><name><surname>Sankey</surname><given-names>T</given-names></name><name><surname>Moore</surname><given-names>MM</given-names></name><name><surname>Thode</surname><given-names>AE</given-names></name></person-group><article-title xml:lang="en">Evaluating unmanned aerial vehicle images for estimating forest canopy fuels in a ponderosa pine stand</article-title><source>Remote Sens</source><year>2018</year><volume>10</volume><fpage>1266</fpage><pub-id pub-id-type="doi">10.3390/rs10081266</pub-id></mixed-citation></ref><ref id="CR62"><label>62.</label><mixed-citation publication-type="other">Iizuka K, Yonehara T, Itoh M, Kosugi Y. Estimating tree height and diameter at breast height (DBH) from digital surface models and orthophotos obtained with an unmanned aerial system for a Japanese Cypress (Chamaecyparis obtusa) Forest. Remote Sens. 2018;10. <ext-link xlink:href="10.3390/rs10010013" ext-link-type="doi">https://doi.org/10.3390/rs10010013</ext-link>.</mixed-citation></ref><ref id="CR63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guerra-Hernández</surname><given-names>J</given-names></name><name><surname>Cosenza</surname><given-names>DN</given-names></name><name><surname>Rodriguez</surname><given-names>LCE</given-names></name><name><surname>Silva</surname><given-names>M</given-names></name><name><surname>Tomé</surname><given-names>M</given-names></name><name><surname>Díaz-Varela</surname><given-names>RA</given-names></name><name><surname>González-Ferreiro</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Comparison of ALS- and UAV(SfM)-derived high-density point clouds for individual tree detection in Eucalyptus plantations</article-title><source>Int J Remote Sens</source><year>2018</year><volume>39</volume><fpage>5211</fpage><lpage>5235</lpage><pub-id pub-id-type="doi">10.1080/01431161.2018.1486519</pub-id></mixed-citation></ref><ref id="CR64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodbody</surname><given-names>TRH</given-names></name><name><surname>Coops</surname><given-names>NC</given-names></name><name><surname>Hermosilla</surname><given-names>T</given-names></name><name><surname>Tompalski</surname><given-names>P</given-names></name><name><surname>Crawford</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Assessing the status of forest regeneration using digital aerial photogrammetry and unmanned aerial systems</article-title><source>Int J Remote Sens</source><year>2018</year><volume>39</volume><fpage>5246</fpage><lpage>5264</lpage><pub-id pub-id-type="doi">10.1080/01431161.2017.1402387</pub-id></mixed-citation></ref><ref id="CR65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feduck</surname><given-names>C</given-names></name><name><surname>McDermid</surname><given-names>G</given-names></name><name><surname>Castilla</surname><given-names>G</given-names></name><name><surname>Feduck</surname><given-names>C</given-names></name><name><surname>McDermid</surname><given-names>GJ</given-names></name><name><surname>Castilla</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Detection of coniferous seedlings in UAV imagery</article-title><source>Forests</source><year>2018</year><volume>9</volume><fpage>432</fpage><pub-id pub-id-type="doi">10.3390/f9070432</pub-id></mixed-citation></ref><ref id="CR66"><label>66.</label><mixed-citation publication-type="other">• Puliti S, Solberg S, Granhus A. Use of UAV photogrammetric data for estimation of biophysical properties in forest stands under regeneration. Remote Sens. 2019;11:233. <ext-link xlink:href="10.3390/rs11030233" ext-link-type="doi">https://doi.org/10.3390/rs11030233</ext-link>. <bold>This paper demonstrates that high resolution UAV-SfM data can outperform ALS and traditional field data in forest inventory.</bold></mixed-citation></ref><ref id="CR67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Næsset</surname><given-names>E</given-names></name><name><surname>Økland</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">Estimating tree height and tree crown properties using airborne scanning laser in a boreal nature reserve</article-title><source>Remote Sens Environ</source><year>2002</year><volume>79</volume><fpage>105</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1016/S0034-4257(01)00243-7</pub-id></mixed-citation></ref><ref id="CR68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brandtberg</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">Automatic individual tree based analysis of high spatial resolution aerial images on naturally regenerated boreal forests</article-title><source>Can J For Res</source><year>1999</year><volume>29</volume><fpage>1464</fpage><lpage>1478</lpage><pub-id pub-id-type="doi">10.1139/x99-150</pub-id></mixed-citation></ref><ref id="CR69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyyppä</surname><given-names>J</given-names></name><name><surname>Inkinen</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Detecting and estimating attributes for single trees using laser scanner</article-title><source>Photogramm J Finl</source><year>1999</year><volume>16</volume><fpage>27</fpage><lpage>42</lpage></mixed-citation></ref><ref id="CR70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohan</surname><given-names>M</given-names></name><name><surname>Silva</surname><given-names>C</given-names></name><name><surname>Klauberg</surname><given-names>C</given-names></name><name><surname>Jat</surname><given-names>P</given-names></name><name><surname>Catts</surname><given-names>G</given-names></name><name><surname>Cardil</surname><given-names>A</given-names></name><name><surname>Hudak</surname><given-names>A</given-names></name><name><surname>Dia</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Individual tree detection from unmanned aerial vehicle (UAV) derived canopy height model in an open canopy mixed conifer forest</article-title><source>Forests</source><year>2017</year><volume>8</volume><fpage>340</fpage><pub-id pub-id-type="doi">10.3390/f8090340</pub-id></mixed-citation></ref><ref id="CR71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nevalainen</surname><given-names>O</given-names></name><name><surname>Honkavaara</surname><given-names>E</given-names></name><name><surname>Tuominen</surname><given-names>S</given-names></name><name><surname>Viljanen</surname><given-names>N</given-names></name><name><surname>Hakala</surname><given-names>T</given-names></name><name><surname>Yu</surname><given-names>X</given-names></name><name><surname>Hyyppä</surname><given-names>J</given-names></name><name><surname>Saari</surname><given-names>H</given-names></name><name><surname>Pölönen</surname><given-names>I</given-names></name><name><surname>Imai</surname><given-names>N</given-names></name><name><surname>Tommaselli</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Individual tree detection and classification with UAV-based photogrammetric point clouds and hyperspectral imaging</article-title><source>Remote Sens</source><year>2017</year><volume>9</volume><fpage>185</fpage><pub-id pub-id-type="doi">10.3390/rs9030185</pub-id></mixed-citation></ref><ref id="CR72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liang</surname><given-names>X</given-names></name><name><surname>Kankare</surname><given-names>V</given-names></name><name><surname>Hyyppä</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Kukko</surname><given-names>A</given-names></name><name><surname>Haggrén</surname><given-names>H</given-names></name><name><surname>Yu</surname><given-names>X</given-names></name><name><surname>Kaartinen</surname><given-names>H</given-names></name><name><surname>Jaakkola</surname><given-names>A</given-names></name><name><surname>Guan</surname><given-names>F</given-names></name><name><surname>Holopainen</surname><given-names>M</given-names></name><name><surname>Vastaranta</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Terrestrial laser scanning in forest inventories</article-title><source>ISPRS J Photogramm Remote Sens</source><year>2016</year><volume>115</volume><fpage>63</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.isprsjprs.2016.01.006</pub-id></mixed-citation></ref><ref id="CR73"><label>73.</label><mixed-citation publication-type="other">Wulder MA, Bater CW, Coops NC, Hilker TH, White JC. The role of LiDAR in sustainable forest management. For Chron. 2008;84:807–826.</mixed-citation></ref><ref id="CR74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liang</surname><given-names>X</given-names></name><name><surname>Jaakkola</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Hyyppä</surname><given-names>J</given-names></name><name><surname>Honkavaara</surname><given-names>E</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Kaartinen</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">The use of a hand-held camera for individual tree 3D mapping in forest sample plots</article-title><source>Remote Sens</source><year>2014</year><volume>6</volume><fpage>6587</fpage><lpage>6603</lpage><pub-id pub-id-type="doi">10.3390/rs6076587</pub-id></mixed-citation></ref><ref id="CR75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liang</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Jaakkola</surname><given-names>A</given-names></name><name><surname>Kukko</surname><given-names>A</given-names></name><name><surname>Kaartinen</surname><given-names>H</given-names></name><name><surname>Hyyppä</surname><given-names>J</given-names></name><name><surname>Honkavaara</surname><given-names>E</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Forest data collection using terrestrial image-based point clouds from a handheld camera compared to terrestrial and personal laser scanning</article-title><source>IEEE Trans Geosci Remote Sens</source><year>2015</year><volume>53</volume><fpage>5117</fpage><lpage>5132</lpage><pub-id pub-id-type="doi">10.1109/TGRS.2015.2417316</pub-id></mixed-citation></ref><ref id="CR76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Surový</surname><given-names>P</given-names></name><name><surname>Yoshimoto</surname><given-names>A</given-names></name><name><surname>Panagiotidis</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Accuracy of reconstruction of the tree stem surface using terrestrial close-range photogrammetry</article-title><source>Remote Sens</source><year>2016</year><volume>8</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.3390/rs8020123</pub-id></mixed-citation></ref><ref id="CR77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Feng</surname><given-names>Z</given-names></name><name><surname>Yang</surname><given-names>L</given-names></name><name><surname>Mannan</surname><given-names>A</given-names></name><name><surname>Khan</surname><given-names>T</given-names></name><name><surname>Zhao</surname><given-names>Z</given-names></name><name><surname>Cheng</surname><given-names>Z</given-names></name></person-group><article-title xml:lang="en">Extraction of sample plot parameters from 3D point cloud reconstruction based on combined RTK and CCD continuous photography</article-title><source>Remote Sens</source><year>2018</year><volume>10</volume><fpage>1299</fpage><pub-id pub-id-type="doi">10.3390/rs10081299</pub-id></mixed-citation></ref><ref id="CR78"><label>78.</label><mixed-citation publication-type="other">Mokroš M, Liang X, Surový P, Valent P, Čerňava J, Chudý F. Evaluation of close-range photogrammetry image collection methods for estimating tree diameters. Int J Geo-Inf. 2018;7:93.</mixed-citation></ref><ref id="CR79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morgenroth</surname><given-names>J</given-names></name><name><surname>Gomez</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Assessment of tree structure using a 3D image analysis technique-a proof of concept</article-title><source>Urban For Urban Green</source><year>2014</year><volume>13</volume><fpage>198</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1016/j.ufug.2013.10.005</pub-id></mixed-citation></ref><ref id="CR80"><label>80.</label><mixed-citation publication-type="other">Miller JM. Estimation of individual tree metrics using structure-from-motion photogrammetry. MSc Thesis. 2015.</mixed-citation></ref><ref id="CR81"><label>81.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bauwens</surname><given-names>S</given-names></name><name><surname>Fayolle</surname><given-names>A</given-names></name><name><surname>Gourlet-Fleury</surname><given-names>S</given-names></name><name><surname>Ndjele</surname><given-names>LM</given-names></name><name><surname>Mengal</surname><given-names>C</given-names></name><name><surname>Lejeune</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Terrestrial photogrammetry: a non-destructive method for modelling irregularly shaped tropical tree trunks</article-title><source>Methods Ecol Evol</source><year>2017</year><volume>8</volume><fpage>460</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1111/2041-210X.12670</pub-id></mixed-citation></ref><ref id="CR82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berveglieri</surname><given-names>A</given-names></name><name><surname>Tommaselli</surname><given-names>AMG</given-names></name><name><surname>Liang</surname><given-names>X</given-names></name><name><surname>Honkavaara</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Vertical optical scanning with panoramic vision for tree trunk reconstruction</article-title><source>Sensors (Switzerland)</source><year>2017</year><volume>17</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.3390/s17122791</pub-id></mixed-citation></ref><ref id="CR83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Chen</surname><given-names>C</given-names></name><name><surname>Tang</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Three-dimensional digitization of the arid land plant Haloxylon ammodendron using a consumer-grade camera</article-title><source>Ecol Evol</source><year>2018</year><volume>8</volume><fpage>5891</fpage><lpage>5899</lpage><pub-id pub-id-type="doi">10.1002/ece3.4126</pub-id></mixed-citation></ref><ref id="CR84"><label>84.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lausch</surname><given-names>A</given-names></name><name><surname>Erasmi</surname><given-names>S</given-names></name><name><surname>King</surname><given-names>D</given-names></name><name><surname>Magdon</surname><given-names>P</given-names></name><name><surname>Heurich</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Understanding forest health with remote sensing -part I—a review of spectral traits, processes and remote-sensing characteristics</article-title><source>Remote Sens</source><year>2016</year><volume>8</volume><fpage>1029</fpage><pub-id pub-id-type="doi">10.3390/rs8121029</pub-id></mixed-citation></ref><ref id="CR85"><label>85.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stone</surname><given-names>C</given-names></name><name><surname>Mohammed</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Application of remote sensing technologies for assessing planted forests damaged by insect pests and fungal pathogens: a review</article-title><source>Curr For Rep</source><year>2017</year><volume>3</volume><fpage>75</fpage><lpage>92</lpage></mixed-citation></ref><ref id="CR86"><label>86.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Näsi</surname><given-names>R</given-names></name><name><surname>Honkavaara</surname><given-names>E</given-names></name><name><surname>Lyytikäinen-Saarenmaa</surname><given-names>P</given-names></name><name><surname>Blomqvist</surname><given-names>M</given-names></name><name><surname>Litkey</surname><given-names>P</given-names></name><name><surname>Hakala</surname><given-names>T</given-names></name><name><surname>Viljanen</surname><given-names>N</given-names></name><name><surname>Kantola</surname><given-names>T</given-names></name><name><surname>Tanhuanpää</surname><given-names>T</given-names></name><name><surname>Holopainen</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Using UAV-based photogrammetry and hyperspectral imaging for mapping bark beetle damage at tree-level</article-title><source>Remote Sens</source><year>2015</year><volume>7</volume><fpage>15467</fpage><lpage>15493</lpage><pub-id pub-id-type="doi">10.3390/rs71115467</pub-id></mixed-citation></ref><ref id="CR87"><label>87.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Minařík</surname><given-names>R</given-names></name><name><surname>Langhammer</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Use of a multispectral UAV photogrammetry for detection and tracking of forest disturbance dynamics</article-title><source>Int Arch Photogramm Remote Sens Spat Inf Sci</source><year>2016</year><volume>41</volume><fpage>711</fpage><lpage>718</lpage><pub-id pub-id-type="doi">10.5194/isprsarchives-XLI-B8-711-2016</pub-id></mixed-citation></ref><ref id="CR88"><label>88.</label><mixed-citation publication-type="other">Aasen H, Bareth G. Spectral and 3D nonspectral approaches to crop trait estimation using ground and UAV sensing. In Biophys. Biochem. Charact. Plant Species Stud: CRC Press; 2019;103–32.</mixed-citation></ref><ref id="CR89"><label>89.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunt</surname><given-names>ER</given-names></name><name><surname>Daughtry</surname><given-names>CST</given-names></name></person-group><article-title xml:lang="en">What good are unmanned aircraft systems for agricultural remote sensing and precision agriculture?</article-title><source>Int J Remote Sens</source><year>2018</year><volume>39</volume><fpage>5345</fpage><lpage>5376</lpage><pub-id pub-id-type="doi">10.1080/01431161.2017.1410300</pub-id></mixed-citation></ref><ref id="CR90"><label>90.</label><mixed-citation publication-type="other">Pauly K. Towards calibrated vegetation indices from UAS-derived orthomosaics. 13th Int Conf Precis Agric. 2016. <ext-link xlink:href="10.13140/RG.2.2.21842.35524" ext-link-type="doi">https://doi.org/10.13140/RG.2.2.21842.35524</ext-link>.</mixed-citation></ref><ref id="CR91"><label>91.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Näsi</surname><given-names>R</given-names></name><name><surname>Honkavaara</surname><given-names>E</given-names></name><name><surname>Blomqvist</surname><given-names>M</given-names></name><name><surname>Lyytikäinen-Saarenmaa</surname><given-names>P</given-names></name><name><surname>Hakala</surname><given-names>T</given-names></name><name><surname>Viljanen</surname><given-names>N</given-names></name><name><surname>Kantola</surname><given-names>T</given-names></name><name><surname>Holopainen</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Remote sensing of bark beetle damage in urban forests at individual tree level using a novel hyperspectral camera from UAV and aircraft</article-title><source>Urban For Urban Green</source><year>2018</year><volume>30</volume><fpage>72</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1016/j.ufug.2018.01.010</pub-id></mixed-citation></ref><ref id="CR92"><label>92.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Minařík</surname><given-names>R</given-names></name><name><surname>Langhammer</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Use of a multispectral Uav photogrammetry for detection and tracking of forest disturbance dynamics</article-title><source>Int Arch Photogramm Remote Sens Spat Inf Sci</source><year>2016</year><volume>XLI-B8</volume><fpage>711</fpage><lpage>718</lpage><pub-id pub-id-type="doi">10.5194/isprsarchives-XLI-B8-711-2016</pub-id></mixed-citation></ref><ref id="CR93"><label>93.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baena</surname><given-names>S</given-names></name><name><surname>Moat</surname><given-names>J</given-names></name><name><surname>Whaley</surname><given-names>O</given-names></name><name><surname>Boyd</surname><given-names>DS</given-names></name></person-group><article-title xml:lang="en">Identifying species from the air: UAVs and the very high resolution challenge for plant conservation</article-title><source>PLoS One</source><year>2017</year><volume>12</volume><fpage>1</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0188714</pub-id></mixed-citation></ref><ref id="CR94"><label>94.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blaschke</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">Object based image analysis for remote sensing</article-title><source>ISPRS J Photogramm Remote Sens</source><year>2010</year><volume>65</volume><fpage>2</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1016/j.isprsjprs.2009.06.004</pub-id></mixed-citation></ref><ref id="CR95"><label>95.</label><mixed-citation publication-type="other">Frey J, Kovach K, Stemmler S, Koch B. UAV photogrammetry of forests as a vulnerable process. A sensitivity analysis for a structure from motion RGB-image pipeline. Remote Sens. 2018;10. <ext-link xlink:href="10.3390/rs10060912" ext-link-type="doi">https://doi.org/10.3390/rs10060912</ext-link>.</mixed-citation></ref><ref id="CR96"><label>96.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>W</given-names></name><name><surname>Sun</surname><given-names>G</given-names></name><name><surname>Pang</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Yang</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Mapping three-dimensional structures of forest canopy using UAV stereo imagery: evaluating impacts of forward overlaps and image resolutions with LiDAR data as reference</article-title><source>IEEE J Sel Top Appl Earth Obs Remote Sens</source><year>2018</year><volume>11</volume><fpage>3578</fpage><lpage>3589</lpage><pub-id pub-id-type="doi">10.1109/JSTARS.2018.2867945</pub-id></mixed-citation></ref><ref id="CR97"><label>97.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dandois</surname><given-names>JP</given-names></name><name><surname>Olano</surname><given-names>M</given-names></name><name><surname>Ellis</surname><given-names>EC</given-names></name></person-group><article-title xml:lang="en">Optimal altitude, overlap, and weather conditions for computer vision uav estimates of forest structure</article-title><source>Remote Sens</source><year>2015</year><volume>7</volume><fpage>13895</fpage><lpage>13920</lpage><pub-id pub-id-type="doi">10.3390/rs71013895</pub-id></mixed-citation></ref><ref id="CR98"><label>98.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>James</surname><given-names>MR</given-names></name><name><surname>Robson</surname><given-names>S</given-names></name><name><surname>Smith</surname><given-names>MW</given-names></name></person-group><article-title xml:lang="en">3-D uncertainty-based topographic change detection with structure-from-motion photogrammetry: precision maps for ground control and directly georeferenced surveys</article-title><source>Earth Surf Process Landf</source><year>2017</year><volume>42</volume><fpage>1769</fpage><lpage>1788</lpage><pub-id pub-id-type="doi">10.1002/esp.4125</pub-id></mixed-citation></ref></ref-list></ref-list><notes notes-type="Misc"><title>Publisher’s Note</title><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Ecology</facet-value><facet-value count="1">Environment</facet-value><facet-value count="1">Environmental Management</facet-value><facet-value count="1">Forestry</facet-value><facet-value count="1">Forestry Management</facet-value><facet-value count="1">Nature Conservation</facet-value><facet-value count="1">Sustainable Development</facet-value></facet><facet name="keyword"><facet-value count="1">Close-range photogrammetry (CRP)</facet-value><facet-value count="1">Forest health</facet-value><facet-value count="1">Forest inventory</facet-value><facet-value count="1">Point cloud</facet-value><facet-value count="1">SfM</facet-value><facet-value count="1">UAV</facet-value></facet><facet name="pub"><facet-value count="1">Current Forestry Reports</facet-value></facet><facet name="year"><facet-value count="1">2019</facet-value></facet><facet name="country"><facet-value count="1">Austria</facet-value><facet-value count="1">Germany</facet-value><facet-value count="1">Norway</facet-value><facet-value count="1">Spain</facet-value><facet-value count="1">United Kingdom</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
