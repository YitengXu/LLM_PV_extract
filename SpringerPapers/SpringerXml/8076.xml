<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1007/s10462-023-10466-8</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="research-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">10462</journal-id><journal-id journal-id-type="doi">10.1007/10462.1573-7462</journal-id><journal-title-group><journal-title>Artificial Intelligence Review</journal-title><journal-subtitle>An International Science and Engineering Journal</journal-subtitle><abbrev-journal-title abbrev-type="publisher">Artif Intell Rev</abbrev-journal-title></journal-title-group><issn pub-type="ppub">0269-2821</issn><issn pub-type="epub">1573-7462</issn><publisher><publisher-name>Springer Netherlands</publisher-name><publisher-loc>Dordrecht</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s10462-023-10466-8</article-id><article-id pub-id-type="manuscript">10466</article-id><article-id pub-id-type="doi">10.1007/s10462-023-10466-8</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title xml:lang="en">Deep learning modelling techniques: current progress, applications, advantages, and challenges</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="Au1"><name><surname>Ahmed</surname><given-names>Shams Forruque</given-names></name><address><email>shams.ahmed@auw.edu.bd</email><email>shams.f.ahmed@gmail.com</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="corresp" rid="IDs10462023104668_cor1">a</xref></contrib><contrib contrib-type="author" id="Au2"><name><surname>Alam</surname><given-names>Md. Sakib Bin</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au3"><name><surname>Hassan</surname><given-names>Maruf</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" id="Au4"><name><surname>Rozbu</surname><given-names>Mahtabin Rodela</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au5"><name><surname>Ishtiak</surname><given-names>Taoseef</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author" id="Au6"><name><surname>Rafa</surname><given-names>Nazifa</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author" id="Au7"><name><surname>Mofijur</surname><given-names>M.</given-names></name><xref ref-type="aff" rid="Aff6">6</xref><xref ref-type="aff" rid="Aff7">7</xref></contrib><contrib contrib-type="author" id="Au8"><name><surname>Shawkat Ali</surname><given-names>A. B. M.</given-names></name><xref ref-type="aff" rid="Aff8">8</xref><xref ref-type="aff" rid="Aff9">9</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au9"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2798-0104</contrib-id><name><surname>Gandomi</surname><given-names>Amir H.</given-names></name><address><email>gandomi@uts.edu.au</email></address><xref ref-type="aff" rid="Aff10">10</xref><xref ref-type="aff" rid="Aff11">11</xref><xref ref-type="corresp" rid="IDs10462023104668_cor9">j</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.449190.1</institution-id><institution-id institution-id-type="ISNI">0000 0000 8877 4625</institution-id><institution content-type="org-division">Science and Math Program</institution><institution content-type="org-name">Asian University for Women</institution></institution-wrap><addr-line content-type="postcode">4000</addr-line><addr-line content-type="city">Chattogram</addr-line><country country="BD">Bangladesh</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.418142.a</institution-id><institution-id institution-id-type="ISNI">0000 0000 8861 2220</institution-id><institution content-type="org-division">Data Science and Artificial Intelligence</institution><institution content-type="org-name">Asian Institute of Technology</institution></institution-wrap><addr-line content-type="postcode">12120</addr-line><addr-line content-type="city">Chang Wat</addr-line><addr-line content-type="state">Pathum Thani</addr-line><country country="TH">Thailand</country></aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.147455.6</institution-id><institution-id institution-id-type="ISNI">0000 0001 2097 0344</institution-id><institution content-type="org-division">Department of Computational Biology</institution><institution content-type="org-name">Carnegie Mellon University</institution></institution-wrap><addr-line content-type="postcode">15213</addr-line><addr-line content-type="city">Pittsburgh</addr-line><addr-line content-type="state">PA</addr-line><country country="US">USA</country></aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.34428.39</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 893X</institution-id><institution content-type="org-division">School of Computer Science</institution><institution content-type="org-name">Carleton University</institution></institution-wrap><addr-line content-type="postcode">K1S 5B6</addr-line><addr-line content-type="city">Ottawa</addr-line><addr-line content-type="state">ON</addr-line><country country="CA">Canada</country></aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.5335.0</institution-id><institution-id institution-id-type="ISNI">0000000121885934</institution-id><institution content-type="org-division">Department of Geography</institution><institution content-type="org-name">University of Cambridge</institution></institution-wrap><addr-line content-type="street">Downing Place</addr-line><addr-line content-type="postcode">CB2 3EN</addr-line><addr-line content-type="city">Cambridge</addr-line><country country="GB">UK</country></aff><aff id="Aff6"><label>6</label><institution-wrap><institution-id institution-id-type="GRID">grid.117476.2</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7611</institution-id><institution content-type="org-division">Centre for Technology in Water and Wastewater, School of Civil and Environmental Engineering</institution><institution content-type="org-name">University of Technology Sydney</institution></institution-wrap><addr-line content-type="postcode">2007</addr-line><addr-line content-type="city">Ultimo</addr-line><addr-line content-type="state">NSW</addr-line><country country="AU">Australia</country></aff><aff id="Aff7"><label>7</label><institution-wrap><institution-id institution-id-type="GRID">grid.449337.e</institution-id><institution-id institution-id-type="ISNI">0000 0004 1756 6721</institution-id><institution content-type="org-division">Mechanical Engineering Department</institution><institution content-type="org-name">Prince Mohammad Bin Fahd University</institution></institution-wrap><addr-line content-type="postcode">31952</addr-line><addr-line content-type="city">Al Khobar</addr-line><country country="SA">Saudi Arabia</country></aff><aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="GRID">grid.1023.0</institution-id><institution-id institution-id-type="ISNI">0000 0001 2193 0854</institution-id><institution content-type="org-division">School of Engineering and Technology</institution><institution content-type="org-name">Central Queensland University</institution></institution-wrap><addr-line content-type="postcode">300</addr-line><addr-line content-type="city">Melbourne</addr-line><addr-line content-type="state">VIC</addr-line><country country="AU">Australia</country></aff><aff id="Aff9"><label>9</label><institution-wrap><institution-id institution-id-type="GRID">grid.449678.0</institution-id><institution-id institution-id-type="ISNI">0000 0004 0416 0773</institution-id><institution content-type="org-division">School of Science and Technology</institution><institution content-type="org-name">The University of Fiji</institution></institution-wrap><addr-line content-type="city">Lautoka</addr-line><country country="FJ">Fiji</country></aff><aff id="Aff10"><label>10</label><institution-wrap><institution-id institution-id-type="GRID">grid.117476.2</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7611</institution-id><institution content-type="org-division">Faculty of Engineering and Information Technology</institution><institution content-type="org-name">University of Technology Sydney</institution></institution-wrap><addr-line content-type="postcode">2007</addr-line><addr-line content-type="city">Sydney</addr-line><addr-line content-type="state">NSW</addr-line><country country="AU">Australia</country></aff><aff id="Aff11"><label>11</label><institution-wrap><institution-id institution-id-type="GRID">grid.440535.3</institution-id><institution-id institution-id-type="ISNI">0000 0001 1092 7422</institution-id><institution content-type="org-division">University Research and Innovation Center (EKIK)</institution><institution content-type="org-name">Óbuda University</institution></institution-wrap><addr-line content-type="postcode">1034</addr-line><addr-line content-type="city">Budapest</addr-line><country country="HU">Hungary</country></aff></contrib-group><author-notes><corresp id="IDs10462023104668_cor1"><label>a</label><email>shams.ahmed@auw.edu.bd</email><email>shams.f.ahmed@gmail.com</email></corresp><corresp id="IDs10462023104668_cor9"><label>j</label><email>gandomi@uts.edu.au</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>17</day><month>4</month><year>2023</year></pub-date><fpage>1</fpage><lpage>97</lpage><history><date date-type="registration"><day>9</day><month>3</month><year>2023</year></date><date date-type="online"><day>17</day><month>4</month><year>2023</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2023</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">Deep learning (DL) is revolutionizing evidence-based decision-making techniques that can be applied across various sectors. Specifically, it possesses the ability to utilize two or more levels of non-linear feature transformation of the given data via representation learning in order to overcome limitations posed by large datasets. As a multidisciplinary field that is still in its nascent phase, articles that survey DL architectures encompassing the full scope of the field are rather limited. Thus, this paper comprehensively reviews the state-of-art DL modelling techniques and provides insights into their advantages and challenges. It was found that many of the models exhibit a highly domain-specific efficiency and could be trained by two or more methods. However, training DL models can be very time-consuming, expensive, and requires huge samples for better accuracy. Since DL is also susceptible to deception and misclassification and tends to get stuck on local minima, improved optimization of parameters is required to create more robust models. Regardless, DL has already been leading to groundbreaking results in the healthcare, education, security, commercial, industrial, as well as government sectors. Some models, like the convolutional neural network (CNN), generative adversarial networks (GAN), recurrent neural network (RNN), recursive neural networks, and autoencoders, are frequently used, while the potential of other models remains widely unexplored. Pertinently, hybrid conventional DL architectures have the capacity to overcome the challenges experienced by conventional models. Considering that capsule architectures may dominate future DL models, this work aimed to compile information for stakeholders involved in the development and use of DL models in the contemporary world.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Deep learning</kwd><kwd>Deep learning architecture</kwd><kwd>Neural network</kwd><kwd>Boltzmann machine</kwd><kwd>Deep belief network</kwd><kwd>Autoencoders</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution>University of Technology Sydney</institution></institution-wrap></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Springer</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>No</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>ContentOnly</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>3</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>9</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>ArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>ContentOnly</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>true</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/10462_2023_Article_10466.pdf</meta-value></custom-meta><custom-meta><meta-name>pdf-type</meta-name><meta-value>Typeset</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>OriginalPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Computer Science</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Artificial Intelligence</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Computer Science, general</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Computer Science</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Developing machines with the ability to ‘think’ has been a long-running aspiration of inventors throughout history. The popular idea of replicating intelligent human behavior arranged as processes in machines (Dick <xref ref-type="bibr" rid="CR57">2019</xref>) has fueled researchers’ imaginations. In the present time, artificial intelligence (AI) is a thriving and rapidly changing field with various applications in society and economics, such as understanding speech or images, textual analysis, and in supporting an actively growing research body (Lu et al. <xref ref-type="bibr" rid="CR160">2018</xref>). Machine learning (ML), a part of AI, is a multidisciplinary field spanning computer science, statistics, and data science that addresses the need for computers to improve automatically through experience and by the use of data (Jordan and Mitchell <xref ref-type="bibr" rid="CR113">2015</xref>). ML is advancing evidence-based decision-making in the fields of healthcare, education, national security, finance, economics, manufacturing, and marketing (Jordan and Mitchell, <xref ref-type="bibr" rid="CR113">2015</xref>), specifically by implementing various approaches to teach computers to achieve tasks. However, conventional ML techniques cannot efficiently process raw data and require mindful engineering and great expertise (Lecun et al. <xref ref-type="bibr" rid="CR133">2015</xref>). In the real world, every piece of data may be influenced by different factors of variations, thus requiring humans to factor in those variations and decide whether to incorporate them or not. Overcoming such flaws, deep learning (DL) has recently emerged as a promising approach in ML (Lecun et al. <xref ref-type="bibr" rid="CR133">2015</xref>), currently dominating the majority of the works in the field of ML (Alpaydin <xref ref-type="bibr" rid="CR14">2020</xref>).</p><p id="Par3">While it may appear as a seemingly new concept, the idea of DL can be traced back to the 1940s and subsequently underwent roughly three waves of development with the most recent current revival beginning in 2006 (Goodfellow et al. <xref ref-type="bibr" rid="CR81">2016</xref>). During the first wave between 1940 and 1960, DL was known as cybernetics, then it gained popularity again in the 1980s-1990s as connectionism. Fundamental methods such as radial basis function networks and multilayer perceptrons were employed in 2014 to solve the problem of designing mobile adaptive tracking controllers (Tzafestas <xref ref-type="bibr" rid="CR266">2014</xref>). These two neural networks were found suitable for decision-making and control. Later, Sengupta et al. (Sengupta et al. <xref ref-type="bibr" rid="CR227">2020</xref>) pointed out a few reasons why DL rose to prominence in the twenty-first century, including the surge of “big data” with quality labels, improvements in regularization techniques, development of near-perfect optimization algorithms, creation of niche software platforms that can enable the integration of architectures, and advancements in parallel computing power and multi-core, multi-threaded execution. In fact, big data became a huge issue for conventional ML algorithms along with the increasing size of the network, whereby the performance of old algorithms either became overloaded or deteriorated (Khamparia and Singh <xref ref-type="bibr" rid="CR120">2019</xref>). The enhanced performance of DL can be attributed to its ability to utilize two or more levels of non-linear feature transformation of the given data (Zeiler and Fergus <xref ref-type="bibr" rid="CR294">2014</xref>).</p><p id="Par4">Deep learning allows computational models with multiple layers to gradually extract higher-level features from the raw input (Alpaydin <xref ref-type="bibr" rid="CR14">2020</xref>; Deng and Yu <xref ref-type="bibr" rid="CR53">2014</xref>). The “deep” in DL, therefore, denotes a high credit assignment path (CAP) depth, which has been assigned a value of 2 by most researchers (Sugiyama <xref ref-type="bibr" rid="CR241">2019</xref>; Telikani et al. <xref ref-type="bibr" rid="CR261">2021</xref>; Kashyap et al. <xref ref-type="bibr" rid="CR118">2021</xref>; Mousavi and Gandomi <xref ref-type="bibr" rid="CR177">2021</xref>; Tahmassebi et al. <xref ref-type="bibr" rid="CR252">2018a, b</xref>, <xref ref-type="bibr" rid="CR254">2019</xref>, <xref ref-type="bibr" rid="CR255">2020</xref>; Jayaraman et al. <xref ref-type="bibr" rid="CR110">2020</xref>; Kumar et al. <xref ref-type="bibr" rid="CR129">2019</xref>). Deep learning enables computers to learn complex concepts by forming them out of simple ones. Goodfellow et al. (<xref ref-type="bibr" rid="CR81">2016</xref>) adequately explained that, “Deep learning is a particular kind of machine learning that achieves great power and flexibility by learning to represent the world as a nested hierarchy of concepts, with each concept defined in relation to simpler concepts, and more abstract representations computed in terms of less abstract ones” (Goodfellow et al. <xref ref-type="bibr" rid="CR81">2016</xref>). DL is primarily based on artificial neural networks, a type of computing system roughly mimicking the biological neural networks of animal brains (Chen et al. <xref ref-type="bibr" rid="CR41">2019</xref>), and may employ supervised, unsupervised, or semi-supervised representation learning (Bengio et al. <xref ref-type="bibr" rid="CR26">2013</xref>; Lecun et al. <xref ref-type="bibr" rid="CR133">2015</xref>; Schmidhuber <xref ref-type="bibr" rid="CR225">2015</xref>). Representation learning, also known as feature learning, sets DL apart from other techniques in ML. Unlike manual feature engineering, feature learning enables computers to spontaneously find the representations required for the classifications from raw data (Bengio et al. <xref ref-type="bibr" rid="CR26">2013</xref>). DL, therefore, relies on very little hand-tuning and has the ability to analyze the rapidly increasing computations and data. The requirement for manual engineering is only restricted to operations, such as altering the numbers and sizes of layers, to yield different degrees of abstraction (Bengio et al. <xref ref-type="bibr" rid="CR26">2013</xref>; Lecun et al. <xref ref-type="bibr" rid="CR133">2015</xref>).</p><p id="Par5">The applications of DL span various disciplines and sectors. To begin with, DL has exhibited remarkable performance in image recognition (Carrio et al. <xref ref-type="bibr" rid="CR36">2017</xref>; Krizhevsky and Hinton <xref ref-type="bibr" rid="CR128">2017</xref>; Lecun et al. <xref ref-type="bibr" rid="CR133">2015</xref>; Szegedy et al. <xref ref-type="bibr" rid="CR250">2015</xref>; Tompson et al. <xref ref-type="bibr" rid="CR263">2014</xref>; Wei et al. <xref ref-type="bibr" rid="CR277">2019</xref>), displayed potential in image restoration (Schmidt <xref ref-type="bibr" rid="CR226">2014</xref>), and demonstrated groundbreaking results in speech recognition (Cireşan et al. <xref ref-type="bibr" rid="CR45">2012</xref>; Deoras et al. <xref ref-type="bibr" rid="CR55">2011</xref>; Hinton et al. <xref ref-type="bibr" rid="CR98">2012</xref>; Lecun et al. <xref ref-type="bibr" rid="CR133">2015</xref>; Sainath et al. <xref ref-type="bibr" rid="CR221">2013</xref>). It is currently used in the speech recognition systems of major day-to-day products (Case et al. <xref ref-type="bibr" rid="CR37">2014</xref>; Deng and Yu <xref ref-type="bibr" rid="CR53">2014</xref>; Lemley et al. <xref ref-type="bibr" rid="CR139">2017</xref>) as well as in the operation of unmanned vehicles (Carrio et al. <xref ref-type="bibr" rid="CR36">2017</xref>). The area of language processing has also been harnessing the benefits of DL (Deng and Yu <xref ref-type="bibr" rid="CR53">2014</xref>), in which DL contributes to natural language understanding and translation (Collobert et al. <xref ref-type="bibr" rid="CR46">2011</xref>; Mesnil et al. <xref ref-type="bibr" rid="CR166">2015</xref>; Sutskever et al. <xref ref-type="bibr" rid="CR247">2014</xref>), query response (Bordes et al. <xref ref-type="bibr" rid="CR29">2014</xref>), sentiment analysis, text classification, information recovery (Huang et al. <xref ref-type="bibr" rid="CR105">2013</xref>; Shen et al. <xref ref-type="bibr" rid="CR230">2014</xref>), and writing style recognition (Brocardo et al. <xref ref-type="bibr" rid="CR32">2017</xref>), just to name a few. DL has also been revolutionizing the health sector (Miotto et al. <xref ref-type="bibr" rid="CR171">2018</xref>), particularly yielding far-reaching implications for drug discovery and design and in effectively predicting interactions of potential drugs with molecules of interest (Ma et al. <xref ref-type="bibr" rid="CR162">2015</xref>). DL’s ability to acquire end-to-end learning models from complex, unstructured, diverse, and poorly annotated data has also led to advancements in biomedical research (Collobert et al. <xref ref-type="bibr" rid="CR46">2011</xref>; Naylor <xref ref-type="bibr" rid="CR181">2018</xref>; Ravì et al. <xref ref-type="bibr" rid="CR215">2017</xref>). With its high image recognition skills, DL has been applied in clinical imaging, such as neuroimaging (Sui et al. <xref ref-type="bibr" rid="CR242">2020</xref>), and has shown great promise in the identification and detection of lesions, cancer cells, and different organs, as well as in image enhancement (Cao et al. <xref ref-type="bibr" rid="CR35">2019</xref>; Litjens et al. <xref ref-type="bibr" rid="CR154">2017</xref>; Wieslander et al. <xref ref-type="bibr" rid="CR278">2017</xref>). Bioinformatics has also applied DL for predicting gene ontology annotations, understanding the functions of different genes (Chicco et al. <xref ref-type="bibr" rid="CR43">2014</xref>), and most importantly for anticipating how mutations in non-coding DNA affect gene expressions and susceptibility to diseases (Leung et al. <xref ref-type="bibr" rid="CR141">2014</xref>; Xiong et al. <xref ref-type="bibr" rid="CR283">2016</xref>).</p><p id="Par6">DL’s applications range far beyond science. For example, the military has taken advantage of the highly efficient image and object recognition ability of DL for various operations (Mendis et al. <xref ref-type="bibr" rid="CR165">2016</xref>; Yang et al. <xref ref-type="bibr" rid="CR288">2018</xref>). Businesses have applied DL for improving their customer relationship management, where it allows for the estimation of the customer lifetime value that would result from possible direct marketing activities (Tkachenko <xref ref-type="bibr" rid="CR262">2015</xref>). The recommendation systems in various commercial products utilize DL to understand and predict user preferences (Da’u and Salim <xref ref-type="bibr" rid="CR48">2020</xref>; Feng et al. <xref ref-type="bibr" rid="CR69">2019</xref>; Oord et al. <xref ref-type="bibr" rid="CR191">2013</xref>). Similarly, it has been also used in targeting an appropriate audience for mobile advertisements (De et al. <xref ref-type="bibr" rid="CR50">2017</xref>). Furthermore, DL utilizes both supervised and unsupervised learning in financial fraud detection and anti-money laundering by identifying anomalies and abnormal money transactions (Paula et al. <xref ref-type="bibr" rid="CR203">2016</xref>). While DL has been helping to advance several fields of research, society, and the economy, it can also be exploited for malicious attempts. For instance, DL has been drawing criticisms for compromising cybersecurity as it is susceptible to attacks by hackers and to deceit (Li et al. <xref ref-type="bibr" rid="CR148">2019a</xref>, <xref ref-type="bibr" rid="CR142">b</xref>, <xref ref-type="bibr" rid="CR143">c</xref>, <xref ref-type="bibr" rid="CR144">d</xref>; Norton and Qi <xref ref-type="bibr" rid="CR187">2017</xref>; Papernot et al. <xref ref-type="bibr" rid="CR196">2016</xref>). Nevertheless, DL modelling architectures suffer from some errors; in several instances, DL was found to misclassify or randomly classify images (Nguyen et al. <xref ref-type="bibr" rid="CR184">2015</xref>; Szegedy et al. <xref ref-type="bibr" rid="CR250">2015</xref>). To tackle these issues, it is pertinent to design models that internally create states that are equivalent to image-grammar (Zhu and Mumford <xref ref-type="bibr" rid="CR310">2006</xref>). In addition, Mühlhoff (<xref ref-type="bibr" rid="CR178">2020</xref>) has argued that despite its much-extolled advantage of requiring minimal hand-tuning, DL, in fact, relies on microwork by humans, thereby calling it “a form of distributed orchestration of human cognition through networked media technology” (Mühlhoff <xref ref-type="bibr" rid="CR178">2020</xref>).</p><p id="Par7">The uses of DL technologies in the contemporary world and their potential for further applications cannot be disregarded, despite some limitations. Many scholarly works have been undertaken to comprehensively review the applications of DL technologies across different sectors. Most review works focus on specific areas and implementations of DL (Arulkumaran et al. <xref ref-type="bibr" rid="CR17">2017</xref>; Gheisari et al. <xref ref-type="bibr" rid="CR76">2017</xref>; Pouyanfar et al. <xref ref-type="bibr" rid="CR210">2018</xref>; Vargas et al. <xref ref-type="bibr" rid="CR269">2017</xref>). Other reviews have surveyed DL architectures and algorithms in the context of specific applications, such as speech emotion recognition (Fayek et al. <xref ref-type="bibr" rid="CR68">2017</xref>; Pandey et al. <xref ref-type="bibr" rid="CR195">2019</xref>), text classification (Zulqarnain et al. <xref ref-type="bibr" rid="CR313">2020</xref>), early diagnosis of Alzheimer’s (Ortiz et al. <xref ref-type="bibr" rid="CR193">2016</xref>), electronic health records (Roberto et al. <xref ref-type="bibr" rid="CR217">2020</xref>; Xiao et al. <xref ref-type="bibr" rid="CR282">2018</xref>), medical image analysis (Akkus et al. <xref ref-type="bibr" rid="CR8">2017</xref>; Cao et al. <xref ref-type="bibr" rid="CR35">2019</xref>; Liu et al. <xref ref-type="bibr" rid="CR155">2019</xref>; Shoeibi et al. <xref ref-type="bibr" rid="CR232">2020</xref>), time series forecasting (Lara-ben and Carranza-garc <xref ref-type="bibr" rid="CR131">2021</xref>), aircraft maintenance, repair, and overhaul (Rengasamy et al. <xref ref-type="bibr" rid="CR216">2018</xref>), and land cover mapping (Pashaei and Kamangir <xref ref-type="bibr" rid="CR202">2020</xref>). With DL having gained momentum only recently, review articles on DL architectures encompassing the full scope of the field are still lacking. Dixit et al. (Dixit et al. <xref ref-type="bibr" rid="CR59">2018</xref>) provided a brief overview of seven of the most widely used DL architectures (deep neural networks, deep belief networks, recurrent neural networks, deep Boltzmann machine, restricted Boltzmann machine, deep autoencoders, and convolutional neural networks), a list of DL libraries, and some of the most common applications. However, as is perceivable, their paper is not a comprehensive review of existing architectures. In addition to the models discussed by Dixit et al. (<xref ref-type="bibr" rid="CR59">2018</xref>), Sengupta et al. (<xref ref-type="bibr" rid="CR227">2020</xref>) have covered generative adversarial neural networks and highlighted tests that can be undertaken before implementing different neural networks in safety–critical systems. Shrestha et al. (Shrestha <xref ref-type="bibr" rid="CR233">2019</xref>) provided a rigorous overview of the neural networks and DNNs and found certain limitations that constrain training, such as overfitting, long training time, and high susceptibility to getting stuck in the local minima.</p><p id="Par8">Khamparia and Singh (<xref ref-type="bibr" rid="CR120">2019</xref>) contributed perhaps one of the most important studies on DL architectures, even though it is limited to neural networks. Their meta-analysis critically reviewed twelve DL modelling techniques and found that advanced DL architectures that are combinations of a few conventional architectures are far more robust than their conventional counterparts. A comprehensive list of DL architectures and their related applications was also presented. Nevertheless, as a continuously expanding and developing field, there is a need to critically review and compile information on the state-of-art DL modelling techniques. Therefore, by first delving into a brief discussion on DL as a subset of ML, this paper comprehensively reviews all of the available DL modelling techniques. While these modelling techniques have many benefits across multiple disciplines, they are not without limitations. Therefore, this paper also highlights the advantages and drawbacks of these models and concludes with future perspectives on DL models, providing directions for enhancing the architecture designs and increasing the implementation of DL technologies across more sectors. Overall, this paper aims to disseminate essential information on the constantly evolving field of deep learning and direct future research towards improving existing modelling techniques.</p></sec><sec id="Sec2"><title>Methodology for selecting, collecting, and analyzing pertinent data</title><p id="Par9">This review utilized an integrative literature method to analyze almost all available deep learning modelling approaches, as well as their current progress, applications, advantages, and challenges. Throughout this method, relevant and reliable papers were selected, collected, filtered, carefully evaluated and analyzed. The database was found using credible websites, e.g. Scopus and refereed journals from reputable publishers such as Nature, Elsevier, Taylor &amp; Francis, Springer, Wiley, ACS, Inderscience, MDPI, Frontiers, and Sage. Relevant keywords such as “Deep learning”, “Deep learning architecture”, “Deep learning modelling”, “Advantages of deep learning”, “Challenges of deep learning”, “Future of deep learning”, and each deep learning model such as “Vector space model”, “Convolutional neural network”, “Recurrent neural network” and so on, were used to find out publications related to the present work. Through the Scopus database, 186,154 papers published within the last five years were identified. The references and bibliographies of the aforementioned publications were sifted and compiled in order to locate more relevant papers. The following criteria were used to thoroughly scan and categorize the abstract, introduction, and conclusion from selected papers:<list list-type="order"><list-item><p id="Par10">Preliminary consideration was given to only peer-reviewed articles from reputable publishers and websites</p></list-item><list-item><p id="Par11">Researchers who are actively engaged in the relevant research field were chosen and collected</p></list-item><list-item><p id="Par12">The selected publications were evaluated for their balance between modern studies and prior research</p></list-item><list-item><p id="Par13">Referring to websites that employ the aforementioned keywords commercially</p></list-item><list-item><p id="Par14">The most recent and cutting-edge algorithms relevant to the present work were emphasised</p></list-item><list-item><p id="Par15">Some publications of relevance that were cited in recent studies were rigorously retrieved as the original source of the studies.</p></list-item></list></p><p id="Par16">The above criteria assisted in selecting 748 papers that are more relevant. Throughout the entire review process of available relevant papers, several questions were raised. To answer these questions, some other references were sourced and examined for further clarification and improvement. Papers for the present study were chosen based on a set of inclusion and exclusion criteria, which are illustrated in Table <xref rid="Tab1" ref-type="table">1</xref>. A total of 419 articles were finally selected by applying the exclusion criteria. Although the exclusion criteria appeared to provide a solid foundation to find peer-reviewed and high-quality academic articles, some of the characteristics of the exclusion criteria appeared to be biased and skewed, making it difficult to discover high-quality academic journals. The authors conducted a test–retest procedure to overcome this issue.<table-wrap id="Tab1"><label>Table 1</label><caption xml:lang="en"><p>Inclusion and exclusion criteria to select papers for the present review</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Inclusion criteria</p></th><th align="left"><p>Exclusion criteria</p></th></tr></thead><tbody><tr><td align="left"><p>The publications chosen are all academic and peer-reviewed</p></td><td align="left"><p>Even if they are academic or peer-reviewed, publications lacking a robust discussion are not included</p></td></tr><tr><td align="left"><p>The publications should be pertinent to the topic of the present study</p></td><td align="left"><p>Publications that lack information about the aforementioned keywords are not selected</p></td></tr><tr><td align="left"><p>The papers should be capable of answering the research questions</p></td><td align="left"><p>The results of any literature that showed a high level of repetition were filtered out</p></td></tr><tr><td align="left"><p>Any additional information that appears pertinent and valuable is also selected</p></td><td align="left"><p>Any literature with insufficient references and contexts was not considered</p></td></tr></tbody></table></table-wrap></p></sec><sec id="Sec3"><title>Deep learning</title><p id="Par17">Deep learning (DL) is considered an evolution of machine learning (ML) that incorporates algorithms to learn from data to accomplish some tasks without being explicitly programmed (Lecun et al. <xref ref-type="bibr" rid="CR133">2015</xref>). Both ML and DL are a subset of artificial intelligence (AI). ML powers a wide range of automated functions in various businesses, from data security services hunting down malware to finance specialists looking for trade warnings. It has also a wide variety of applications in modern society, such as: developing intelligent personal assistants for finding helpful information (Dhyani and Kumar <xref ref-type="bibr" rid="CR56">2019</xref>), recommender systems that can suggest relevant items to the users (Zhang et al. <xref ref-type="bibr" rid="CR302">2019</xref>), machine translation to provide the most accurate translation of any text in any language (Poliak et al. <xref ref-type="bibr" rid="CR208">2018</xref>), and predicting the class of object in an image (Chen et al. <xref ref-type="bibr" rid="CR39">2018a</xref>; <xref ref-type="bibr" rid="CR40">b</xref>). The way machines can learn new techniques becomes interesting whenever deep learning techniques are employed. The effectiveness of traditional machine-learning approaches is comparatively lower than DL techniques, as illustrated in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, considering that they require a large volume of data to provide significant results. For a long time, designing a feature extractor for machine learning systems demanded hand-crafted features to simplify the learning process. However, such feature extraction techniques need human expertise and significant domain understanding.<fig id="Fig1"><label>Fig. 1</label><caption xml:lang="en"><p>Performance of deep learning against traditional learning (Ng <xref ref-type="bibr" rid="CR182">2015</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig1_HTML.png" id="MO1"/></fig></p><p id="Par18">Deep learning allows machines to learn from their mistakes and comprehend the world as a hierarchy of concepts. In this learning process, the machines learn from data using a general-purpose learning algorithm, thus needing less human expertise to describe all the knowledge that the machine requires expressly. The models of DL employ a layered network architecture, known as an artificial neural network (ANN) (Schmidhuber <xref ref-type="bibr" rid="CR225">2015</xref>), which is modelled after the human brain's analogous networks. The embedding of layers results in a significantly more efficient learning experience than traditional machine learning models. The ability of deep learning to achieve high-level features from a massive amount of input data, referred to as feature engineering, distinguishes it from machine learning. As a result, deep learning is gaining popularity with innovative applications in natural language processing (NLP), computer vision, and predictive modelling (Ahmad et al. <xref ref-type="bibr" rid="CR7">2019</xref>).</p></sec><sec id="Sec4"><title>Deep learning modelling techniques</title><p id="Par19">Deep learning modelling techniques enable computational models to learn feature representation in data using multiple processing layers and several levels of abstraction (Lecun et al. <xref ref-type="bibr" rid="CR133">2015</xref>). Artificial neural networks (ANNs) provide the foundation of advanced deep learning models (Schmidhuber <xref ref-type="bibr" rid="CR225">2015</xref>) and perform well in a variety of domains. However, ANNs suffer from certain drawbacks, such as no guaranteed convergence to an optimal solution and being prone to overfitting the training data. Therefore, researchers have tried to find solutions using deep architecture. The term “deep” in “deep learning” was motivated by the number of processing layers through which the data must pass in the network. A deep learning model is made up of multiple layers that stack up on top of each other (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). The first layer (input) consists of units containing values fed to every neuron in the first hidden layer, then the predicted results come out of the model from the output (final) layer. The number of units in this layer equals the number of output classes desired. The hidden layers placed between the input and output layers apply weights to the inputs and pass them through an activation function. The activation function is used to help the network add non-linearity and learn complex relationships in the data. The backpropagation algorithm computes the error between the predicted result and the desired class in the output layer, then proceeds to the hidden layer to reduce the loss by adjusting the weights. This process is repeated until the output is accurate enough to be useful.<fig id="Fig2"><label>Fig. 2</label><caption xml:lang="en"><p><bold>a</bold> Conventional neural network <bold>b</bold> Deep learning neural network (Oka et al. <xref ref-type="bibr" rid="CR190">2021</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig2_HTML.png" id="MO2"/></fig></p><p id="Par20">Considering the concepts of neural networks discussed above, several deep learning modelling techniques are built as described in the following subsections. These techniques have various applications, such as the detection, classification of objects in images and video data (Lea et al. <xref ref-type="bibr" rid="CR132">2016</xref>), finding sentiment and emotion from text data (Jin Wang et al. <xref ref-type="bibr" rid="CR275">2016a</xref>; Hassan et al. <xref ref-type="bibr" rid="CR94">2018</xref>; Majumder et al. <xref ref-type="bibr" rid="CR164">2019</xref>), audio processing applications like speech recognition (Rao et al. <xref ref-type="bibr" rid="CR213">2018a</xref>; <xref ref-type="bibr" rid="CR214">b</xref>), and neural machine translation (NMT) with translation between different languages (Sutskever et al. <xref ref-type="bibr" rid="CR247">2014</xref>). Developing a deep learning-based model in these fields requires the pre-processing of raw data, feature selection, optimal parameter determination, and the evaluation of classification accuracy and convergence speed. This section covers different types of deep learning modelling approaches and explains their underlying mathematical concepts, advancements, latest implementations, and applications in various fields.</p><sec id="Sec5"><title>Vector space model</title><p id="Par21">The vector space model (VSM) is an arithmetic model in which texts are represented as vectors. It has been successfully applied in information filtering, information retrieval, and other areas (Abualigah and Hanandeh, <xref ref-type="bibr" rid="CR211">2015</xref>; Van Gysel et al. <xref ref-type="bibr" rid="CR268">2018</xref>; Mitra and Craswell <xref ref-type="bibr" rid="CR173">2017</xref>). The vector elements describe the weights or importance of every word in a document. The cosine similarity technique can be applied to find the degree of similarity between two documents (Günther et al. <xref ref-type="bibr" rid="CR86">2016</xref>). In the vector space model shown below, documents are described as a term-document matrix (Shi et al. <xref ref-type="bibr" rid="CR231">2018</xref>) or a term-frequency matrix, where the rows represent the documents and the terms are defined by the columns. Words, sentences, or phrases are often used as terms, each of which depends on the application and context. Each cell signifies the term’s weight in a document, and if a term is present in the document, the cell value will be non-zero.<disp-formula id="Equa"><alternatives><mml:math display="block" id="Equa_Math"><mml:mfenced close="]" open="["><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd/></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi>D</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>T</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi>w</mml:mi><mml:mn>11</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>w</mml:mi><mml:mn>12</mml:mn></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mo>⋯</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>T</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msub><mml:mi>T</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>w</mml:mi><mml:mn>21</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>w</mml:mi><mml:mn>22</mml:mn></mml:msub></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msub><mml:mi>w</mml:mi><mml:mn>11</mml:mn></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>⋯</mml:mo></mml:mtd><mml:mtd><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi mathvariant="italic">tn</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math><tex-math id="Equa_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left[\begin{array}{ccc}\begin{array}{c}\\ {D}_{1}\\ \begin{array}{c}{D}_{2}\\ \cdots \\ {D}_{n}\end{array}\end{array}&amp; \begin{array}{c}{T}_{1}\\ {w}_{11}\\ \begin{array}{c}{w}_{12}\\ \cdots \\ {w}_{1n}\end{array}\end{array}&amp; \begin{array}{c}\begin{array}{ccc}{T}_{2}&amp; \dots &amp; {T}_{t}\end{array}\\ \begin{array}{ccc}{w}_{21}&amp; \dots &amp; {w}_{t1}\end{array}\\ \begin{array}{c}\begin{array}{ccc}{w}_{22}&amp; \dots &amp; {w}_{11}\end{array}\\ \begin{array}{ccc}\cdots &amp; \cdots &amp; \cdots \end{array}\\ \begin{array}{ccc}{w}_{2n}&amp; \cdots &amp; {w}_{tn}\end{array}\end{array}\end{array}\end{array}\right]$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equa.gif"/></alternatives></disp-formula></p><p id="Par22">Suppose there is a document <inline-formula id="IEq1"><alternatives><mml:math id="IEq1_Math"><mml:msub><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><tex-math id="IEq1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{k}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq1.gif"/></alternatives></inline-formula> and a query <inline-formula id="IEq2"><alternatives><mml:math id="IEq2_Math"><mml:mi>q</mml:mi></mml:math><tex-math id="IEq2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$q$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq2.gif"/></alternatives></inline-formula>. The cosine similarity formula can be used to find the similarity between <inline-formula id="IEq3"><alternatives><mml:math id="IEq3_Math"><mml:msub><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><tex-math id="IEq3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{k}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq3.gif"/></alternatives></inline-formula> and <inline-formula id="IEq4"><alternatives><mml:math id="IEq4_Math"><mml:mi>q</mml:mi></mml:math><tex-math id="IEq4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$q$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq4.gif"/></alternatives></inline-formula> using the formula:<disp-formula id="Equ1"><label>1</label><alternatives><mml:math display="block" id="Equ1_Math"><mml:mrow><mml:mi mathvariant="italic">cos</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:msqrt><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ1_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathit{cos}\left({D}_{k}, q\right)= \frac{{\sum }_{i=1}^{N}{w}_{i,j}{w}_{i, q}}{\sqrt{{\sum }_{i=1}^{N}{{w}_{i,j}}^{2}}\sqrt{{\sum }_{i=1}^{N}{{w}_{i,q}}^{2}}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ1.gif"/></alternatives></disp-formula></p><p id="Par23">The query and document vectors are not correlated if the cosine value gives zero in Eq. (<xref rid="Equ1" ref-type="disp-formula">1</xref>). The vector space model assumes that the terms are independent of each other. As a result, the model ignores the possibility of semantically related index terms.</p><sec id="Sec6"><title>Word embedding</title><p id="Par24">In recent years, research interest in the concept of using a vector representation of words and word embedding has increasingly progressed. The latter has been often utilized in advanced natural language processing applications, such as information retrieval, question answering (Zhou et al. <xref ref-type="bibr" rid="CR309">2016</xref>), and machine translation (Zhang et al. <xref ref-type="bibr" rid="CR299">2017a</xref>; <xref ref-type="bibr" rid="CR300">b</xref>, <xref ref-type="bibr" rid="CR301">c</xref>). Word embedding is a method of generating vectors and mapping them to associated words. Tomas Mikolov’s word2vec (Mikolov et al. <xref ref-type="bibr" rid="CR170">2013</xref>) models can generate high-dimensional vector representations of words when training on a large text dataset (Demeester et al. <xref ref-type="bibr" rid="CR51">2016</xref>). These vectors are capable of capturing syntactic and semantic information. In its simplest form, a word2vec model involves the training of a simple neural network to complete a task and includes only one hidden layer in the neural network, as shown in Fig.. The goal is to simply learn the hidden layers' weights, which are used as word vectors in many applications (Zhang et al. <xref ref-type="bibr" rid="CR297">2015</xref>). The size of the input layer depends on the number of words in the vocabulary for training, where one neuron represents one word. The hidden layer size is defined by how many dimensions we want to keep in the resulting word vectors. It is suggested that the dimensionality of the vectors be set between 100 and 1000 in the original model (Demeester et al. <xref ref-type="bibr" rid="CR51">2016</xref>). Higher dimensionality provides high quality of word embedding, while the output layer has the same size as the input layer.</p><p id="Par25">To train the embedded weights, the continuous bag of words (CBOW) and skip-gram are two useful techniques. Given a target word, the skip-gram model attempts to predict alternative context words. Here, input to hidden layer connections remains the same as the word2vec fully connected network. However, a simple modification is made in the hidden to output layer connection to give space for the selected number of context words. Contrariwise, the CBOW model aims to predict target words given a set of context words, the number of which depends on the setting of the window size. For example, in the sentence, “the quick brown fox jumped over the lazy dog.”, ‘the’ and ‘brown’ might be used as context words and ‘quick’ as the target word. A tweak to the neural network architecture is required in this scenario as is a simple modification to adjust the input to hidden layer connection C times. Here, C is the number of context words. By adding these configurations to the network, the hidden layer's output can be found by taking the mean of the context words. The steps after calculating the hidden layer remain precisely the same. A text classification system was proposed by Ali et al. (<xref ref-type="bibr" rid="CR12">2019</xref>) for retrieving transportation sentiment from social networking and news sites. The authors combined a topic2vec and word2vec to create a word embedding model that describes the documents using a low dimensional vector but keeps the semantic meanings. The model obtains a sentiment classification accuracy of 93% with transportation datasets, outperforming topic2vec document representation approaches. The model treats the unimportant words as sentiment words that cause decreasing classification performance. However, sophisticated data pre-processing is needed to improve classification accuracy (see Figs. <xref rid="Fig2" ref-type="fig">2</xref>, <xref rid="Fig3" ref-type="fig">3</xref>).<fig id="Fig3"><label>Fig. 3</label><caption xml:lang="en"><p>Illustration of word2vec fully connected neural network (Orkphol and Yang <xref ref-type="bibr" rid="CR192">2019</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig3_HTML.png" id="MO3"/></fig></p></sec><sec id="Sec7"><title>Sentence embedding</title><p id="Par26">The sentence embedding model aims to produce a fixed-length continuous vector representing the entire input. A rough sense of the relative locations of the sentence vectors in the original vector space can be obtained from the figure. Similar sentences are close together in summary-vector space. Skip-thought is one of the popular sentence embedding models that demonstrates significant results in several tasks, including semantic similarity, paraphrase detection, image annotation (how well the sentences describe an image), and classifications (Kiros et al. <xref ref-type="bibr" rid="CR124">2015</xref>).</p><p id="Par27">Vector representation, which is used for words, phrases, sentences, paragraphs, documents, or even images, can be generalized as representing “thoughts.” On the other hand, the skip-thought model abstracts skip-gram architecture to the sentence level (Kiros et al. <xref ref-type="bibr" rid="CR124">2015</xref>). The idea behind this model is that the context words embed a word's meaning. The model tries to map sentences with common syntactic and semantic information into similar vectors by reconstructing the neighbouring sentence. The skip-thought model has three main parts: encoder, previous decoder, and next decoder, as shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>.<fig id="Fig4"><label>Fig. 4</label><caption xml:lang="en"><p>Skip-thought model overview (Hassan et al. <xref ref-type="bibr" rid="CR94">2018</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig4_HTML.png" id="MO4"/></fig></p><p id="Par28">In Fig. <xref rid="Fig4" ref-type="fig">4</xref>, given a sentence <inline-formula id="IEq5"><alternatives><mml:math id="IEq5_Math"><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq5.gif"/></alternatives></inline-formula> at index <inline-formula id="IEq6"><alternatives><mml:math id="IEq6_Math"><mml:mi>i</mml:mi></mml:math><tex-math id="IEq6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq6.gif"/></alternatives></inline-formula>, the encoder produces a fixed-length representation <inline-formula id="IEq7"><alternatives><mml:math id="IEq7_Math"><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq7_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq7.gif"/></alternatives></inline-formula>. It needs to access the word embedding layer (also called the lookup table layer) that maps each word into a corresponding vector. Inside an encoder, a recurrent neural network (RNN) with the gated recurrent unit (GRU) or long short-term memory (LSTM) activation is fed every word sequentially in a sentence. This encoder captures the temporal patterns of sequential word vectors. The previous decoder takes the embedding <inline-formula id="IEq8"><alternatives><mml:math id="IEq8_Math"><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq8_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq8.gif"/></alternatives></inline-formula> from the encoder and “tries” to generate the proceeding sentence <inline-formula id="IEq9"><alternatives><mml:math id="IEq9_Math"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="IEq9_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s}_{i-1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq9.gif"/></alternatives></inline-formula>. This decoder uses another recurrent network that generates the sentence sequentially and shares the same lookup table layer from the encoder. The next decoder takes the embedding <inline-formula id="IEq10"><alternatives><mml:math id="IEq10_Math"><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq10_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq10.gif"/></alternatives></inline-formula> from the encoder and “tries” to generate the subsequent sentence <inline-formula id="IEq11"><alternatives><mml:math id="IEq11_Math"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="IEq11_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s}_{i+1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq11.gif"/></alternatives></inline-formula>. This decoder also uses a recurrent network similar to the previous decoder. The encoder is the end result of the skip-thought model as it contains syntactic and semantic information.</p><p id="Par29">Due to the vast amount of textual data surfacing online, the demand for text summarization is continuously increasing worldwide. As a result, the necessity of natural language processing (NLP) models arises to extract the essential and valuable information from the long text while maintaining critical information. Mohd et al. (<xref ref-type="bibr" rid="CR176">2020</xref>) introduced a text summarizer that obtains the features of a long text document using different techniques, such as Latent Dirichlet Allocation (LDA) and Term Frequency-Inverse Document Frequency (TF-IDF), which represents each sentence as a numerical vector. Similar vectors are aggregated together using a genetic algorithm. Lastly, the LDA technique was utilized to obtain the center sentence of each cluster to be included in the resulting summary. The macro-average of precision from the experimental results was found to be 34%, which is higher than the benchmark standard. However, the technique was performed on only one dataset, and thus the precision may not be feasible.</p><p id="Par30">Different types of difficulties, such as combining syntactic information or identifying different labels for the document classification task, are acknowledged using DocBERT. The DocBERT is a document classification model based on Bidirectional Encoder Representations from Transformers (BERT) (Adhikari et al. <xref ref-type="bibr" rid="CR5">2019</xref>). The general idea is to use a fully connected layer to filter the representation obtained from the common language specification (CLS) token and then employ a SoftMax layer to convert 768-dimensional encoding to class distribution. Adhikari et al. (<xref ref-type="bibr" rid="CR5">2019</xref>) reported the state-of-the-art results on four popular datasets, attempting to address the BERT model's high computational expense and reduce the parameters by 30-fold. The average document length was found to be less than BERT, while the maximum length was 512. However, BERT can outperform non-contextual embeddings on various tasks, such as the clinical domain. Si et al. (<xref ref-type="bibr" rid="CR234">2019</xref>) explored the performance of classic word embedding approaches (word2vec, GloVe) and contextualized methods (BERT) on a clinical concept extraction task. The output of the BERT model was fed into a bi-LSTM, which showed that contextual embeddings play a significant role in achieving better performance (F1-measures of 93.18) on various benchmark tests in the datasets like SemEval.</p></sec><sec id="Sec8"><title>Graph embedding</title><p id="Par31">Graph embedding is a technique for transforming a whole graph into a single vector while preserving the graph's relevant information. The resulting vectors contain highly informative features that can be used for the task, such as node classification, ranking, alignment, link prediction, clustering, and visualization. The primary goal of graph embedding techniques is to reflect high-dimensional points into a residual continuous vector space with low dimensions (Fig. <xref rid="Fig5" ref-type="fig">5</xref>). As a result, it is easy to compute the node similarity using the dot product or cosine distance formula. Graph analytics is also considerably faster and more accurate than computing in the high-dimensional complex graph domain.<fig id="Fig5"><label>Fig. 5</label><caption xml:lang="en"><p>Graph embedding (Xu <xref ref-type="bibr" rid="CR284">2020</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig5_HTML.png" id="MO5"/></fig></p><p id="Par32">Although matrix-factorization approaches have been proposed to represent a node earlier, they are significantly affected by conventional dimension reduction techniques. Comparatively, recent techniques focus on learning node embeddings using random walk characteristics. A graph structure can be translated into a sample collection of linear sequences using the DeepWalk model (Perozzi et al. <xref ref-type="bibr" rid="CR205">2014</xref>), which employs hierarchical SoftMax techniques as the loss function. The primary concept underlying this method is to learn embeddings, and therefore (Hamilton et al. <xref ref-type="bibr" rid="CR91">2017</xref>):<disp-formula id="Equ2"><label>2</label><alternatives><mml:math display="block" id="Equ2_Math"><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>C</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>≜</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msup><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>z</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>≈</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ2_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$DEC\left({z}_{i}, {z}_{j}\right)\triangleq \frac{{e}^{{z}_{i}^{T}{z}_{j}}}{{\sum }_{{v}_{k}\in V}{e}^{{z}_{i}^{T}{z}_{k}}}\approx {P}_{g}, T({v}_{j}|{v}_{i})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ2.gif"/></alternatives></disp-formula>where <inline-formula id="IEq12"><alternatives><mml:math id="IEq12_Math"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="IEq12_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${P}_{g}, T({v}_{j}|{v}_{i})$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq12.gif"/></alternatives></inline-formula> denotes the probability of visiting from vertex <inline-formula id="IEq13"><alternatives><mml:math id="IEq13_Math"><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq13_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq13.gif"/></alternatives></inline-formula> to <inline-formula id="IEq14"><alternatives><mml:math id="IEq14_Math"><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="IEq14_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{j}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq14.gif"/></alternatives></inline-formula> on a length-<italic>T</italic><inline-formula id="IEq15"><alternatives><mml:math id="IEq15_Math"><mml:mrow><mml:mo>;</mml:mo><mml:mi mathvariant="normal">and</mml:mi><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>C</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq15_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$;\mathrm{ and} DEC\left({z}_{i}, {z}_{j}\right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq15.gif"/></alternatives></inline-formula> is a function that takes the node embeddings <inline-formula id="IEq16"><alternatives><mml:math id="IEq16_Math"><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq16_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq16.gif"/></alternatives></inline-formula> and <inline-formula id="IEq17"><alternatives><mml:math id="IEq17_Math"><mml:msub><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="IEq17_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${z}_{j}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq17.gif"/></alternatives></inline-formula> and uses them to decode the graph metrics.</p><p id="Par33">A hypergraph embedding method, LBSN2Vec, was developed by Yang et al. (<xref ref-type="bibr" rid="CR290">2019</xref>) for location-based social network (LBSN) data that enhances friendship and location prediction task effectiveness. LBSN provides services to the users to publish their location and location-related contents like photos or notes. Encoding both users and places into low-dimensional vectors produces hyperedges by sampling friendships and checking-in using a random walk. The model chooses two nodes from the sample graph and then feeds the nodes into a model similar to skip-gram to generate low-dimensional vectors representing the nodes. The authors revealed that the LBSN2Vec model outperforms the baseline graph embeddings in predicting the friendship of two individuals and location prediction by 32.95% and 25.32%, respectively. However, the study was limited to random walk approaches for the location prediction task in the hypergraph. Further research is thus required to take advantage of the meta-graph or hypergraph for the deep learning-based recommendation model.</p></sec></sec><sec id="Sec9"><title>Convolutional neural network</title><p id="Par34">Convolutional neural networks (CNNs) are particularly useful to reduce the number of parameters in an ANN. This has inspired researchers and practitioners to consider adopting larger models to accomplish tasks that were previously difficult to handle with regular ANNs. The CNN model is influenced by an animal's visual cortex and is intended to learn low-level to high-level features from the data received gradually. For example, the model first detects the low-level edge in the first layer in the image classification task and then the high-level features like shapes and faces in an image (see Fig. <xref rid="Fig5" ref-type="fig">5</xref>).</p><p id="Par35">To understand the architecture of CNN, we explain the essential CNN model components. A CNN model is comprised of three primary layers: convolution, pooling, and fully connected layers. The first two layers generate features from the input, while the third layer, the fully connected layer, connects the extracted features to the final output. The convolution layers retrieve the high-level characteristics from the data provided. The primary objective is to compute different feature maps by projecting a tiny array of numbers called a "kernel" to the input data. The input is also known as a tensor. An element-wise product between each kernel element and the input tensor is performed at each position of the tensor. Then, the summation of these values is calculated and applied to the associated index of the output tensor (Fig. <xref rid="Fig6" ref-type="fig">6</xref>). Multiple kernels are used to repeat this process to produce an arbitrary number of feature maps. Each feature map represents distinct input tensors' characteristics, and each kernel can be considered as a different feature generator. The size and number of kernels are two primary hyperparameters that describe the convolution operation. Usually, the kernels' size is 3 × 3, but it can also be 5 × 5 or 7 × 7. The number of kernels is chosen arbitrarily depending on the depth of the output feature maps. Mathematically, convolution operation can be defined by the following equation (Khan et al. <xref ref-type="bibr" rid="CR121">2020</xref>):<disp-formula id="Equ3"><label>3</label><alternatives><mml:math display="block" id="Equ3_Math"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>c</mml:mi></mml:munder><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>i</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>⊙</mml:mo><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equ3_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f_{l}^{k} \left( {p, q} \right) = \mathop \sum \limits_{c} \mathop \sum \limits_{x,y} i_{c} \left( {x,y} \right) \odot e_{l}^{k} \left( {u, v} \right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ3.gif"/></alternatives></disp-formula>where <inline-formula id="IEq18"><alternatives><mml:math id="IEq18_Math"><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup></mml:math><tex-math id="IEq18_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{l}^{k}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq18.gif"/></alternatives></inline-formula> is the output feature map of the <inline-formula id="IEq19"><alternatives><mml:math id="IEq19_Math"><mml:mi>k</mml:mi></mml:math><tex-math id="IEq19_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq19.gif"/></alternatives></inline-formula>-th convolution operation of the <inline-formula id="IEq20"><alternatives><mml:math id="IEq20_Math"><mml:mi>l</mml:mi></mml:math><tex-math id="IEq20_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq20.gif"/></alternatives></inline-formula>-th layer. This can be computed as <inline-formula id="IEq21"><alternatives><mml:math id="IEq21_Math"><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mfenced><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>P</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="IEq21_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{l}^{k}=[{f}_{l}^{k}\left(\mathrm{1,1}\right), \dots {f}_{l}^{k}\left(p, q\right),\dots {f}_{l}^{k}(P, Q)]$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq21.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq22"><alternatives><mml:math id="IEq22_Math"><mml:msub><mml:mi>i</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:math><tex-math id="IEq22_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${i}_{c}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq22.gif"/></alternatives></inline-formula> is the input tensor and <inline-formula id="IEq23"><alternatives><mml:math id="IEq23_Math"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq23_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${i}_{c}\left(x,y\right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq23.gif"/></alternatives></inline-formula> is an element of that tensor. These values will be element-wise multiplied by <inline-formula id="IEq24"><alternatives><mml:math id="IEq24_Math"><mml:mrow><mml:msubsup><mml:mi>e</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="IEq24_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${e}_{l}^{k}(u, v)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq24.gif"/></alternatives></inline-formula>, the <inline-formula id="IEq25"><alternatives><mml:math id="IEq25_Math"><mml:mi>k</mml:mi></mml:math><tex-math id="IEq25_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq25.gif"/></alternatives></inline-formula>-th convolutional kernel of the <inline-formula id="IEq26"><alternatives><mml:math id="IEq26_Math"><mml:mi>l</mml:mi></mml:math><tex-math id="IEq26_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq26.gif"/></alternatives></inline-formula>-th layer.<fig id="Fig6"><label>Fig. 6</label><caption xml:lang="en"><p>Convolution operation</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig6_HTML.png" id="MO6"/></fig></p><p id="Par36">CNN introduces non-linearity to the network by applying a non-linear activation function. Previously, the popular choice was non-linear activation functions, including sigmoid or tangent functions (LeCun et al. <xref ref-type="bibr" rid="CR134">2012</xref>). However, to resolve the vanishing gradient problem (Nwankpa et al. <xref ref-type="bibr" rid="CR188">2018</xref>) of the sigmoid and tangent function, Rectified Linear Unit (ReLU) and its variants, such as leaky ReLU and Parametric Rectified Linear Unit (PReLU), are used. One of the recently proposed activation functions named Mish outperforms ReLU and other typical activation functions in many deep networks across benchmark datasets (Misra <xref ref-type="bibr" rid="CR172">2019</xref>). The activation function of the convolutional feature map can be computed as:<disp-formula id="Equ4"><label>4</label><alternatives><mml:math display="block" id="Equ4_Math"><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ4_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${a}_{l}^{k}=g({F}_{l}^{k})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ4.gif"/></alternatives></disp-formula>where <inline-formula id="IEq27"><alternatives><mml:math id="IEq27_Math"><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup></mml:math><tex-math id="IEq27_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{l}^{k}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq27.gif"/></alternatives></inline-formula> is the output of a convolutional operation that goes to an activation function <italic>g()</italic>; and <inline-formula id="IEq28"><alternatives><mml:math id="IEq28_Math"><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup></mml:math><tex-math id="IEq28_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${a}_{l}^{k}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq28.gif"/></alternatives></inline-formula> is the non-linear output of the <italic>k</italic>-th input feature map in the <inline-formula id="IEq29"><alternatives><mml:math id="IEq29_Math"><mml:mi>l</mml:mi></mml:math><tex-math id="IEq29_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq29.gif"/></alternatives></inline-formula>-th layer.</p><p id="Par37">The extracted features from the convolutional and pooling layers are flattened to a one-dimensional array of numbers. Those features are then fed into the traditional neural network, where each input is connected to its subsequent layer neurons by a learnable weight. The main drawback of a fully CNN is that it requires training many parameters, which contributes to its high computational expense and possible overfitting. The dropout technique is used to overcome such difficulties, in which a few nodes and connections are removed (Goodfellow et al. <xref ref-type="bibr" rid="CR82">2013</xref>). The output layer is the final layer of CNNs, where <inline-formula id="IEq30"><alternatives><mml:math id="IEq30_Math"><mml:mrow><mml:mi mathvariant="italic">softmax</mml:mi></mml:mrow></mml:math><tex-math id="IEq30_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$softmax$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq30.gif"/></alternatives></inline-formula> function is widely used to provide probability distribution (Russakovsky et al. <xref ref-type="bibr" rid="CR218">2015</xref>). Another classifier, the support vector machine (SVM), can also classify data (Tang <xref ref-type="bibr" rid="CR258">2013</xref>).</p><p id="Par38">Parallel computing has made CNNs more efficient than humans in recognizing visual patterns, making them a desirable alternative for wide-area monitoring because of their advantages over humans. Mukherjee et al. (<xref ref-type="bibr" rid="CR179">2020</xref>) proposed a CNN-based generative model, namely “GenInSAR”, for combined coherence estimation and phase filtering which directly learns interferometric synthetic aperture radar (InSAR) data distribution. InSAR is a developing and extremely successful remote sensing method for monitoring a variety of geophysical parameters, including surface deformation. The unsupervised training on simulated and satellite InSAR images of the proposed model (GenInSAR) outperformed the other comparable methods (CNN-InSAR(as-is), CNN-InSAR(retrained), NLSAR, NLInSAR, Goldstein, Boxcar) in reducing the total residue (by more than 16.5% on average), with fewer over-smoothing/artifacts surrounding branch cuttings. Compared to the related methods, the phase cosine error, coherence and phase root-mean-square-error of GenInSAR were improved by 0.05, 0.07 and 0.54, respectively. As a result, the InSAR machine learning can be improved by GenInSAR's ability to produce new interferograms.</p><sec id="Sec10"><title>CNN-LSTM</title><p id="Par39">Long short-term memory (LSTM) can learn long-term relationships in data. However, spatial data like images are challenging to model with the standard LSTM. The convolutional neural network combined with long short-term memory (CNN-LSTM) is based on an LSTM network that is primarily designed for sequence prediction tasks where the input is spatial data, such as images, videos, or temporal structure of words in a sentence, paragraph, or document. The model shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref> illustrates the combined regional CNN and LSTM to identify the sentiment of text (Wang et al. <xref ref-type="bibr" rid="CR275">2016a</xref>), which considers an individual sentence as a region and long-distance relationship of sentences in the prediction task.<fig id="Fig7"><label>Fig. 7</label><caption xml:lang="en"><p>Regional CNN-LSTM model for sentiment analysis (Jin Wang et al. <xref ref-type="bibr" rid="CR275">2016a</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig7_HTML.png" id="MO7"/></fig></p><p id="Par40">The main architecture of the CNN-LSTM model consists of the input layer, convolution layer, pooling layer, sequential layer (LSTM hidden layer), and fully connected layer. The first three layers are the CNN layers. The CNN layer's output data is transferred to the LSTM layer. Following temporal modelling, the data from the LSTM layers are sent to a fully connected layer. These layers are well-suited to produce higher-order features that are easy to distinguish within distinct categories. The CNN model is used for feature extraction, while the LSTM model is employed for data interpretation over time.</p></sec><sec id="Sec11"><title>Temporal convolutional network (TCN)</title><p id="Par41">The novel work on the temporal convolutional networks (TCNs) was first proposed by Lea et al. (<xref ref-type="bibr" rid="CR132">2016</xref>) for video-based action segmentation. This approach involves two phases: (i) CNN computes the low-level features that encapsulate spatial–temporal information, and (ii) RNN feeds the low-level features into a classifier to extract the high-level temporal information. Although TCN demands the integration of two different models, it offers a unified technique to capture all two layers of information in a hierarchical manner. The original TCN model possesses a convolutional encoder and decoder architecture. The model captures a set of video features as the input and then extracts a <italic>D</italic>-dimensional feature vector for each video frame. If a video has <italic>T</italic> frames, the input <italic>X</italic> appends all the frame-wise features in a way that <inline-formula id="IEq31"><alternatives><mml:math id="IEq31_Math"><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>×</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="IEq31_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X\in {\mathbb{R}}^{T\times D}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq31.gif"/></alternatives></inline-formula>. Similar to other CNN architectures, the networks apply some filters followed by non-linear activation of the input to extract features. The convolution consists of <italic>l</italic> layers, where the collection of filters in each layer is defined as <inline-formula id="IEq32"><alternatives><mml:math id="IEq32_Math"><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:msubsup></mml:math><tex-math id="IEq32_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\{{W}^{(i)}\}}_{i=1}^{{F}_{l}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq32.gif"/></alternatives></inline-formula> for <inline-formula id="IEq33"><alternatives><mml:math id="IEq33_Math"><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="IEq33_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}^{(i)}\in {\mathbb{R}}^{d\times {F}_{l-1}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq33.gif"/></alternatives></inline-formula>. Here, <inline-formula id="IEq34"><alternatives><mml:math id="IEq34_Math"><mml:msub><mml:mi>F</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="IEq34_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{l}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq34.gif"/></alternatives></inline-formula> is the number of convolution filters in the <italic>l</italic> layer with a temporal window <italic>d.</italic> If <inline-formula id="IEq35"><alternatives><mml:math id="IEq35_Math"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="IEq35_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{l-1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq35.gif"/></alternatives></inline-formula> is an output from the previous layer, the <italic>l</italic>-th layer output, <inline-formula id="IEq36"><alternatives><mml:math id="IEq36_Math"><mml:msub><mml:mi>X</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><tex-math id="IEq36_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{l}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq36.gif"/></alternatives></inline-formula>, can be calculated as follows (Kim and Reiter <xref ref-type="bibr" rid="CR123">2017</xref>):<disp-formula id="Equ5"><label>5</label><alternatives><mml:math display="block" id="Equ5_Math"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ5_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${X}_{l}=f(W*{X}_{l-1})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ5.gif"/></alternatives></disp-formula>where <inline-formula id="IEq37"><alternatives><mml:math id="IEq37_Math"><mml:mi>f</mml:mi></mml:math><tex-math id="IEq37_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq37.gif"/></alternatives></inline-formula> denotes any non-linear activations functions, e.g., ReLu.</p><p id="Par42">Convolutional neural networks and their variants are used in various applications, such as the detection, classification of objects in images and video data, finding sentiment and emotions in natural language data, and audio processing applications like voice recognition. A CNN-based architecture named LeafNet was developed by Barré et al. (<xref ref-type="bibr" rid="CR21">2017</xref>) to identify plant species from the leaf images. The authors experimented with their model on three publicly available state-of-the-art datasets of leaf images: LeafSnap, Foliage, and Flavia. The previous studies on these datasets were based on the hand-crafted feature extraction technique. After data augmentation, approximately 270,000 leaf images were used on a 17-layer CNN to train the LeafNet model with image sizes of 256 × 256 pixels. Improved accuracies (by 0.8–13.3%) of 86.3%, 95.8%, and 97.9% were found on the LeafSnap, Foliage, and Flavia datasets, respectively, compared to previous studies. However, this method is comparatively slow (training takes about 32 h) and lacks context due to the small, cropped window sizes.</p><p id="Par43">In another work, a region-based convolutional neural network (R-CNN) has been applied in the computer vision field for the object detection task. Li et al. (<xref rid="CR148" ref-type="bibr">2019a</xref>, <xref rid="CR142" ref-type="bibr">b</xref>, <xref rid="CR143" ref-type="bibr">c</xref>, <xref rid="CR144" ref-type="bibr">d</xref>) proposed the stereo R-CNN method that can perform three-dimensional (3D) object detection in autonomous vehicle navigation. The method identifies and integrates objects in both the left and right images simultaneously and uses a region-based object detection alignment to retrieve the correct 3D bounding box. The stereo R-CNN captures input images with a resolution of 600 × 2000 and takes advantage of ImageNet’s pre-trained ResNet-101. The model was evaluated on the KITTI object detection benchmark. The proposed method outperformed a previous study (Chen et al. <xref ref-type="bibr" rid="CR39">2018a</xref>, <xref ref-type="bibr" rid="CR40">b</xref>) for 3D object proposals by over 25–30%. Due to the absence of precise depth information, the model can only produce shallow 3D detection results. Variations in appearance can also have a significant impact.</p><p id="Par44">Chen et al. (<xref ref-type="bibr" rid="CR39">2018a</xref>, <xref ref-type="bibr" rid="CR40">b</xref>) introduced an unsupervised domain adaptation model for cross-domain object detection based on the faster R-CNN model (Zhang et al. <xref ref-type="bibr" rid="CR298">2016a</xref>, <xref ref-type="bibr" rid="CR304">b</xref>). They employed two domain classifiers: one for high-level features at the global image scale and another for features clipped by the region proposal network at the instance (object) scale. The model was validated for different domain shift datasets. Via experiments, the authors found that the domain adaptive faster R-CNN model outperforms the faster R-CNN model by over 8.8%. This improvement was found consistent across the categories, thus indicating that the suggested method can minimize domain mismatch between object categories. However, the model was not trained to recognize traffic in darkness and is only adaptable to specific scenarios.</p><p id="Par45">A dynamic CNN-based system was proposed by Chu et al. (<xref ref-type="bibr" rid="CR44">2017</xref>) for tracking objects in videos. Using shared CNN features and Region of Interest Pooling, the model takes advantage of single object trackers. The experimental results showed that the proposed online multi-object tracking algorithm outperforms Markov decision processes by 4%. Although the model performed well in tracking objects, it is unsuitable for applications with limited resources. Also, the model may consume a lot of memory and time as it constructs a network for individual objects and performs online learning. Since CNN works well for both image classification and natural language processing tasks, CNN-based text classification models are gaining popularity. For instance, multi-layer CNN produces optimal features during the training process to reflect the semantics of the sentence being evaluated. These semantic constructs can be applied to a variety of applications, including text classification, text summarization, and information retrieval.</p><p id="Par46">A CNN-based method was suggested by Hughes et al. (<xref ref-type="bibr" rid="CR106">2017</xref>) for classifying clinical texts into one of 26 categories, such as “Brain” or “Cancer.” The model classifies texts by converting each document into a sentence-level representation. The authors used two stacked convolutional layers followed by a pooling layer. The experimental analysis revealed that the model improves the word embedding-based methods by accuracy of around 15%. However, the model was trained with a relatively small dataset (4000 sentences). To improve the model performance, domain adaptation techniques can be used to transfer knowledge from another domain to the medical field (Sun et al. <xref ref-type="bibr" rid="CR245">2016</xref>).</p><p id="Par47">CNN-based models have also been successfully applied in the sentiment analysis of Twitter data. To predict user behavior via sentiment analysis, Liao et al. (<xref ref-type="bibr" rid="CR149">2017</xref>) examined different deep learning techniques. They employed CNN and word embedding techniques to get better results than traditional learning algorithms, such as SVM and Naive Bayes classifiers. Their approach interpreted the sentence matrix to be the same as an image matrix. A linear kernel was convoluted to that sentence matrix, and a max-pooling function was applied to each feature to find the fixed-length representation of the sentence. The model was assessed on several benchmark datasets, including MR and STS Gold. The maximum development accuracy was found to be up to 74.5%. To improve the model accuracy, a multilayer CNN may be used instead of a simple CNN (single channel) for sentence classification.</p><p id="Par48">CNN-based approaches are also becoming more prominent in cosmology because of their noticeable performance. DeepSphere is a graph-based CNN that works on cosmological data analysis (Perraudin et al. <xref ref-type="bibr" rid="CR206">2019</xref>) to predict a class from a map and classify pixels. The data often come as spherical maps represented as a graph in the network so that the model can perform the convolution and pooling operations. In the latter work, DeepSphere outperformed all the baselines by 10% in terms of classification accuracy. However, the model was applied to only the classification problem performed on scalar fields. To further demonstrate the performance of DeepSphere, it would be useful to make comparisons to various spherical CNN implementations with different sampling techniques.</p></sec></sec><sec id="Sec12"><title>Recurrent neural network (RNN)</title><p id="Par49">Recurrent neural networks (RNNs) have recently demonstrated promising performance on various natural language processing tasks and have produced superior results on multiple tasks, such as sentiment classification (Wang et al. <xref ref-type="bibr" rid="CR276">2016c</xref>), image captioning (Yao et al. <xref ref-type="bibr" rid="CR291">2017</xref>), and language translation (Li et al. <xref ref-type="bibr" rid="CR146">2017a</xref>; <xref ref-type="bibr" rid="CR147">b</xref>). There are numerous situations in which data sequences describe the case itself. For example, in a language modelling task, a sequence of words defines their meaning. If the sequences are disturbed, the information makes no sense. In a traditional neural network, the assumption is that there has no dependency between the input and output. Considering this case, a network connecting to prior information is needed to fully comprehend the data. As a response, RNNs are useful, which are termed from the fact that they execute the same computation for each sequence element. The output in every state is dependent on the previous calculation. RNNs keep a "memory" that captures the information about what has been computed so far (Tomaš Mikolov et al. <xref ref-type="bibr" rid="CR168">2010</xref>, <xref ref-type="bibr" rid="CR169">2011</xref>). An RNN can be unfolded into an entire network, as illustrated in Fig. <xref rid="Fig8" ref-type="fig">8</xref>.<fig id="Fig8"><label>Fig. 8</label><caption xml:lang="en"><p>Unfolded recurrent neural network (Lecun et al. <xref ref-type="bibr" rid="CR133">2015</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig8_HTML.png" id="MO8"/></fig></p><p id="Par50">The computation flows running in an RNN for the text processing task are as follows:<list list-type="bullet"><list-item><p id="Par51"><inline-formula id="IEq38"><alternatives><mml:math id="IEq38_Math"><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq38_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq38.gif"/></alternatives></inline-formula> denotes the present input at time step <italic>t</italic>, where input is given as a one-hot encoded vector. For example, <inline-formula id="IEq39"><alternatives><mml:math id="IEq39_Math"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:math><tex-math id="IEq39_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{1}={\begin{array}{cc}[\begin{array}{cc}\begin{array}{cc}1&amp; 0\end{array}&amp; \begin{array}{cc}0&amp; 0\end{array}\end{array}&amp; 0\end{array}]}^{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq39.gif"/></alternatives></inline-formula> is the initial word in a sentence.</p></list-item><list-item><p id="Par52"><inline-formula id="IEq40"><alternatives><mml:math id="IEq40_Math"><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq40_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq40.gif"/></alternatives></inline-formula> signifies the hidden state at time step <italic>t</italic>, captures the “memory of the network, and is computed using the previous hidden state and the present step's input:<disp-formula id="Equ6"><label>6</label><alternatives><mml:math display="block" id="Equ6_Math"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>U</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>W</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ6_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s}_{t}=f(U{x}_{t}+W{s}_{t-1})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ6.gif"/></alternatives></disp-formula></p></list-item></list>where <inline-formula id="IEq41"><alternatives><mml:math id="IEq41_Math"><mml:mi>f</mml:mi></mml:math><tex-math id="IEq41_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq41.gif"/></alternatives></inline-formula> is an element-wise non-linear function, such as <inline-formula id="IEq42"><alternatives><mml:math id="IEq42_Math"><mml:mrow><mml:mi mathvariant="italic">tanh</mml:mi></mml:mrow></mml:math><tex-math id="IEq42_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$tanh$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq42.gif"/></alternatives></inline-formula> or <inline-formula id="IEq43"><alternatives><mml:math id="IEq43_Math"><mml:mrow><mml:mi mathvariant="italic">ReLU</mml:mi></mml:mrow></mml:math><tex-math id="IEq43_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ReLU$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq43.gif"/></alternatives></inline-formula>. In the case of calculating the first hidden state, <inline-formula id="IEq44"><alternatives><mml:math id="IEq44_Math"><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="IEq44_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s}_{t-1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq44.gif"/></alternatives></inline-formula> is typically set to all zeros. <bold>W</bold> and <bold>U</bold> are the weight matrix of the hidden state and input, respectively.<list list-type="bullet"><list-item><p id="Par53"><inline-formula id="IEq45"><alternatives><mml:math id="IEq45_Math"><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq45_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${o}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq45.gif"/></alternatives></inline-formula> represents the output at time step <italic>t</italic>. For instance, to predict the next word in a sentence, the probability can be calculated by applying the <inline-formula id="IEq46"><alternatives><mml:math id="IEq46_Math"><mml:mrow><mml:mi mathvariant="italic">softmax</mml:mi></mml:mrow></mml:math><tex-math id="IEq46_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$softmax$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq46.gif"/></alternatives></inline-formula> function.<disp-formula id="Equ7"><label>7</label><alternatives><mml:math display="block" id="Equ7_Math"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ7_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${o}_{t}=softmax(V{s}_{t})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ7.gif"/></alternatives></disp-formula></p></list-item></list></p><p id="Par54">An RNN can, in theory, summarize all historical information up to time step <inline-formula id="IEq47"><alternatives><mml:math id="IEq47_Math"><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq47_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq47.gif"/></alternatives></inline-formula>. Unfortunately, the accuracy of RNNs is significantly inhibited by the vanishing gradient problem (Bengio et al. <xref ref-type="bibr" rid="CR25">1994</xref>). To address this problem, gated recurrent units and long short-term memory have become more powerful models and gained acceptance in recent years as the best strategy to implement recurrent neural networks.</p><sec id="Sec13"><title>Long short-term memory (LSTM)</title><p id="Par55">A long short-term memory (LSTM) network is comprised of different memory blocks referred to as cells. A cell is constructed by gates that control the flow of information: forget, input, and output gates (Fig. <xref rid="Fig9" ref-type="fig">9</xref>). A forget gate removes information from a cell configuration, and the input gate updates the newly entered data to the cell. The input gate determines the rate at which new data enter the cell, whereas the output gate limits the data in the cell and computes the output activation of the LSTM unit.<fig id="Fig9"><label>Fig. 9</label><caption xml:lang="en"><p>A schematic for a long short-term memory cell (Jenkins et al. <xref ref-type="bibr" rid="CR111">2018</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig9_HTML.png" id="MO9"/></fig></p><p id="Par56">The gating mechanism in a LSTM can be defined by the following equations:<disp-formula id="Equ8"><label>8</label><alternatives><mml:math display="block" id="Equ8_Math"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ8_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${i}_{t}=\sigma ({W}^{i}{x}_{t}+{U}^{i}{h}_{t-1}+{b}^{i})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ8.gif"/></alternatives></disp-formula><disp-formula id="Equ9"><label>9</label><alternatives><mml:math display="block" id="Equ9_Math"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ9_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{t}=\sigma ({W}^{f}{x}_{t}+{U}^{f}{h}_{t-1}+{b}^{f})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ9.gif"/></alternatives></disp-formula><disp-formula id="Equ10"><label>10</label><alternatives><mml:math display="block" id="Equ10_Math"><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>o</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mi>o</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>o</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ10_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${o}_{t}=\sigma ({W}^{o}{x}_{t}+{U}^{o}{h}_{t-1}+{b}^{o})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ10.gif"/></alternatives></disp-formula><disp-formula id="Equ11"><label>11</label><alternatives><mml:math display="block" id="Equ11_Math"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ11_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widetilde{C}}_{t}=tanh({W}^{g}{x}_{t}+{U}^{g}{h}_{t-1}+{b}^{g})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ11.gif"/></alternatives></disp-formula><disp-formula id="Equ12"><label>12</label><alternatives><mml:math display="block" id="Equ12_Math"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="Equ12_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${C}_{t}= {f}_{t}\otimes {C}_{t-1}+{i}_{t}\otimes {\widetilde{C}}_{t}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ12.gif"/></alternatives></disp-formula><disp-formula id="Equ13"><label>13</label><alternatives><mml:math display="block" id="Equ13_Math"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>⊗</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ13_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{t}= {o}_{t}\otimes tanh({c}_{t})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ13.gif"/></alternatives></disp-formula>where <inline-formula id="IEq48"><alternatives><mml:math id="IEq48_Math"><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq48_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${i}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq48.gif"/></alternatives></inline-formula> is input gate; <inline-formula id="IEq49"><alternatives><mml:math id="IEq49_Math"><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq49_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq49.gif"/></alternatives></inline-formula> denotes forget gate; <inline-formula id="IEq50"><alternatives><mml:math id="IEq50_Math"><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq50_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${o}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq50.gif"/></alternatives></inline-formula> is output gate at a time step <italic>t</italic>; <inline-formula id="IEq51"><alternatives><mml:math id="IEq51_Math"><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq51_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widetilde{C}}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq51.gif"/></alternatives></inline-formula> is a new memory cell vector; and <bold>W</bold> and <bold>U</bold> are parameter matrices.</p></sec><sec id="Sec14"><title>Bidirectional long-short time memory (BiLSTM)</title><p id="Par57">Regular recurrent neural networks with LSTM cells can be extended to bidirectional recurrent neural networks in which the data is passed through two LSTMs (Graves et al. <xref ref-type="bibr" rid="CR84">2013</xref>; Graves and Schmidhuber <xref ref-type="bibr" rid="CR85">2005</xref>). One forward LSTM offers the input sequence in the correct order (forward layer), and another backward LSTM provides the input sequence in reverse order (backward layer). This technique improves the model's accuracy by capturing the long-term dependencies of the input sequence in both directions. In the BiLSTM, the forward layer computation is identical to those in the regular LSTM that computes the sequences (<inline-formula id="IEq52"><alternatives><mml:math id="IEq52_Math"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="IEq52_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overrightarrow{{h}_{t}}, \overrightarrow{{c}_{t}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq52.gif"/></alternatives></inline-formula>) from <inline-formula id="IEq53"><alternatives><mml:math id="IEq53_Math"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:math><tex-math id="IEq53_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t = 1 to T$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq53.gif"/></alternatives></inline-formula>. On the other hand, the backward layer computes the sequences <inline-formula id="IEq54"><alternatives><mml:math id="IEq54_Math"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mover accent="true"><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="IEq54_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow{{h}_{t}, }\overleftarrow{{c}_{t}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq54.gif"/></alternatives></inline-formula> from <inline-formula id="IEq55"><alternatives><mml:math id="IEq55_Math"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="IEq55_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t = T to 1$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq55.gif"/></alternatives></inline-formula> as described below:<disp-formula id="Equ14"><label>14</label><alternatives><mml:math display="block" id="Equ14_Math"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ14_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow{{i}_{t}}=\sigma ({W}^{i}{x}_{t}+{U}^{i}{h}_{t+1}+{b}^{i})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ14.gif"/></alternatives></disp-formula><disp-formula id="Equ15"><label>15</label><alternatives><mml:math display="block" id="Equ15_Math"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ15_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow{{f}_{t}}=\sigma ({W}^{f}{x}_{t}+{U}^{f}{h}_{t+1}+{b}^{f})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ15.gif"/></alternatives></disp-formula><disp-formula id="Equ16"><label>16</label><alternatives><mml:math display="block" id="Equ16_Math"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>o</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mi>o</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>o</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ16_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow{{o}_{t}}=\sigma ({W}^{o}{x}_{t}+{U}^{o}{h}_{t+1}+{b}^{o})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ16.gif"/></alternatives></disp-formula><disp-formula id="Equ17"><label>17</label><alternatives><mml:math display="block" id="Equ17_Math"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>U</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>g</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ17_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow{{\widetilde{C}}_{t}}=tanh({W}^{g}{x}_{t}+{U}^{g}{h}_{t+1}+{b}^{g})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ17.gif"/></alternatives></disp-formula><disp-formula id="Equ18"><label>18</label><alternatives><mml:math display="block" id="Equ18_Math"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>C</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>⊗</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>⊗</mml:mo><mml:mover accent="true"><mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo stretchy="true">~</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="Equ18_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow{{C}_{t}}= \overleftarrow{{f}_{t}}\otimes \overleftarrow{{C}_{t+1}}+\overleftarrow{{i}_{t}}\otimes \overleftarrow{{\widetilde{C}}_{t}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ18.gif"/></alternatives></disp-formula><disp-formula id="Equ19"><label>19</label><alternatives><mml:math display="block" id="Equ19_Math"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo>⊗</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">←</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ19_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow{{h}_{t}}= \overleftarrow{{o}_{t}}\otimes tanh(\overleftarrow{{c}_{t}})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ19.gif"/></alternatives></disp-formula></p><p id="Par58">In a study conducted by Siami-Namini, Tavakoli, and Namin (2019), LSTM and BiLSTM were compared in terms of time series data modelling. The prediction accuracy of the BiLSTM-based model was 37.78% higher than that of standard LSTM-based models after training with both directions of input data. However, BiLSTM-based models achieved slower performance than the LSTM-based models. Another study (Brahma <xref ref-type="bibr" rid="CR31">2018</xref>) introduced a new model suffix bidirectional LSTM (SuBiLSTM) that improved BiLSTM for sentiment classification and question classification tasks (see Figs. <xref rid="Fig7" ref-type="fig">7</xref>, <xref rid="Fig8" ref-type="fig">8</xref>, <xref rid="Fig9" ref-type="fig">9</xref>).</p></sec><sec id="Sec15"><title>Gated recurrent unit (GRU)</title><p id="Par59">The architectures of a gated recurrent unit (GRU) and long short-term memory (LSTM) are closely related, since both are crafted similarly and, in some situations, generate equally outstanding results (Murali and Swapna <xref ref-type="bibr" rid="CR180">2019</xref>). The GRU cell is comprised of two gates: an update gate <italic>z</italic> and a reset gate <italic>r</italic>. It addresses the vanishing gradient problem of a regular RNN by using the update gate to determine how much historical memory (from earlier time steps) should be maintained and proceed to the future and the reset gate to pair the new input with the prior memory, as shown in Fig. <xref rid="Fig10" ref-type="fig">10</xref>.<fig id="Fig10"><label>Fig. 10</label><caption xml:lang="en"><p>Gated recurrent unit cell (Zhao et al. <xref ref-type="bibr" rid="CR306">2019</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig10_HTML.png" id="MO10"/></fig></p><p id="Par60">The gating mechanism in GRU is expressed by the following equations:<disp-formula id="Equ20"><label>20</label><alternatives><mml:math display="block" id="Equ20_Math"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="Equ20_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$z= \sigma ({W}_{z}{h}_{t-1}+{U}_{z}{x}_{t})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ20.gif"/></alternatives></disp-formula><disp-formula id="Equ21"><label>21</label><alternatives><mml:math display="block" id="Equ21_Math"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="Equ21_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r= \sigma ({W}_{r}{h}_{t-1}+{U}_{r}{x}_{t})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ21.gif"/></alternatives></disp-formula><disp-formula id="Equ22"><label>22</label><alternatives><mml:math display="block" id="Equ22_Math"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="italic">tan</mml:mi><mml:mi>h</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⊗</mml:mo><mml:mi>r</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ22_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c=\mathit{tan}h\left({{W}_{c}(h}_{t-1}\otimes r\right)+{U}_{c}{x}_{t})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ22.gif"/></alternatives></disp-formula><disp-formula id="Equ23"><label>23</label><alternatives><mml:math display="block" id="Equ23_Math"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mi>z</mml:mi><mml:mo>⊗</mml:mo><mml:mi>c</mml:mi></mml:mfenced><mml:mo>⊗</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⊗</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ23_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{t}=\left(z\otimes c\right)\otimes ((1-z)\otimes {h}_{t-1})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ23.gif"/></alternatives></disp-formula>where <inline-formula id="IEq56"><alternatives><mml:math id="IEq56_Math"><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq56_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq56.gif"/></alternatives></inline-formula> is the input vector; <inline-formula id="IEq57"><alternatives><mml:math id="IEq57_Math"><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq57_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq57.gif"/></alternatives></inline-formula> is output vector; <bold>W</bold> and <bold>U</bold> are parameter matrices; <inline-formula id="IEq58"><alternatives><mml:math id="IEq58_Math"><mml:mi>σ</mml:mi></mml:math><tex-math id="IEq58_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq58.gif"/></alternatives></inline-formula> is the sigmoid function; and <inline-formula id="IEq59"><alternatives><mml:math id="IEq59_Math"><mml:mo>⊗</mml:mo></mml:math><tex-math id="IEq59_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\otimes$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq59.gif"/></alternatives></inline-formula> denotes the Hadamard product (entry-wise product).</p><p id="Par61">Due to their versatility in various applications, RNNs have been successfully used in multiple tasks, including language modelling, speech-to-text processing, caption generator, machine translation, and other fields. RNN has also been applied in the sentiment analysis task to produce effective outcomes. For instance, Basiri et al. (<xref ref-type="bibr" rid="CR23">2021</xref>) proposed a model to determine the sentiment from long reviews and short tweet text. In the model, the attention mechanism in RNNs is used to pay more attention to certain factors by assigning different weights when processing the data. The linguistic structures become more descriptive by applying the attention mechanism. Two bidirectional LSTM and GRU are also employed to generate the input text's previous and next contexts feature representation. The proposed model improved the accuracy from 1.85% to 3.63% for five long review datasets and from 0.25% to 0.54% for three short tweet datasets. While the study emphasized sentiment classification at the document level, there is potential to investigate sentiment classification at the sentence and aspect levels.</p><p id="Par62">Another RNN model based on dialogue was built with an attention mechanism for emotion detection in textual conversations with six emotion labels (Majumder et al. <xref ref-type="bibr" rid="CR164">2019</xref>). The model has several variants, including DialogueRNN + Att and BiDialgouRNN, and considers both context and speaker information. The network employs three GRUs to track individual speaker states, global context from the preceding utterances, and the emotional state through the conversations. The data are provided and fed into the GRU for emotion representation, depending on the context. Although the DialogueRNN model achieved a better f1-score of 6.62% on several experiments, which is above the baselines (Majumder et al. <xref ref-type="bibr" rid="CR164">2019</xref>), it is time-consuming for training and not parameter-efficient for global or local contexts.</p><p id="Par63">In RNN-based neural machine translation (NMT), sequence-to-sequence (seq2seq) architectures are used to deal with translation between languages. These seq2seq architectures apply two RNNs, namely an encoder and decoder. A study (Camgoz et al. <xref ref-type="bibr" rid="CR34">2018</xref>) utilized the standard seq2seq model to recognize sign language gestures from a video of someone performing continuous signs. In the study, the CNN was trained on the sentence level annotation to extract features from the video before translating it to text. These features were fed to the seq2seq model. The model scored 18.13 on the BLEU-4 matric (Papineni et al. <xref ref-type="bibr" rid="CR197">2001</xref>) and 43.80 on the ROUGE matric (Lin <xref ref-type="bibr" rid="CR152">2004</xref>). The model assumed that the CNN could learn good feature representation, but this hypothesis’s validity was not evaluated.</p><p id="Par64">To model long texts for generating semantic relations between sentences, researchers face challenges in sentiment analysis. Rao et al. (<xref ref-type="bibr" rid="CR213">2018a</xref>, <xref ref-type="bibr" rid="CR214">b</xref>) handled the problem by proposing the State Refinement-LSTM (SR-LSTM) and SSR-LSTM models based on deep RNN. The models have two hidden layers: the first one uses LSTM to represent the semantic relationship of sentences, and the second one encodes those sentence relationships at the document level. The SR-LSTM model outperformed other models by obtaining an accuracy of 44% and 63.9% on the IMDB and yelp2015 datasets, respectively, while the SSR-LSTM model achieved an accuracy of 44.3% and 63.8% on the same datasets. However, the models considered only the sequential order of the documents. In future works, it may possible to represent the documents using tree-structured LSTM.</p><p id="Par65">RNNs have also been successfully applied in intelligent health care systems. For example, Uddin et al. (<xref ref-type="bibr" rid="CR267">2020</xref>) presented a multi-sensors data fusion network that relies on a recurrent neural network to recognize human activities and behavior. They extracted features from multiple body sensors and enhanced the features using Kernel Principal Component Analysis (KPCA) techniques. Then, human activities were recognized by training a deep RNN. The proposed method was assessed on three publicly available datasets. The average performance was found to be 99% using precision, recall, and F1-score matrices. It is possible to extend the work by developing a real-time human behavior tracking system with considering more complex human activities.</p><p id="Par66">The RNN-LSTM approach for time series modelling has recently attracted much interest. The applicability of RNN-LSTM was analyzed by Sahoo et al. (<xref ref-type="bibr" rid="CR220">2019</xref>) for predicting daily flows during the low-flow periods. The model effectively used the time series data by taking advantage of the LSTM memory cell to learn features from both the current and past values of an observable object. The model’s performance (root-mean-square error RMSE = 0.487) on hydrological data outperformed the traditional RNN model (RMSE = 0.516) and naive method (RMSE = 0.793). Nevertheless, multiple hidden LSTM layers can be used to enhance the performance of the model. Experts are also attempting to use deep learning approaches in typhoon prediction as deep learning techniques become more sophisticated. Alemany et al. (<xref ref-type="bibr" rid="CR11">2019</xref>) proposed a fully connected RNN to predict hurricane trajectories from historical cyclone data that could learn from all types of hurricanes. The model produced better prediction accuracy than the previous models. For example, the mean absolute error (0.0842) of the RNN model was better than that of the previous sparse RNN average model (0.4612) to track Hurricane Sandy in 2012. The model may take advantage of converting the grid locations to latitude–longitude coordinates to reduce the conversion error.</p></sec><sec id="Sec16"><title>Deep echo state network</title><p id="Par67">The deep echo state network (DeepESN) is a recently proposed technique to enhance the efficiency of a general echo state network (ESN) in several domains. ESN is a reservoir computing model in which the reservoir computing shows efficiency to train RNNs by preserving memory using its recurrent nature. A dynamic reservoir is incorporated in ESN, presenting a sparsely linked recurrent network of neurons that differs from a traditional multilayered neural network. The reservoir is the network's only hidden layer, and its input connections are assigned at random and cannot be trained. On the other hand, the weights between the reservoir and output are the only ones that can be trained. The system learns the weights by linear regression rather than backpropagation. DeepESN is simply the ESN model's application of the deep learning architecture.</p><p id="Par68">The DeepESN output is produced using a linear structure of the recurrent units across all recurrent layers. After initialization, the DeepESN reservoir component is left untrained. Therefore, the usual ESN technique is subject to stability limitations. Such limits are stated in DeepESN by the criteria for the ESN of the deep reservoir computing network. In the deep echo state network, input is processed by the first layer, and the previous layers’ outputs process the successive layers’ inputs. Therefore, the state transition function of a DeepESN can be presented by the following equation (Lukoševičius and Jaeger <xref ref-type="bibr" rid="CR161">2009</xref>):<disp-formula id="Equ24"><label>24</label><alternatives><mml:math display="block" id="Equ24_Math"><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup></mml:mfenced><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup><mml:mfenced close=")" open="("><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mfenced><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mi mathvariant="normal">tanh</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">in</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msubsup><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup><mml:mfenced close=")" open="("><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mfenced><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ24_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}^{\left(l\right)}\left(t\right)=\left(1-{a}^{\left(l\right)}\right){x}^{\left(l\right)}\left(t-1\right)+{a}^{(l)}\mathrm{tanh}({W}_{in}^{\left(l\right)}{i}^{\left(l\right)}\left(t\right)+{\theta }^{\left(l\right)}+{\widehat{W}}^{\left(l\right)}{x}^{\left(l\right)}\left(t-1\right))$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ24.gif"/></alternatives></disp-formula>where <inline-formula id="IEq60"><alternatives><mml:math id="IEq60_Math"><mml:mi>l</mml:mi></mml:math><tex-math id="IEq60_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq60.gif"/></alternatives></inline-formula> represents the number of layers; <inline-formula id="IEq61"><alternatives><mml:math id="IEq61_Math"><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">in</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math><tex-math id="IEq61_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{in}^{(l)}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq61.gif"/></alternatives></inline-formula> refers to the input matrix for <inline-formula id="IEq62"><alternatives><mml:math id="IEq62_Math"><mml:mi>l</mml:mi></mml:math><tex-math id="IEq62_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq62.gif"/></alternatives></inline-formula>; <inline-formula id="IEq63"><alternatives><mml:math id="IEq63_Math"><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math><tex-math id="IEq63_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }^{(l)}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq63.gif"/></alternatives></inline-formula> denotes bias weight vector; and <inline-formula id="IEq64"><alternatives><mml:math id="IEq64_Math"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math><tex-math id="IEq64_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{W}}^{(l)}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq64.gif"/></alternatives></inline-formula> expresses the recurrent weight matrix for layer <inline-formula id="IEq65"><alternatives><mml:math id="IEq65_Math"><mml:mi>l</mml:mi></mml:math><tex-math id="IEq65_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq65.gif"/></alternatives></inline-formula>. Here, <inline-formula id="IEq66"><alternatives><mml:math id="IEq66_Math"><mml:mrow><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="IEq66_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${i}^{\left(l\right)}(t)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq66.gif"/></alternatives></inline-formula> signifies the input for the <italic>l</italic> th layer of the network at time <inline-formula id="IEq67"><alternatives><mml:math id="IEq67_Math"><mml:mi>t</mml:mi></mml:math><tex-math id="IEq67_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq67.gif"/></alternatives></inline-formula>. The output of the model can be expressed by the following equation:<disp-formula id="Equ25"><label>25</label><alternatives><mml:math display="block" id="Equ25_Math"><mml:mrow><mml:mi>y</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msup><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msup><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced><mml:mo>⋯</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="Equ25_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y\left(t\right)={W}_{out}{[{x}^{\left(1\right)}\left(t\right){x}^{\left(2\right)}\left(t\right)\dots {x}^{({N}_{l})}]}^{T}+ {\theta }_{out}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ25.gif"/></alternatives></disp-formula>where <inline-formula id="IEq68"><alternatives><mml:math id="IEq68_Math"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq68_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{out}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq68.gif"/></alternatives></inline-formula> is the weight matrix between the reservoir and output <inline-formula id="IEq69"><alternatives><mml:math id="IEq69_Math"><mml:mrow><mml:mi>y</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq69_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y(t)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq69.gif"/></alternatives></inline-formula>.</p><p id="Par69">Based on the DeepESN, a novel technique was developed by Gallicchio et al. (<xref ref-type="bibr" rid="CR72">2018a</xref>) for diagnosing Parkinson’s disease. This is a significant initial work in the DeepESN domain that shows the superiority of DeepESN over the shallow echo state network model. The proposed technique identified Parkinson’s disease by using the time series data gathered from a tablet device while subjects performed sketching spiral tests with a pen. The acquired data contain <italic>x</italic> and <italic>y</italic> components of the pen, pen pressure, and grip angle. These signals were used to feed the model with no feature extraction and data pre-processing. The proposed model was evaluated on a public spiral test dataset and showed to perform better than the shallow ESN and other state-of-the-art methods.</p><p id="Par70">Gallicchio et al. (<xref ref-type="bibr" rid="CR71">2018b</xref>) proposed a DeepESN technique based on additive decomposition for predicting the time series data where the additive decomposition technique was used as a pre-processing step to the model. Data are split into three parts by additive decomposition (trend, seasonality, and residual) and then fed to the DeepESN. The performance of the additive decomposition-DeepESN was compared with LSTM, GRU, ESN, and DeepESN algorithms on six different datasets. The proposed model demonstrated significant performance for large, multidimensional data. Although ESN was found to be computationally efficient, it delivered a poor performance in prediction. LSTM and GRU required five times more computational time than DeepESN and additive decomposition-DeepESN. The additive decomposition-DeepESN model showed a low standard deviation, proving its stability, whereas other reservoir algorithms were unstable, i.e., with a higher standard deviation. Thus, the additive decomposition technique has the ability to improve the stability and performance of the DeepESN.</p></sec><sec id="Sec17"><title>Elman recurrent neural network</title><p id="Par71">The difference between the Elman recurrent neural network (ERNN) (Elman <xref ref-type="bibr" rid="CR65">1990</xref>) and other recurrent networks is that the hidden layer’s output is used as input for the context layer in the former. The architecture of ERNN consists of four layers: input layer, recurrent layer, hidden, and output layer. Each layer has one or multiple neurons that use a non-linear function of their weighted sum of inputs to transfer information from one layer to the next. Each hidden neuron is linked to a neuron of the single recurrent layer with the constant weight of one. As a result, the recurrent layer contains a copy of the hidden layer's state one instant ago. The benefit of using ERNN is that it emphasizes the relationship between future and previous values even when it is difficult to learn from them. The ERNN can be described by the following equations (Achanta and Gangashetty <xref ref-type="bibr" rid="CR4">2017</xref>):<disp-formula id="Equ26"><label>26</label><alternatives><mml:math display="block" id="Equ26_Math"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>W</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">Wh</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><tex-math id="Equ26_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{t}=f\left({W}_{i}{x}_{t}+ {Wh}_{t-1}+ {b}_{h}\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ26.gif"/></alternatives></disp-formula><disp-formula id="Equ27"><label>27</label><alternatives><mml:math display="block" id="Equ27_Math"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">Uh</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ27_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}_{t}=g({Uh}_{t}+{b}_{o})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ27.gif"/></alternatives></disp-formula>where <inline-formula id="IEq70"><alternatives><mml:math id="IEq70_Math"><mml:msub><mml:mi>W</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq70_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq70.gif"/></alternatives></inline-formula> signifies hidden weight’s input; <inline-formula id="IEq71"><alternatives><mml:math id="IEq71_Math"><mml:mi>W</mml:mi></mml:math><tex-math id="IEq71_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq71.gif"/></alternatives></inline-formula> denotes the recurrent weight matrix of the hidden layer; <inline-formula id="IEq72"><alternatives><mml:math id="IEq72_Math"><mml:msub><mml:mi>b</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:math><tex-math id="IEq72_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{h}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq72.gif"/></alternatives></inline-formula> represents the hidden bias; <inline-formula id="IEq73"><alternatives><mml:math id="IEq73_Math"><mml:mi>U</mml:mi></mml:math><tex-math id="IEq73_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$U$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq73.gif"/></alternatives></inline-formula> refers to the hidden output matrix; <inline-formula id="IEq74"><alternatives><mml:math id="IEq74_Math"><mml:msub><mml:mi>b</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:math><tex-math id="IEq74_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{o}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq74.gif"/></alternatives></inline-formula> is the Bias Vector of the output layer; and <inline-formula id="IEq75"><alternatives><mml:math id="IEq75_Math"><mml:mi>f</mml:mi></mml:math><tex-math id="IEq75_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq75.gif"/></alternatives></inline-formula> and <inline-formula id="IEq76"><alternatives><mml:math id="IEq76_Math"><mml:mi>g</mml:mi></mml:math><tex-math id="IEq76_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq76.gif"/></alternatives></inline-formula> are the non-linear functions of hidden and output layers, respectively. Input is represented by <inline-formula id="IEq77"><alternatives><mml:math id="IEq77_Math"><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq77_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq77.gif"/></alternatives></inline-formula>, the state of <inline-formula id="IEq78"><alternatives><mml:math id="IEq78_Math"><mml:msub><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq78_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq78.gif"/></alternatives></inline-formula> and <inline-formula id="IEq79"><alternatives><mml:math id="IEq79_Math"><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math><tex-math id="IEq79_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}_{t}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq79.gif"/></alternatives></inline-formula> refer to the outputs at time<italic> t</italic>.</p><p id="Par72">An ERNN model with a stochastic time effective function (ST-ERNN) was developed by Jie Wang et al. (<xref ref-type="bibr" rid="CR273">2016b</xref>) to forecast stock indices. The architecture is built by combining ERNN, multilayer perceptron, and stochastic-time-effective function, where a stochastic process is used to describe the level of historical data impact in the market. The time-strength function includes a drift function and Brownian motion to model the appearance of random changes while keeping the primary trend. The proposed neural network performs better than other existing neural networks in financial time series forecasting. Considering the rapid changes in the stock market data that make the field non-linear and nonstationary, predicting this kind of data is very challenging. Nevertheless, ST-ERNN showed a significant performance that can be crucial for future experiments in this domain. Krichene et al. (<xref ref-type="bibr" rid="CR127">2017</xref>) applied ERNN for forecasting Mackey Glass time-series elements. The performance of ERNN was evaluated via comparison with two other existing models (Al-Jumeily et al. <xref ref-type="bibr" rid="CR13">2014</xref>; Park <xref ref-type="bibr" rid="CR200">2010</xref>) using the same dataset, where ERNN showed better performance. It is worth noting that optimal performance was achieved when the weights of the context units were randomly initialized.</p></sec></sec><sec id="Sec18"><title>Recursive neural network</title><p id="Par73">A recursive neural network (RvNN) is a nonlinear model that can function on structured inputs and is applicable to parse trees in natural language processing (NLP), image analysis, protein topologies, among other applications in structured domains. For instance, RvNN performs extremely well in the NLP tasks. Despite their deep structure, the architecture of RvNN lacks the capacity for hierarchical representation (Irsoy and Cardie <xref ref-type="bibr" rid="CR107">2014</xref>) and contains complex informative processing models. Because they acquire high-level representations from explicit inputs, recursive networks are effective in many deep learning tasks where the input is a structure. RvNNs are normally defined on a directed positional acyclic graph (Micheli et al. <xref ref-type="bibr" rid="CR167">2007</xref>). The form of RvNN is shown in Fig. <xref rid="Fig11" ref-type="fig">11</xref>, referring to the parse tree on the left side (Ma et al. <xref ref-type="bibr" rid="CR163">2018</xref>). If the parent node’s feature vector is <inline-formula id="IEq80"><alternatives><mml:math id="IEq80_Math"><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math><tex-math id="IEq80_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p,$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq80.gif"/></alternatives></inline-formula> and <inline-formula id="IEq81"><alternatives><mml:math id="IEq81_Math"><mml:mrow><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:math><tex-math id="IEq81_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c1$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq81.gif"/></alternatives></inline-formula> and <inline-formula id="IEq82"><alternatives><mml:math id="IEq82_Math"><mml:mrow><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:math><tex-math id="IEq82_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c2$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq82.gif"/></alternatives></inline-formula> are its children, then<disp-formula id="Equ28"><label>28</label><alternatives><mml:math display="block" id="Equ28_Math"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo>.</mml:mo><mml:mfenced close="]" open="["><mml:mi>c</mml:mi><mml:mn>1</mml:mn><mml:mo>;</mml:mo><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:mfenced><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="Equ28_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p=f(w.\left[c1;c2\right]+b)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ28.gif"/></alternatives></disp-formula>where <inline-formula id="IEq83"><alternatives><mml:math id="IEq83_Math"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>.</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq83_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f(.)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq83.gif"/></alternatives></inline-formula> is the activation function. The computation is recursively done for all nodes, and the hidden vectors of nodes’ can then be used for different classification tasks.<fig id="Fig11"><label>Fig. 11</label><caption xml:lang="en"><p>The tree and its associated RvNN architecture (Ma et al. <xref ref-type="bibr" rid="CR163">2018</xref>). In the figure, <italic>S</italic> represents a sentence, <italic>NP</italic> is a noun phrase, <italic>VP</italic> is a verb phrase, <italic>D</italic> denotes determiner, <italic>N</italic> signifies noun, and <italic>V</italic> is a verb</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig11_HTML.png" id="MO11"/></fig></p><p id="Par74">Tree-structured recursive neural networks (RvNNs) were used to perform rumor detection on Twitter by Jing Ma, Gao, and Wong (2018). This study constructed two recursive networks on top-down and bottom-up tree-structured neural networks. Rather than a sentence’s parse tree, the model's input is a propagation tree rooted from a source post, and each node is a sensitive post rather than individual words. Recursive feature learning can capture the content semanticization of posts along with the tree structure and the receptive relationship between them. The basic concept of the bottom-up model is to create a feature vector by traversing each node recursively from the leaves to the root on the top. On the other hand, the concept of the top-down approach is to create an enhanced feature vector for each post, considering its propagation direction, in which rumor indicators are combined along the path of propagation. However, for the non-rumor class, the proposed models did not perform well. Yet, they could add other types of data into the structured neural models, such as user properties, to boost representation learning even further.</p><p id="Par75">Biancofiore et al. (<xref ref-type="bibr" rid="CR28">2017</xref>) analyzed atmospheric particulate matter (PM) and forecasted daily averaged concentrations of PM10 and PM2.5 up to 1–3 days. Particulate matter is a significant pollutant that affects human health, thus studies on reducing PM are critical. The latter researchers implemented a multiple linear regression model, feed-forward neural network, and neural networks with the recursive structure and found that the recursive neural network model outperforms the other methods. The total number of input variables and neurons in the second layer in the model determines how many neurons are in the first layer. The network’s output, the predicted particulate matter concentration, is represented by a single neuron in the final layer. In the latter work, the RvNN model correctly predicted 95% of the days, but this decreased to 57% when considering only the days where the limits were exceeded. In addition, the false-positive rate was 30% in this study.</p><p id="Par76">Lim and Kang (<xref ref-type="bibr" rid="CR150">2018</xref>) extracted the relation between chemical compounds and genes. They experimented with three methods, a tree-LSTM model with a position feature and a subtree containment feature, and implemented an ensemble process. The authors also implemented a stack augmented parser interpreter neural network (SPNN). The study revealed that the SPNN with ensemble technique outperformed the tree-LSTM with ensemble technique, which means that the extra tracking layer is beneficial. However, the proposed model is unable to comprehend the structure of a sentence. More training instances are needed to resolve this error. Also, coordination was not detected, whereby a comma, parenthesis, or special term like “and” or “or” is used to express coordination relations. This form of error may be avoided with the use of a separate module that looks for terms of equal emphasis.</p></sec><sec id="Sec19"><title>Neural tensor network</title><p id="Par77">In several natural language processing tasks, neural tensor networks (NTNs) have been successful. However, they need to estimate a considerable number of parameters, often resulting in overfitting (Yang et al. <xref ref-type="bibr" rid="CR289">2015</xref>) and excessive training times. An NTN model constructed by Socher, Chen, et al. (<xref ref-type="bibr" rid="CR400">2013</xref>) implements a 3D tensor for combining two input vectors as bellow:<disp-formula id="Equ29"><label>29</label><alternatives><mml:math display="block" id="Equ29_Math"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mfenced close="]" open="["><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>k</mml:mi></mml:mfenced></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mfenced close="]" open="["><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="Equ29_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f({x}_{1}^{T} {W}^{\left[1:k\right]}{x}_{2}+V\left[ \begin{array}{c}x1 \\ x2\end{array}\right]+b)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ29.gif"/></alternatives></disp-formula>where <inline-formula id="IEq84"><alternatives><mml:math id="IEq84_Math"><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">nxnxk</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="IEq84_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}^{[1:k]}\in {\mathbb{R}}^{nxnxk}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq84.gif"/></alternatives></inline-formula> is the tensor (<inline-formula id="IEq85"><alternatives><mml:math id="IEq85_Math"><mml:mi>W</mml:mi></mml:math><tex-math id="IEq85_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq85.gif"/></alternatives></inline-formula> is a slice matrix); <inline-formula id="IEq86"><alternatives><mml:math id="IEq86_Math"><mml:mrow><mml:mi>V</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="IEq86_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V \in {\mathbb{R}}^{k \times 2n}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq86.gif"/></alternatives></inline-formula> is the linear mapping to combine input vectors <italic>x</italic><sub><italic>1</italic></sub> and <italic>x</italic><sub><italic>2</italic></sub>; <inline-formula id="IEq87"><alternatives><mml:math id="IEq87_Math"><mml:mi>b</mml:mi></mml:math><tex-math id="IEq87_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq87.gif"/></alternatives></inline-formula> refers to a bias term; <inline-formula id="IEq88"><alternatives><mml:math id="IEq88_Math"><mml:mi>f</mml:mi></mml:math><tex-math id="IEq88_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq88.gif"/></alternatives></inline-formula> is the non-linear activation function; and <inline-formula id="IEq89"><alternatives><mml:math id="IEq89_Math"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq89_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{1}^{T}{W}^{[1:k]}{x}_{2}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq89.gif"/></alternatives></inline-formula> is an array of <inline-formula id="IEq90"><alternatives><mml:math id="IEq90_Math"><mml:mi>k</mml:mi></mml:math><tex-math id="IEq90_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq90.gif"/></alternatives></inline-formula> bilinear products.</p><p id="Par78">In contrast to the regular neural network model, NTN can connect two input vectors with a tensor directly. Although the NTN model is efficient, it takes considerable time to compute. Several studies were done to reduce the time complexity using parameter reduction techniques. For instance, Ishihara et al. (<xref ref-type="bibr" rid="CR108">2018</xref>) introduced two-parameter reduction techniques based on the matrix decomposition method, while Y. Zhao, Liu, and Sun (<xref ref-type="bibr" rid="CR307">2015</xref>) and P. Liu, Qiu, and Huang (<xref ref-type="bibr" rid="CR212">2015</xref>) proposed simple matrix decomposition techniques for reducing parameters. A neural tensor model named the convolutional NTN converts all word tokens into vectors with the help of a lookup layer, encode questions and answers with coevolutionary, pooling layers to fixed-length vectors, and finally modelling their interactions with a tensor layer. Therefore, in a semantic vector space, this model will group related questions and answers to avoid the problem of lexical distances.</p><p id="Par79">Qiu and Huang (<xref ref-type="bibr" rid="CR212">2015</xref>) proposed a convolutional NTN for community-based question answering, integrating sentence modelling and semantic matching into one model. They implemented contrastive max-margin criterion to train the model. This study evaluated two different datasets for English and Chinese languages and found that the proposed model can handle more complex interactions with tensor layers than existing models. However, texts were converted into fixed-length vectors with the proposed convolutional layer, saving the essential information lost in bag-of-words. The experiments on the Chinese dataset demonstrated worse performance than the English dataset, which may be due to some mistakes in the segmentation of the Chinese expression.</p><p id="Par80">A deep attention NTN for visual question answering was introduced by Bai et al. (<xref ref-type="bibr" rid="CR20">2018</xref>). In this approach, tensor-based representations are used to find the joint relationship between images, questions, and responses. The authors used bilinear features to model images and questions that were further encoded by third dimension, i.e. the response as a triplet. The correlation between various triplets was broken down by different types of answers and questions. For the most discriminatory inference reasoning method, a slice-wise attention module was developed. The model was optimized by learning a label regression with Kullback–Leibler divergence losses. This designing technique enabled fast convergence and scalable training across a wide range of answer sets. The proposed model structure was integrated into the known visual question answering models MLB (Kim et al. <xref ref-type="bibr" rid="CR122">2017</xref>) and MUTAN (Ben-Younes et al. <xref ref-type="bibr" rid="CR27">2017</xref>). The proposed technique showed more accuracy than independent MLB and MUTAN models. This study compared GloVe word embedding with the word embedding learned from the proposed model and demonstrated that the model could be applied to more visual question answering models for further verification.</p><p id="Par81">Hu et al. (<xref ref-type="bibr" rid="CR103">2017</xref>) proposed enhanced face recognition performance by combining face recognition features and facial attribute features in a variety of tasks. They created a robust tensor-based model that develops fusion as a problem of tensor optimization. Due to the great number of parameters, the model was not effective in explicitly optimizing this tensor, and therefore a rich fusion architecture was proposed on the basis of the tensor. The results revealed that this tensor-based fusion’s Tucker-Low-Rank decomposition has the same Gated Two Stream neural network, making neural network learning simple but effective. The authors experimented on three well-known databases (MultiPIE, CASIA NIR-VIS2.0, and LFW) and found that the fusion approach significantly increased the face recognition performance. This technique can be expanded to large-scale data utilizing effective Mini Batch SGD-based learning since they set the equivalence between tensor-factorization and gated neural network architecture. Another advantage is that this model can be expanded to deeper architectures.</p></sec><sec id="Sec20"><title>Continuous-bag-of-word with denoising autoencoder-logistic regression</title><p id="Par82">To analyze sentiments, a Multimodal Learning technique was presented by Baecchi et al. (<xref ref-type="bibr" rid="CR19">2016</xref>) by implementing neural network-based models for microblogging contents that might consist of texts and images. The proposed architecture is based on the continuous-bag-of-word (CBOW) model (Mikolov et al. <xref ref-type="bibr" rid="CR170">2013</xref>) and was further extended to include a denoising autoencoder (DA) to include visual data. Thus, CBOW-logistic regression (LR) is the extended version of CBOW. The difference between CBOW and the extended model is that the new architecture can perform classification and representation concurrently. The idea behind this approach is that the multi-tasking technique can develop the performance of a neural network, while the proposed model can incorporate semantic and sentiment polarity. The model was further extended to CBOW-DA-LR to include visual data, such as images in tweets. The descriptor acquired by the denoising autoencoder, along with the regular word presentation, provides a new descriptor for a word window in the tweet and learns a logistic regressor at the same time. The proposed CBOW-DA-LR technique was compared to SentiBank, a commonly-used approach in this domain, and showed higher accuracy (79% accuracy on text + image data vs. 72% of SentiBank). Although this specific technique shows significant improvements, it should be further evaluated to ensure its validity.</p></sec><sec id="Sec21"><title>Deep belief network</title><p id="Par83">A deep belief network (DBN) is used to stack several unsupervised networks utilizing the hidden layer of each network for the next layer's input. A stack of restricted Boltzmann machines (RBMs) is typically used in the DBN. The benefit of the restricted Boltzmann machine is to fit the sample features (Hinton <xref ref-type="bibr" rid="CR97">2009</xref>). Therefore, a hidden layer’s output in an RBM can be used as another RBM’s visible layer input. This method may be considered as the further extraction of the features from the extracted features of the samples.</p><p id="Par84">Suppose that <inline-formula id="IEq91"><alternatives><mml:math id="IEq91_Math"><mml:mi>W</mml:mi></mml:math><tex-math id="IEq91_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq91.gif"/></alternatives></inline-formula> is the generative weights of the hidden layers learned by an RBM denote <inline-formula id="IEq92"><alternatives><mml:math id="IEq92_Math"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq92_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(v|h,W)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq92.gif"/></alternatives></inline-formula> and prior distribution over hidden vectors <inline-formula id="IEq93"><alternatives><mml:math id="IEq93_Math"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq93_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(h|W)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq93.gif"/></alternatives></inline-formula>. If <inline-formula id="IEq94"><alternatives><mml:math id="IEq94_Math"><mml:mi>v</mml:mi></mml:math><tex-math id="IEq94_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq94.gif"/></alternatives></inline-formula> is the visible vector, then the probability of <inline-formula id="IEq95"><alternatives><mml:math id="IEq95_Math"><mml:mi>v</mml:mi></mml:math><tex-math id="IEq95_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq95.gif"/></alternatives></inline-formula> can be expressed by the equation:<disp-formula id="Equ30"><label>30</label><alternatives><mml:math display="block" id="Equ30_Math"><mml:mrow><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mi>v</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>h</mml:mi></mml:munder><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mi>h</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>W</mml:mi></mml:mfenced><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ30_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p\left(v\right)=\sum_{h}p\left(h|W\right)p(v|h,W)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ30.gif"/></alternatives></disp-formula>where <inline-formula id="IEq96"><alternatives><mml:math id="IEq96_Math"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq96_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(v|h,W)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq96.gif"/></alternatives></inline-formula> is kept after learning W; and <inline-formula id="IEq97"><alternatives><mml:math id="IEq97_Math"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq97_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p(h|W)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq97.gif"/></alternatives></inline-formula> is replaced by a more reliable model of the grouped following distribution on hidden vectors.</p><p id="Par85">A computer-aided diagnosis system was built by Abdel-Zaher and Eldeib (<xref ref-type="bibr" rid="CR2">2016</xref>) for detecting breast cancer, utilizing a weight-initialized backpropagation neural network from a trained DBN having identical architecture. The authors implemented DBN in an unsupervised state for acquiring the input features from the main Wisconsin breast cancer dataset. The obtained network weight matrix of DBN was then shifted into the backpropagation neural network to enroll the supervised state. In the supervised form, the backpropagation neural network was evaluated on Levenberg Marquardt and Conjugate Gradient algorithms. The proposed methodology showed 99.68% accuracy, which outperforms prior studies. Therefore, this work proposes an efficient system to construct an accurate breast cancer classification model. However, a deep belief network needs significant computational effort on hardware, and thus building a real-life computer-aided diagnosis system based on DBN is very challenging.</p><p id="Par86">Zhao et al. (<xref ref-type="bibr" rid="CR305">2017</xref>) proposed a feature learning technique named discriminant DBN for synthetic aperture radar (SAR) image classification. In the study, discriminant features were obtained in an unsupervised way by integrating the ensemble-learning technique with a DBN. Some SAR image patch subsets were organized and labelled for training weak classifiers, then the particular patch was defined by projection vectors. The SAR image patch was projected into each weak decision space covered by weak classifiers. The model’s performance was found to be better than other proposed approaches in this domain. However, since fixed neighbors govern the model, the weak classifier's training strategy's neighbor selection process may cause significant variance in pseudo-labelling. Some adaptive strategies can be utilized to choose specific samples for training the weak classifiers.</p><p id="Par87">Another deep belief network, namely convolutional deep belief network (CDBN) is a hierarchical generative model for a real size image. RBM and DBN find it challenging to scale to complete pictures since they do not take into account the 2D form of the image, and therefore, the weights for detecting a specific feature must be acquired separately for each position. CDBN addresses this issue by scaling to the size of real images. The key to this solution is probabilistic max-pooling, a new strategy for shrinking higher layer representations in a probabilistically sound manner. This model stacks convolutional RBMs (CRBMs) to construct a multilayer structure similar to DBNs. The CRBM is analogous to RBM, except the weight among the hidden and visible layers is distributed over each position in the image. By integrating the energy functions of all individual layer pairs, the system generates an energy function. After training the given layer, the weights and activations of the layer are frozen and passed on to the next layer as input.</p><p id="Par88">Assume a CDBN with detection layer (<inline-formula id="IEq98"><alternatives><mml:math id="IEq98_Math"><mml:mi>H</mml:mi></mml:math><tex-math id="IEq98_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$H$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq98.gif"/></alternatives></inline-formula>), visible layer (<inline-formula id="IEq99"><alternatives><mml:math id="IEq99_Math"><mml:mi>V</mml:mi></mml:math><tex-math id="IEq99_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$V$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq99.gif"/></alternatives></inline-formula>), pooling layer (<inline-formula id="IEq100"><alternatives><mml:math id="IEq100_Math"><mml:mi>P</mml:mi></mml:math><tex-math id="IEq100_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq100.gif"/></alternatives></inline-formula>), and another higher detection layer (<inline-formula id="IEq101"><alternatives><mml:math id="IEq101_Math"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:math><tex-math id="IEq101_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{^{\prime}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq101.gif"/></alternatives></inline-formula>); <inline-formula id="IEq102"><alternatives><mml:math id="IEq102_Math"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:math><tex-math id="IEq102_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{^{\prime}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq102.gif"/></alternatives></inline-formula> and <inline-formula id="IEq103"><alternatives><mml:math id="IEq103_Math"><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:math><tex-math id="IEq103_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${K}^{^{\prime}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq103.gif"/></alternatives></inline-formula> has groups, shared weights <inline-formula id="IEq104"><alternatives><mml:math id="IEq104_Math"><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⋯</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">Γ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:mrow></mml:msup><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><tex-math id="IEq104_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Gamma =\{{\Gamma }^{\mathrm{1,1}}\dots {\Gamma }^{k,{k}^{^{\prime}}}\}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq104.gif"/></alternatives></inline-formula> connects pooling unit <inline-formula id="IEq105"><alternatives><mml:math id="IEq105_Math"><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:math><tex-math id="IEq105_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${P}^{k}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq105.gif"/></alternatives></inline-formula> and detection unit <inline-formula id="IEq106"><alternatives><mml:math id="IEq106_Math"><mml:msup><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msup></mml:math><tex-math id="IEq106_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}^{l}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq106.gif"/></alternatives></inline-formula>. The energy function can be described as (Lee et al. <xref ref-type="bibr" rid="CR138">2009</xref>):<disp-formula id="Equ31"><label>31</label><alternatives><mml:math display="block" id="Equ31_Math"><mml:mrow><mml:mi>E</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mi>v</mml:mi><mml:mo>∘</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow/><mml:mo>∗</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:msub><mml:mi>b</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>∘</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi mathvariant="italic">kl</mml:mi></mml:mrow></mml:msup><mml:mrow/><mml:mo>∗</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mi>l</mml:mi></mml:munder><mml:msubsup><mml:mi>b</mml:mi><mml:mi>l</mml:mi><mml:mo>′</mml:mo></mml:msubsup><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math><tex-math id="Equ31_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$E\left( {v,h,p,h^{\prime}} \right) = - \mathop \sum \limits_{k} v \circ \left( {W^{k} *h^{k} } \right) - \mathop \sum \limits_{k} b_{k} \mathop \sum \limits_{ij} h_{ij}^{k} - \mathop \sum \limits_{k,l} p^{k} \circ \left( {\Gamma^{kl} *h^{^{\prime}l} } \right) - \mathop \sum \limits_{l} b^{\prime}_{l} \mathop \sum \limits_{ij} h_{ij}^{^{\prime}l}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ31.gif"/></alternatives></disp-formula></p><p id="Par89">Based on CNN structure, Wu et al. (<xref ref-type="bibr" rid="CR280">2018</xref>) presented a novel technique for pathological voice detection, in which the weights of the CNN are pre-trained by a CDBN. The model uses statistical approaches to detect the structure of the input data. The performance of the proposed technique was compared with the existing techniques using the Saarbrucken voice database. Generative models are generally used to develop the deep learning models on a small dataset and avoid overfitting. The study reported an accuracy of 68% and 71% on the validation set, respectively. This is a slight improvement compared to other existing methods. The results demonstrated that CNN can be tuned more robustly by applying CDBN to initiate the weights and can avoid the overfitting issue. However, the accuracy for the testing set decreased, which proves that a more robust system might affect the accuracy.</p><p id="Par90">A Gaussian Bernoulli-based CDBN (GCDBN) model is made up of many coevolutionary layers that are built on Gaussian Bernoulli restricted Boltzmann machines (GBRBM). Therefore, the architecture takes the benefit of GBRBM and convolution neural networks. After each convolutional layer, the feature maps are down-sampled using a stochastic pooling layer. Using a convolutional neural network and GRBM, the proposed system can extract relevant features from a real-sized image using generative convolution filters, reducing the amount of connecting weights, and improving the learning of spatial information from nearby picture patches. Li et al. (<xref ref-type="bibr" rid="CR148">2019a</xref>, <xref ref-type="bibr" rid="CR142">b</xref>, <xref ref-type="bibr" rid="CR143">c</xref>, <xref ref-type="bibr" rid="CR144">d</xref>) proposed the GCDBN model for image feature extraction, which can reduce the computational cost significantly by replacing fully connected weights with the convolutional filter. However, as a limitation of this study, only one GCDBN was built with five layers. The recognition accuracy can be increased by adding more convolutional and pooling layers in the proposed architecture.</p><p id="Par91">DBNs are also widely used in the analysis of hyperspectral imaging (HSI). However, they fail to examine training samples’ prior knowledge, limiting the discriminant capacity of retrieved features for classification. MMDBN, a manifold-based multi-DBN was thus proposed by Li et al. (<xref ref-type="bibr" rid="CR145">2022</xref>) in order to acquire deep manifold characteristics of hyperspectral imaging. The MMDBN created a hierarchical initiation approach that initializes the network based on the data's hidden local geometric structure. The MMDBN algorithm efficiently extracted the deep characteristics from each HSI class. Experimental findings on the Salinas, Botswana and Indian Pines datasets reach 90.48%, 97.35%, and 78.25%, respectively, demonstrating that MMDBN outperforms some state-of-the-art algorithms in classification performance. MMDBN’s classification performance can be further improved by designing the combined spectral-spatial deep manifold networks.</p></sec><sec id="Sec22"><title>Hybrid neural network</title><p id="Par92">The process of artificial neural network (ANN) learning entails predicting values for a set of parameters and an architecture (Guti <xref ref-type="bibr" rid="CR89">2011</xref>). After choosing an architecture, supervised, unsupervised, or reinforcement learning is often accomplished by repetitively modifying the connection weights using a gradient descent-based optimization method. The significant challenges with this type of technique are the need for a prior-determined architecture for the neural net, its sensitivity to early training conditions, and its local nature. Several activations or transfer methods have been used for the hidden layer nodes in hybrid models. Many studies have suggested hybridizing various basis functions via a single hybrid hidden layer or different linked pure layers. A hybrid neural network (HNN) was initially introduced to model a fed-batch bioreactor [36]. The hybrid model is comprised of a partial first principal model that provides previous information about the process with a neural network, which acts as an estimate of unmeasured process arguments.</p><p id="Par93">A genetic algorithm is a type of evolutionary algorithm that uses evolutionary biology concepts like inheritance and mutation. A number of operators (selection operator, substitution operator, recombination operator, and mutation operator) are used in genetic algorithms to bring together the current generation’s eligible members to produce new eligible members. Arabasadi et al. (<xref ref-type="bibr" rid="CR15">2017</xref>) developed a hybrid technique that combines genetic algorithms with neural networks for diagnosing coronary artery disease, using Gini-index, principal component analysis, information-gain, and weight-by-SVM for feature selection. The initial weights of a neural network were determined with a genetic algorithm, then the neural network was trained using training data. The proposed technique implements a feed-forward topology with one hidden layer in the neural network. The experiment contained 22 inputs and five neurons in a hidden layer to produce an output that indicates whether the patient has CAD or not. The suggested approach improved the performance of a neural network by around 10% by upgrading its initial weights with a genetic algorithm that offers better weights for the neural network. However, several limitations were found in this study. Instead of genetic algorithms, other established evolutionary algorithms like evolution strategy and Particle-Swarm-Optimization (PSO) could be implemented to ensure the validity of the model. Some parameters, such as momentum factor and learning rate, could also be optimized.</p><p id="Par94">A novel metaheuristic method was suggested for improving the free parameters of the PV generation forecasting engine. Using this metaheuristic optimization approach, the shark-smell-optimization (SSO) technique has been enhanced. The metaheuristic algorithm incorporates efficient operators to improve its global and local search capabilities. A new forecasting methodology was applied to a hybrid forecasting engine that combines a neural network with a metaheuristic algorithm (Abedinia, Amjady, and Ghadimi <xref ref-type="bibr" rid="CR3">2018</xref>). This method includes a two-stage feature selection filter that filters out inefficient inputs using information-theoretic criteria, such as mutual information and interaction gain. For PV generation prediction, a three-stage neural network-based forecasting engine was designed and trained via a combination of a metaheuristic algorithm and the Levenberg–Marquardt learning method. With the help of this hybrid technique, the neural network-based forecasting engine eliminated underfitting and overfitting problems.</p><p id="Par95">An HNN with Wavelet Transform and Bayesian Optimization was used in a study conducted by (Liu et al. <xref ref-type="bibr" rid="CR156">2022</xref>) to predict the copper price for the short-term and long-term. Wavelet Transform was applied to the data to reduce noise and remove extraneous information whereas the algorithm of Bayesian Optimization was utilized on the searching task’s hyperparameter. For training and forecasting copper price, GRU and LSTM were used. The results showed that the proposed approaches, GRU or LSTM, can accurately forecast the copper price in the short and long term with the mean squared errors of less than 3% in both cases. With this HNN, the unnecessary data can be filtered out while the optimal hyperparameter set is searched. It is simple and straightforward to use in predicting the price of other commodities such as the stock market.</p><sec id="Sec23"><title>Probabilistic neural network (PNN) and two-layered restricted Boltzmann (RBM)</title><p id="Par96">A hybrid deep learning model was presented by Ghosh, Ravi, and Ravi (2016) for sentiment classification that combines a two-layered restricted Boltzmann machine (RBM) and probabilistic neural network (PNN). Sentiment classification is a sub-domain of sentiment analysis that identifies positive and negative sentiments from a review. In the proposed architecture, RBM was used for dimensionality reduction, and PNN classified the sentiment. The hybrid model was assessed in five datasets and performed better than other existing models in this domain. The technique achieved a sensitivity of 92.7%,93.3%, 93.1%, 94.9%, and 93.2% for a book dataset, movie dataset, electronics, and kitchen appliance dataset, respectively. The study revealed that the model does not rely on external resources, such as sentiment dictionaries, reducing the system’s complexity. It also does not perform POS tagging, which, although is typically needed in this domain, reduces the system’s time complexity. In future works, the model should be evaluated with more experiments to ensure its validity.</p></sec><sec id="Sec24"><title>Dynamic artificial neural network</title><p id="Par97">In the field of deep learning, dynamic neural networks (DNNs) are an emerging technique that can outperform traditional static models in terms of accuracy, adaptiveness, and computational complexity (Han et al. <xref ref-type="bibr" rid="CR92">2021</xref>). Static models have limited parameters and computational graphs at the inference stage, whereas DNN architecture and parameters are flexible to different inputs. The outputs of static models are computed based on their link with feed-forward inputs, as there is no feedback. However, the outputs of dynamic neural networks are determined by the present and previous values of inputs, outputs, and the network architecture (Abbas Ali Abounoori Esmaeil Naderi Nadiya Gandali Alikhani Hanieh Mohammadali <xref ref-type="bibr" rid="CR1">2016</xref>). DNNs can be divided into three types (Tavarone et al <xref ref-type="bibr" rid="CR260">2018</xref>): (i) instance-wise dynamic models that process each instance individually using data-dependent structures or parameters, (ii) spatial-wise dynamic models that perform adaptive computing on image data at various spatial locations, and (iii) temporal-wise dynamic models that accomplish adaptive inference for sequential data, such as movies and texts along the temporal dimension. Instance-wise and spatial-wise methods are used specifically in image recognition, whereas temporal-wise models show emerging improvements in text and audio data. These three types can be combined simultaneously for video-related research domains (Li et al. <xref ref-type="bibr" rid="CR146">2017a</xref>, <xref ref-type="bibr" rid="CR147">b</xref>; Niklaus et al. <xref ref-type="bibr" rid="CR186">2017</xref>).</p><p id="Par98">Godarzi et al. (<xref ref-type="bibr" rid="CR79">2014</xref>) improved an artificial neural network (ANN), specifically named a nonlinear autoregressive model with eXogenous input (NARX), to predict oil prices by developing a dynamic neural network. For the validation and improvements of results, the methodology followed three stages: ANN static, time series, and NARX. For identifying the significant factors that affect the oil price, a time series model was developed in the first stage. Then, a static ANN model was built to verify the acquired data from the first stage to ensure the optimal performance of the NARX model. In the last phase, the NARX model was implemented for the prediction. The methodology was found to be a novel approach for oil price prediction and can be used for other domains like predicting coal or natural gas price.</p></sec></sec><sec id="Sec25"><title>Generative adversarial networks</title><p id="Par99">Goodfellow et al. (<xref ref-type="bibr" rid="CR80">2014</xref>) was the pioneer of adversarial training for image generation, whereby training is formulated as a minimax adversarial game and a discriminator is used to distinguish fake data from real samples. The generator works by generating fake samples based on a probabilistic model with the given data. Then, a classification model is applied to verify whether the generated samples belong to the expected class. The generator aims to fool the discriminator, whereas the discriminator works to detect the false samples generated by the generator. Generative models have been used in a wide range of research domains and have undergone numerous advances since their introduction (Bau et al. <xref ref-type="bibr" rid="CR24">2019</xref>; Odena et al. <xref ref-type="bibr" rid="CR189">2017</xref>; Brock et al. <xref ref-type="bibr" rid="CR33">2019</xref>; Ledig et al. <xref ref-type="bibr" rid="CR136">2017</xref>; Miyato et al. <xref ref-type="bibr" rid="CR174">2018</xref>; Karras et al. <xref ref-type="bibr" rid="CR116">2018</xref>). In every adversarial approach, there are two models working simultaneously: (i) the generative model acquires the data distribution, and (ii) the discriminative model measures the probability of sample point whether it is coming from the training samples. Generative adversarial networks (GAN) learning concerns finding the optimal parameters <inline-formula id="IEq107"><alternatives><mml:math id="IEq107_Math"><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:math><tex-math id="IEq107_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{G}^{*}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq107.gif"/></alternatives></inline-formula> for a generator function <inline-formula id="IEq108"><alternatives><mml:math id="IEq108_Math"><mml:mrow><mml:mi>G</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="script">Z</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq108_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G\left(\mathcal{Z}; {\theta }_{G}\right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq108.gif"/></alternatives></inline-formula> by a minimax game. This relation can be represented by the following expressions (<xref rid="Equ32" ref-type="disp-formula">32</xref>–<xref rid="Equ35" ref-type="disp-formula">35</xref>), as suggested by Goodfellow et al. (<xref ref-type="bibr" rid="CR80">2014</xref>):<disp-formula id="Equ32"><label>32</label><alternatives><mml:math display="block" id="Equ32_Math"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow/><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:msub><mml:msup><mml:mrow/><mml:mi mathvariant="normal">argmin</mml:mi></mml:msup><mml:msub><mml:mrow/><mml:msub><mml:mi>θ</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:mi mathvariant="italic">max</mml:mi></mml:mrow></mml:msup><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><tex-math id="Equ32_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{G}^{*}={}_{{\theta }_{G}}{}^{\mathrm{argmin}} {}_{{\theta }_{D}}{}^{max}f\left({\theta }_{G}, {\theta }_{D}\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ32.gif"/></alternatives></disp-formula><disp-formula id="Equ33"><label>33</label><alternatives><mml:math display="block" id="Equ33_Math"><mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow/><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:msub><mml:msup><mml:mrow/><mml:mi mathvariant="normal">argmin</mml:mi></mml:msup><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ33_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$={}_{{\theta }_{G}}{}^{\mathrm{argmin}} f({\theta }_{G},{\theta }_{D}^{*}({\theta }_{G}))$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ33.gif"/></alternatives></disp-formula><disp-formula id="Equ34"><label>34</label><alternatives><mml:math display="block" id="Equ34_Math"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mfenced close=")" open="("><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow/><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:msub><mml:msup><mml:mrow/><mml:mi mathvariant="normal">argmax</mml:mi></mml:msup><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><tex-math id="Equ34_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{D}^{*}\left({\theta }_{G}\right)={}_{{\theta }_{G}}{}^{\mathrm{argmax}} f \left({\theta }_{G}, {\theta }_{D}\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ34.gif"/></alternatives></disp-formula>where <italic>f</italic> is determined by:<disp-formula id="Equ35"><label>35</label><alternatives><mml:math display="block" id="Equ35_Math"><mml:mrow><mml:mi>f</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mo>∼</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="italic">data</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfenced close="]" open="["><mml:mrow><mml:mo>log</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mi>D</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mspace width="0.166667em"/><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi mathvariant="script">Z</mml:mi><mml:mo>∼</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mfenced close=")" open="["><mml:mrow><mml:mrow><mml:mo>log</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">Z</mml:mi><mml:mo>;</mml:mo></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>;</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ35_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f\left( {\theta_{G} , \theta_{D} } \right) = {\mathbb{E}}_{{x\sim p_{data} }} \left[ {\log \left( {D\left( {\,x; \theta_{D} } \right)} \right)} \right] + {\mathbb{E}}_{{{\mathcal{Z}}\sim {\mathcal{N}}\left( {0,1} \right)}} \left[ {\log (1 - D(G({\mathcal{Z}};\theta_{G} } \right) ; \theta_{D} ))]$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ35.gif"/></alternatives></disp-formula></p><p id="Par100">For ensuring maximum loss in the above equation, the optimal discriminator <inline-formula id="IEq109"><alternatives><mml:math id="IEq109_Math"><mml:mrow><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mi>x</mml:mi></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq109_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}^{*} \left(x\right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq109.gif"/></alternatives></inline-formula> is a known smooth function for the generator probability <inline-formula id="IEq110"><alternatives><mml:math id="IEq110_Math"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="IEq110_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{G}(x)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq110.gif"/></alternatives></inline-formula>, as described in (Goodfellow et al. <xref ref-type="bibr" rid="CR80">2014</xref>). The smooth function can be formulated as:<disp-formula id="Equ36"><label>36</label><alternatives><mml:math display="block" id="Equ36_Math"><mml:mrow><mml:msup><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mi>x</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="italic">data</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi mathvariant="italic">data</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>x</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ36_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}^{*} \left(x\right)=\frac{{p}_{data} (x)}{{p}_{data} \left(x\right)+{p}_{G}(x)}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ36.gif"/></alternatives></disp-formula></p><p id="Par101">GAN has been in a wide range of applications since its emergence. Generative approaches are being applied to validate machine learning models’ robustness and to generate new data for rare examples and for image-to-image translation (Park et al. <xref ref-type="bibr" rid="CR199">2019</xref>; Taigman et al. <xref ref-type="bibr" rid="CR256">2017</xref>; Xu et al. <xref ref-type="bibr" rid="CR285">2018</xref>), image super-resolution (Ledig et al. <xref ref-type="bibr" rid="CR136">2017</xref>; Sønderby et al. <xref ref-type="bibr" rid="CR239">2017</xref>), synthesis training (Brock et al. <xref ref-type="bibr" rid="CR33">2019</xref>; Tang et al. <xref ref-type="bibr" rid="CR259">2019</xref>), text-to-image synthesis (Hong et al. <xref ref-type="bibr" rid="CR100">2018</xref>; Zhang et al. <xref ref-type="bibr" rid="CR299">2017a</xref>, <xref ref-type="bibr" rid="CR300">b</xref>, <xref ref-type="bibr" rid="CR301">c</xref>), and many more. However, the training of generative models is very sensitive to the selected hyperparameters. New network architectures have been introduced on a regular basis to this research paradigm in order to maintain training stability.</p><sec id="Sec26"><title>Unrolled generative adversarial networks</title><p id="Par102">To solve the problems of mode collapse, instability of GANs network training with complex recurrent generators, and increasing diversity, Pfau (<xref ref-type="bibr" rid="CR207">2017</xref>) introduced a method for reducing complexity in GANs training. The proposed algorithm defines the generator’s objective in order to achieve an unrolled optimization of the discriminator. The authors argued to use a local optimum of the discriminator parameters <inline-formula id="IEq111"><alternatives><mml:math id="IEq111_Math"><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:math><tex-math id="IEq111_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{D}^{*}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq111.gif"/></alternatives></inline-formula>(as presented in Eq. <xref rid="Equ34" ref-type="disp-formula">34</xref>) to be demonstrated as a fixed point, which comes from an iterative optimization procedure. Pfau (<xref ref-type="bibr" rid="CR207">2017</xref>) developed the complex recurrent generators increasing the diversity and scope of the data distribution. To explain the unrolled GAN, the authors used the discriminator parameter <inline-formula id="IEq112"><alternatives><mml:math id="IEq112_Math"><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:math><tex-math id="IEq112_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{D}^{*}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq112.gif"/></alternatives></inline-formula> to express the fixed mark of an iterative optimization process. The expression continues in the following order (15–17):<disp-formula id="Equ37"><label>37</label><alternatives><mml:math display="block" id="Equ37_Math"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="Equ37_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{D}^{0}={\theta }_{D}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ37.gif"/></alternatives></disp-formula><disp-formula id="Equ38"><label>38</label><alternatives><mml:math display="block" id="Equ38_Math"><mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ38_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$={\theta }_{D}^{k}+{\eta }^{k}\frac{df ({\theta }_{G} ,{ \theta }_{D}^{k})}{d{\theta }_{D}^{K}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ38.gif"/></alternatives></disp-formula><disp-formula id="Equ39"><label>39</label><alternatives><mml:math display="block" id="Equ39_Math"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mfenced close=")" open="("><mml:msub><mml:mi>θ</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:munder><mml:mi mathvariant="normal">lim</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo stretchy="false">→</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup></mml:mrow></mml:math><tex-math id="Equ39_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{D}^{*}\left({\theta }_{G}\right)= \underset{k\to \infty }{\mathrm{lim}}{\theta }_{D}^{k}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ39.gif"/></alternatives></disp-formula>where <inline-formula id="IEq113"><alternatives><mml:math id="IEq113_Math"><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:math><tex-math id="IEq113_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\eta }^{k}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq113.gif"/></alternatives></inline-formula> represents the learning rate scheduler. Equation (<xref rid="Equ37" ref-type="disp-formula">37</xref>) is the full batch steepest gradient ascent equation, and Eqs. (<xref rid="Equ36" ref-type="disp-formula">36</xref>) and (<xref rid="Equ38" ref-type="disp-formula">38</xref>) supplement the expression to explain the iterative optimization process. This approach is different from that presented in (Goodfellow et al. <xref ref-type="bibr" rid="CR80">2014</xref>), which indicates that the generator requires that the discriminator be updated via several steps to run every update step for the generator. Some drawbacks of this algorithm include high computational cost and cost for each training period as well as increased complexity with respect to the number of steps.</p></sec><sec id="Sec27"><title>Style-based generator architecture for generative adversarial networks</title><p id="Par103">Motivated by the style-transfer model presented in (Huang and Belongie <xref ref-type="bibr" rid="CR104">2017</xref>), an alternative generator architecture was proposed in (Karras et al. <xref ref-type="bibr" rid="CR117">2019</xref>) for GANs. The presented generator improved the state-of-the-art work with regard to traditional distribution matrices, which continued towards finding better interpolation properties and latent factors variation. The authors stated that compared to the traditional generators (Karras et al. <xref ref-type="bibr" rid="CR116">2018</xref>) that are used to feed the latent code within the input layer, their architecture (Karras et al. <xref ref-type="bibr" rid="CR117">2019</xref>) allows input to be mapped through an intermediate space. This latent space then allows control of the generator through the adaptive instance normalization or AdaIN (Dumoulin et al. <xref ref-type="bibr" rid="CR63">2018</xref>, <xref ref-type="bibr" rid="CR64">2017</xref>; Ghiasi et al. <xref ref-type="bibr" rid="CR77">2017</xref>; Huang and Belongie <xref ref-type="bibr" rid="CR104">2017</xref>) within every convolutional layer. The proposed automated linear separability and perceptual path metrics quantified the aspects needed for the generator.</p><p id="Par104">The affine transformations learned from the 8-layer MLP was specialized by a parameter <italic>w</italic> to styles <italic>y,</italic> where <italic>y</italic> = <italic>(y</italic><sub><italic>s</italic></sub><italic>, y</italic><sub><italic>b</italic></sub><italic>)</italic>, which led to AdaIN (Dumoulin et al. <xref ref-type="bibr" rid="CR63">2018</xref>, <xref ref-type="bibr" rid="CR64">2017</xref>; Ghiasi et al. <xref ref-type="bibr" rid="CR77">2017</xref>; Huang and Belongie <xref ref-type="bibr" rid="CR104">2017</xref>). Followed by the synthesis network <inline-formula id="IEq114"><alternatives><mml:math id="IEq114_Math"><mml:mi>g</mml:mi></mml:math><tex-math id="IEq114_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq114.gif"/></alternatives></inline-formula> of each convolution layer, AdaIN function performs the computation as follows:<disp-formula id="Equ40"><label>40</label><alternatives><mml:math display="block" id="Equ40_Math"><mml:mrow><mml:mtext>AdaIN</mml:mtext><mml:mspace width="0.166667em"/><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mi>μ</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mrow><mml:mi>σ</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="Equ40_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{AdaIN}}\,{(}x_{i} ,\,y) = y_{s,i} \frac{{x_{i} - \mu \left( {x_{i} } \right)}}{{\sigma \left( {x_{i} } \right)}} + y_{b,i}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ40.gif"/></alternatives></disp-formula>where each feature map <inline-formula id="IEq115"><alternatives><mml:math id="IEq115_Math"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq115_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${x}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq115.gif"/></alternatives></inline-formula> is normalized individually, the feature matrix is scaled, and bias is added by applying the respective scalar components from the style <inline-formula id="IEq116"><alternatives><mml:math id="IEq116_Math"><mml:mi>y</mml:mi></mml:math><tex-math id="IEq116_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$y$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq116.gif"/></alternatives></inline-formula>. Karras et al. (<xref ref-type="bibr" rid="CR117">2019</xref>) redesigned the generator architecture, which exposed new approaches for image synthesis tasks. It is clear from the obtained results that style-based generators outperform the traditional GAN generators.</p></sec><sec id="Sec28"><title>Multi-Level generative models for partial label learning (MGPLL) with non-random label noise</title><p id="Par105">The presented MGPLL method (Yan and Guo <xref ref-type="bibr" rid="CR287">2020</xref>) learns a problem through a feature level and label level generator. It follows a bidirectional mapping of data points and label vectors. A noise label generation is also used while developing the network to form non-random noise and to execute label denoising. The model architecture has a multi-class predictor to locate the training samples to denoise label vectors. Afterwards, a conditional feature generator is applied to perform the inverse mapping. Yan and Guo (<xref ref-type="bibr" rid="CR287">2020</xref>) adopted adversarial loss from Wasserstein Generative Adversarial Network (WGAN) to formulate their learning. They claimed their model to be the pioneering work that exploited multi-level generative architecture models. Moreover, the network was modelled with non-random noise labels in order to learn the partial label (Zeng et al. <xref ref-type="bibr" rid="CR295">2013</xref>). The noise label generator was responsible for exploiting non-random characteristics of noise labels, whereas the data feature generator was accountable for executing the conditioning upon the data samples based on the particular ground data. Later, the prediction model performed inverse mapping between these labels and features. The GAN architecture was designed particularly for label learning partially. The conditional label level generator pointed to the advent of the label-dependent non-random noise, whereas the feature level generator was used to produce data from the denoised label vectors. As a partial label learning generative architecture, the authors tested the model against both synthetic PL and real-world (FG-NET, Lost, MSRCv2, Birdsong, Yahoo! News) datasets, where they achieved satisfactory state-of-the-art performance.</p></sec><sec id="Sec29"><title>Dual adversarial co-learning for multi-domain text classification</title><p id="Par106">Multi-domain sentiment classification was performed by Wu and Guo (<xref ref-type="bibr" rid="CR279">2020</xref>) through the novel dual adversarial co-learning method. The authors explored a number of real-world sentiment analysis tasks and demonstrated how multi-domain text classification (MDTC) addresses the problem of a model constructed for one domain failing when tested on another domain. The methodology focuses on domain-invariant and domain-specific features by shared-private networks, and two classifiers were trained to extract features. Both the classifiers and feature extractors were designed to work in an adversarial manner, which resulted in the basis of prediction discrepancy on unlabeled data. A multinomial multi-domain adversarial discriminator was developed to enhance the effectiveness of feature extraction of the domain invariant features. This technique separates the domain-specific features from the domain invariant features. The presented methodology is novel in such a way that the network tries to align data across domains within the extracted feature space and labelled and unlabeled data within each domain. This technique also contributes to avoiding overfitting the limited labelled data.</p><p id="Par107">According to Wu and Guo (<xref ref-type="bibr" rid="CR279">2020</xref>), if each of the <italic>M</italic> domains has a limited number of labelled instances, then <inline-formula id="IEq117"><alternatives><mml:math id="IEq117_Math"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:msubsup></mml:mrow></mml:math><tex-math id="IEq117_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{m}={\{({x}_{i}, {y}_{i})\}}_{i=1}^{{l}_{m}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq117.gif"/></alternatives></inline-formula> and unlabeled instances <inline-formula id="IEq118"><alternatives><mml:math id="IEq118_Math"><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:msubsup></mml:mrow></mml:math><tex-math id="IEq118_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${U}_{m}={\{({x}_{i})\}}_{i=1}^{{u}_{m}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq118.gif"/></alternatives></inline-formula>. In the study, the challenge was to make use of all available resources of the <italic>M</italic> domains. The authors reported that this helped to improve the multi-domain classification performance. They furthermore introduced separation regularizer (Bousmalis et al. <xref ref-type="bibr" rid="CR30">2016</xref>; Liu et al. <xref ref-type="bibr" rid="CR158">2016</xref>) to ensure that domain-specific extractors remained distinct from the extractors, which are domain-invariant. The introduced methodology was designed to pull features from domain invariant and domain-specific literature. The shared private network was used to pass the extracted features from the texts, followed by two classifiers that work together in an adversarial fashion. A multinomial multi-domain discriminator was applied to increase the effectiveness of domain-invariant feature extraction. The authors tested this model on two MDTC benchmark datasets and for unsupervised domain adaptability. The generative model positions data with respect to extracted feature space and distinguishes labelled and unlabeled data between each domain. However, the model should be more robust to avoid overfitting for limited data samples.</p></sec><sec id="Sec30"><title>Capsule neural network</title><p id="Par108">A capsule neural network (CapsNet) was first introduced by Sabour et al. (<xref ref-type="bibr" rid="CR219">2017</xref>) to address a few drawbacks of the convolutional neural network (CNN). For instance, the sub-sampling layers involved in CNN provide less translation invariance. Also, CNN loses the information about location and position estimation and is more prone to overfitting training data for these reasons. It learns the features without understanding the spatial information. Thus, most of the CNN models are not effective to avoid misclassification. CapsNet addresses these issues by avoiding the sub-sampling layers, which helps the model to maintain the spatial and pose information. The idea of capsules was introduced by Hinton et al. (<xref ref-type="bibr" rid="CR99">2011</xref>). CapsNets use these “capsule” neural units to encode the relationship between features and location with capsules as well as transformation matrices. Since this approach acquires translation equivariance, CapsNets are more powerful than CNN for samples with misled spatial and pose information.</p><p id="Par109">The dynamic routing algorithm (Sabour et al. <xref ref-type="bibr" rid="CR219">2017</xref>) also helps CapsNets to overcome the inability of features to acquire spatial information and scarcity of rotational invariance. CapsNets also encode part-whole relationships like orientations, brightness, and scales among different entities that are objects’ features or feature parts. They use shallow CNN to acquire spatial information. However, CapsNets perform poorly on classification tasks for missing semantic information. For shallow convolutional architecture, a high number of convolutional kernels are used to provide the network with a broad receptive field, but this approach is also prone to overfitting. Since their inception, CapsNets has been employed in various researches, including cancer and tumor cell detection (Mobiny and Van Nguyen <xref ref-type="bibr" rid="CR175">2018</xref>; Afshar et al. <xref ref-type="bibr" rid="CR6">2018</xref>), generative adversarial network (Jaiswal et al. <xref ref-type="bibr" rid="CR109">2019</xref>), monitoring machine health (Zhu et al. <xref ref-type="bibr" rid="CR311">2019</xref>), object height classification (Popperli et al. <xref ref-type="bibr" rid="CR209">2019</xref>), rice image recognition (Li et al. <xref ref-type="bibr" rid="CR148">2019a</xref>, <xref ref-type="bibr" rid="CR142">b</xref>, <xref ref-type="bibr" rid="CR143">c</xref>, <xref ref-type="bibr" rid="CR144">d</xref>), protein translational analysis (Wang et al. <xref ref-type="bibr" rid="CR274">2019</xref>), hyperspectral images (Landgrebe <xref ref-type="bibr" rid="CR130">2002</xref>), and many more.</p><p id="Par110">Hyperspectral images are used for agriculture (Gevaert et al. <xref ref-type="bibr" rid="CR75">2015</xref>), land coverage classification (Yan et al. <xref ref-type="bibr" rid="CR286">2015</xref>), vegetation and water resource studies (Govender et al. <xref ref-type="bibr" rid="CR83">2007</xref>), scene classification (Hu et al. <xref ref-type="bibr" rid="CR101">2015</xref>), and other environmental monitoring related activities. Deng et al. (<xref ref-type="bibr" rid="CR54">2018</xref>) presented two-layered CapsNet, which was trained on less training samples than Hyperspectral Image (HSI) classification. The work was motivated by the simplicity and comparability of shallower deep networks. The model was trained on two real-life HSI data: PaviaU (PU) and Salins A. Upon the observation, CapsNet gave an overall accuracy of 94% and an average accuracy of 95.90% on the PU dataset, whereas CNN had 93.45% and 95.63% accuracy, respectively. The study also made a comparison among Random Forests, Support Vector Machines, and CNN with CapsNet in terms of network architecture. The authors stated that traditional deep learning-based models would not be suitable for HSI datasets (Zhong et al. <xref ref-type="bibr" rid="CR308">2018</xref>) and that CNN could achieve higher performance with more training samples, but for limited training data, CapsNet worked better. Figure <xref rid="Fig12" ref-type="fig">12</xref> shows the native logic for Hyperspectral Image (HSI) classification in its conceptual form.<fig id="Fig12"><label>Fig. 12</label><caption xml:lang="en"><p>HSI classification overview presented in (Deng et al. <xref ref-type="bibr" rid="CR54">2018</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig12_HTML.png" id="MO12"/></fig></p><p id="Par111">CapsNet was also used in another HSI study (Jiang et al. <xref ref-type="bibr" rid="CR112">2020</xref>), in which a new model called Conv-Caps was designed by integrating CNN and a capsule network with Markov Random Fields (MRF) for possessing spectral as well as spatial information. With MRF, the study used graph cut expansion for more efficient classification performance. A CNN-based feature extractor was also used in the network design. In the model, the layer was followed by a feature map in order to obtain a probability map. In the last stage, MRF was used to find subdivision labels. This method takes proper advantage of the spectral and spatial information that hyperspectral images provide. The model was evaluated with a Bayesian framework perspective and produced satisfactory results. To make capsule networks more robust, various research approaches have been introduced over time, a few of which are presented below.</p></sec><sec id="Sec31"><title>Multi-lane capsule network</title><p id="Par112">Multi-Lane Capsule Network (MLCN) was introduced by Do Rosario et al. (<xref ref-type="bibr" rid="CR60">2019</xref>) to address the limitation of traditional Capsule Networks. The algorithm was tested on the reputed FashionMNIST and CIFAR10 datasets. When compared to traditional CapsNet architectures, the authors achieved satisfactory outcomes with their novel lane proposals. The experimental baseline was similar to the original configuration employed in (Sabour et al. <xref ref-type="bibr" rid="CR219">2017</xref>). According to the findings of do Rosario et al. (<xref ref-type="bibr" rid="CR61">2021</xref>), MLCN was found to be two times more efficient, on average, than the typical capsule network. The authors introduced the problem of load balancing that occurs when distributing heterogeneous lanes within both homogeneous and heterogeneous accelerators. They addressed this issue with a greedy approach, which was argued to be 50% more efficient than the brute force naive approach. Furthermore, the load balancing issue was handled by the neural architecture search created by their MLCN models, which matched device memory.</p><p id="Par113">Chang and Liu (<xref ref-type="bibr" rid="CR38">2020</xref>) improved the MLCN algorithm by addressing the issue of capsule networks creating undesirable priorities in the background, which usually results in poor performance if the background contains too much variance. The authors proposed a newly configured multi-lane capsule network architecture with a strict-squash (MLSCN) function for image classification with a complex background to solve this issue. The novel architecture replaced the traditional squash function and optimized the dropout function d. The strict-squash algorithm was proposed to prevent the vulnerability of dynamic routing while also limiting the uselessness of the capsule initialization features. For meaningful feature extraction, the authors also proposed a coherent dynamic weighting assignment strategy in the multi-lane module. By combining these two methods, the authors recommended MLSCN on the basis of MLCN. The research work focused on addressing the issue of misclassification of images with complex backgrounds. This issue can be represented with the input formalized as below (Chang and Liu <xref ref-type="bibr" rid="CR38">2020</xref>):<disp-formula id="Equ41"><label>41</label><alternatives><mml:math display="block" id="Equ41_Math"><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi mathvariant="italic">in</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>×</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mn>11</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ41_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${G}_{in}^{i\times j}=(({g}_{11}, . ..,{g}_{1j}),({g}_{21},. . .,{g}_{2j}),. . .,({g}_{i1},. . .,{g}_{ij}))$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ41.gif"/></alternatives></disp-formula>where <inline-formula id="IEq119"><alternatives><mml:math id="IEq119_Math"><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq119_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${g}_{ij}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq119.gif"/></alternatives></inline-formula> is the input pixel value in location (<inline-formula id="IEq120"><alternatives><mml:math id="IEq120_Math"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math><tex-math id="IEq120_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i,j$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq120.gif"/></alternatives></inline-formula>). After the convolutional network processes, the feature map can be obtained using:<disp-formula id="Equ42"><label>42</label><alternatives><mml:math display="block" id="Equ42_Math"><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>×</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>11</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>21</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ42_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{out}^{i\times j}=(({\hat{g} }_{11}, . ..,{\hat{g} }_{1j}),({\hat{g} }_{21},. . .,{\hat{g} }_{2j}),. . .,({\hat{g} }_{i1},. . .,{\hat{g} }_{ij}))$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ42.gif"/></alternatives></disp-formula>where  <inline-formula id="IEq121"><alternatives><mml:math id="IEq121_Math"><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq121_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{g} }_{ij}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq121.gif"/></alternatives></inline-formula> is the output pixel value in the location (<inline-formula id="IEq122"><alternatives><mml:math id="IEq122_Math"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math><tex-math id="IEq122_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i,j$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq122.gif"/></alternatives></inline-formula>); and <inline-formula id="IEq123"><alternatives><mml:math id="IEq123_Math"><mml:msubsup><mml:mi>F</mml:mi><mml:mrow><mml:mi mathvariant="italic">out</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>×</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="IEq123_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{out}^{i\times j}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq123.gif"/></alternatives></inline-formula> is the capsule layer input, which is responsible to finish the classification step. Following this step, the output layer can be defined as:<disp-formula id="Equb"><alternatives><mml:math display="block" id="Equb_Math"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math><tex-math id="Equb_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=\{{p}_{1} , {p}_{2} , . . . {p}_{j}\}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equb.gif"/></alternatives></disp-formula>where <inline-formula id="IEq124"><alternatives><mml:math id="IEq124_Math"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq124_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq124.gif"/></alternatives></inline-formula> is the probability for each category. Most of the regions of an input image have a background as the content or information; however, this information is useless as it is the background of the image. Yet, the capsule network provides redundant attention to the information. As a result, it was identified as the fundamental cause of poor performance in traditional capsule networks. This problem was solved using the aforementioned network combined with the original capsule network along with multi-lane architectures. Chang and Liu (<xref ref-type="bibr" rid="CR38">2020</xref>) improved their work by making three major contributions: the strict-squash function, lanes filter, and drop-circuit.</p><p id="Par114">If <inline-formula id="IEq125"><alternatives><mml:math id="IEq125_Math"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq125_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${u}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq125.gif"/></alternatives></inline-formula> is activation vector of the capsule <italic>i</italic> of the previous layer, <inline-formula id="IEq126"><alternatives><mml:math id="IEq126_Math"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq126_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${V}_{j|i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq126.gif"/></alternatives></inline-formula> is the inclination of the capsule <inline-formula id="IEq127"><alternatives><mml:math id="IEq127_Math"><mml:mi>i</mml:mi></mml:math><tex-math id="IEq127_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq127.gif"/></alternatives></inline-formula> moving to be clustered in capsule <inline-formula id="IEq128"><alternatives><mml:math id="IEq128_Math"><mml:mi>j</mml:mi></mml:math><tex-math id="IEq128_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq128.gif"/></alternatives></inline-formula>. The relation between these two parameters can be formalized by the following equation (Chang and Liu <xref ref-type="bibr" rid="CR38">2020</xref>):<disp-formula id="Equ43"><label>43</label><alternatives><mml:math display="block" id="Equ43_Math"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="Equ43_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${V}_{j|i}={w}_{j|i}\times {u}_{i}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ43.gif"/></alternatives></disp-formula></p><p id="Par115">The summation of coupling coefficients between <italic>i</italic> and the other previous capsules equals 1, which was achieved by a ‘routing SoftMax’ in which the initial logits <inline-formula id="IEq129"><alternatives><mml:math id="IEq129_Math"><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq129_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{ij}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq129.gif"/></alternatives></inline-formula> are prior probabilities and the capsule <italic>i</italic> must be coupled with capsule <italic>j.</italic> Equations (<xref rid="Equ44" ref-type="disp-formula">44</xref>)-(<xref rid="Equ45" ref-type="disp-formula">47</xref>) are used to perform the necessary computations for the model architecture (Chang and Liu <xref ref-type="bibr" rid="CR38">2020</xref>).<disp-formula id="Equ44"><label>44</label><alternatives><mml:math display="block" id="Equ44_Math"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi mathvariant="italic">ik</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ44_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${c}_{ij}=\frac{\mathrm{exp}\left({b}_{ij}\right)}{\sum_{k}{b}_{ik}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ44.gif"/></alternatives></disp-formula><disp-formula id="Equ45"><label>45</label><alternatives><mml:math display="block" id="Equ45_Math"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ45_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s}_{j}=\sum_{i}({c}_{j|i}\times {v}_{j|i})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ45.gif"/></alternatives></disp-formula></p><p id="Par116">The squash function is interpreted as a normalization step upon the weighted sum from the previous layers and is presented as:<disp-formula id="Equ46"><label>46</label><alternatives><mml:math display="block" id="Equ46_Math"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>q</mml:mi><mml:mi>u</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mfenced close="|" open="|"><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mfenced close="|" open="|"><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mfrac><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mfenced close="|" open="|"><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ46_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${u}_{j}=Squash\left({S}_{j}\right)=\frac{{|\left|{S}_{j}\right||}^{2}}{1+{|\left|{S}_{j}\right||}^{2}}\frac{{S}_{j}}{|\left|{S}_{j}\right||}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ46.gif"/></alternatives></disp-formula></p><p id="Par117">Finally, to compute <inline-formula id="IEq130"><alternatives><mml:math id="IEq130_Math"><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq130_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${c}_{j|i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq130.gif"/></alternatives></inline-formula> and update <inline-formula id="IEq131"><alternatives><mml:math id="IEq131_Math"><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq131_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${u}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq131.gif"/></alternatives></inline-formula> or <inline-formula id="IEq132"><alternatives><mml:math id="IEq132_Math"><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq132_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{j|i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq132.gif"/></alternatives></inline-formula>, the following equation is used, where <inline-formula id="IEq133"><alternatives><mml:math id="IEq133_Math"><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="IEq133_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${u}_{j}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq133.gif"/></alternatives></inline-formula> is the result of the first iteration:<disp-formula id="Equ47"><label>47</label><alternatives><mml:math display="block" id="Equ47_Math"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="Equ47_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{j|i}={b}_{j|i}+{v}_{j|i}\times {u}_{j}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ47.gif"/></alternatives></disp-formula></p><p id="Par118">Based on the best classification performance on four benchmark image classification datasets, Chang and Liu (<xref ref-type="bibr" rid="CR38">2020</xref>) found that, in comparison with a single input type, multiple input types can help the multi-lane architecture to achieve better results. One shortcoming of their research was the drop-circuit, which could not recognize the combined adapted lanes. Consequently, the dropout algorithm would need further research as it establishes randomness in the experimental results.</p></sec><sec id="Sec32"><title>Complex-valued capsule network (Cv-CapsNet)</title><p id="Par119">To adjust complex datasets, He et al. (<xref ref-type="bibr" rid="CR95">2019</xref>) focuses on the extraction of multi-scale, complex-valued, and high-level features. Moreover, they introduced an algorithm with a restricted encoding unit of the complex-valued capsule and dense network, with a generalization of the dynamic routing in the complex-valued realm. The generalized dynamic routing algorithm was used to fuse the real- and imaginary values of complex-valued primary capsules. The parameters trained for complex-valued routing were lowered when compared to real-valued routing of the same dimensional capsules. He et al. (<xref ref-type="bibr" rid="CR95">2019</xref>) also introduced Cv-CapsNet +  + as an extended framework utilizing a 3-level Cv-CapsNet model. It was designed for multi-scale high-level complex-value feature extraction and merging the low-level capsules information that represents the features of instantiation. In addition, Trabelsi et al. (<xref ref-type="bibr" rid="CR264">2018</xref>) presented a method to simulate complex and real-valued convolution, which was demonstrated for a complex-valued filter matrix <inline-formula id="IEq134"><alternatives><mml:math id="IEq134_Math"><mml:mrow><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:mi>B</mml:mi></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq134_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W=\left(A+iB\right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq134.gif"/></alternatives></inline-formula> and a complex-valued vector <inline-formula id="IEq135"><alternatives><mml:math id="IEq135_Math"><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq135_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h=(x+iy)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq135.gif"/></alternatives></inline-formula> using the following computation:<disp-formula id="Equ48"><label>48</label><alternatives><mml:math display="block" id="Equ48_Math"><mml:mrow><mml:mi>W</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:mi>B</mml:mi></mml:mfenced><mml:mrow/><mml:mo>∗</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ48_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W*h=\left(A+iB\right)*(x+iy)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ48.gif"/></alternatives></disp-formula></p><p id="Par120">Real-valued matrices were also presented to introduce the real and imaginary parts in Eq. (<xref rid="Equ49" ref-type="disp-formula">49</xref>)<disp-formula id="Equ49"><label>49</label><alternatives><mml:math display="block" id="Equ49_Math"><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="fraktur">R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mi mathvariant="fraktur">I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>A</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mo>-</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mi>B</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi>A</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mrow/><mml:mo>∗</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>x</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mi>y</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equ49_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left[\begin{array}{c}\mathfrak{R}(W*h)\\ \mathfrak{I}(W*h)\end{array}\right]=\left[\begin{array}{cc}A&amp; -B\\ B&amp; A\end{array}\right]*\left[\begin{array}{c}x\\ y\end{array}\right]$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ49.gif"/></alternatives></disp-formula></p><p id="Par121">Here, the real and the imaginary components of the output convolutions are two separate parts. Moreover, the real and the imaginary part for all complex-valued convolutions are detached from each other but concatenated with respect to the real and complex parts for the following complex-part layer. He et al. (<xref ref-type="bibr" rid="CR95">2019</xref>) argued that this modelling guarantees the sustainability of the complex-valued convolutions and ensures the complex-valued encoding. Thus, the architecture was employed to fetch multi-scale features, including original, semantic, and structure features. In the model, CReLU (complex-valued) (Trabelsi et al. <xref ref-type="bibr" rid="CR264">2018</xref>) was chosen as the activation function. The authors implemented the model on CIFAR10 Fashion and MNIST datasets. The model performed well by achieving fewer trainable parameters with a smaller number of iterations. The generalized dynamic routing algorithm helped to combine the real values with the imaginary values, greatly reducing the number of trainable parameters for the same dimensional complex routing model as compared to the real-valued routing models. However, they could not reduce the computational complexity for training the model.</p></sec><sec id="Sec33"><title>Multi-scale CapsNet</title><p id="Par122">A novel variation of capsule networks was introduced by Xiang et al. (<xref ref-type="bibr" rid="CR281">2018</xref>), focusing on computational efficacy and representation capacity. In the leading stage of the presented multi-scale architecture, information was extracted following the multi-scale information extraction method. However, on the second stage hierarchy, the features were encoded into multi-dimensional capsules. An improved drop-out was also introduced in the research work to enhance the robustness of the capsule network. The authors considered the hierarchical features of the dataset and exploited multi-dimensional capsules for encoding those features. The multi-scale capsule encoding consists of two stages, where the first stage obtains the semantic and structural information through multi-scale feature acquisition. Another top branch of the two layers retrieved the semantic information from the data as well. The foremost hierarchy of the middle branch of the architecture performed the medium-level feature extraction process. The last branch took on the actual original features that were obtained without trainable parameters. In the second stage of the architecture, feature hierarchies were encoded into multi-dimensional capsules. The final branch layer was encoded to high-level features of 12D, medium level features of 8D and low-level features of 4D. The following weight matrices were used to compute the predicted vectors (Xiang et al. <xref ref-type="bibr" rid="CR281">2018</xref>):<disp-formula id="Equc"><alternatives><mml:math display="block" id="Equc_Math"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msubsup></mml:mrow></mml:math><tex-math id="Equc_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{u} }_{j|i}^{1}= {W}_{ij}{u}_{i}^{1}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equc.gif"/></alternatives></disp-formula><disp-formula id="Equd"><alternatives><mml:math display="block" id="Equd_Math"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math><tex-math id="Equd_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{u} }_{j|i}^{2}= {V}_{ij}{u}_{i}^{2}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equd.gif"/></alternatives></disp-formula><disp-formula id="Eque"><alternatives><mml:math display="block" id="Eque_Math"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msubsup></mml:mrow></mml:math><tex-math id="Eque_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{u} }_{j|i}^{3}= {U}_{ij}{u}_{i}^{3}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Eque.gif"/></alternatives></disp-formula><disp-formula id="Equf"><alternatives><mml:math display="block" id="Equf_Math"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mn>1</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equf_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{u} =concat({\hat{u} }^{1},{\hat{u} }^{2},{\hat{u} }^{3})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equf.gif"/></alternatives></disp-formula></p><p id="Par123">Equation (<xref rid="Equ50" ref-type="disp-formula">50</xref>) is used as the objective function of the multi-category capsule network (Xiang et al. <xref ref-type="bibr" rid="CR281">2018</xref>):<disp-formula id="Equ50"><label>50</label><alternatives><mml:math display="block" id="Equ50_Math"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>J</mml:mi></mml:munderover><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi mathvariant="italic">max</mml:mi><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msup><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">‖</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mfenced close=")" open="("><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo stretchy="false">‖</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">‖</mml:mo><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math><tex-math id="Equ50_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{M}=\sum_{j=1}^{J}{T}_{j}\mathit{max}{\left(0,{m}^{+}-\| {V}_{j}\| \right)}^{2}+ \lambda \left(1-{T}_{j}\right)max{(0,\Vert {V}_{j}\Vert -{m}^{-})}^{2}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ50.gif"/></alternatives></disp-formula></p><p id="Par124">The length of a capsule portrays the probability of the entity, where the length is argued to be compressed to [0,1]. Equation (<xref rid="Equ51" ref-type="disp-formula">51</xref>) represents that the length can be compressed without changing its direction and helps in translating the length as the capsule detects the actual probability of a given data feature:<disp-formula id="Equ51"><label>51</label><alternatives><mml:math display="block" id="Equ51_Math"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mfrac><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">‖</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ51_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{j}=\frac{{\| {s}_{j}\| }^{2}}{1+{\| {s}_{j}\| }^{2}}\frac{{s}_{j}}{\| {s}_{j}\| }$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ51.gif"/></alternatives></disp-formula>where <inline-formula id="IEq136"><alternatives><mml:math id="IEq136_Math"><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="IEq136_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{j}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq136.gif"/></alternatives></inline-formula> represents the capsule output of the <italic>j</italic>-th unit; and <inline-formula id="IEq137"><alternatives><mml:math id="IEq137_Math"><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="IEq137_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s}_{j}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq137.gif"/></alternatives></inline-formula> is the total input. Dynamic routing was used as a form of the information selection method, which ensures that the outputs of the children capsules are sent to their respective parent capsules (Xiang et al. <xref ref-type="bibr" rid="CR281">2018</xref>). On the other side, the routing coefficients are adjusted by the <italic>update()</italic> function shown below:<disp-formula id="Equg"><alternatives><mml:math display="block" id="Equg_Math"><mml:mrow><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="Equg_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}^{i+1}={b}^{i}+{\hat{u} }_{j}\cdot {u}_{j}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equg.gif"/></alternatives></disp-formula><disp-formula id="Equh"><alternatives><mml:math display="block" id="Equh_Math"><mml:mrow><mml:msup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equh_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${c}^{i+1}=softmax({b}^{i+1})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equh.gif"/></alternatives></disp-formula></p><p id="Par125">The authors achieved state-of-the-art performance of the model on FashionMNIST and CIFAR10 datasets. MS-CapsNet was also used in the Synthetic Aperture Radar (SAR) image detection task (Xiang et al. <xref ref-type="bibr" rid="CR281">2018</xref>). Gao et al. (<xref ref-type="bibr" rid="CR73">2021</xref>) addressed the issue of noise detection and deformation sensing in traditional CNN architectures with their implemented multiscale capsule network for feature extraction in SAR image pixels. The multiscale module exploited spatial information from the image features. The authors also applied an adaptive fusion convolution module to address the issue of noise detection and tested the model's architecture on three real-life SAR datasets.</p></sec><sec id="Sec34"><title>Attention mechanism</title><p id="Par126">The attention mechanism is described as a mapping mechanism to query and set a key-value pair to the output. In the output, all of the elements in values, keys, query, and output are vectors. The output values are produced as a weighted sum of the input values, and the weight values are assigned using a compatibility function. The query with respect to the associated key generates this compatibility function. Self-attention, also known as intra-attention, is such an attention-based mechanism that relates various positions of a unit sequence to compute the representation of that sequence input. The self-attention algorithm has been used for reading comprehension (Cheng et al. <xref ref-type="bibr" rid="CR42">2016</xref>), textual entailment (Paulus et al. <xref ref-type="bibr" rid="CR204">2018</xref>), summarization (Parikh et al. <xref ref-type="bibr" rid="CR198">2016</xref>), task-dependent sentence representation (Lin et al. <xref ref-type="bibr" rid="CR151">2017</xref>), and in many other fields.</p><p id="Par127">Vaswani (<xref ref-type="bibr" rid="CR270">2017</xref>) introduced the transformer-based attention mechanism for sequence transduction, replacing the recurrent units to employ in encoder-decoder network architectures for multi-headed self-attention units. The transformer was trained significantly for translation tasks and was found to be faster than the recurrent and convolutional-based architectures. The model was applied to 2014 WMT English-to-German and 2014 WMT English-to-French machine translation work. The encoder was used to map and input sequence for symbol representations and to generate an output sequence given the continuous representation. The transformer was employed to follow the overall architecture with the help of self-attention as well as the point-wise fully connected layers within the encoder-decoder network architecture.</p><p id="Par128">Vaswani (<xref ref-type="bibr" rid="CR270">2017</xref>) proposed a self-attention algorithm to perform two machine translation work and achieved satisfactory and parallelizable results. The model obtained a 28.4 score on BLEU for the 2014 WMT English-German machine translation task and a 41.8 score on the 2014 WMT English-French machine translation work. The model was generalized through the transformer-based attention mechanism on words, which proved to be advantageous over previous researches (Gehring et al. <xref ref-type="bibr" rid="CR74">2017</xref>; Kaiser and Sutskever <xref ref-type="bibr" rid="CR115">2016</xref>). It was successfully implemented to the English constituency parsing task with both large and limited training samples. However, the authors did not evaluate this model for image, audio, and video data.</p></sec><sec id="Sec35"><title>Deep Boltzmann machines</title><p id="Par129">Deep Boltzmann Machine (DBM) (Srivastava and Salakhutdinov <xref ref-type="bibr" rid="CR240">2014</xref>), a deep neural network architecture, is trained in a semi-supervised approach. The architecture of DBM allows the network to acquire knowledge about complex feature-based relationships. DBMs have a wide range of applications like facial expression recognition (He et al. <xref ref-type="bibr" rid="CR96">2013</xref>), text recognition (Srivastava and Salakhutdinov <xref ref-type="bibr" rid="CR240">2014</xref>), person identification from audio-visual data (Alam et al. <xref ref-type="bibr" rid="CR10">2017</xref>), 3D model recognition (Leng et al. <xref ref-type="bibr" rid="CR140">2015</xref>), and many more. DBM consists of units that are respective to input data. The hidden units in a DBM consist of symmetrical-coupled stochastic binary units. Different layers of the DBM architecture hold the binary hidden units. Coupling is enabled in consecutive two layers in a top-down and bottom-up approach. Such structure allows DBM to understand complicated internal representations of input data.</p></sec><sec id="Sec36"><title>Deep-FS: A feature selection algorithm for deep Boltzmann machines</title><p id="Par130">A deep feature selection algorithm was presented by Taherkhani et al. (<xref ref-type="bibr" rid="CR251">2018</xref>), which was argued to have the ability to remove unwanted features from extensively large datasets. Considering that a feature selection algorithm can help improve the performance of a machine learning model significantly, this algorithm was developed for DBM domain work. The algorithm was used by a Deep Boltzmann Machine and gathered the data distribution in a network. Such an algorithm is capable of embedding feature selection within a Restricted Boltzmann Machine, as presented in Fig. <xref rid="Fig13" ref-type="fig">13</xref>.<fig id="Fig13"><label>Fig. 13</label><caption xml:lang="en"><p>Representation of a restricted Boltzmann machine comprised of two layers of hidden and visible neurons. In the network, there are D visible and F hidden neural units (Taherkhani et al. <xref ref-type="bibr" rid="CR251">2018</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig13_HTML.png" id="MO13"/></fig></p><p id="Par131">Considering an RBM of D binary units, if <bold>V</bold> is a vector containing states of the D units, there is the set <bold>V</bold><inline-formula id="IEq138"><alternatives><mml:math id="IEq138_Math"><mml:mo>∈</mml:mo></mml:math><tex-math id="IEq138_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\in$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq138.gif"/></alternatives></inline-formula> {0,1}<sup>D</sup> and a vector <bold>h,</bold> which contains states of the hidden units. If an RBM has F hidden neurons, the F dimensional hidden variables are h <inline-formula id="IEq139"><alternatives><mml:math id="IEq139_Math"><mml:mo>∈</mml:mo></mml:math><tex-math id="IEq139_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\in$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq139.gif"/></alternatives></inline-formula> {0,1}<sup>F</sup>. Taherkhani et al. (<xref ref-type="bibr" rid="CR251">2018</xref>) expressed the joint configuration of <bold>V</bold> and <bold>h</bold> as defined in the following Eq. (<xref rid="Equ52" ref-type="disp-formula">52</xref>):<disp-formula id="Equ52"><label>52</label><alternatives><mml:math display="block" id="Equ52_Math"><mml:mrow><mml:mi>E</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="bold">V</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>F</mml:mi></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:munderover><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>F</mml:mi></mml:munderover><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math><tex-math id="Equ52_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$E\left(\mathbf{V},{\varvec{h}}\right)=-\sum_{i=1}^{D}\sum_{j=1}^{F}{W}_{ij}{v}_{i}{h}_{j}-\sum_{i=1}^{D}{b}_{i}{v}_{i}-\sum_{j=1}^{F}{a}_{j}{h}_{j}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ52.gif"/></alternatives></disp-formula>where <inline-formula id="IEq140"><alternatives><mml:math id="IEq140_Math"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="IEq140_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{ij}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq140.gif"/></alternatives></inline-formula> is the weight connecting the <italic>i</italic>th visible component <inline-formula id="IEq141"><alternatives><mml:math id="IEq141_Math"><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq141_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${v}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq141.gif"/></alternatives></inline-formula> and the <italic>j</italic>th hidden component <inline-formula id="IEq142"><alternatives><mml:math id="IEq142_Math"><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="IEq142_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{j}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq142.gif"/></alternatives></inline-formula>; and <inline-formula id="IEq143"><alternatives><mml:math id="IEq143_Math"><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><tex-math id="IEq143_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${b}_{i}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq143.gif"/></alternatives></inline-formula> and <inline-formula id="IEq144"><alternatives><mml:math id="IEq144_Math"><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math><tex-math id="IEq144_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${a}_{j}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq144.gif"/></alternatives></inline-formula> are the biases connecting to the <italic>i</italic>th visible units and the <italic>j</italic>th hidden units, respectively. An energy function was employed by Taherkhani et al. (<xref ref-type="bibr" rid="CR251">2018</xref>) for the joint distribution of the visible and hidden variables, which assignment is demonstrated in Eq. (<xref rid="Equ53" ref-type="disp-formula">53</xref>):<disp-formula id="Equ53"><label>53</label><alternatives><mml:math display="block" id="Equ53_Math"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi mathvariant="bold">V</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi mathvariant="bold-italic">Z</mml:mi></mml:mrow></mml:mfrac><mml:mi mathvariant="normal">exp</mml:mi><mml:mfenced close=")" open="("><mml:mo>-</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">E</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi mathvariant="bold">V</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow></mml:mfenced></mml:mfenced></mml:mrow></mml:math><tex-math id="Equ53_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{P}}\left(\mathbf{V},{\varvec{h}}\right)=\frac{1}{{\varvec{Z}}}\mathrm{exp}\left(-{\varvec{E}}\left(\mathbf{V},{\varvec{h}}\right)\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ53.gif"/></alternatives></disp-formula>where <inline-formula id="IEq145"><alternatives><mml:math id="IEq145_Math"><mml:mrow><mml:mi mathvariant="bold-italic">Z</mml:mi></mml:mrow></mml:math><tex-math id="IEq145_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{Z}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq145.gif"/></alternatives></inline-formula> is a partition function, also known as the normalizing term. The function <inline-formula id="IEq146"><alternatives><mml:math id="IEq146_Math"><mml:mrow><mml:mi mathvariant="bold-italic">Z</mml:mi></mml:mrow></mml:math><tex-math id="IEq146_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{Z}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq146.gif"/></alternatives></inline-formula> is defined below:<disp-formula id="Equ54"><label>54</label><alternatives><mml:math display="block" id="Equ54_Math"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">Z</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow></mml:munder><mml:mi mathvariant="normal">exp</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>-</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">E</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">V</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ54_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varvec{Z}}=\sum_{{\varvec{V}}}\sum_{{\varvec{h}}}\mathrm{exp}(-{\varvec{E}}(\mathbf{V},{\varvec{h}}))$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ54.gif"/></alternatives></disp-formula></p><p id="Par132">The overall sum was calculated for all pairs <bold><italic>(V,h)</italic></bold>. If <bold><italic>V</italic></bold> is a D dimensional vector and <bold><italic>h</italic></bold> is an F dimensional binary vector, there are 2<sup>D+F</sup> different pairs of <bold><italic>(V,h)</italic></bold> that are possible. Additionally, the visible units are considered to be binary. Moreover, the conditional probabilities of <inline-formula id="IEq147"><alternatives><mml:math id="IEq147_Math"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq147_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P\left({\varvec{h}}|{\varvec{V}}\right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq147.gif"/></alternatives></inline-formula>  and <inline-formula id="IEq148"><alternatives><mml:math id="IEq148_Math"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq148_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P\left({\varvec{V}}|{\varvec{h}}\right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq148.gif"/></alternatives></inline-formula> were calculated in (Taherkhani et al. <xref ref-type="bibr" rid="CR251">2018</xref>) by the following equations:<disp-formula id="Equ55"><label>55</label><alternatives><mml:math display="block" id="Equ55_Math"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>F</mml:mi></mml:munderover><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equ55_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P\left({\varvec{h}}|{\varvec{V}}\right)=\prod_{j=1}^{F}p\left({h}_{j}|{\varvec{V}}\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ55.gif"/></alternatives></disp-formula><disp-formula id="Equ56"><label>56</label><alternatives><mml:math display="block" id="Equ56_Math"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:munderover><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:math><tex-math id="Equ56_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P\left({\varvec{V}}|{\varvec{h}}\right)=\prod_{i=1}^{D}p\left({v}_{i}|{\varvec{h}}\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ56.gif"/></alternatives></disp-formula></p><p id="Par133">Furthermore, these conditional probabilities can be extended as:<disp-formula id="Equ57"><label>57</label><alternatives><mml:math display="block" id="Equ57_Math"><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ57_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{p}\left({h}_{j}=1|\mathbf{V}\right)=\mathrm{g}(\sum_{i=1}^{D}{W}_{ij}{v}_{i}+{a}_{j})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ57.gif"/></alternatives></disp-formula><disp-formula id="Equ58"><label>58</label><alternatives><mml:math display="block" id="Equ58_Math"><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="bold">h</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>F</mml:mi></mml:munderover><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ58_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{p}\left({v}_{i}=1|\mathbf{h}\right)=\mathrm{g}(\sum_{j=1}^{F}{W}_{ij}{h}_{j}+{b}_{i})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ58.gif"/></alternatives></disp-formula></p><p id="Par134">Based on the results of Taherkhani et al. (<xref ref-type="bibr" rid="CR251">2018</xref>), the novel feature selection algorithm was designed to handle feature selection from large datasets. The algorithm was embedded into DBM classifiers, which helped to handle a reduced quantity of input features with less learning errors from large datasets. The algorithm performed well because of its ability to remove irrelevant features from large data. The results demonstrated that more than 45% of the features can be reduced from the FashionMNIST dataset, which helped to reduce the network error from 0.97 to 0.90%. In addition, the time of execution was reduced by more than 5.5% for classification tasks. The model was tested on GISETTE, PANCAN, and MADELON datasets and showed to be highly effective for all datasets. Specifically, it reduced the input features by 81% for GISETTE, 77% for PANCAN, and 57% for MADELON datasets.</p></sec><sec id="Sec37"><title>Restricted Boltzmann machine</title><p id="Par135">Restricted Boltzmann machine (RBM) is a variant of the Boltzmann Machine, containing a stochastic neural network (generally) for unsupervised learning (Guo et al. <xref ref-type="bibr" rid="CR87">2016</xref>). Unlike other Boltzmann machines, RBMs have a defining trait of providing a bipartite graph for its visible and hidden layers, enabling the implementation of a gradient-based contrastive divergence algorithm for training. Developed RBM models use noisy rectified units (linear) to store data on intensities. To create learning modules, RBMs can be efficiently applied to compose deep networking models, such as Deep Energy Models (DBNs), Deep Boltzmann Machines (DBMs), and Deep Belief Networks (DBNs). Generally, RBMs are not a popular choice for computer vision-based applications; however, in recent times, a few RBM models have been structured to perform vision tasks. For example, Shape Boltzmann Machine, proposed by Eslami et al. (<xref ref-type="bibr" rid="CR67">2014</xref>), can learn to apply the probability distribution method on object shapes to model binary shape images.</p><p id="Par136">Another prominent use of RBMs, suggested by Kae et al. (<xref ref-type="bibr" rid="CR114">2013</xref>), is in combination with CRF to model local and global structures for face segmentation with improved performance in face labelling. Furthermore, another novel method based on DBN architecture and mean-covariance RBM was employed for phone recognition. Various frameworks and models for RBMs have been intensively studied and developed, each having its own sets of merits and demerits. Although most RBMs that are utilized for vision tasks exhibit remarkable capability in performing image and object classification/identifying tasks, such models must be a hybrid of one or more networks to be efficient. As of yet, standard RBMs alone are not adopted for memory associative or computer vision-based tasks and are usually in compliance with more than one other deep learning framework.</p></sec><sec id="Sec38"><title>Sequence classification restricted Boltzmann machines with gated units</title><p id="Par137">The intractability of learning and inference in RBM was investigated by Tran et al. (<xref ref-type="bibr" rid="CR265">2020</xref>) considering the exponential complexity of the gradient computation while maximizing the log-likelihoods. The algorithm optimized a conditional probability distribution in place of a joint probability distribution for sequence classification. The authors also introduced gated-Sequence Classification Restricted Boltzmann Machine (gSCRBM), in which an information processing gate is integrated alongside long short-term memory (LSTM) networks. The network architecture was evaluated in an optical character recognition (OCR) task and for multi-resident activity recognition in smart homes. It was argued that gSCRBM requires much fewer parameters compared to other recurrent architectures with memory gates. The SCRBM was constructed by the rolling RBMs along with the class label over the time of training. The network architecture interpreted the probability distribution with the following equation:<disp-formula id="Equ59"><label>59</label><alternatives><mml:math display="block" id="Equ59_Math"><mml:mrow><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:msup><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ59_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p\left( {y^{1:T} ,x^{1:T} ,h^{1:T} } \right) = \mathop \prod \limits_{t = 1}^{T} p(y^{t} ,x^{t} ,h^{t} |h^{t - 1} )$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ59.gif"/></alternatives></disp-formula>where <inline-formula id="IEq149"><alternatives><mml:math id="IEq149_Math"><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="IEq149_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{x}}^{1:T}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq149.gif"/></alternatives></inline-formula>, <inline-formula id="IEq150"><alternatives><mml:math id="IEq150_Math"><mml:msup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="IEq150_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{h}}^{1:T}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq150.gif"/></alternatives></inline-formula> are the time series corresponding to the visible and hidden states; <inline-formula id="IEq151"><alternatives><mml:math id="IEq151_Math"><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="IEq151_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}^{1:T}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq151.gif"/></alternatives></inline-formula> is a sequence of class labels; and <inline-formula id="IEq152"><alternatives><mml:math id="IEq152_Math"><mml:msup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msup></mml:math><tex-math id="IEq152_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{h}}^{0}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq152.gif"/></alternatives></inline-formula> are the hidden unit biases.</p><p id="Par138">The model faced difficulty with an intractable inference, as explained in (Sutskever and Hinton <xref ref-type="bibr" rid="CR248">2007</xref>). The authors also suggested that this problem could be solved through the addition of recurrent units, as done for RTRBM (Sutskever et al. <xref ref-type="bibr" rid="CR246">2009</xref>). For RTRBM, the class labels were excluded, while in the case of SCRBMs, local distribution at time <italic>t</italic> was<italic> p</italic>(<inline-formula id="IEq153"><alternatives><mml:math id="IEq153_Math"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="IEq153_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}^{t} ,{\mathbf{x}}^{t} ,{\mathbf{h}}^{t}|{\mathbf{h}}^{t-1})$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq153.gif"/></alternatives></inline-formula>. This was replaced by the expression presented in Eq. (<xref rid="Equ60" ref-type="disp-formula">60</xref>):<disp-formula id="Equ60"><label>60</label><alternatives><mml:math display="block" id="Equ60_Math"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mfenced close=")" open="|"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mo>;</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>-</mml:mo></mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>;</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ60_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p({y}^{t} ,{\mathbf{x}}^{t} ,{\mathbf{h}}^{t}\left|{\hat{\mathbf{h}}}^{t-1}\right)=\frac{\mathrm{exp}(-{E}_{\theta }({y}^{t} ,{\mathbf{x}}^{t} ,{\mathbf{h}}^{t};{\hat{\mathbf{h}}}^{t-1})}{{\sum }_{{y}^{t} ,{\mathbf{x}}^{t} ,{\mathbf{h}}^{t}}\mathrm{exp}(-{E}_{\theta }({y}^{^{\prime}} ,{\mathbf{x}}^{^{\prime}} ,{\mathbf{h}}^{^{\prime}};{\hat{\mathbf{h}}}^{t-1})}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ60.gif"/></alternatives></disp-formula>where <inline-formula id="IEq154"><alternatives><mml:math id="IEq154_Math"><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math><tex-math id="IEq154_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\mathbf{h}}}^{t-1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq154.gif"/></alternatives></inline-formula> is the expected values vector for the hidden units at time t-1 and is calculated as:<disp-formula id="Equ61"><label>61</label><alternatives><mml:math display="block" id="Equ61_Math"><mml:mrow><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ61_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\mathbf{h}}}^{t-1}={\mathbb{E}}[{\mathbf{H}}^{t-1}|{\mathbf{x}}^{1:t-1}, {y}^{1:t-1}]$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ61.gif"/></alternatives></disp-formula></p><p id="Par139">The local energy function is given by:<disp-formula id="Equ62"><label>62</label><alternatives><mml:math display="block" id="Equ62_Math"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>;</mml:mo><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mfenced><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfenced close="]" open="["><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup></mml:mfenced></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mi mathvariant="italic">xh</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="bold">u</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">⊤</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced close=")" open="("><mml:msup><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">h</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mfenced></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">⊤</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mrow><mml:mi mathvariant="italic">hh</mml:mi></mml:mrow></mml:msub></mml:mfenced><mml:msup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">a</mml:mi></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup></mml:msub><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:math><tex-math id="Equ62_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{\theta }\left({y}^{^{\prime}} ,{\mathbf{x}}^{^{\prime}} ,{\mathbf{h}}^{^{\prime}};{\hat{\mathbf{h}}}^{{\varvec{t}}-1}\right)=-\left[{\left({\mathbf{x}}^{t}\right)}^{\mathrm{\top }}{\mathbf{W}}_{xh}+{\mathbf{u}}_{{{\varvec{y}}}^{{\varvec{t}}}}^{\boldsymbol{\top }}+{\left({\hat{\mathbf{h}}}^{{\varvec{t}}-1}\right)}^{\boldsymbol{\top }}{\mathbf{W}}_{hh}\right]{\mathbf{h}}^{t}-{\mathbf{a}}^{\top }{\mathbf{x}}^{t}-{b}_{{y}^{t}}-{\mathbf{c}}^{\top }{\mathbf{h}}^{t}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ62.gif"/></alternatives></disp-formula></p><p id="Par140">The algorithm was designed to achieve better learning and dynamic interference in sequence classification. For long-term information retrieval, the algorithm followed the structure of rolling RBMs, and gated units (gSCRBM) were introduced. The gSCRBM performed better in terms of parameters because it was trained with fewer parameters than traditional LSTMs and GRUs. The model was evaluated to prove its superior performance over advanced LSTM structures (Yu et al. <xref ref-type="bibr" rid="CR293">2019</xref>), Bidirectional LSTM (BiLSTM), and Stacked LSTM (StackedLSTM) (Graves and Schmidhuber <xref ref-type="bibr" rid="CR85">2005</xref>). It was found that SCRBM outperformed the other models in terms of generalization. Although GRUs and LSTMs generated better results in a few circumstances, the authors explained that those architectures demand more sophisticated structures, longer processing time, and more hidden units. SCRBM was found to be more compact with fewer parameters but with the same amount of neurons as another RNN network containing the same hyperparameters. However, the SCRBM was not able to capture long-term information, which led to a vanishing gradient or exploding gradient problem. This issue was later resolved by the gated unit (gSCRBM).</p></sec></sec><sec id="Sec39"><title>Stacked denoising autoencoders</title></sec><sec id="Sec40"><title>Autoencoders</title><p id="Par141">Autoencoder neural networks were designed for unsupervised learning by applying a backpropagation algorithm of the target values for equalizing the inputs. The autoencoder learns the approximation between the output and identity function when the input is compared to the output. When the autoencoder discovers the features or data structure, the hidden units are subjected to a sparsity constraint. Autoencoder models require knowledge of the geometry of the data to properly understand the input data. Constraining the node in the hidden layer allows autoencoders to learn the low-dimensional representation of the model.</p><sec id="Sec41"><title>Autoencoders for Words</title><p id="Par142">Liou et al. (<xref ref-type="bibr" rid="CR153">2014</xref>) presented the Elman network for encoding each word of a different vector in semantic space, which is related to corresponding entropy coding (Elman <xref ref-type="bibr" rid="CR65">1990</xref>, <xref ref-type="bibr" rid="CR66">1998</xref>) and is operated on an encoder for training. The authors utilized the Elman network as a super Turing machine for powerful computation work (Siegelmann <xref ref-type="bibr" rid="CR236">1995</xref>). Figure <xref rid="Fig14" ref-type="fig">14</xref> illustrates the Elman network employed by a simple recurrent network, which was designed for semantic word categorization. However, because it could not handle the encoding task, the Elman network was redesigned in order to encode the words into the semantic space domain. The achieved codes were utilized in indexing, ranking, and categorizing literary tasks.<fig id="Fig14"><label>Fig. 14</label><caption xml:lang="en"><p>Representation of Elman network (Liou et al. <xref ref-type="bibr" rid="CR153">2014</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig14_HTML.png" id="MO14"/></fig></p><p id="Par143">Liou et al. (<xref ref-type="bibr" rid="CR153">2014</xref>) encoded each word for individual vectors while training. The ward was bound with corresponding entropy coding in semantic space. The training methodology also included ranking, indexing and categorizing literacy steps from the training data. The model was trained on the basis of acquired datasets from two Chinese novels: <italic>Romance of the Three Kingdom and Dream of the Red Chamber</italic>. However, they still needed to investigate whether a low error rate could be achieved without the renewed coding units and the same network architecture.</p></sec><sec id="Sec42"><title>Deep energy models</title><p id="Par144">The deep energy model (DEM) is a deep learning training technique for deep networks and architects based on the restrictive Boltzmann machine learning methodology (I. Goodfellow et al. <xref ref-type="bibr" rid="CR81">2016</xref>; Guo et al. <xref ref-type="bibr" rid="CR87">2016</xref>). It includes a feed-forward neural network that transforms data inputs deterministically rather than modelling the output via a layer of stochastic hidden units (perceptron/neuron), as shown in Fig. <xref rid="Fig15" ref-type="fig">15</xref>. The feedforward network <inline-formula id="IEq155"><alternatives><mml:math id="IEq155_Math"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq155_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({g}_{\theta })$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq155.gif"/></alternatives></inline-formula> acts on the universal approximation theorem in order to approximate a continuous function, mapping corresponding inputs and outputs (Nguyen-Thanh et al. <xref ref-type="bibr" rid="CR185">2020</xref>).<fig id="Fig15"><label>Fig. 15</label><caption xml:lang="en"><p>Schematic representation of deep energy model (Samaniego et al. <xref ref-type="bibr" rid="CR222">2020</xref>)</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/10462_2023_10466_Fig15_HTML.png" id="MO15"/></fig></p><p id="Par145">Unlike deep belief networks and deep Boltzmann machines that have multiple stochastic hidden layers, DEM consists of a single stochastic hidden layer (h), which allows efficient inference and simultaneous training of all the layers within the network (Ngiam et al. <xref ref-type="bibr" rid="CR183">2011</xref>). Hopfield energy models were one of the earlier developed DEMs that, in their simplistic nature, allow closed-form modelling (Bartunov et al. <xref ref-type="bibr" rid="CR22">2019</xref>). However, the Hopfield model has significant demerits and is unable to work with the quadratic dimensionality of memory patterns. The capacity for more patterns is also limited by the number of parameters in the network. Since real-world data consist of higher-order dependencies, the Hopfield energy model cannot be used (Bartunov et al. <xref ref-type="bibr" rid="CR22">2019</xref>). Ngiam et al. (<xref ref-type="bibr" rid="CR183">2011</xref>) utilized the DEM approach to process natural images, demonstrating significant improvements in data outputs when compared to greedy layer-wise training. In recent years, the development of energy-based models meta-learning (EBMM) has been observed to show better performance as a memory model that is capable of recalling training, memorizing patterns, and performing compression (Bartunov et al. <xref ref-type="bibr" rid="CR22">2019</xref>; Kraska et al. <xref ref-type="bibr" rid="CR126">2018</xref>; Parkhi et al. <xref ref-type="bibr" rid="CR201">2015</xref>; Sun et al. <xref ref-type="bibr" rid="CR243">2015</xref>; Zhang et al. <xref ref-type="bibr" rid="CR298">2016a</xref>, <xref ref-type="bibr" rid="CR304">b</xref>). Meta-based learning primarily operates on the read (x<inline-formula id="IEq156"><alternatives><mml:math id="IEq156_Math"><mml:mrow><mml:mo>;</mml:mo><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow></mml:math><tex-math id="IEq156_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$;\uptheta$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq156.gif"/></alternatives></inline-formula>) and write (X) functions by means of truncated gradient descent, as follows:<disp-formula id="Equ63"><label>63</label><alternatives><mml:math display="block" id="Equ63_Math"><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mspace width="0.166667em"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>;</mml:mo><mml:mspace width="0.166667em"/><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mo>=</mml:mo><mml:mspace width="0.166667em"/><mml:msup><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>K</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mi>γ</mml:mi><mml:mfenced close=")" open="("><mml:mi>k</mml:mi></mml:mfenced></mml:msup><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mi>E</mml:mi><mml:mfenced close=")" open="("><mml:msup><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mi>k</mml:mi></mml:mfenced></mml:msup></mml:mfenced><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:math><tex-math id="Equ63_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$read\,(\tilde{x};\,\theta )\, = \,x^{{\left( {K + 1} \right)}} = x^{k} - \gamma^{ \left( k \right)} \nabla_{x} E\left( {x^{\left( k \right)} } \right),\,x^{(0)} = \tilde{x}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ63.gif"/></alternatives></disp-formula><disp-formula id="Equ64"><label>64</label><alternatives><mml:math display="block" id="Equ64_Math"><mml:mrow><mml:mtext>L</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:mtext>X</mml:mtext><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mfenced close="|" open="|"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mtext>read</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:mover><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>;</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mrow><mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ64_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{L}}\left( {{\text{X}}, \theta } \right) = \frac{1}{N}\mathop \sum \limits_{i = 1}^{N} E[|\left| {x_{i} - {\text{read}}\left( {\overline{{x_{i} }} ;\theta } \right)} \right||_{2}^{2} ]$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ64.gif"/></alternatives></disp-formula><disp-formula id="Equ65"><label>65</label><alternatives><mml:math display="block" id="Equ65_Math"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="normal">θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mfenced close="|" open="|"><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">x</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="normal">θ</mml:mi></mml:mfenced></mml:mfenced><mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">β</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mover><mml:mi mathvariant="normal">θ</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math><tex-math id="Equ65_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{W}(\mathrm{x},\uptheta ) =\mathrm{ E}(\mathrm{x};\uptheta ) +\mathrm{ \alpha }|\left|{\nabla }_{\mathrm{x}}\mathrm{E}\left(\mathrm{x};\uptheta \right)\right|{|}_{2}^{2}+\upbeta ||\uptheta - \overline{\uptheta }|{|}_{2}^{2}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ65.gif"/></alternatives></disp-formula><disp-formula id="Equ66"><label>66</label><alternatives><mml:math display="block" id="Equ66_Math"><mml:mrow><mml:mtext>write</mml:mtext><mml:mspace width="0.166667em"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:msup><mml:mi>θ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>θ</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced></mml:msup><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:msup><mml:mi>θ</mml:mi><mml:mfenced close=")" open="("><mml:mi>t</mml:mi></mml:mfenced></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mover><mml:mi>θ</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mspace width="0.166667em"/></mml:mrow></mml:math><tex-math id="Equ66_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{write}}\,(X)\,\theta^{(T)} ,\,\theta^{{\left( {t + 1} \right)}} = \theta^{\left( t \right)} - \eta^{\left( t \right)} \frac{1}{N}\mathop \sum \limits_{i = 1}^{N} \nabla_{\theta } W(x_{i, } \theta^{\left( t \right)} ),\,\theta^{(0)} = \overline{\theta }\,$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ66.gif"/></alternatives></disp-formula>where <inline-formula id="IEq157"><alternatives><mml:math id="IEq157_Math"><mml:mi mathvariant="normal">x</mml:mi></mml:math><tex-math id="IEq157_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{x}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq157.gif"/></alternatives></inline-formula> is the input (the deterministic dynamics); X represents the Nth set of input patterns compressed into parameters,<inline-formula id="IEq158"><alternatives><mml:math id="IEq158_Math"><mml:mi mathvariant="normal">θ</mml:mi></mml:math><tex-math id="IEq158_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uptheta$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq158.gif"/></alternatives></inline-formula>, by the writing rule; N is the number of stored patterns; k = 1, 2,…K (number of sequences required to be updated to perform gradient descent for optimization for reading function); t = 1, 2,…T (number of sequences required to be updated to perform gradient descent for optimization for write function), respectively; <inline-formula id="IEq159"><alternatives><mml:math id="IEq159_Math"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">γ</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">k</mml:mi></mml:mfenced></mml:msup><mml:mi mathvariant="normal">and</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="normal">η</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math><tex-math id="IEq159_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\upgamma }^{ \left(\mathrm{k}\right)}\mathrm{ and }{\upeta }^{(\mathrm{t})}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq159.gif"/></alternatives></inline-formula> are the learned stepped sizes for reading and writing functions respectively; <inline-formula id="IEq160"><alternatives><mml:math id="IEq160_Math"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">x</mml:mi></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq160_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{E}\left(\mathrm{x}\right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq160.gif"/></alternatives></inline-formula> represents the energy function; <inline-formula id="IEq161"><alternatives><mml:math id="IEq161_Math"><mml:msub><mml:mi mathvariant="normal">∇</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:msub></mml:math><tex-math id="IEq161_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\nabla }_{\mathrm{x}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq161.gif"/></alternatives></inline-formula> is the derivative operator; and <inline-formula id="IEq162"><alternatives><mml:math id="IEq162_Math"><mml:mrow><mml:mi mathvariant="normal">W</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">θ</mml:mi></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq162_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{W}\left(\mathrm{x},\uptheta \right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq162.gif"/></alternatives></inline-formula> is the writing loss function, consisting of meta parameters <inline-formula id="IEq163"><alternatives><mml:math id="IEq163_Math"><mml:mi>α</mml:mi></mml:math><tex-math id="IEq163_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{\alpha }$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq163.gif"/></alternatives></inline-formula> and<inline-formula id="IEq164"><alternatives><mml:math id="IEq164_Math"><mml:mi mathvariant="normal">β</mml:mi></mml:math><tex-math id="IEq164_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\upbeta$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq164.gif"/></alternatives></inline-formula>, representing the energy function at a local minimum that must be two-fold and requires the hessian term to be positive. The later part of the writing loss function performs optimization, limiting deviation of prior parameter, <inline-formula id="IEq165"><alternatives><mml:math id="IEq165_Math"><mml:mover><mml:mi mathvariant="normal">θ</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math><tex-math id="IEq165_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overline{\uptheta }$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq165.gif"/></alternatives></inline-formula>, from the initial parameter,<inline-formula id="IEq166"><alternatives><mml:math id="IEq166_Math"><mml:mi mathvariant="normal">θ</mml:mi></mml:math><tex-math id="IEq166_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uptheta$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq166.gif"/></alternatives></inline-formula>. Finally, implementing gradient descent tunes the writing function as Eq. (<xref rid="Equ34" ref-type="disp-formula">34</xref>); where <inline-formula id="IEq167"><alternatives><mml:math id="IEq167_Math"><mml:mrow><mml:mi mathvariant="normal">L</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">X</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">θ</mml:mi></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq167_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{L}\left(\mathrm{X},\uptheta \right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq167.gif"/></alternatives></inline-formula> denotes the score matching objective, or the reconstruction error for the read function.</p><p id="Par146">Compared to past DEMs, EBMMs can utilize slow gradient learning, having effective convolutional memories, particularly due to fast writing rules (Bartunov et al. <xref ref-type="bibr" rid="CR22">2019</xref>). EBMMs also adhere to and manage memory capacity efficiently, even for non-compressible inputs, such as binary strings to natural images of high compression. It also has the ability to differentiate different patterns (energy levels). The method proposed by Bartunov et al. (<xref ref-type="bibr" rid="CR22">2019</xref>) resolves the functioning pace of EBMMs with fast writing and limited parameter updates (a maximum of 5 steps), adding new inputs for the weights. Another advantage of this method is the association of faster reading and fewer gradient descent steps. The employability of the proposed operations, which store N patterns in memory and do not require additional assumptions, further adds to the efficiency of the model (Bartunov et al. <xref ref-type="bibr" rid="CR22">2019</xref>). However, batch writing assumption is a challenge for EBMM and could be improved with more elaborate architecture.</p><p id="Par147">It is also difficult to find the optimum balance between writing speed and the model’s capacity (a commonality for most deep learning energy models) (Ba et al. <xref ref-type="bibr" rid="CR18">2016</xref>; Bartunov et al. <xref ref-type="bibr" rid="CR22">2019</xref>). In addition, the characterized properties of the learning attractor models are not yet known, and EBMM cannot return different associations when under uncertainty, which occurs due to compression. Furthermore, with the general application of gradient-based meta-learning, it is difficult to evaluate the expected outcome of EBMMs, mainly because of the high dimensionality pattern space of inputs that increases the resulting distortion of the model and decreases the output reliability after adaptation. Therefore, a different gradient descent functionality is necessary. Also, parametric gradient-based optimization requires significant updates (for memory/recalling applications) and, hence, is slow. Resolving these existing issues, together with the observation and exploration of more stochastic variants for EBMMs would lead to significant improvements for DEM.</p><p id="Par148">Statistical learning and construction of an inference-free hierarchical framework offer a viable solution for density estimation, consisting of higher dimensional challenges. By utilizing Bayesian (Eq. (<xref rid="Equ67" ref-type="disp-formula">67</xref>)) and Parzen score matching functions (Eq. (<xref rid="Equ68" ref-type="disp-formula">68</xref>)) (Saremi et al. <xref ref-type="bibr" rid="CR223">2018</xref>; Vincent <xref ref-type="bibr" rid="CR272">2011</xref>) together with a multilayer perceptron of scalable energy learning operation (Eq. (<xref rid="Equ69" ref-type="disp-formula">69</xref>)), the deep energy estimator network (DEEN) can be modelled and further optimized (Saremi et al. <xref ref-type="bibr" rid="CR223">2018</xref>), as follows:<disp-formula id="Equ67"><label>67</label><alternatives><mml:math display="block" id="Equ67_Math"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="normal">x</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">ξ</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="normal">ξ</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">σ</mml:mi><mml:mn>2</mml:mn><mml:mi mathvariant="normal">ψ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">ξ</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="normal">θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ67_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widehat{\mathrm{x}}\left(\upxi \right)=\upxi +\upsigma 2\uppsi (\upxi ;\uptheta )$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ67.gif"/></alternatives></disp-formula>where σ denotes any level of noise; ψ represents the score function; ξ is the noisy measurement of underlying random variable x; and <inline-formula id="IEq168"><alternatives><mml:math id="IEq168_Math"><mml:mi mathvariant="normal">θ</mml:mi></mml:math><tex-math id="IEq168_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uptheta$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq168.gif"/></alternatives></inline-formula> is the parameter vector.<disp-formula id="Equ68"><label>68</label><alternatives><mml:math display="block" id="Equ68_Math"><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">ξ</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="normal">n</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mi mathvariant="normal">k</mml:mi></mml:munder><mml:mi mathvariant="normal">S</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">ξ</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">k</mml:mi></mml:mfenced></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ68_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{P}\left(\upxi \right)=\frac{1}{\mathrm{n}}\sum_{\mathrm{k}}\mathrm{S}(\upxi |{\mathrm{x}}^{\left(\mathrm{k}\right)})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ68.gif"/></alternatives></disp-formula>where P represents the Parzen density estimator; S signifies the smoothing kernel; k represents the nth x of a dataset, x = {<inline-formula id="IEq169"><alternatives><mml:math id="IEq169_Math"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>⋯</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mi mathvariant="normal">n</mml:mi></mml:msup></mml:mrow></mml:math><tex-math id="IEq169_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{x}}^{1}, {\mathrm{x}}^{2}\dots {\mathrm{x}}^{\mathrm{n}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq169.gif"/></alternatives></inline-formula>}; and n is the number of elements in the dataset, x.<disp-formula id="Equ69"><label>69</label><alternatives><mml:math display="block" id="Equ69_Math"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">x</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="normal">θ</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:msubsup><mml:mi mathvariant="normal">w</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">L</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mi mathvariant="normal">h</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">L</mml:mi></mml:mfenced></mml:msubsup><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">x</mml:mi><mml:mo>;</mml:mo><mml:mfenced close="}" open="{"><mml:msup><mml:mrow><mml:mi mathvariant="normal">w</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mn>1</mml:mn></mml:mfenced></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">w</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mn>2</mml:mn></mml:mfenced></mml:msup><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">w</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">L</mml:mi></mml:mfenced></mml:msup></mml:mfenced></mml:mfenced><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>α</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mi>α</mml:mi></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="normal">θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ69_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{E}\left(\mathrm{x};\uptheta \right)= \sum_{\mathrm{\alpha }}{\mathrm{w}}_{\mathrm{\alpha }}^{(\mathrm{L}+1)}{\mathrm{h}}_{\mathrm{\alpha }}^{\left(\mathrm{L}\right)}\left(\mathrm{x};\left\{{\mathrm{w}}^{\left(1\right)}, {\mathrm{w}}^{\left(2\right)}, \dots , {\mathrm{w}}^{\left(\mathrm{L}\right)}\right\}\right)=\sum_{\mathrm{\alpha }}{\upvarepsilon }^{\mathrm{\alpha }}(\mathrm{x};\uptheta )$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ69.gif"/></alternatives></disp-formula></p><p id="Par149">In Eq. (<xref rid="Equ69" ref-type="disp-formula">69</xref>) (Saremi et al. <xref ref-type="bibr" rid="CR223">2018</xref>), <inline-formula id="IEq170"><alternatives><mml:math id="IEq170_Math"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">x</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="normal">θ</mml:mi></mml:mfenced></mml:mrow></mml:math><tex-math id="IEq170_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{E}\left(\mathrm{x};\uptheta \right)$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq170.gif"/></alternatives></inline-formula> is linearly constructed from the preceding hidden layer h<sup>L</sup>, in which w is the weight of each data x and parameter <inline-formula id="IEq171"><alternatives><mml:math id="IEq171_Math"><mml:mi mathvariant="normal">θ</mml:mi></mml:math><tex-math id="IEq171_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uptheta$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq171.gif"/></alternatives></inline-formula>, <inline-formula id="IEq172"><alternatives><mml:math id="IEq172_Math"><mml:msup><mml:mrow><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mi>α</mml:mi></mml:msup></mml:math><tex-math id="IEq172_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\upvarepsilon }^{\mathrm{\alpha }}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq172.gif"/></alternatives></inline-formula> denotes the expert (corresponding products of expert, PoE) parametrized by the neural network, and α signifies the number of iterations.</p><p id="Par150">Deep energy estimator networks (DEENs) have been demonstrated to be effective with high dimensionality data values (Saremi et al. <xref ref-type="bibr" rid="CR223">2018</xref>). However, it is important to note that although DEEN can auto-regularize due to its Parzen function, it is not an autoencoder. In fact, DEEN can operate with a decoder by not directly estimating the score functions (Alain et al. <xref ref-type="bibr" rid="CR9">2014</xref>) and, thus, skipping stability issues of denoising autoencoders. Being dataset-dependent, DEEN does not impose any bounds towards σ and can be effectively regularized. Apart from working with higher dimensionality data, deep energy estimators are employed for semi-supervised, unsupervised learning, and generative modelling (Saremi et al. <xref ref-type="bibr" rid="CR223">2018</xref>). DEENs provide consistent estimations and, therefore, acquire increasing interest; however, more testing is required to examine the network’s performance for dynamic data as well as the scalability potential.</p><p id="Par151">Another prominent application of DEM is the nonlinear finite deformation hyper-elasticity problem, operating on an energy and loss function. For instance, using Eulerian motion description and transport deformation gradient formulation, the nonlinear response of elastic materials (in 3D) with a large deformation continuum can be modelled by employing DEM via DNNs. In a previous work, a neural network is structured using Eq. (<xref rid="Equ70" ref-type="disp-formula">70</xref>), then optimized to minimize its potential energy using a loss function (Nguyen-Thanh et al. <xref ref-type="bibr" rid="CR185">2020</xref>):<disp-formula id="Equ70"><label>70</label><alternatives><mml:math display="block" id="Equ70_Math"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mtext>z</mml:mtext><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>k</mml:mtext></mml:mrow><mml:mtext>l</mml:mtext></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">σ</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mrow><mml:mtext>j</mml:mtext><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow><mml:msub><mml:mtext>n</mml:mtext><mml:mrow><mml:mtext>l</mml:mtext><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:munderover><mml:msubsup><mml:mtext>w</mml:mtext><mml:mrow><mml:mtext>kj</mml:mtext></mml:mrow><mml:mtext>l</mml:mtext></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mtext>z</mml:mtext><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mtext>k</mml:mtext></mml:mrow><mml:mrow><mml:mtext>l</mml:mtext><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mspace width="0.333333em"/><mml:mtext>b</mml:mtext></mml:mrow><mml:mrow><mml:mtext>k</mml:mtext></mml:mrow><mml:mtext>l</mml:mtext></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mn>0</mml:mn><mml:mspace width="0.166667em"/><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mtext>L</mml:mtext><mml:mspace width="0.166667em"/><mml:mrow><mml:mtext>(the final layer)</mml:mtext></mml:mrow></mml:mrow></mml:math><tex-math id="Equ70_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{\text{z}}}_{{\text{k}}}^{{\text{l}}} = {\upsigma }\left( {\mathop \sum \limits_{{{\text{j}} = 1}}^{{{\text{n}}_{{{\text{l}} - 1}} }} {\text{w}}_{{{\text{kj}}}}^{{\text{l}}} {\hat{\text{z}}}_{{\text{k}}}^{{{\text{l}} - 1}} + {\text{ b}}_{{\text{k}}}^{{\text{l}}} } \right),\,0\, &lt; 1 &lt; {\text{L}}\,{\text{(the final layer)}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ70.gif"/></alternatives></disp-formula>where <inline-formula id="IEq173"><alternatives><mml:math id="IEq173_Math"><mml:mover accent="true"><mml:mi mathvariant="normal">z</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><tex-math id="IEq173_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widehat{\mathrm{z}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq173.gif"/></alternatives></inline-formula> is the final output of the final layer l; w and b are weights and biases, respectively; and <inline-formula id="IEq174"><alternatives><mml:math id="IEq174_Math"><mml:mi mathvariant="normal">σ</mml:mi></mml:math><tex-math id="IEq174_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\upsigma$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq174.gif"/></alternatives></inline-formula> is the activation function acting on the kth neuron of the lth layer.</p><p id="Par152">DEM can also be utilized for nonlinear deformation, being faster with fewer coding and having the traction-free boundary conditions to be auto-filled. Training enables faster solution retrieval, and the model can be easily coded in common machine learning operating platforms, such as TensorFlow and Pytorch (Nguyen-Thanh et al. <xref ref-type="bibr" rid="CR185">2020</xref>). However, the use of DEM has certain drawbacks due to the imposition of the boundary condition of parameters and the associated integrations used for modelling and, therefore, requires further study to improve the integration techniques. Moreover, the modelling tends towards non-convexity of loss function during the nonlinear evolution of network neurons, and so, an enhanced theoretical understanding is required to better establish the deep neural network architecture. DNNs for finite deformation hyper-elasticity are trained using backpropagation, computing the gradient loss and minimizing the function, using a standard optimizer. Considering the tendency of a gap to exist between backpropagation and energy-based models, Nguyen-Thanh et al. (<xref ref-type="bibr" rid="CR185">2020</xref>) administered forward propagation to approximate the solution with defined boundary conditions, which directs the prediction. Scellier and Bengio (<xref ref-type="bibr" rid="CR224">2017</xref>) proposed equilibrium propagation to bridge gaps between backpropagation and the energy-based model. The main objective of equilibrium propagation is to ensure a learning framework for the DEMs with a 0.00% training error. Provided the statistics of an excellent training error score, it would be interesting to observe the performance of such a system for different deep learning techniques and DEMs with complex non-linear data of high parameters and dimensions.</p><p id="Par153">Reinforcement learning (RL) is another intensively studied deep learning method that has unique connections with DEMs in terms of state and action spaces. RL surpluses the shortcomings associated with DEMs, which are mostly sampling issues and unpopularity with regression models (Zhang et al. <xref ref-type="bibr" rid="CR303">2020</xref>). For example, performing molecular modelling using a DEM-based system would be difficult due to the absence of frameworks that do not involve a classification route for the dataset. Consequently, when it comes to modelling problems that do not involve density estimations or the necessity for energy functions, a new neural network is required. Recently, Zhang et al. (<xref ref-type="bibr" rid="CR303">2020</xref>) proposed a novel approach, where RL is reformulated into distribution learning to resolve sampling issues, using a minimax generative adversarial network to develop a targeted adversarial learning optimized sampling (TALOS) methodology. Another technique using entropy policy, called variational adversarial density estimation (VADE), was also effective (for molecular modelling), demonstrating how cross-fertilization between EBMs/DEMs and RL can overcome the challenges of EBMs. Haarnoja et al. (<xref ref-type="bibr" rid="CR90">2017</xref>) explored maximum RL via DEM using the Markov decision process (Eq. (<xref rid="Equ71" ref-type="disp-formula">71</xref>)) and modified the objective to maximize the entropy (Eq. (<xref rid="Equ72" ref-type="disp-formula">72</xref>)). Using soft Q learning and the Bellman equation, the model operated on learning maximum entropy policies (Eq. (<xref rid="Equ73" ref-type="disp-formula">73</xref>)).<disp-formula id="Equ71"><label>71</label><alternatives><mml:math display="block" id="Equ71_Math"><mml:mrow><mml:msub><mml:mi mathvariant="normal">π</mml:mi><mml:mrow><mml:mi mathvariant="normal">std</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">argmax</mml:mi><mml:mi mathvariant="normal">π</mml:mi></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mi mathvariant="normal">t</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">π</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ71_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\uppi }_{\mathrm{std}= }{\mathrm{argmax}}_{\uppi }\sum_{\mathrm{t}}{\mathrm{E}}_{{(\mathrm{s}}_{\mathrm{t}+{\mathrm{a}}_{\mathrm{t}}})\sim {\mathrm{p}}_{\uppi }}[\mathrm{r}({\mathrm{s}}_{\mathrm{t}}, {\mathrm{a}}_{\mathrm{t}})]$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ71.gif"/></alternatives></disp-formula><disp-formula id="Equ72"><label>72</label><alternatives><mml:math display="block" id="Equ72_Math"><mml:mrow><mml:msub><mml:mi mathvariant="normal">π</mml:mi><mml:mrow><mml:mi mathvariant="normal">MaxEnt</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">argmax</mml:mi><mml:mi mathvariant="normal">π</mml:mi></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mi mathvariant="normal">t</mml:mi></mml:munder><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">π</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi mathvariant="normal">r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mi mathvariant="normal">H</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">π</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="normal">st</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ72_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\uppi }_{\mathrm{MaxEnt}= }{\mathrm{argmax}}_{\uppi }\sum_{\mathrm{t}}{\mathrm{E}}_{{(\mathrm{s}}_{\mathrm{t}+{\mathrm{a}}_{\mathrm{t}}})\sim {\mathrm{p}}_{\uppi }}[\mathrm{r}({\mathrm{s}}_{\mathrm{t}}, {\mathrm{a}}_{\mathrm{t}})]+\mathrm{\alpha H}(\uppi (\cdot |\mathrm{st}))]$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ72.gif"/></alternatives></disp-formula>where <italic>S</italic> and <italic>a</italic> are state and action space, respectively; <italic>r</italic> denotes reward; <inline-formula id="IEq175"><alternatives><mml:math id="IEq175_Math"><mml:msub><mml:mi>p</mml:mi><mml:mi>π</mml:mi></mml:msub></mml:math><tex-math id="IEq175_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{\pi }$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq175.gif"/></alternatives></inline-formula> signifies the marginals of state and state action for the policy, <inline-formula id="IEq176"><alternatives><mml:math id="IEq176_Math"><mml:mrow><mml:mi mathvariant="normal">π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>·</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="normal">st</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><tex-math id="IEq176_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\uppi (\cdot |\mathrm{st})$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq176.gif"/></alternatives></inline-formula>; and <inline-formula id="IEq177"><alternatives><mml:math id="IEq177_Math"><mml:mi>α</mml:mi></mml:math><tex-math id="IEq177_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{\alpha }$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq177.gif"/></alternatives></inline-formula> acts as a hyperparameter.<disp-formula id="Equ73"><label>73</label><alternatives><mml:math display="block" id="Equ73_Math"><mml:mrow><mml:msub><mml:mi mathvariant="normal">π</mml:mi><mml:mi mathvariant="normal">MaxEnt</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">at</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="normal">st</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="normal">exp</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mi>α</mml:mi></mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Q</mml:mi><mml:mrow><mml:mi mathvariant="normal">soft</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub></mml:mfenced><mml:mo>-</mml:mo><mml:msubsup><mml:mi mathvariant="normal">V</mml:mi><mml:mrow><mml:mi mathvariant="normal">soft</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">st</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ73_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\uppi }_{\mathrm{MaxEnt }}\left(\mathrm{at}|\mathrm{st}\right)=\mathrm{exp}\frac{1}{\mathrm{\alpha }}({\mathrm{Q}}_{\mathrm{soft}}^{*}\left({\mathrm{S}}_{\mathrm{t}}, {\mathrm{a}}_{\mathrm{t}}\right)-{\mathrm{V}}_{\mathrm{soft}}^{*}(\mathrm{st})))$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ73.gif"/></alternatives></disp-formula>where <inline-formula id="IEq178"><alternatives><mml:math id="IEq178_Math"><mml:msubsup><mml:mi mathvariant="normal">V</mml:mi><mml:mrow><mml:mi mathvariant="normal">soft</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:math><tex-math id="IEq178_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{V}}_{\mathrm{soft}}^{*}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq178.gif"/></alternatives></inline-formula> represents a partition log function; and <inline-formula id="IEq179"><alternatives><mml:math id="IEq179_Math"><mml:msubsup><mml:mi mathvariant="normal">Q</mml:mi><mml:mrow><mml:mi mathvariant="normal">soft</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:math><tex-math id="IEq179_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{Q}}_{\mathrm{soft}}^{*}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq179.gif"/></alternatives></inline-formula> denotes a Q-function (proven and detailed by Ziebart and Fox (<xref ref-type="bibr" rid="CR312">2010</xref>) and Haarnoja et al. (<xref ref-type="bibr" rid="CR90">2017</xref>), respectively).</p><p id="Par154">Reinforcement learning energy modelling policies, which are suitable for high-dimensional values, have been observed to be robust and applicable to code robotic tasks and, hence, have become quite popular amid humanoid robots. Although the model requires pre-training of the general-purpose stochastic policies, when compared with other deep energy modelling techniques, reinforcement learning via DEM seems most promising, particularly by being able to solve inputs and sampling issues for energy-based modellings.</p></sec><sec id="Sec43"><title>Deep coding network</title><p id="Par155">Deep predictive coding network is a bio-inspired framework built on the theoretical understanding of how the brain infers sensory stimuli. The mechanism by which the brain speculates decisions based on certain data (e.g. visual information) has been formulated as the baseline for predictive coding, followed by the adaptation of filter objectives and training of modules via gradient descent. However, due to the still very misunderstood functioning of neurons in the brain, it is likely that the connected neurons in the brain consist of a more complex architecture, significantly limiting existing deep learning models. Incorporating a feedforward and feedback (prediction making) system along with each layer of a neural network is a generative understanding of deep coding networks, particularly the deep predictive coding system. Such networks are heavily studied and used for computer vision, where classification for images and videos is performed.</p><p id="Par156">A base equation for a deep predictive coding network is given by (Dora et al. <xref ref-type="bibr" rid="CR62">2018</xref>):<disp-formula id="Equ74"><label>74</label><alternatives><mml:math display="block" id="Equ74_Math"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi mathvariant="normal">N</mml:mi></mml:munderover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:munderover><mml:msub><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="normal">y</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="normal">y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:msubsup></mml:mfenced><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:munderover><mml:msub><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msubsup><mml:mi mathvariant="normal">y</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mi mathvariant="normal">l</mml:mi></mml:msubsup></mml:mfenced><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">n</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">w</mml:mi><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">n</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">i</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">j</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">l</mml:mi></mml:mfenced></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ74_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{E}= \sum_{\mathrm{l}=0}^{\mathrm{N}}(\sum_{\mathrm{m},\mathrm{n}}^{{\mathrm{Y}}_{1}, {\mathrm{X}}_{1}}{\mathrm{l}}_{\mathrm{p}}\left({\mathrm{y}}_{\mathrm{m},\mathrm{n}}^{\mathrm{l}}-{\widehat{\mathrm{y}}}_{\mathrm{m},\mathrm{n}}^{\mathrm{l}}\right)+ \sum_{\mathrm{m},\mathrm{n}}^{{\mathrm{Y}}_{1}, {\mathrm{X}}_{1}}{\mathrm{l}}_{\mathrm{p}}\left({\mathrm{y}}_{\mathrm{m},\mathrm{n}}^{\mathrm{l}}\right)+\sum_{\mathrm{m},\mathrm{n},\mathrm{i},\mathrm{j}}{\mathrm{l}}_{\mathrm{p}}({\mathrm{w}}_{\mathrm{m},\mathrm{n},\mathrm{i},\mathrm{j}}^{\left(\mathrm{l}\right)}))$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ74.gif"/></alternatives></disp-formula>where <inline-formula id="IEq180"><alternatives><mml:math id="IEq180_Math"><mml:msub><mml:mi>l</mml:mi><mml:mi>p</mml:mi></mml:msub></mml:math><tex-math id="IEq180_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${l}_{p}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq180.gif"/></alternatives></inline-formula> is the calculated error in compliance with p-norm; <inline-formula id="IEq181"><alternatives><mml:math id="IEq181_Math"><mml:msubsup><mml:mi>y</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msubsup></mml:math><tex-math id="IEq181_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}_{m,n}^{l}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq181.gif"/></alternatives></inline-formula> is a vector in a channel of the <italic>l</italic>th layer, consisting of <italic>m</italic>th rows and <italic>n</italic>th columns; <inline-formula id="IEq182"><alternatives><mml:math id="IEq182_Math"><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mfenced close=")" open="("><mml:mi>l</mml:mi></mml:mfenced></mml:msubsup></mml:math><tex-math id="IEq182_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${w}_{m,n,i,j}^{\left(l\right)}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq182.gif"/></alternatives></inline-formula> represents the filter through which neurons at m, n position of <italic>l</italic> layer is projected; <inline-formula id="IEq183"><alternatives><mml:math id="IEq183_Math"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi mathvariant="normal">and</mml:mi><mml:msub><mml:mi mathvariant="normal">X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math><tex-math id="IEq183_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{Y}}_{1}\mathrm{ and }{\mathrm{X}}_{1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq183.gif"/></alternatives></inline-formula> are the height and width of the layer arranged in a 3D box shape; and <inline-formula id="IEq184"><alternatives><mml:math id="IEq184_Math"><mml:mover accent="true"><mml:mi mathvariant="normal">y</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><tex-math id="IEq184_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widehat{\mathrm{y}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq184.gif"/></alternatives></inline-formula> and <inline-formula id="IEq185"><alternatives><mml:math id="IEq185_Math"><mml:mi mathvariant="normal">y</mml:mi></mml:math><tex-math id="IEq185_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{y}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq185.gif"/></alternatives></inline-formula> denote the predicted and actual activity of neurons, respectively.</p><p id="Par157">With limited research and understanding of brain processing, particularly of events associated with memory, learning, and attention, developing mature and complex deep predicting coding network architectures remains challenging. Therefore, visual image mapping requires further analysis. Nevertheless, many novel deep learning frameworks and applications employ the use of predictive coding across various fields for plethora machine learning applications. For instance, Dora et al. (<xref ref-type="bibr" rid="CR62">2018</xref>) developed a generative model based on deep predictive coding and trained using unsupervised learning for processing real-world images and to effectively capture the statistical regularities of the data. Such ability makes the model suitable for various image classification and computer vision tasks. The application of a similar model in security is another prominent example.</p><p id="Par158">The importance of machines to detect video anomalies is gaining popularity to enhance security and surveillance. However, video anomalies are highly ambiguous and complex, with high error margins and poor scores in existing reconstruction and prediction modules (Hasan et al. <xref ref-type="bibr" rid="CR93">2016</xref>; Liu et al. <xref ref-type="bibr" rid="CR159">2017</xref>; Ye et al. <xref ref-type="bibr" rid="CR292">2019</xref>). A recent application of deep learning by Ye et al. (<xref ref-type="bibr" rid="CR292">2019</xref>) demonstrated an improved video anomaly detection. Using a predictive coding network with an error refinement module, the methodology was able to refine coarse predictions, reconstruct errors, and create a framework that assembles reconstruction and prediction modules. The modified predictive coding model uses a multilayer network that extracts prediction error features (Eqs. (<xref rid="Equ75" ref-type="disp-formula">75</xref>) and (<xref rid="Equ76" ref-type="disp-formula">76</xref>)). The new predictions are then generated to rectify prediction errors using the convolution of the ConvLSTM unit, enabling sequential dynamics modelling (Eq. (<xref rid="Equ77" ref-type="disp-formula">77</xref>)). Afterwards, the system performs refinement. To reach a refined estimation, score gaps between the frames (normal and abnormal) are reconstructed. Equation (<xref rid="Equ79" ref-type="disp-formula">79</xref>) represents the error refinement module based on Eq. (<xref rid="Equ78" ref-type="disp-formula">78</xref>). The objective functions were minimized and optimized. Metrics, including intensity (to measure pixel-wise difference), gradient (to prevent blurry predictions), and motion constraints, were utilized as a part of the adversarial training strategy.<disp-formula id="Equ75"><label>75</label><alternatives><mml:math display="block" id="Equ75_Math"><mml:mrow><mml:mi mathvariant="normal">PEP</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">I</mml:mi><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">I</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math><tex-math id="Equ75_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{PEP}: {\mathrm{E}}_{\mathrm{j}-1}={\mathrm{I}}_{\mathrm{j}-1}-{\widehat{\mathrm{I}}}_{(\mathrm{j}-1)}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ75.gif"/></alternatives></disp-formula>where <inline-formula id="IEq186"><alternatives><mml:math id="IEq186_Math"><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="IEq186_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{E}}_{\mathrm{j}-1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq186.gif"/></alternatives></inline-formula> is the previous prediction error; <inline-formula id="IEq187"><alternatives><mml:math id="IEq187_Math"><mml:msub><mml:mi mathvariant="normal">I</mml:mi><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="IEq187_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{I}}_{\mathrm{j}-1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq187.gif"/></alternatives></inline-formula> represents the ground truth; and <inline-formula id="IEq188"><alternatives><mml:math id="IEq188_Math"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">I</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:math><tex-math id="IEq188_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\widehat{\mathrm{I}}}_{(\mathrm{j}-1)}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq188.gif"/></alternatives></inline-formula> denotes the previous prediction.<disp-formula id="Equ76"><label>76</label><alternatives><mml:math display="block" id="Equ76_Math"><mml:mrow><mml:msub><mml:mi mathvariant="normal">R</mml:mi><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">PEP</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ76_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{R}}_{\mathrm{j}-1}=\mathrm{PEP}({\mathrm{E}}_{\mathrm{j}-1})$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ76.gif"/></alternatives></disp-formula></p><p id="Par159">In Eq. (<xref rid="Equ44" ref-type="disp-formula">44</xref>), <inline-formula id="IEq189"><alternatives><mml:math id="IEq189_Math"><mml:msub><mml:mi mathvariant="normal">R</mml:mi><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="IEq189_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{R}}_{\mathrm{j}-1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq189.gif"/></alternatives></inline-formula> extracts deep features, and <inline-formula id="IEq190"><alternatives><mml:math id="IEq190_Math"><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="IEq190_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{E}}_{\mathrm{j}-1}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq190.gif"/></alternatives></inline-formula> is the previous prediction error.<disp-formula id="Equ77"><label>77</label><alternatives><mml:math display="block" id="Equ77_Math"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:msub><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Conv</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">ConvLSTM</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">R</mml:mi><mml:mrow><mml:mi mathvariant="normal">j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfenced><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ77_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widehat{{\mathrm{I}}_{\mathrm{j}}}=\mathrm{Conv}(\mathrm{ConvLSTM}\left({\mathrm{R}}_{\mathrm{j}-1}\right))$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ77.gif"/></alternatives></disp-formula>where <inline-formula id="IEq191"><alternatives><mml:math id="IEq191_Math"><mml:mover accent="true"><mml:msub><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">j</mml:mi></mml:msub><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><tex-math id="IEq191_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widehat{{\mathrm{I}}_{\mathrm{j}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq191.gif"/></alternatives></inline-formula> is the updated prediction generated from the previous prediction error; and ConvLSTM is a special LSTM operation (spatial convolutions placed for connected transformations).<disp-formula id="Equ78"><label>78</label><alternatives><mml:math display="block" id="Equ78_Math"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">N</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:msub></mml:mfrac><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:math><tex-math id="Equ78_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta \mathrm{S}= \frac{{\sum }_{\mathrm{t}\in \mathrm{N}}{\mathrm{S}}_{\mathrm{t}}}{{\mathrm{T}}_{\mathrm{n}}}-\frac{{\sum }_{\mathrm{t}\in \mathrm{A}}{\mathrm{S}}_{\mathrm{t}}}{{\mathrm{T}}_{\mathrm{a}}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ78.gif"/></alternatives></disp-formula>where <inline-formula id="IEq192"><alternatives><mml:math id="IEq192_Math"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:math><tex-math id="IEq192_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\Delta \mathrm{S}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq192.gif"/></alternatives></inline-formula> is the regularity score gap for error refinement (between normal and abnormal frame); <inline-formula id="IEq193"><alternatives><mml:math id="IEq193_Math"><mml:msub><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub></mml:math><tex-math id="IEq193_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{S}}_{\mathrm{t}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq193.gif"/></alternatives></inline-formula> is the regularity score; t, time frame; N is the sequence number set for the normal frame; A is the sequence number set for the abnormal frame; and <inline-formula id="IEq194"><alternatives><mml:math id="IEq194_Math"><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:msub></mml:math><tex-math id="IEq194_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{T}}_{\mathrm{n}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq194.gif"/></alternatives></inline-formula> and <inline-formula id="IEq195"><alternatives><mml:math id="IEq195_Math"><mml:msub><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">a</mml:mi></mml:msub></mml:math><tex-math id="IEq195_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{T}}_{\mathrm{a}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq195.gif"/></alternatives></inline-formula> denote the total number of normal and abnormal frames, respectively.<disp-formula id="Equ79"><label>79</label><alternatives><mml:math display="block" id="Equ79_Math"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi mathvariant="normal">ERM</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><tex-math id="Equ79_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widehat{{\mathrm{E}}_{\mathrm{t}}}=\mathrm{ERM}\left({\mathrm{E}}_{\mathrm{t}}\right)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ79.gif"/></alternatives></disp-formula>where <inline-formula id="IEq196"><alternatives><mml:math id="IEq196_Math"><mml:mover accent="true"><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><tex-math id="IEq196_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widehat{{\mathrm{E}}_{\mathrm{t}}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq196.gif"/></alternatives></inline-formula> and <inline-formula id="IEq197"><alternatives><mml:math id="IEq197_Math"><mml:msub><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub></mml:math><tex-math id="IEq197_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{E}}_{\mathrm{t}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq197.gif"/></alternatives></inline-formula> are the updated prediction error and preceding prediction error of time step t, respectively.</p><p id="Par160">Another novel method was proposed by Tandiya et al. (<xref ref-type="bibr" rid="CR257">2018</xref>) based on deep parse coding to detect radio frequency (RF) anomalies that are present in wireless connections. The neural network was trained to recognize the anomaly when there is a potent deviation between the predicted and actual outcomes. The method performs real-time RF monitorization, which is both non-intrusive and automated. Tandiya et al. (<xref ref-type="bibr" rid="CR257">2018</xref>) demonstrated that the use of deep predictive coding is faster and more efficient than other ML-based approaches. Sequenced images of the network’s normal operation were obtained using Prednet, a video frame detector, which teaches the network to make predictions and detect anomalies. Auto-tuning the hyperparameters could be one significant improvement for the predictive coding networks, using:<disp-formula id="Equ80"><label>80</label><alternatives><mml:math display="block" id="Equ80_Math"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">xx</mml:mi></mml:mrow><mml:mi>α</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:mfrac><mml:msub><mml:mi>X</mml:mi><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:msub><mml:mfenced close=")" open="("><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn></mml:mfenced><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>-</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><tex-math id="Equ80_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${S}_{xx}^{\alpha }\left(n,f\right)=\frac{1}{N}\sum_{r=1}^{N}\frac{1}{{N}^{^{\prime}}}{X}_{{N}^{^{\prime}}}\left(n,f+\alpha /2\right){{X}^{*}}_{{N}^{^{\prime}}}(n,f-\alpha /2)$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ80.gif"/></alternatives></disp-formula>where <italic>α</italic> = cycle frequency as one axis.</p><p id="Par161">The anomaly detection efficiency of this neural network was close to 100%. The seismocardiography-based detector showed to act relatively faster than the first detector, which is responsible for the detection anomaly in consecutive spectrogram images. The seismocardiography-based detector spots image anomalies almost instantaneously, and such a methodology of anomaly detection can be employed for networks with variable constraints and devices. However, the robustness of detection can be further improved by working with complex anomalies, evaluating longer run times, and employing machine learning techniques to process raw data in different forms. Showing promising error rates and efficient predictive capacity, each framework has its own merits and demerits. Given that predictive coding is an area that requires further understanding, the functions and frameworks applied by machine learning engineers to solve problems in various disciplines, with various biases, can be significantly improved and optimized further.</p><p id="Par162">The main objective of sparse coding, a special case of deep predictive coding, is to determine a set of input vectors as a linear combination of basis vectors, which is then taught to efficiently represent data, as seen in Eq. (<xref rid="Equ49" ref-type="disp-formula">49</xref>) (for example, image data for classification). In a study by Zhang et al. (<xref ref-type="bibr" rid="CR299">2017a</xref>, <xref ref-type="bibr" rid="CR300">b</xref>, <xref ref-type="bibr" rid="CR301">c</xref>), deep sparse coding (a deep modelling technique) produced effective results in extracting high distinct features from raw image pixels, for which the process is based on unsupervised learning. The deep sparse coding network is constructed upon basic input, a sparse-coding and pooling layer, and a normalization and map reduction layer. Such an algorithm uses heuristics to minimize non-convex functions. Although the system is dependent on a CNN architecture and could have improved speed, the overall framework is easier to code and functions better than any independent CNNs. However, deep sparse coding suffers from not being mathematically rigorous and converging towards a local minimum. Arora et al. (<xref ref-type="bibr" rid="CR16">2015</xref>) demonstrated how sparse coding can also converge to a global minimum, providing a novel-based initialization method that returns a better starting point.<disp-formula id="Equ81"><label>81</label><alternatives><mml:math display="block" id="Equ81_Math"><mml:mrow><mml:msub><mml:mtext>C</mml:mtext><mml:mtext>ij</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mo>arg</mml:mo><mml:mo movablelimits="true">min</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mtext>x</mml:mtext><mml:mrow><mml:mtext>i</mml:mtext><mml:mo>,</mml:mo><mml:mtext>j</mml:mtext></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mtext>W</mml:mtext><mml:msub><mml:mtext>c</mml:mtext><mml:mtext>ij</mml:mtext></mml:msub></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:mrow><mml:mspace width="0.333333em"/><mml:mtext>s</mml:mtext></mml:mrow><mml:mo>.</mml:mo><mml:mtext>t</mml:mtext><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mfenced close="|" open="|"><mml:msub><mml:mtext>c</mml:mtext><mml:mtext>ij</mml:mtext></mml:msub></mml:mfenced><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mtext>L</mml:mtext><mml:mn>0</mml:mn></mml:msub></mml:msub><mml:mrow/><mml:mo>≤</mml:mo><mml:mrow><mml:mspace width="0.333333em"/><mml:mtext>K</mml:mtext></mml:mrow></mml:mrow></mml:math><tex-math id="Equ81_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{C}}_{{{\text{ij}}}} = \arg \min \frac{1}{2}||{\text{x}}_{{{\text{i}},{\text{j}}}} - {\text{W}}_{{{\text{c}}_{{{\text{ij}}}} }} ||^{2} ,{\text{ s}}.{\text{t}}|\left| {{\text{c}}_{{{\text{ij}}}} } \right||_{{{\text{L}}_{0} }} { } \le {\text{ K}}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ81.gif"/></alternatives></disp-formula>where X<sub>ij</sub> is the receptive field at spatial location i, j; W represents the weight of the input; C is the number of colored channels (of the input layer), as well as the number of feature maps for the feature map layer (Zhang et al. <xref ref-type="bibr" rid="CR299">2017a</xref>, <xref ref-type="bibr" rid="CR300">b</xref>, <xref ref-type="bibr" rid="CR301">c</xref>); K controls the sparsity of <inline-formula id="IEq198"><alternatives><mml:math id="IEq198_Math"><mml:msub><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">ij</mml:mi></mml:msub></mml:math><tex-math id="IEq198_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{c}}_{\mathrm{ij}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq198.gif"/></alternatives></inline-formula>; and <inline-formula id="IEq199"><alternatives><mml:math id="IEq199_Math"><mml:msub><mml:mi mathvariant="normal">L</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math><tex-math id="IEq199_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{L}}_{0}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq199.gif"/></alternatives></inline-formula> is a constraint under batch tree orthogonal matching pursuit.<disp-formula id="Equ82"><label>82</label><alternatives><mml:math display="block" id="Equ82_Math"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mo>arg</mml:mo><mml:mo movablelimits="true">min</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mfenced close="∥" open="∥"><mml:mrow><mml:mi>I</mml:mi><mml:mo>-</mml:mo><mml:munderover><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mrow/></mml:mrow><mml:mrow/></mml:munderover></mml:mrow></mml:mfenced><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mn>2</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow/><mml:mi>F</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:munderover><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:mfenced close="|" open="|"><mml:msub><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfenced></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:munderover></mml:mrow></mml:math><tex-math id="Equ82_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C = \arg \min \frac{1}{2} \left\| {I - \mathop {\sum\nolimits_{m = 1}^{M} {w_{m} * C_{m} } }\limits_{{}}^{{}} } \right\|\begin{array}{*{20}c} 2 \\ F \\ \end{array} + \beta \mathop {\sum\nolimits_{m = 1}^{M} {\left| {C_{1} } \right|} }\limits_{m = 1}^{M}$$\end{document}</tex-math><graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_Equ82.gif"/></alternatives></disp-formula>where <inline-formula id="IEq200"><alternatives><mml:math id="IEq200_Math"><mml:msub><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:msub></mml:math><tex-math id="IEq200_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{w}}_{\mathrm{m}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq200.gif"/></alternatives></inline-formula> is the kernel; and <inline-formula id="IEq201"><alternatives><mml:math id="IEq201_Math"><mml:msub><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:msub></mml:math><tex-math id="IEq201_TeX">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym}
				\usepackage{amsfonts}
				\usepackage{amssymb}
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{C}}_{\mathrm{m}}$$\end{document}</tex-math><inline-graphic specific-use="web" mime-subtype="GIF" xlink:href="10462_2023_10466_Article_IEq201.gif"/></alternatives></inline-formula> is the sparse feature map.</p><p id="Par163">Convolutional sparse coding network (CSN), based on Eq. (<xref rid="Equ50" ref-type="disp-formula">50</xref>), incorporates the framework of a convolutional system (Zhang et al. <xref ref-type="bibr" rid="CR301">2017c</xref>). Similar to a deep sparse coding network that primarily performs patch-level approximation, CSN conducts image-level reconstruction (approximation as well), but with more hindrance due to the convolution’s nature. Therefore, deep sparse coding was observed to propagate sharp information forward. The hierarchical sparse coding (HSC) framework is a similar working sparse coding network that completes the patch operation using concatenation methodology. For HSCs, map reduction layers are essential to delve deeper. Utilizing multi-level optimization and non-negative sparse coding, Sun et al. (<xref ref-type="bibr" rid="CR244">2017</xref>) developed a multilayer sparse coding network. The latter system is a deep learning framework consisting of bottleneck modules with an expansion and reduction layer of sparse coding, consisting of wide and slim dictionaries that are able to generate high- and low-dimensional distinct features and clustered representations, respectively. A supervised learning technique was also employed to train the dictionaries, optimizing regulatory parameters. Although the network requires fewer layers and parameters, the deep learning architecture should be further studied to improve processing efficiency. The general descriptions of each deep learning modelling technique, as well as the main surveyed studies in terms of their main objectives, outcomes, and applications, have been summarized in Table <xref rid="Tab2" ref-type="table">2</xref>.<table-wrap id="Tab2"><label>Table 2</label><caption xml:lang="en"><p>Overview of the studies conducted on deep learning modelling</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Model</p></th><th align="left"><p>General description</p></th><th align="left"><p>Study surveyed</p></th><th align="left"><p>Main task(s)</p></th><th align="left"><p>Outcome(s)</p></th><th align="left"><p>Application(s)</p></th><th align="left"><p>Remarks</p></th></tr></thead><tbody><tr><td align="left" rowspan="5"><p>Vector space model (VSM)</p></td><td align="left" rowspan="5"><p>VSM is an arithmetic model in which texts are represented as vectors. The vector elements characterize the weights or significance of each word within a document. It can identify similarities among distinct documents, and thus assists to detect plagiarism. However, due to their low similarity values, long documents/papers are poorly represented. The VSM has been effectively implemented in information filtering and retrieval, among other applications</p></td><td align="left"><p>Ali et al. (<xref ref-type="bibr" rid="CR12">2019</xref>)</p></td><td align="left"><p>Propose a text classification system for retrieving transportation sentiment from social networking and news sites</p></td><td align="left"><p>Achieved an accuracy of 93% for sentiment classification, which outperformed topic2vec document representation methods with transportation datasets</p></td><td align="left"><p>Sentiment analysis, topic modelling</p></td><td align="left"><p>Sophisticated data pre-processing is needed to improve classification accuracy</p></td></tr><tr><td align="left"><p>Adhikari et al. (<xref ref-type="bibr" rid="CR5">2019</xref>)</p></td><td align="left"><p>Development of document classification model based on BERT for identifying different labels for the document classification task</p></td><td align="left"><p>Reduced the number of parameters by 30 times</p></td><td align="left"><p>Document classification</p></td><td align="left"><p>The average document length is less than bidirectional encoder representations from the transformer (BERT); the maximum length is 512</p></td></tr><tr><td align="left"><p>Si et al. (<xref ref-type="bibr" rid="CR234">2019</xref>)</p></td><td align="left"><p>Assessment of how well classic word embedding approaches (word2vec, GloVe) and contextualized methods (BERT) perform on a clinical concept extraction task</p></td><td align="left"><p>Achieving better performance (F1-measures of 93.18) on various benchmark tests</p></td><td align="left"><p>Clinical concept extraction</p></td><td align="left"><p>Not investigates the performance benefits of fine-tuning BioBERT with clinical text</p></td></tr><tr><td align="left"><p>Mohd et al. (<xref ref-type="bibr" rid="CR176">2020</xref>)</p></td><td align="left"><p>Introduced a text summarizer that obtains the features of a long text document to extract the essential and valuable information while maintaining critical information</p></td><td align="left"><p>The macro-average of precision from the experimental results was found 34%</p></td><td align="left"><p>Text summarization</p></td><td align="left"><p>Tested the technique with only one dataset</p></td></tr><tr><td align="left"><p>Yang et al. (<xref ref-type="bibr" rid="CR290">2019</xref>)</p></td><td align="left"><p>Develop a hypergraph embedding method LBSN2Vec for location-based social network data that enhanced friendship and location prediction task effectiveness</p></td><td align="left"><p>Outperforms the baseline graph embeddings an average growth of 32.95% and 25.32%, respectively</p></td><td align="left"><p>Location-based social network</p></td><td align="left"><p>Examined only the random walk in the hypergraph for location prediction tasks</p></td></tr><tr><td align="left" rowspan="8"><p>Convolutional neural network (CNN)</p></td><td align="left" rowspan="8"><p>A CNN model is comprised of three primary layers: convolution, pooling, and fully connected layers. The first two layers generate features from the input, while the third layer, the fully connected layer, connects the extracted features to the final output. The convolution layers extract high-level features from the provided data. CNNs are especially beneficial for reducing the number of parameters in an artificial neural network. However, sometimes they take a longer time to train data. These models are typically used in object detection, text classification and sentiment analysis</p></td><td align="left"><p>Barré et al. (<xref ref-type="bibr" rid="CR21">2017</xref>)</p></td><td align="left"><p>Construct LeafNet that can be used to identify plant species from the leaf images</p></td><td align="left"><p>Found an accuracy of 86.3%, 95.8%, and 97.9% on the LeafSnap, Foliage, and Flavia dataset, respectively</p></td><td align="left"><p>Plant classification</p></td><td align="left"><p>- Comparatively slow (training took about 32 h)</p><p>- Lacks context due to the small, cropped window sizes</p></td></tr><tr><td align="left"><p>Li et al. (<xref ref-type="bibr" rid="CR148">2019a</xref>, <xref ref-type="bibr" rid="CR142">b</xref>, <xref ref-type="bibr" rid="CR143">c</xref>, <xref ref-type="bibr" rid="CR144">d</xref>)</p></td><td align="left"><p>Propose a method Stereo R-CNN that can perform 3D object detection in autonomous driving</p></td><td align="left"><p>Outperformed one of the previous studies by over 25%—30%</p></td><td align="left"><p>Object detection</p></td><td align="left"><p>- Due to the absence of precise depth information, the model can only produce shallow 3D detection results</p><p>- Variations in appearance can also have a significant impact</p></td></tr><tr><td align="left"><p>Chen et al. (<xref ref-type="bibr" rid="CR39">2018a</xref>, <xref ref-type="bibr" rid="CR40">b</xref>)</p></td><td align="left"><p>Apply an unsupervised domain adaptation method for object detection in a variety of image domains</p></td><td align="left"><p>Outperformed the faster R-CNN model up to + 8.8%</p></td><td align="left"><p>Object detection</p></td><td align="left"><p>The model is adaptable to specific scenarios only</p></td></tr><tr><td align="left"><p>Chu et al. (<xref ref-type="bibr" rid="CR44">2017</xref>)</p></td><td align="left"><p>Propose a dynamic CNN-based framework for tracking objects in videos</p></td><td align="left"><p>The proposed online multi-object tracking algorithm performed better than Markov decision processes by 4%</p></td><td align="left"><p>Object tracking</p></td><td align="left"><p>- Unsuitable for applications with limited resources</p><p>- Consume a lot of memory and time</p></td></tr><tr><td align="left"><p>Hughes et al. (<xref ref-type="bibr" rid="CR106">2017</xref>)</p></td><td align="left"><p>Classify clinical text into one of 26 categories, such as "Brain" or "Cancer"</p></td><td align="left"><p>Showed better prediction accuracy compared to the word embedding based methods by about 15%</p></td><td align="left"><p>Text classification</p></td><td align="left"><p>Domain Adaptation Techniques can be used to transfer knowledge from another domain to the medical field</p></td></tr><tr><td align="left"><p>Liao et al. (<xref ref-type="bibr" rid="CR149">2017</xref>)</p></td><td align="left"><p>Predict user behavior from Twitter data</p></td><td align="left"><p>Development accuracy was maximum up to 74.5%</p></td><td align="left"><p>Sentiment analysis</p></td><td align="left"><p>A multilayer CNN may be used to boost the model</p></td></tr><tr><td align="left"><p>Perraudin et al. (<xref ref-type="bibr" rid="CR206">2019</xref>)</p></td><td align="left"><p>Develop DeepSphere, a graph-based convolutional neural network that can predict a class from a map and classify pixels from cosmological data</p></td><td align="left"><p>Better than the baselines by 10% in terms of classification accuracy</p></td><td align="left"><p>Cosmological data analysis</p></td><td align="left"><p>Missing the comparison of DeepSphere to various spherical CNN implementations with different sampling techniques</p></td></tr><tr><td align="left"><p>Mukherjee et al. (<xref ref-type="bibr" rid="CR179">2020</xref>)</p></td><td align="left"><p>Construct a CNN-based generative model, namely “GenInSAR”, for combined coherence estimation and phase filtering which directly learns interferometric synthetic aperture radar (InSAR) data distribution</p></td><td align="left"><p>Compared to the related methods, the phase cosine error,</p><p>coherence and phase root-mean-square-error of GenInSAR were improved by 0.05, 0.07 and 0.54, respectively</p></td><td align="left"><p>Synthetic aperture radar data distribution</p></td><td align="left"><p>The InSAR machine learning can be improved by GenInSAR's ability to produce new interferograms</p></td></tr><tr><td align="left" rowspan="8"><p>Recurrent neural network (RNN)</p></td><td align="left" rowspan="8"><p>RNNs are neural networks with memories capable of capturing all information recorded sequentially in the preceding unit. It is advantageous in forecasting time series since the highlight point works as a reminder of previous inputs. RNNs are useful due to the fact that they execute the same computation for each sequence element. But they suffer from gradient and exploding vanishing issues, which limits longer sequences</p></td><td align="left"><p>Siami-Namini et al. (<xref ref-type="bibr" rid="CR235">2019</xref>)</p></td><td align="left"><p>Compare LSTM and BiLSTM in time series data modelling</p></td><td align="left"><p>Enhanced forecasting accuracy by 37.78% to standard LSTM-based models</p></td><td align="left"><p>Time series modelling</p></td><td align="left"><p>BiLSTM based models appear to achieve slower performance than the LSTM-based models</p></td></tr><tr><td align="left"><p>Basiri et al. (<xref ref-type="bibr" rid="CR23">2021</xref>)</p></td><td align="left"><p>Build CNN-RNN model that can find out the sentiment from long reviews as well as short tweet text</p></td><td align="left"><p>Improved from 1.85% to 3.63% for five long review datasets in terms of accuracy</p></td><td align="left"><p>Sentiment analysis</p></td><td align="left"><p>There is potential to investigate sentiment classification at the sentence and aspect levels</p></td></tr><tr><td align="left"><p>Majumder et al. (<xref ref-type="bibr" rid="CR164">2019</xref>)</p></td><td align="left"><p>Introduced DialogueRNN built on RNN with attention mechanism for emotion detection in textual conversations with one of six emotion labels</p></td><td align="left"><p>Outperformed the baseline methods by achieving a 6.62% higher F1-score on average</p></td><td align="left"><p>Emotion detection</p></td><td align="left"><p>Time-consuming for training and not parameter-efficient for global or local contexts</p></td></tr><tr><td align="left"><p>Camgoz et al. (<xref ref-type="bibr" rid="CR34">2018</xref>)</p></td><td align="left"><p>Recognize sign language gestures from a video of someone performing continuous signs</p></td><td align="left"><p>Scored 18.13 on the BLEU-4 matric and 43.80 on the ROUGE matric</p></td><td align="left"><p>Neural machine translation</p></td><td align="left"><p>CNN could learn good feature representation, but this hypothesis's validity was not evaluated</p></td></tr><tr><td align="left"><p>G. Rao et al. (<xref ref-type="bibr" rid="CR213">2018a</xref>, <xref ref-type="bibr" rid="CR214">b</xref>)</p></td><td align="left"><p>Model long texts for generating semantic relations between sentences for sentiment analysis</p></td><td align="left"><p>Showed better performance than other models by obtaining an accuracy of 44% and 63.9%</p></td><td align="left"><p>Sentiment analysis</p></td><td align="left"><p>- Considered only the sequential order of the documents</p><p>- It is possible to represent the documents using tree-structured LSTM</p></td></tr><tr><td align="left"><p>Uddin et al. (<xref ref-type="bibr" rid="CR267">2020</xref>)</p></td><td align="left"><p>Present a multi-sensors data fusion network to recognize human activities and behavior</p></td><td align="left"><p>The average performance was measured as 99% using precision, recall, and F1-score matrices</p></td><td align="left"><p>Intelligent health care systems</p></td><td align="left"><p>The work can be extended to develop a real-time human behavior monitoring system with considering more complex human activities</p></td></tr><tr><td align="left"><p>Sahoo et al. (<xref ref-type="bibr" rid="CR220">2019</xref>)</p></td><td align="left"><p>Analyze the applicability of LSTM-RNN to forecast daily flows during low-flow periods</p></td><td align="left"><p>LSTM-RNN model performance (RMSE = 0.487) on hydrological data outperformed the traditional RNN model (RMSE = 0.516) and naive method (RMSE = 0.793)</p></td><td align="left"><p>Time series modelling</p></td><td align="left"><p>Multiple hidden LSTM layers can be used to boost the performance of the model</p></td></tr><tr><td align="left"><p>Alemany et al. (<xref ref-type="bibr" rid="CR11">2019</xref>)</p></td><td align="left"><p>Propose a fully connected RNN to predict hurricane trajectories from historical cyclone data that could learn from all types of hurricanes</p></td><td align="left"><p>For hurricane SANDY, the mean absolute error from the RNN model (0.0842) is better than the previous sparse RNN average (0.4612) model</p></td><td align="left"><p>Typhoon prediction</p></td><td align="left"><p>The model may take advantage of converting the grid locations to latitude–longitude coordinates to reduce the conversion error</p></td></tr><tr><td align="left" rowspan="3"><p>Recursive neural network (RvNN)</p></td><td align="left" rowspan="3"><p>RvNN is a nonlinear model that operates on structured inputs and is useful to parse trees in natural language processing (NLP), image analysis, and protein topologies, among other structured domain applications</p><p>It works exceptionally well in NLP-related tasks</p></td><td align="left"><p>Ma et al. (<xref ref-type="bibr" rid="CR163">2018</xref>)</p></td><td align="left"><p>Develop two recursive models for rumor detection, based on top-down and bottom-up tree-structured neural networks</p></td><td align="left"><p>Showed a strong ability to identify rumors at an early stage. Accuracy on two different datasets was calculated as 72.3% and 73.7%, better than other existing approaches</p></td><td align="left"><p>Rumor detection on Twitter</p></td><td align="left"><p>Other types of data can be added into the structured neural models, such as user properties, to boost representation learning even further</p></td></tr><tr><td align="left"><p>Biancofiore et al. (<xref ref-type="bibr" rid="CR28">2017</xref>)</p></td><td align="left"><p>Analyze atmospheric particulate matter, and forecast daily averaged concentration of PM10 and PM2.5 from one to three days ahead</p></td><td align="left"><p>Correctly predicted 95% of the days analyzed in this study</p></td><td align="left"><p>Forecasting PM10 and PM2.5</p></td><td align="left"><p>Actual prediction accuracy is decreased if only the days where the exceeded limits are considered</p></td></tr><tr><td align="left"><p>Lim and Kang (<xref ref-type="bibr" rid="CR150">2018</xref>)</p></td><td align="left"><p>Extract relationships between chemical compounds and genes</p></td><td align="left"><p>F- scores for the model including extra pre-processing and the SPINN model were calculated at 63.7 and 64.1%, respectively</p></td><td align="left"><p>Chemical compounds and genes</p></td><td align="left"><p>Coordination is not detected which may be avoided with the use of a separate module</p></td></tr><tr><td align="left" rowspan="3"><p>Neural tensor network (NTN)</p></td><td align="left" rowspan="3"><p>In contrast to conventional neural network models, NTN can directly connect two input vectors to a tensor. NTNs have been successful in various natural language processing applications</p><p>Although the NTN model is effective, it is computationally intensive</p></td><td align="left"><p>Qiu and Huang (<xref ref-type="bibr" rid="CR212">2015</xref>)</p></td><td align="left"><p>Construct a convolutional NTN for community-based question answering, integrating sentence modelling and semantic matching into one model</p></td><td align="left"><p>Outperformed the state-of-the-arts on two different languages datasets, English and Chinese</p></td><td align="left"><p>Community-based question answering</p></td><td align="left"><p>The convolutional NTN can handle more complex interactions with tensor layers than existing models</p></td></tr><tr><td align="left"><p>Bai et al. (<xref ref-type="bibr" rid="CR20">2018</xref>)</p></td><td align="left"><p>Develop deep attention NTN for visual question answering</p></td><td align="left"><p>Increased performance of 1.98% and 1.70% than existing MLB and MUTAN models respectively</p></td><td align="left"><p>Visual question answering</p></td><td align="left"><p>This method could be applied to more visual question answering models for further verification</p></td></tr><tr><td align="left"><p>Hu et al. (<xref ref-type="bibr" rid="CR103">2017</xref>)</p></td><td align="left"><p>Demonstrate how the combination of face recognition features and facial attribute features can improve face recognition performances in different challenges</p></td><td align="left"><p>The model obtained almost 100% accuracy on three databases CASIA NIR-VIS2.0, MultiPIE, and LFW</p></td><td align="left"><p>Face recognition</p></td><td align="left"><p>The approach used in the study can be scaled to big data using effective mini-batch SGD-based learning</p></td></tr><tr><td align="left" rowspan="3"><p>Deep belief network (DBN)</p></td><td align="left" rowspan="3"><p>In DBN, a stack of restricted Boltzmann machines (RBMs) is typically utilized. The DBN is used to stack multiple unsupervised networks, with the hidden layer of each network serving as the input for the subsequent layer. The RBM has the advantage of fitting sample characteristics</p></td><td align="left"><p>Abdel-Zaher and Eldeib (<xref ref-type="bibr" rid="CR2">2016</xref>)</p></td><td align="left"><p>Diagnose breast cancer through a weight-initialized backpropagation neural network from a trained DBN having identical architecture</p></td><td align="left"><p>The accuracy of the model was evaluated as 99.68% on the Wisconsin breast cancer dataset</p></td><td align="left"><p>Breast cancer detection</p></td><td align="left"><p>Since DBN requires significant computational effort on hardware, building a real-life computer-aided diagnosis system is quite challenging</p></td></tr><tr><td align="left"><p>Zhao et al. (<xref ref-type="bibr" rid="CR305">2017</xref>)</p></td><td align="left"><p>Propose a feature learning technique named discriminant DBN for synthetic aperture radar (SAR) image classification</p></td><td align="left"><p>Significantly outperformed the state-of-the-art</p></td><td align="left"><p>SAR image classification</p></td><td align="left"><p>The neighbor selection process of the training strategy of a weak classifier may cause significant variance in pseudo-labelling as it is governed by fixed neighbors. Some adaptive strategies can be followed to pick specific samples for training the weak classifiers</p></td></tr><tr><td align="left"><p>Li et al. (<xref ref-type="bibr" rid="CR145">2022</xref>)</p></td><td align="left"><p>To develop MMDBN model, a manifold-based multi-DBN to acquire deep manifold characteristics of hyperspectral imaging</p></td><td align="left"><p>Experimental findings on the Salinas, Botswana and Indian Pines datasets reach 90.48%, 97.35%, and 78.25%, respectively, demonstrating that MMDBN outperforms some state-of-the-art algorithms in classification performance</p></td><td align="left"><p>Hyperspectral imaging</p></td><td align="left"><p>MMDBN’s classification performance can be further improved by designing the combined spectral-spatial deep manifold networks</p></td></tr><tr><td align="left" rowspan="2"><p>Convolutional deep belief network (CDBN)</p></td><td align="left" rowspan="2"><p>CDBN is a hierarchical generative model for a real size image. This model stacks convolutional RBMs (CRBMs) to construct a multilayer structure similar to DBNs. Unlike RBM, the CRBM distributes the weight of the hidden and visible layers across the image</p></td><td align="left"><p>Wu et al. (<xref ref-type="bibr" rid="CR280">2018</xref>)</p></td><td align="left"><p>Present a novel technique for pathological voice detection based on CNN structure</p></td><td align="left"><p>For the validation and testing sets the accuracy of CNN was 66% and 77% respectively whereas CDBN achieved 68% and 71% respectively</p></td><td align="left"><p>Pathological voice detection</p></td><td align="left"><p>CNN can be tuned more robustly by applying CDBN to initiate the weights, and it can keep away the overfitting issue</p></td></tr><tr><td align="left"><p>Li et al. (<xref ref-type="bibr" rid="CR148">2019a</xref>, <xref ref-type="bibr" rid="CR142">b</xref>, <xref ref-type="bibr" rid="CR143">c</xref>, <xref ref-type="bibr" rid="CR144">d</xref>)</p></td><td align="left"><p>Propose a model based on Gaussian Bernoulli restricted Boltzmann machines (GBRBM) to take the benefit of GBRBM and convolution neural networks</p></td><td align="left"><p>By considering variance and convolution, feature extraction performance was improved. The model showed low computational cost compared with the existing methods</p></td><td align="left"><p>Image feature extraction</p></td><td align="left"><p>This experiment just built one GCDBN with only five layers. The recognition accuracy can be increased by adding more convolutional and pooling layers</p></td></tr><tr><td align="left" rowspan="4"><p>Hybrid neural network (HNN)</p></td><td align="left" rowspan="4"><p>The HNN is comprised of a partial first principal model that provides previous information about the process with a neural network, which acts as an estimate of unmeasured process arguments. It is useful for sentiment classification, energy forecasting, disease diagnosis, and many other applications</p></td><td align="left"><p>Arabasadi et al. (<xref ref-type="bibr" rid="CR15">2017</xref>)</p></td><td align="left"><p>Develop a hybrid technique that combines genetic algorithms with neural networks for diagnosing coronary artery disease</p></td><td align="left"><p>The hybrid approach improves the performance of a neural network by around 10% by upgrading its initial weights with a genetic algorithm</p></td><td align="left"><p>Diagnosing coronary artery disease</p></td><td align="left"><p>Some other parameters such as learning rate and momentum factor could be optimized</p></td></tr><tr><td align="left"><p>Abedinia et al. (<xref ref-type="bibr" rid="CR3">2018</xref>)</p></td><td align="left"><p>Suggest a new forecasting methodology based on a hybrid forecasting engine by integrating a neural network with a Metaheuristic algorithm</p></td><td align="left"><p>The proposed model provided better prediction accuracy than other models in the domain</p></td><td align="left"><p>Solar energy forecasting</p></td><td align="left"><p>The neural network-based forecasting engine is able to prevent underfitting and overfitting issues with the help of this hybrid method</p></td></tr><tr><td align="left"><p>Ghosh et al. (<xref ref-type="bibr" rid="CR78">2016</xref>)</p></td><td align="left"><p>Propose an architecture using probabilistic neural network (PNN) and restricted Boltzmann machine (RBM) together</p></td><td align="left"><p>Performed better than other models in Books and DVD datasets but could not perform better in Electronics, and Kitchen appliance datasets</p></td><td align="left"><p>Sentiment classification</p></td><td align="left"><p>This model does not rely on external resources, such as sentiment dictionaries, and thus reduces the system’s complexity</p></td></tr><tr><td align="left"><p>(Liu et al. <xref ref-type="bibr" rid="CR156">2022</xref>)</p></td><td align="left"><p>Use HNN with Wavelet Transform and Bayesian Optimization to predict the copper price for the short term and long-term</p></td><td align="left"><p>The proposed approaches, GRU or LSTM, accurately forecasted the copper price in the short and long term with the mean squared errors of less than 3% in both cases</p></td><td align="left"><p>Price forecasting</p></td><td align="left"><p>With the HNN, the unnecessary data can be filtered out while the optimal hyperparameter set is searched</p></td></tr><tr><td align="left"><p>Dynamic neural network (DNN)</p></td><td align="left"><p>Dynamic neural networks (DNNs) are an emerging technique that can outperform traditional static models in terms of accuracy, adaptiveness, and computational complexity</p></td><td align="left"><p>Godarzi et al. (<xref ref-type="bibr" rid="CR79">2014</xref>)</p></td><td align="left"><p>Improve the performance of an ANN to predict oil prices by developing a dynamic neural network</p></td><td align="left"><p>Better accuracy was achieved using DNN than time-series and ANN models for oil price prediction</p></td><td align="left"><p>Oil price prediction</p></td><td align="left"><p>The model adjusts the outputs obtained from the time-series model and increases the prediction accuracy</p></td></tr><tr><td align="left"><p>CBOW-DA-LR</p></td><td align="left"><p>CBOW-logistic regression (LR) is an extension of the CBOW algorithm. CBOW-DA-LR is an enhancement of CBOW-LR that incorporates visual data, such as images in tweets</p></td><td align="left"><p>Baecchi et al. (<xref ref-type="bibr" rid="CR19">2016</xref>)</p></td><td align="left"><p>Analyze sentiments with the use of multimodal learning techniques by implementing neural network-based models for microblogging content that might consist of texts and images</p></td><td align="left"><p>Outperformed the SentiBank approach, which is a well-established approach</p></td><td align="left"><p>Sentiment analysis</p></td><td align="left"><p>Can be performed well in syntactic/semantic word-similarities</p></td></tr><tr><td align="left" rowspan="2"><p>Deep echo state network (DeepESN)</p></td><td align="left" rowspan="2"><p>The DeepESN can enhance the efficiency of a general echo state network (ESN) in several domains. The DeepESN output is produced using a linear structure of the recurrent units across all recurrent layers. The usual ESN technique is subject to stability limitations. Such limits are stated in DeepESN by the criteria for the ESN of the deep reservoir computing network</p></td><td align="left"><p>Gallicchio et al. (<xref ref-type="bibr" rid="CR72">2018a</xref>)</p></td><td align="left"><p>Develop a novel technique based on DeepESN for diagnosing Parkinson’s disease</p></td><td align="left"><p>DeepESN showed significant performance compared to the echo state network (ESN). For training, validation and testing set, its accuracy was 2.67, 2.95 and 3.07% more than ESN</p></td><td align="left"><p>Diagnosing Parkinson’s disease</p></td><td align="left"><p>This is a significant initial work in the domain of DeepESN that shows the superiority of DeepESN over the shallow ESN model</p></td></tr><tr><td align="left"><p>Gallicchio et al. (<xref ref-type="bibr" rid="CR71">2018b</xref>)</p></td><td align="left"><p>Construct a DeepESN model denoted by AD-DeepESN for the time series data prediction where additive decomposition (AD) technique was used as a pre-processing step to the model</p></td><td align="left"><p>AD-DeepESN model performed well on six datasets with a low standard deviation</p></td><td align="left"><p>Time series prediction</p></td><td align="left"><p>A low standard deviation proves the stability of the model. Significant performance can be achieved for a large multidimensional data</p></td></tr><tr><td align="left" rowspan="2"><p>Elman recurrent neural network (ERNN)</p></td><td align="left" rowspan="2"><p>In ERNN, the hidden layer’s output is used as input for the context layer in the former. The ERNN architecture comprises four layers: input layer, recurrent layer, hidden and output layer. Each layer has one or multiple neurons that use a non-linear function of their weighted sum of inputs to transfer information from one layer to the next one</p></td><td align="left"><p>Wang et al. (<xref ref-type="bibr" rid="CR275">2016a</xref>, <xref ref-type="bibr" rid="CR273">b</xref>, <xref ref-type="bibr" rid="CR276">c</xref>)</p></td><td align="left"><p>Build an architecture by combining ERNN, multilayer perceptron, and stochastic-time-effective function</p></td><td align="left"><p>The proposed model showed an improvement in forecasting precision in comparison with BPNN, STNN, and ERNN</p></td><td align="left"><p>Stock indices forecasting</p></td><td align="left"><p>Nonlinear and nonstationary data can be used for getting a noticeable performance of the model</p></td></tr><tr><td align="left"><p>Krichene et al. (<xref ref-type="bibr" rid="CR127">2017</xref>)</p></td><td align="left"><p>Apply a non-linear chaotic system named Mackey–Glass to RNN that shows a good benchmark test since its elements are challenging for prediction</p></td><td align="left"><p>The proposed model’s normalized root mean square error value was minimal (0.0165) compared to other traditional RNN models</p></td><td align="left"><p>Forecasting Mackey Glass time-series elements</p></td><td align="left"><p>Randomly initializing the weights of the context units can produce the optimal results</p></td></tr><tr><td align="left" rowspan="5"><p>Deep energy model (DEM)</p></td><td align="left" rowspan="5"><p>DEM is a deep learning training technique for deep networks and architects based on the RBM learning methodology. It includes a feed-forward neural network that transforms data inputs deterministically rather than modelling the output via a layer of stochastic hidden units (perceptron/neuron). In contrast to DBNs and deep Boltzmann machines, DEM consists of a single stochastic hidden layer, which enables rapid inference and simultaneous training of all the layers within the network</p></td><td align="left"><p>Bartunov et al. (<xref ref-type="bibr" rid="CR22">2019</xref>)</p></td><td align="left"><p>Employment of meta-based learning method to energy-based memory model (EBMM) for storing patterns</p></td><td align="left"><p>The method resolved the functioning pace of EBMMs, having fast writing and limited parameter updates, adding new inputs for the weights</p></td><td align="left"><p>Building compressed memories</p></td><td align="left"><p>Compared to past DEMs, EBMMs can utilize slow gradient learning, having effective convolutional memories, particularly due to fast writing rules</p></td></tr><tr><td align="left"><p>Saremi et al. (<xref ref-type="bibr" rid="CR223">2018</xref>)</p></td><td align="left"><p>Demonstrate the utility of deep learning estimator network (DEEN) in learning scoring function, the energy, and single-step denoising operations for high-dimensional and synthetic data</p></td><td align="left"><p>Deep learning estimator network performs well for consistent estimation</p></td><td align="left"><p>Density estimation in statistical learning</p></td><td align="left"><p>The DEEN model is unexamined for linear complex higher dimensions and parameters</p></td></tr><tr><td align="left"><p>Haarnoja et al. (<xref ref-type="bibr" rid="CR90">2017</xref>)</p></td><td align="left"><p>Explore maximum reinforcement learning via DEM, using the Markov decision process</p></td><td align="left"><p>The model is capable of accurately representing complicated multi-modal behavior in a variety of contexts</p></td><td align="left"><p>Robotic tasks; Building humanoid robots</p></td><td align="left"><p>Effectively captures complex multimodal behavior pre-training general-purpose stochastic policies</p></td></tr><tr><td align="left"><p>Nguyen-Thanh et al. (<xref ref-type="bibr" rid="CR185">2020</xref>)</p></td><td align="left"><p>Directly minimizes potential energy</p></td><td align="left"><p>Fulfils equilibrium state when potential energy is minimized</p></td><td align="left"><p>Finite deformation hyper-elasticity</p></td><td align="left"><p>- Nonconvexity of the loss function when neurons are evaluated by a nonlinear activation</p><p>- Imposition of boundary conditions, integration techniques need improvements</p></td></tr><tr><td align="left"><p>Scellier and Bengio (<xref ref-type="bibr" rid="CR224">2017</xref>)</p></td><td align="left"><p>Propose equilibrium propagation to bridge gaps between backpropagation and the energy-based model</p></td><td align="left"><p>The study makes static back-propagation more conceivable</p></td><td align="left"><p>Analog circuits; digital hardware</p><p>(GPU)</p></td><td align="left"><p>Stores every previous state in the training sequences; lengthy relaxation towards a fixed point demonstrates negative impacts</p></td></tr><tr><td align="left" rowspan="5"><p>Deep coding network (DCN)</p></td><td align="left" rowspan="5"><p>DCN is a bio-inspired framework based on the theoretical knowledge of how the brain interprets sensory data. The method through which the brain predicts judgments based on specific facts (such as visual information) has been described as the foundation for predictive coding, followed by the adaption of filter objectives and training of modules via gradient descent. These networks are extensively utilized in computer vision, where image and video classification is accomplished. The DCN is also used in many other sectors including building security and surveillance, autonomous vehicle control, communication services, object detection and classification</p></td><td align="left"><p>Zhang et al. (<xref ref-type="bibr" rid="CR299">2017a</xref>, <xref ref-type="bibr" rid="CR300">b</xref>, <xref ref-type="bibr" rid="CR301">c</xref>)</p></td><td align="left"><p>Image feature learning by deep sparse-coding network</p></td><td align="left"><p>Deep sparse-coding network demonstrated effective results in extracting high distinct features from raw image pixels</p></td><td align="left"><p>Image classification, compression, denoising</p></td><td align="left"><p>Although the deep sparse-coding network detects odd features from raw images automatically, the speed of the deep sparse-coding network needs to be further improved</p></td></tr><tr><td align="left"><p>Dora et al. (<xref ref-type="bibr" rid="CR62">2018</xref>)</p></td><td align="left"><p>Develop a generative model, based on deep predictive coding, trained using unsupervised learning, for processing real-world images</p></td><td align="left"><p>The model was found suitable for various image classification and computer vision tasks</p></td><td align="left"><p>Image translation; computer vision tasks</p></td><td align="left"><p>More studies are necessary to understand the organization of the brain to infer real-world images in order to improve the algorithm</p></td></tr><tr><td align="left"><p>Sun et al. (<xref ref-type="bibr" rid="CR244">2017</xref>)</p></td><td align="left"><p>Intermediate representations with non-negative sparse coding</p></td><td align="left"><p>Efficiently extended</p><p>the conventional sparse coding to multilayer architectures;</p><p>expanded learning capacity</p></td><td align="left"><p>Object detection; Image classification</p></td><td align="left"><p>Reduces the computational costs of sparse coding network; compatible with batch normalization and other deep learning tools; Complies with few parameters and layers</p></td></tr><tr><td align="left"><p>Tandiya et al. (<xref ref-type="bibr" rid="CR257">2018</xref>)</p></td><td align="left"><p>Monitorization and analysis of radiofrequency by deep predictive coding</p></td><td align="left"><p>The use of deep predictive coding was found faster and more efficient than other machine learning-based approaches</p></td><td align="left"><p>Autonomous vehicle control; communication services</p></td><td align="left"><p>Scalable to networks with many devices robustness would require improvement for complex anomalies, evaluating longer run-times and employing machine learning techniques to process raw data in different forms</p></td></tr><tr><td align="left"><p>Ye et al. (<xref ref-type="bibr" rid="CR292">2019</xref>)</p></td><td align="left"><p>Improve video anomaly detection</p></td><td align="left"><p>The predictive coding network with an error refinement module was able to refine coarse predictions, reconstruct errors, and create a framework that assembles reconstruction and prediction modules</p></td><td align="left"><p>Building security and surveillance</p></td><td align="left"><p>Auto-tuning the hyperparameters could be a significant improvement for the predictive coding networks</p></td></tr><tr><td align="left" rowspan="4"><p>Capsule neural network (CapsNet)</p></td><td align="left" rowspan="4"><p>CapsNets use “capsule” neural units to encode the relationship between features and location with capsules as well as transformation matrices. Since this approach acquires translation equivariance, CapsNets are more powerful than CNN for samples with misled spatial and pose information. CapsNets encode part-whole relationships like orientations, brightness, and scales among different entities that are objects’ features or feature parts. They use shallow CNN to acquire spatial information. However, the CapsNets perform poorly on classification tasks for missing semantic information</p></td><td align="left"><p>Chang &amp; Liu (<xref ref-type="bibr" rid="CR38">2020</xref>)</p></td><td align="left"><p>The strict-squash (MLSCN) solved the problem of the traditional capsule network of turning to account for every property of an image</p></td><td align="left"><p>The novel squash functions solved the problem of poor performance issues; due to being sensitive to noise of traditional capsule networks</p></td><td align="left"><p>Image recognition</p></td><td align="left"><p>The dropout mechanism needs further research</p></td></tr><tr><td align="left"><p>J. He et al. (<xref ref-type="bibr" rid="CR95">2019</xref>)</p></td><td align="left"><p>Extracting the high-level information of multi-scale complex-valued features in order to adopt complex datasets</p></td><td align="left"><p>Novel encoding unit of restricted complex-value dense network with another complex-valued capsule, generalizing the dynamic routing algorithm for implementation in the complex-valued domain</p></td><td align="left"><p>Information extraction</p></td><td align="left"><p>Applying the generalized dynamic routing algorithm to fuse the real- and imaginary values of primary capsules that are complex-valued highly decreased the parameters to be trained for complex-valued models compared to real-valued models of similar dimension capsules. However, the models had computational complexity</p></td></tr><tr><td align="left"><p>Deng et al. (<xref ref-type="bibr" rid="CR54">2018</xref>)</p></td><td align="left"><p>A two-layer CapsNet architecture was presented in this paper. The architecture was designed to be trained with limited training examples for Hyperspectral Image Classification (HSI)</p></td><td align="left"><p>The presented CapsNet architecture achieved an overall 94% accuracy and 95.90% on average for the PU and SalinsA datasets; whereas CNN gave 93.45% and 95.63% accuracies respectively</p></td><td align="left"><p>Hyperspectral Image Classification</p></td><td align="left"><p>CapsNets was brought for training HSI classification and made a comparison with the Random Forests, Support Vector Machines and CNN-based state-of-the-art classifiers to prove that CapsNets work better for HSI classification</p></td></tr><tr><td align="left"><p>Xiang et al. (<xref ref-type="bibr" rid="CR281">2018</xref>)</p></td><td align="left"><p>Enhancing the computational efficiency and capacity of representation of traditional capsule networks</p></td><td align="left"><p>Between a two-staged architecture, the first stage is responsible for obtaining semantic and structural information by employing multi-scale information learning; and the second stage is responsible for encoding the hierarchy levels of features for multi-dimensional capsules</p></td><td align="left"><p>Information extraction</p></td><td align="left"><p>The improved dropout enhanced the robustness of the traditional capsule network and MS-CapsNets outperformed traditional CapsNets. No detailed analysis was performed of the network architectures over complex datasets</p></td></tr><tr><td align="left" rowspan="4"><p>Generative adversarial network (GAN)</p></td><td align="left" rowspan="4"><p>GAN is a machine learning algorithm in which two neural networks compete to increase accurate predictions. It often operates unsupervised and utilizes a framework based on cooperative zero-sum games to learn. It is capable of parallelizing the sampling of generated data. However, it is harder to train as various forms of data need to be provided constantly in order to determine whether GAN operates well or not</p></td><td align="left"><p>Pfau (<xref ref-type="bibr" rid="CR207">2017</xref>)</p></td><td align="left"><p>Stabilizing GANs through defining the generator objective regarding unrolled optimization of the discriminator</p></td><td align="left"><p>The introduced method solved the problems of mode collapse and stabilized GANs’ training with recurrent generators. It also increased the assortment and scope of data distribution</p></td><td align="left"><p>Stabilizing GAN training</p></td><td align="left"><p>The computational cost of each training step is as high as it increased linearly with the amount of unrolling steps</p></td></tr><tr><td align="left"><p>Karras et al. (<xref ref-type="bibr" rid="CR117">2019</xref>)</p></td><td align="left"><p>A style transfer-based alternate version of the generative adversarial network</p></td><td align="left"><p>The proposed generator improved the general distribution of quality metrics, leading to understanding more accurate interpolation. The generator also disentangled the variation for the latent factors</p></td><td align="left"><p>Redesigning generator architecture</p></td><td align="left"><p>The style-based generators can perform better than traditional GAN generators</p></td></tr><tr><td align="left"><p>Y. Yan &amp; Guo (<xref ref-type="bibr" rid="CR287">2020</xref>)</p></td><td align="left"><p>-The model worked through two levels of a label based and a feature-based adversarial generator, designed under a bidirectional mapping network framework</p></td><td align="left"><p>The noise label generator model performed non-random aspects of noise labels which are conditioned on the true label. Moreover, the data feature generator model performed conditioning on data samples on the respective true labels. A prediction model was also presented in the paper which performed inverse mappings between labels and features</p></td><td align="left"><p>Label learning</p></td><td align="left"><p>Both of the generators worked simultaneously to identify ground truth labels from the training samples. These training samples were perceived from the features and the candidate points. The authors tested the model across real-world and synthesized datasets and got state-of-the-art result performance</p></td></tr><tr><td align="left"><p>Wu &amp; Guo (<xref ref-type="bibr" rid="CR279">2020</xref>)</p></td><td align="left"><p>The authors proposed a novel approach of co-learning with dual adversarial networks for multi-domain sentiment classification</p></td><td align="left"><p>The proposed approach pulled out features of both domain-invariant and domain-specific texts</p></td><td align="left"><p>Sentiment classification</p></td><td align="left"><p>The proposed method aligned data across domains through the extracted feature space and also situated labelled and unlabeled data between each domain. The proposed methodology was able to avoid overfitting in case of limited data</p></td></tr><tr><td align="left" rowspan="4"><p>Deep Boltzmann Machines (DBM)</p></td><td align="left" rowspan="4"><p>DBM is a deep neural network architecture that is trained in a semi-supervised approach. Its architecture allows the network to acquire knowledge about complex feature-based relationships. DBMs have a wide range of applications like facial expression recognition, text recognition, person identification from audio-visual data, 3D model recognition, and many more</p></td><td align="left"><p>Taherkhani et al. (<xref ref-type="bibr" rid="CR251">2018</xref>)</p></td><td align="left"><p>The proposed research work introduced a unique feature selection method to embed in a Restricted Boltzmann Machine</p></td><td align="left"><p>A novel algorithm was proposed for input feature selection from large datasets. The algorithm was embedded into Deep Boltzmann Machines classifiers to reduce input features and learning errors from large datasets</p></td><td align="left"><p>Feature selection</p></td><td align="left"><p>The novel algorithm is very effective for feature reduction purposes from large datasets. Along with reducing the number of features, the algorithm also reduced error rate and increased classification performance with respect to time variation</p></td></tr><tr><td align="left"><p>Tran et al. (<xref ref-type="bibr" rid="CR265">2020</xref>)</p></td><td align="left"><p>To address the difficulty of learning and interference in Recurrent Temporal Restricted Boltzmann Machine models of the exponential character of gradient computing</p></td><td align="left"><p>To achieve better results in representation learning and dynamic interference upon sequence classification, the authors introduced SCRBM. The model was designed through rolling RBMs with their class nodes with respect to time</p></td><td align="left"><p>Learning and interference</p></td><td align="left"><p>Comparing to standard RNNs, SCRBM is more compact with respect to a number of parameters to learn with an equal number of hidden neural units. However, SCRBM could not accumulate long-term information</p></td></tr><tr><td align="left"><p>Vaswani (<xref ref-type="bibr" rid="CR270">2017</xref>)</p></td><td align="left"><p>A transformer-based attention mechanism dispensed with recurrence and convolution was presented in the paper</p></td><td align="left"><p>Two machine translation tasks were performed that showed better results that were parallelizable and it required less time to be trained</p></td><td align="left"><p>Object detection</p></td><td align="left"><p>Transformer-based models were yet to experiment on problems of input and output modalities which include images, audio and video data</p></td></tr><tr><td align="left"><p>Dahl et al. (<xref ref-type="bibr" rid="CR49">2010</xref>)</p></td><td align="left"><p>Develop a novel method based on DBN architecture and mean-covariance RBM (mcRBM) for phone recognition</p></td><td align="left"><p>Through the use of mcRBM features in conjunction with DBNs, a 20.5% phone error rate was achieved</p></td><td align="left"><p>Phone recognition, face labelling</p></td><td align="left"><p>The mcRBM is useful for a small training set but suffers from representational inefficiency issues</p></td></tr><tr><td align="left"><p>Stacked denoising autoencoders</p><p>(SDAE)</p></td><td align="left"><p>SDAE is an expansion of the stacked autoencoder. Several denoising autoencoders are connected in a chain to form a SDAE. An important feature of SDAE is unsupervised pre-training, which occurs layer by layer as input data is passed through. However, it has a high computational cost</p></td><td align="left"><p>Liou et al. (<xref ref-type="bibr" rid="CR153">2014</xref>)</p></td><td align="left"><p>Using Elman network to work with word sequences from literature work</p></td><td align="left"><p>The training method consisted of encoding each word into separate vectors in semantic space and it was related to corresponding entropy coding. The trained codes had reduced entropy</p></td><td align="left"><p>Indexing, ranking, and categorization of literary tasks</p></td><td align="left"><p>It is necessary to investigate whether reduced errors were attainable without utilizing the revised codes and the same methods</p></td></tr></tbody></table></table-wrap></p></sec></sec></sec><sec id="Sec44"><title>Advantages and challenges of deep learning models</title><p id="Par164">The several advantages underpinning deep learning models, including image processing and recognition, speech recognition, self-driving cars, and so on, have sparked such widespread attention. The main benefit of using deep learning models over machine learning (ML) technologies is their capacity to produce new features through a limited range of features in the trained dataset (Kotsiopoulos et al. <xref ref-type="bibr" rid="CR125">2021</xref>). These models can generate new tasks for solving current ones as well as they also cover a variety of human life aspects. A significant amount of time can be saved using deep learning models when dealing with massive datasets, as deep learning algorithms can generate features without the need for human intervention (Gupta et al. <xref ref-type="bibr" rid="CR88">2021</xref>).</p><p id="Par165">Despite their numerous advantages, deep learning models have a number of noticeable challenges. First, they are unable to provide arguments supporting the fact that a particular conclusion is reached (Signorelli <xref ref-type="bibr" rid="CR237">2018</xref>). In addition, unlike typical machine learning, people are not able to follow an algorithm to figure out why the system decides that the image portrayed is a dog rather than a cat. To correct these types of errors in deep learning algorithms, the entire algorithm must be revised, which requires additional time. Also, high-performance computing units, high powerful GPUs and enormous quantities of storage are needed to train the models. Therefore, deep learning models require more time compared to traditional ML methods (Palanichamy <xref ref-type="bibr" rid="CR194">2019</xref>). The challenges of applying the deep learning models are summarized in Table <xref rid="Tab3" ref-type="table">3</xref> along with their advantages.<table-wrap id="Tab3"><label>Table 3</label><caption xml:lang="en"><p>Advantages and challenges of deep learning modelling techniques</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Deep learning models</p></th><th align="left"><p>Advantages</p></th><th align="left"><p>Challenges</p></th></tr></thead><tbody><tr><td align="left"><p>Vector space model (VSM)</p></td><td align="left"><p>- Ranks retrieved documents by identifying and rating the most relevant text documents for a specific query</p><p>- Identifies similarities among distinct documents, and thus assists to detect plagiarism</p><p>- Simple in structure as it is constructed on the basis of linear algebra</p><p>- Permits for partial matching</p><p>- Term weights are not binary</p><p>- Allows for the computation of the similarity degree between documents and queries on a continuous scale</p></td><td align="left"><p>- Textual VSM is incapable of coping with linguistic ambiguity and a variety</p><p>- Theoretically, terms are assumed to be statistically independent</p><p>- In the presentation of vector space, the order of the terms that appeared in the documents is lost</p><p>- Keywords search must exactly match the terms in the document; word substrings can lead to a match of "false positive "</p><p>- Due to their low similarity values, long documents/papers are poorly represented</p><p>- Suffers from polysemy and synonym</p><p>- The process of weighting is intuitive, although it is not very much formal</p><p>- Sensitivity to semantics; papers with a similar context and a distinct term vocabulary will not be associated, causing a match of "false negative"</p></td></tr><tr><td align="left"><p>Convolutional neural network (CNN)</p></td><td align="left"><p>- Feature engineering is a time-consuming and complicated process used traditionally in image processing that is not required in CNN</p><p>- The models are considered robust under different challenging circumstances such as complex background, system orientation and size, various resolutions, and illumination</p><p>- After training, the efficiency of testing time is substantially higher than that of other approaches including SVM</p><p>- Requires less time in classification</p><p>- Without human supervision, automatically can detect critical parameters</p><p>- High precision in the problems of image recognition</p></td><td align="left"><p>- Poor data labelling, which can significantly reduce system performance and accuracy</p><p>- Comparatively larger data sets are required to train, as well as correct annotation, which requires domain expertise</p><p>- Optimization challenges arising from the complexity of the models, and hardware limitations</p><p>- Sometimes take a longer time to train data</p><p>- Computational cost is high</p><p>- Takes more time to train using a bad GPU</p></td></tr><tr><td align="left"><p>Recurrent neural network (RNN)</p></td><td align="left"><p>- RNNs are frequently used in conjunction with convolutional layers to extend the effective pixel neighborhood</p><p>- It is advantageous in forecasting time series since the highlight point works as a reminder of previous inputs</p><p>- It takes a long time to train an RNN for computational problems</p><p>- Time series inputs allow RNNs to handle nonlinear dynamics, as well as long-term correlations</p><p>- In RNN, weight remains the same over all the layers, limiting the parameters the network needs to learn</p><p>- Any length of input can be processed by RNN</p><p>- The model dimension remains constant even the input dimension is increased</p></td><td align="left"><p>- Suffers from gradient and exploding vanishing issue, which limits longer sequences</p><p>- Unable to stack up</p><p>- Training processes are complex and slow</p><p>- RNN is less powerful than CNN</p><p>- When Relu or Tanh is used as an activating feature, it cannot handle exceedingly long sequences</p><p>- The flow of information across the layers/levels makes it a nightmarish task</p><p>- It cannot be progressed without knowing the structure of the tree for each input sample</p><p>- The computation process is comparatively slow because of its repeated/recurrent nature</p></td></tr><tr><td align="left"><p>Hierarchical bidirectional recurrent neural network (HBRNN)</p></td><td align="left"><p>- Each layer in the HBRNN handles classification tasks and plays a critical role in the effectiveness of the entire network</p><p>- Each layer in the network can constitute a classifier hierarchy</p><p>- In most cases, its efficiency and accuracy are comparatively better than the other networks as the HBRNN is constructed through the extensions of bidirectional recurrent neural network (BRNN) and RNN</p><p>- Simultaneously forecasts both negative and positive time directions</p></td><td align="left"><p>- Must be known of both the beginning and end of the sequence</p><p>- Suffers from computational complexity because of considering more parameters than an RNN</p><p>- May not be suitable in the applications of real-time speech recognition</p><p>- It is necessary to have access to the entire sequence before making predictions</p><p>- Since HBRNN anticipates future words, it may not be appropriate to forecast the next word based on the prior ones. In this case, using HBRNN will result in poor accuracy</p><p>- Large datasets are needed for better prediction accuracy</p></td></tr><tr><td align="left"><p>Recursive neural network (RvNN)</p></td><td align="left"><p>- Extremely beneficial for analyzing language and natural scenes</p><p>- It can be utilized to learn the tree-like structure</p><p>- Useful for categorization tasks such as classifying metagenomic sample morphologies</p><p>- RvNN is capable of identifying the samples which are comparatively similar to one another on the basis of the scoring function</p><p>- Future data can be annotated with class relationships using the recursive neural network</p><p>- Provides a representation of high-dimensional features</p><p>- Capable of generating a tree-like hierarchical relationship between the samples</p><p>- Suitable for both supervised and unsupervised learning tasks as it is capable of addressing both regression and classification problems</p></td><td align="left"><p>- Recursive neural networks may not be as accurate as deep belief networks and graph neural networks</p><p>- It faces a problem with vanishing gradient</p><p>- Tree structures of the input samples need to be known during the training period</p><p>- Parsing is domain-specific and slow</p><p>- RvNN is afflicted by the problem of long-distance reliance</p><p>- Due to the intrinsic complexity, the recursive neural networks are intrinsically complicated</p><p>- Computationally quite expensive during the learning phase</p><p>- The process of obtaining labelled data for RvNNs is excruciatingly difficult and time-consuming</p><p>- Labels are required for every bigram and its supersets that is not easy to find in real world</p></td></tr><tr><td align="left"><p>Neural tensor network (NTN)</p></td><td align="left"><p>- NTN can effectively explain the complicated semantic linkages between relationships and entities</p><p>- Minimize the entity representation learning sparseness problem</p><p>- Generalizes numerous previous models of the neural network</p><p>- Provides a comparatively powerful way for modelling relational data than a typical neural network layer does</p><p>- It can multiply the two inputs rather than only implicitly via non-linearity</p><p>- Able to provide higher precision in the prediction of invisible connections between entities via reasoning within a specified knowledge base</p><p>- Allows database extension even when no exterior textual resources are available</p></td><td align="left"><p>- The level of computational complexity is extremely high</p><p>- Huge triplet samples are required to properly learn</p><p>- Has a minimal impact on sparse knowledge graphs on a wide scale</p><p>- Require the estimation of a huge amount of parameters, which frequently leads to overfitting</p><p>- Long training period is needed compared to the other neural network models as it comprises so many parameters</p></td></tr><tr><td align="left"><p>Deep belief networks (DBN)</p></td><td align="left"><p>- The greedy learning approach with DBNs can address the difficulty of appropriate parameter selection</p><p>- No labelled data is required as it is also an unsupervised process</p><p>- Have significant benefits in learning input features applied broadly in numerous fields including disease diagnosis, speech and face recognition, image processing, traffic flow forecasting, breast cancer classification, and interpretation of natural language</p><p>- DBNs benefit from the steady characteristic learning of randomly input samples, enabling highly efficient application in the areas of handwriting, face and speech recognition</p><p>- It uses layer-by-layer training to effectively learn a deep hierarchy probabilistic model for the performance optimization of classification problems</p></td><td align="left"><p>- DBNs do not take into consideration the two-dimensional framework of input images, which could considerably impact their performance as well as application in multimedia analysis and computer vision problems</p><p>- High computational cost to train a DBN</p><p>- The lack of clarity regarding the processes necessary to further optimize the network using maximum training approximation</p><p>- Due to the vast amount of data involved, the DBN training processes are time-intensive, and thus may not meet the needs of real-time application systems</p><p>- Performance is poor due to the input data being clamped when a contrastive divergence learning algorithm is used to pre-train DBN</p></td></tr><tr><td align="left"><p>Generative adversarial network (GAN)</p></td><td align="left"><p>- It is capable of parallelizing the sampling of generated data</p><p>- GAN does not require to estimate a probability distribution by the introduction of a lower bound like a variational autoencoder</p><p>- It has been empirically demonstrated to yield sharper and better results than any other type of generative model, particularly variational autoencoder</p><p>- Capable to generate similar types of data, image, audio, video and texts to the original one</p><p>- GANs delve into the minutiae of data and can quickly interpret it into many formats, making them useful for machine learning tasks</p><p>- Different types of objects such as trees, bicyclists, parking car on streets, and people can be recognized easily using GANs</p><p>- Able to measure the distance between two different objects</p></td><td align="left"><p>- The data generating process is inherently slow, which is exacerbated when dealing with the generation of high-dimensional data, such as voice recognition</p><p>- GAN training is unstable and challenging to converge</p><p>- It suffers from mode collapse issue</p><p>- Harder to train as various forms of data need to be provided constantly in order to determine whether GAN operates well or not</p><p>- Producing outcomes from speech or text is an extremely complicated process</p><p>- Due to the instability of training and the approach of unsupervised learning, it becomes more difficult to generate output</p><p>- Lack of intrinsic evaluation metrics</p><p>- Unable to forecast the density accuracy and identify an image is dense enough to proceed with</p><p>- Inverting in GANS is not simple</p></td></tr><tr><td align="left"><p>Capsule neural network (CapsNet)</p></td><td align="left"><p>- CapsNet can achieve state-of-the-art performance due to the less complexity in its structure</p><p>- It does not require so many parameters like convolutional neural network</p><p>- Well generalized ability on smaller datasets makes CapsNets suitable for usage in a wide range of applications</p><p>- The usage of pose matrices or parameter vectors allows CapsNets to recognize objects, irrespective of the viewpoint</p><p>- Capable of capturing class object instantiation parameters</p><p>- CapsNets represent more specific features to understand what and how the network is learning</p></td><td align="left"><p>- CapsNets are not able to perform consistently across various datasets, particularly large datasets such as ImageNet</p><p>- The rigid concept of capsule entities may make the concept inappropriate for applications not related to computer vision</p><p>- Not suitable for online-based training</p><p>- Possesses higher complexity to implement compared to convolutional neural networks</p><p>- As the CapsNet generates matrix or vector outputs it cannot simply reuse previous loss functions</p><p>- Not able to distinguish closer objects</p><p>- The routing process is dynamic as well as difficult to parallelize, limiting GPUs from fully utilizing their computational capability</p></td></tr><tr><td align="left"><p>Attention mechanism</p></td><td align="left"><p>- Allows guidance of any tasks of a complex system including prediction, modelling, and identification</p><p>- It is incorporated with a recurrent neural network and long short-term memory which enables the modelling of lengthy temporal dependencies</p><p>- Controls the cognitive process flexibly by concentrating on a collection of elements</p><p>- It is capable of focusing on spatial dimensions, temporal dimensions, or various features of the input vectors</p><p>- Attention mechanism can link each input vector to generate the output vector more directly and symmetrically</p><p>- It can deduce information from an input that is most relevant to completing a task, which improves performance, particularly in language processing</p></td><td align="left"><p>- Attention mechanism adds additional weight parameters in the model, which might lengthen training time, particularly if the model’s input data contains long sequences of data</p><p>- It is a long and tedious process to parallelize the system</p><p>- Attention mechanisms often keep them distinct and disjoined using the dedicated channel and spatial attention module, preventing interaction between these two modules, thus not optimal</p><p>- Numerous attention methods do not prioritize channel interaction when computing attention weights, hence reducing information transmission</p><p>- The majority of attention techniques introduce significant additional computation in model parameter form, causing slower and larger architectures</p></td></tr><tr><td align="left"><p>Deep Boltzmann machine (DBM)</p></td><td align="left"><p>- Capable of learning various levels of representation from input data using multilayer structures</p><p>- Promising in solving speech and object recognition issues</p><p>- DBM model can effectively use large volumes of unlabeled data</p><p>- Can handle ambiguous inputs more robustly</p><p>- Efficiently performs learning inferences and parameters with greedy-layered training</p><p>- Capable of identifying latent features in data</p><p>- DBM model can integrate multiple data sources into a single representation that incorporates useful retrieval and classification features</p></td><td align="left"><p>- Maximum probabilistic learning in deep Boltzmann machines is a challenge due to the hard inference issue caused by partition functions</p><p>- Multiple hidden layers exacerbate the difficulty of learning in deep Boltzmann machines</p><p>- Approximate inference is noticeably slower than a single pass (bottom-up) as in DBNs</p><p>- DBM training is computationally expensive compared to the training of the deep belief network</p><p>- Less intuitive and difficult to train as they require layer-by-layer sampling and pre-training</p></td></tr><tr><td align="left"><p>Stacked denoising autoencoders (SDAE)</p></td><td align="left"><p>- Using SDAE, the weight errors of the process of fine-tuning can be reduced</p><p>- Can effectively avoid gradient vanishing and over-fitting issues</p><p>- Unsupervised learning process utilizing the SDAE is reliable in the load forecasting</p><p>- Can be used in learning compact data representation</p><p>- SDAE improves deep learning accuracy by embedding noisy autoencoders in the layers</p><p>- It can be used to distort data and to introduce some noise to generalize throughout the test set</p><p>- Delivers a raw data version with detailed as well as noteworthy feature information</p></td><td align="left"><p>- Optimizing a threshold that is sufficiently generalizable to previously unseen test scenarios is challenging</p><p>- Lose random control over the input</p><p>- High computational cost</p><p>- Inability to scale to the features with high-dimension</p><p>- SDAE training is comparatively slower than the other competing algorithms as it relies on iterative as well as numerical optimization in learning model parameters</p><p>- Complicated by the input data's dimensionality and the requirement for computationally demanding model selection techniques to adjust hyperparameters</p><p>- A lengthy training time may be required for highly optimized execution</p></td></tr><tr><td align="left"><p>Deep energy model (DEM)</p></td><td align="left"><p>- Capable to incorporate several hidden deterministic layers with single hidden stochastic layers</p><p>- Joint-based learning of DEM enhances generative performance as well as alters the representations learnt at every level</p><p>- It can perform interface and learning efficiently using hidden deterministic layers rather than hidden stochastic layers</p><p>- DEMs are flexible in modelling</p><p>- Useful in object recognition, sequence labelling and image restoration</p><p>- Useful tool to model probability distributions of high-dimension</p></td><td align="left"><p>- No direct sampling method in DEM like flow or autoregressive models as it is not able to compute easily how likely a probable sample is</p><p>- DEMs can yield a longer period to converge although they work in theory</p><p>- Less popular as a result of computational difficulties</p><p>- It is difficult to evaluate likelihood (learning) in DEMs</p><p>- Feature learning is not available</p><p>- Inference in the deep energy-based models is quite difficult due to the function of partition, which is often impossible to compute precisely</p></td></tr><tr><td align="left"><p>Predictive coding network (PCN)</p></td><td align="left"><p>- Effective for several classification problems, such as image classification</p><p>- Can be trained using unsupervised learning</p><p>- Faster and more efficient than other machine learning-based approaches</p><p>- Automated adjustment of hyperparameters could improve PCNs considerably</p><p>- Applicable in the field of computer vision, where natural image and video classifications are performed</p><p>- Single architecture can be reused in PCNs to run top-down and bottom-up processes recursively to refine their presentation concerning more exact and conclusive object recognition</p></td><td align="left"><p>- It is difficult to develop mature and complicated deep predictive coding network designs</p><p>- Computational time is longer than ordinary networks having the same amount of layers</p><p>- More layers are needed to model complicated and nonlinear relations in data</p><p>- A more difficult task simply requires the brain to process information more slowly through the same network</p><p>- Suffers from the uncertainty about how the estimated error minimization functions</p><p>- Each stage of the PCN framework's sub computation may conceal an intractable computing challenge</p></td></tr><tr><td align="left"><p>Restricted Boltzmann Machine (RBM)</p></td><td align="left"><p>- Modelling capacity can be enhanced by incorporating more hidden variables</p><p>- The hidden and visible unit sets are not conditionally dependent in RBMs</p><p>- Suitable for classification, dimensionality reduction, regression, topic modelling, feature learning, and collaborative filtering</p><p>- RBMs are able to be trained in both supervised and unsupervised processes based on the particular task</p><p>- Capable to examine and determine several hidden variables including drama, action, and fantasy</p><p>- Useful for learning unsupervised features</p><p>- It is comparatively faster than a traditional DBM because of the limitations in the number of connections among the nodes</p></td><td align="left"><p>- Computationally intensive process to learn an RBM</p><p>- The approximation inference is significantly slower than the single bottom-up pass used in RBMs</p><p>- In the case of large datasets, the combined optimization of the parameters is not feasible due to the slower approximation interface of RBMs</p><p>- Training is quite complicated since calculating the function of the energy gradient is not easy</p><p>- Suffers from weight Adjustment</p><p>- The training algorithms of RBMs such as contrastive divergence and parallel tempering have limitations for complex and high-dimensional data processing</p><p>- With lower temperature chains, training can be converged more rapidly, but the accuracy suffers</p></td></tr></tbody></table></table-wrap></p><p id="Par166">In general, deep learning (DL) often produces better results as opposed to machine learning. For example, the largest data portion of an institute/organization is unstructured since it appears in so many different formats, including texts and images. Most machine learning (ML) algorithms struggle to make sense of unstructured data, therefore this type of data is underutilized. Herein lies the strength of deep learning. The main benefit of using DL over other ML algorithms is its capacity to produce novel features from limited sets of features already present in the training dataset. It follows that DL algorithms can devise new challenges to address existing problems. DL enables full-cycle learning by using neural networks' capability for featurization, from inputting raw data to producing an outcome. This approach allows for the optimization of all relevant parameters, which ultimately results in improved precision.</p><p id="Par167">A key advantage of using the DL approach is that it can perform feature engineering on its own. In this method, the algorithm is not given any explicit instructions, but rather it automatically searches through the data for features that correlate and then combines them to facilitate faster learning. Because of its ability to handle massive data, DL scales extremely well. The algorithms of DL can be learned on a wide range of data formats while still producing insights relevant to the objectives of the training. For instance, DL algorithms can be utilized to identify correlations between social media activities, market research, and other factors in order to predict the future stock value of a particular firm.</p><p id="Par168">There are a number of issues with DL models as well. In order to outperform alternative methods, deep learning needs access to a massive dataset. Therefore managing data is the key challenge that hinders DL in industrial implementations. Deep learning is currently limited in its applicability because of the extensive computer resources and training datasets it necessitates. It is still a mystery as to how exactly DL models arrive at their conclusions. Not like in traditional ML, where we can trace back the reasoning behind a system’s identification of a given image as representing a cat rather than a dog. To rectify errors in DL algorithms, the entire algorithm must be modified. However, no universally applicable theory is available that can help us to choose the appropriate DL tools as it needs knowledge of training methods, topology, and other features.</p></sec><sec id="Sec45"><title>Comparative analysis of deep learning modelling techniques</title><p id="Par169">Through the present review, it has been determined to what extent deep learning (DL) modelling techniques can be used in real-world applications. In addition, the methods employed, the outcomes, and the challenges of DL that have been modelled are identified. The comparative study compares available DL techniques based on their strengths and weaknesses, as well as performance metrics. The advantages and challenges outlined in the previous section make up the basis for the comparative study on strengths and weaknesses.</p><sec id="Sec46"><title>Comparative study based on weakness and strength</title><p id="Par170">One of the common DL models, namely the vector space model (VSM) is found simple in structure and allows the computation of the similarity degree between documents and queries on a continuous scale. In contrast, the VSM assumes that words are statistically independent. Additionally, documents with a similar context and distinct term vocabulary will not be connected, resulting in a "false negative" match. Convolutional neural network (CNN), on the other hand, uses less time for classification and has good precision in image recognition challenges. However, comparatively larger data sets are required to train for CNN. Poor data labeling is another disadvantage of CNN, which can dramatically affect system performance and precision. Several classification issues, including image classification, have been successfully addressed using a predictive coding network (PCN). One of its drawbacks is that there is a lack of certainty regarding how the estimated error minimization functions.</p><p id="Par171">It is observed that the recurrent neural network (RNN) is useful for time series forecasting. In RNN, weight remains constant across all levels, minimizing the number of parameters the network must learn. However, gradient and explosion vanishing issues limit the length of RNN sequences. Its computation process is comparatively slow because of its repeated/recurrent nature. However, for highly optimal execution, a long training period may be needed. In most cases, the efficiency and accuracy of the Hierarchical bidirectional recurrent neural network (HBRNN) are comparatively better than the other networks as it is constructed through the extensions of bidirectional recurrent neural network (BRNN) and RNN. Before predictions can be made with HBRNN, the full sequence must be accessible. On the basis of the scoring function, the recursive neural network (RvNN) is capable of detecting samples that are relatively similar to one another. Obtaining labeled data for RvNNs is an incredibly challenging and time-consuming task. Compared to a typical neural network layer, a neural tensor network (NTN) is a powerful tool for modelling relational data. Massive triplet samples are required for NTN to properly train, however, this has a little effect on sparse knowledge graphs on a global scale.</p><p id="Par172">Deep belief network (DBN) enables highly efficient applications in the domains of handwriting, face, and speech recognition due to the model's continual learning of the characteristics of randomly input samples. However, DBNs do not account for the two-dimensional structure of input images, which could significantly affect their performance. Attention mechanism can deduce information from an input that is most pertinent to accomplishing a task, hence enhancing performance, especially in language processing. Ambiguous inputs can be handled by Deep Boltzmann machine (DBM) more robustly. DBM is capable of identifying latent features in data. One of the limitations of DBM is that maximum probabilistic learning in DBM is a challenge due to the hard inference issue caused by partition functions. The restricted Boltzmann machine (RBM) is comparatively faster than a traditional DBM because of the limitations in the number of connections among the nodes. But the process of learning an RBM is computationally intensive, and in the case of large datasets, the combined optimization of the parameters is not feasible due to the slower approximation interface of RBMs.</p><p id="Par173">A well-generalized ability on smaller datasets makes capsule neural network (CapsNet) suitable for use in a wide range of applications. CapsNets are not able to perform consistently across various datasets, particularly large datasets such as ImageNet. Using hidden deterministic layers as opposed to hidden stochastic layers, the deep energy model (DEM) can perform interface and learn quickly. It is less popular due to computational difficulties and the difficulty of evaluating the likelihood (learning) in DEMs. A generative adversarial network (GAN) does not require estimating a probability distribution by introducing a lower bound like a variational autoencoder. But GAN has a mode collapse problem, and its data-generation process is intrinsically slow.</p></sec><sec id="Sec47"><title>Comparative study based on performance criteria</title><p id="Par174">This section compares the performance of several deep learning modelling techniques based on two key performance factors such as prediction accuracy and complexity level, which are crucial for suitable model selection. The study of the computational complexity of deep learning models is important because it can answer the fundamental question of why deep learning architecture performs substantially better than traditional machine learning algorithms. In addition, understanding the complexity is useful to analyze and compare different deep learning models and improve their performance. The complexity analysis of deep learning models highly depends on the model structure; on the other hand, the models are structurally different. Therefore, they cannot be generalized and directly compared to one another.</p><p id="Par175">One of the recent studies (Hu et al. <xref ref-type="bibr" rid="CR102">2021</xref>) surveyed the latest research on model complexity in deep learning. In the study, four factors that influence the deep learning model complexity were surveyed: (i) model framework including activation functions such as tanh, ReLu, and others, (ii) model size, including the depths of the neural network layers and the number of trainable parameters, (iii) optimization process such as the number of iterations (epochs) to optimize the model, optimization algorithms, hyperparameters, and (iv) data complexity, which includes class imbalance and high dimensional data. The performance of a DL model also relies on other parameters such as hardware platforms (high-end GPU), compiler optimization, and implementation tools. Based on some of those factors and literature availability, we analyze the performance and computational complexity of different variants of deep learning models across different application fields (Seo et al. <xref ref-type="bibr" rid="CR228">2020</xref>; Zeroual et al. <xref ref-type="bibr" rid="CR296">2020</xref>; Cui et al. <xref ref-type="bibr" rid="CR47">2018</xref>; Vazhayil et al. <xref ref-type="bibr" rid="CR271">2018</xref>; Shakya et al. <xref ref-type="bibr" rid="CR229">2018</xref>), and classify them into three categories: Low, Medium, and High, as illustrated in Table <xref rid="Tab4" ref-type="table">4</xref>. The lack of relevant comparative DL literature is identified as the key challenge behind this comparative survey.<table-wrap id="Tab4"><label>Table 4</label><caption xml:lang="en"><p>Comparison of different variants of deep learning architectures applied in different fields based on performance criteria and complexity</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"><p>Deep learning model</p></th><th align="left"><p>Applied field</p></th><th align="left"><p>Performance (prediction accuracy or other matrices)</p></th><th align="left"><p>Computational complexity</p></th></tr></thead><tbody><tr><td align="left"><p>AE</p></td><td align="left"><p>Time Series Prediction</p></td><td align="left"><p>High</p></td><td align="left"><p>High</p></td></tr><tr><td align="left"><p>BD-LSTM</p></td><td align="left"><p>Sentiment Analysis</p></td><td align="left"><p>High</p></td><td align="left"><p>High</p></td></tr><tr><td align="left"><p>Bi-LSTM</p></td><td align="left"><p>Time Series Prediction</p></td><td align="left"><p>Medium</p></td><td align="left"><p>High</p></td></tr><tr><td align="left" rowspan="4"><p>CNN</p></td><td align="left"><p>Sentiment Analysis</p></td><td align="left"><p>Medium</p></td><td align="left"><p>High</p></td></tr><tr><td align="left"><p>Malicious URLs Detection</p></td><td align="left"><p>High</p></td><td align="left"><p>Medium</p></td></tr><tr><td align="left"><p>Human Activity Recognition</p></td><td align="left"><p>High</p></td><td align="left"><p>High</p></td></tr><tr><td align="left"><p>Intrusion Detection Systems</p></td><td align="left"><p>Medium</p></td><td align="left"><p>Medium</p></td></tr><tr><td align="left"><p>CNN-LSTM</p></td><td align="left"><p>Malicious URLs Detection</p></td><td align="left"><p>High</p></td><td align="left"><p>Medium</p></td></tr><tr><td align="left"><p>GRU</p></td><td align="left"><p>Time Series Prediction</p></td><td align="left"><p>Medium</p></td><td align="left"><p>Medium</p></td></tr><tr><td align="left"><p>LSTM</p></td><td align="left"><p>Time Series Prediction</p></td><td align="left"><p>Medium</p></td><td align="left"><p>Medium</p></td></tr><tr><td align="left" rowspan="3"><p>RNN</p></td><td align="left"><p>Sentiment Analysis</p></td><td align="left"><p>Low</p></td><td align="left"><p>Low</p></td></tr><tr><td align="left"><p>Time Series Prediction</p></td><td align="left"><p>Low</p></td><td align="left"><p>Medium</p></td></tr><tr><td align="left"><p>Intrusion Detection Systems</p></td><td align="left"><p>High</p></td><td align="left"><p>Medium</p></td></tr><tr><td align="left"><p>RNN-GRU</p></td><td align="left"><p>Sentiment Analysis</p></td><td align="left"><p>Medium</p></td><td align="left"><p>Medium</p></td></tr><tr><td align="left"><p>RNN-LSTM</p></td><td align="left"><p>Sentiment Analysis</p></td><td align="left"><p>High</p></td><td align="left"><p>Medium</p></td></tr><tr><td align="left"><p>RNN-LSTM</p></td><td align="left"><p>Human Activity Recognition</p></td><td align="left"><p>Medium</p></td><td align="left"><p>Medium</p></td></tr></tbody></table></table-wrap></p><p id="Par176">The time complexity of an algorithm mainly depends on the input data, and it can be described using the big-oh notation. Due to its complex nature of architecture, structural differences, and many other factors, the time complexity of the deep learning model is usually measured by how long it takes a model to solve a problem on specified hardware. An empirical analysis of how the configuration settings affect the running time of deep learning models was conducted by Lee and Chen (<xref ref-type="bibr" rid="CR137">2020</xref>). The analysis demonstrated that model complexity increases the running time, but if the data quality is below average, it is not worthwhile to increase model complexity. In the sentiment analysis task, increasing the CNN model’s complexity may not improve the performance, whereas increasing the RNN model’s complexity invariably improves the model performance. Bi-LSTM is found to be superior to other CNN and RNN models for sentiment analysis (Seo et al. <xref ref-type="bibr" rid="CR228">2020</xref>). In malicious URL detection, CNN-LSTM gives comparatively high accuracy than ordinary CNN with a little more computational cost (Vazhayil et al. <xref ref-type="bibr" rid="CR271">2018</xref>). However, CNN shows a significant improvement over RNN-LSTM in computer vision tasks such as human activity recognition (Shakya et al. <xref ref-type="bibr" rid="CR229">2018</xref>). CNN is a better choice in intrusion detection systems if it is a binary classification problem (Cui et al. <xref ref-type="bibr" rid="CR47">2018</xref>). For multi-class classification, regular CNN performs poor than others while RNN is a good choice because of the sequential data. It is much more computationally expensive than RNN in its architecture. Compared to RNN, Auto Encoder (AE) shows superior performance in forecasting time-series data. But RNN is relatively faster and needs less computational cost than LSTM, Bi-LSTM, and AE (Zeroual et al. <xref ref-type="bibr" rid="CR296">2020</xref>).</p></sec></sec><sec id="Sec48"><title>Future of deep learning</title><p id="Par177">As we step foot into a new era of surplus big data and information, the future of deep learning is not only prominent but vital for the advancement, resilience, and problem-solving endeavors of the globe. Deep learning has become a necessary tool across every discipline from science, engineering, humanity, and health to climate studies and many more. From developing cybersecurity and surveillance to performing quantum computing, deep learning will be an evident constant of the future. With the great success of deep networks in the field of computer vision and the development of artificial intelligence, being able to extract meaningful and correct features from data to generate necessary outcomes, without discrimination and being more tolerant of nuisance variations in data (Deng <xref ref-type="bibr" rid="CR52">2014</xref>; Guo et al. <xref ref-type="bibr" rid="CR87">2016</xref>), deep learning is the basis for future innovations. As of yet, further knowledge and understanding are required to improve and construct deep learning networks that deal with complex high dimensionality data and variations to characterize inputs and outputs efficiently (Kato et al. <xref ref-type="bibr" rid="CR119">2016</xref>).</p><p id="Par178">The growing interest in investments, particularly of giant tech companies (Google, Facebook, Apple), represents and signals the value and potency of deep learning in the present and future. Although deep learning demands high computational power and constant training to generate reliable results, more work is yet to be done to ensure that deep learning networks are efficient and cost-effective in extracting and identifying distinct features from real-world data, mimicking the ability of biological intelligence. Therefore, when constructing a deep learning methodology, it is important to ensure that the model can deal with uncertainty, is scalable, and has transferable qualities to be implemented and applied to multiple problem systems (Zhang et al. <xref ref-type="bibr" rid="CR303">2020</xref>). Alongside the development of deep learning techniques, the availability of user-friendly hardware and software systems are significant future prospects for deep learning.</p><p id="Par179">Larger and more extensive datasets are necessary for enhancing the performance of DL models in a complex and dynamic construction environment including many human resources, several types of equipment, and a variety of human and equipment activities (Fink et al. <xref ref-type="bibr" rid="CR70">2020</xref>). As humanity surfs the wave of artificial intelligence and deep learning, ethical frameworks must be developed to ensure the sound employment and enhancement of deep learning techniques in order to manage proper conduction and utilization of big data that are fed into deep learning architectures, subsequently generating beneficial and sustainable solutions. Due to the small sample size of training and limited unsafe activities considered, several workers’ actions can not be recognized (Ding et al. <xref ref-type="bibr" rid="CR58">2018</xref>). With a larger dataset, the model can therefore improve and give more precise results. Nevertheless, there is presently no publicly available complete and standardized dataset, also for particular tasks like activity recognition, pose detection and object detection, as well as for different views, a wide range of construction sites, occlusion circumstances, and lighting.</p><p id="Par180">Combining deep learning with expert knowledge can be a fruitful area of research since models may be dynamically augmented with acquired new data, resulting in effective digital twins which can help in maintenance decision making. Despite the fact that physics-induced deep learning is now pursuing multiple directions, there is no agreement or no consolidation on various directions as well as how they can be translated to industrial applications. There is a need for additional studies to refine and consolidate these techniques, which may help increase the generalization ability of the models developed. Another issue that must be addressed in future studies is the effective selection and composition of sets of training data. This is especially important in environments that are constantly changing and have extremely variable operating conditions, where the training dataset is not representative of the whole range of predicted operating conditions. Continuous decisions must be made as to whether new data needs to be included in training datasets and the algorithms updated, or whether the information is repetitive and included already in the datasets used for training the algorithms.</p></sec><sec id="Sec49" sec-type="conclusions"><title>Conclusion</title><p id="Par181">Deep learning (DL) is a thriving multidisciplinary field that is still in its nascent phase. With the growing availability of data, DL architectures can be successfully applied to problems across various sectors in the modern world. This paper provides a comprehensive systematic review of the state-of-the-art DL modelling techniques. Some models can be trained by two or more methods, which means their efficiency relies on the domain in which they are used. The use of hierarchical layers for proper data classification, as well as supervision in learning to determine the importance of the database of interest, are both important factors to develop robust DL models. While nearly all of the models display robustness to some extent, existing techniques are still flawed, which subjects them to criticisms. With the availability of big data across various domains, the quality of data can become an issue when training DL models. Training DL models can also be very time-consuming, expensive, and requires hundreds of correct examples for better accuracy, which can limit their use for everyday purposes or in sensitive security systems. The resulting models may also be domain-specific and, therefore, may have restricted applications. In addition, DL is susceptible to deception and misclassification, which can threaten the social and financial securities of individuals and/or corporations. Getting stuck on local minima also makes most models unsuitable for online modes.</p><p id="Par182">CNNs, RNNs, GANs, and autoencoders are the more frequently used DL architectures across various sectors. However, the potential application of other architectures in current areas that use DL is widely unexplored. This paper found that advanced DL models, which are essentially hybrid conventional DL architectures, have the potential to overcome the challenges experienced by conventional models. Moreover, generative models exhibit greater capabilities as they are less reliant on examples. Future networks should strive to generate a set of possible outcomes, instead of providing one final prediction for the input, which may help tackle the issue of distorted or unclear inputs. Developing new strategies to optimize parameters, particularly hyperparameters, is another possibility that requires further investigation. Capsule architectures may dominate future DL models as they offer an enhanced way of routing information between layers. If the current challenges can be addressed, DL models can potentially contribute to further innovations in the field of AI and for solving far more complex problems.</p></sec></body><back><ack><title>Acknowledgements</title><p>The authors highly express their gratitude to Asian University for Women, Chattogram, Bangladesh for their support in carrying out this study.</p></ack><sec><title>Funding</title><p>Open Access funding enabled and organized by CAUL and its Member Institutions.</p></sec><sec sec-type="ethics-statement"><title>Declarations</title><sec id="FPar1" sec-type="COI-statement"><title>Conflict of interest</title><p id="Par183">The authors declare that they have no known competing financial interests or personal relationships that could appear to have influenced the work reported in this study.</p></sec></sec><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbas</surname><given-names>AA</given-names></name><name><surname>Naderi</surname><given-names>E</given-names></name><name><surname>Gandali</surname><given-names>A</given-names></name><name><surname>Hanieh</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Comparative study of static and dynamic artificial neural network models in forecasting of tehran stock exchange</article-title><source>Int J Bus Dev Stud</source><year>2016</year><volume>8</volume><fpage>43</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.22111/IJBDS.2016.2635</pub-id></mixed-citation></ref><ref id="CR2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abdel-Zaher</surname><given-names>AM</given-names></name><name><surname>Eldeib</surname><given-names>AM</given-names></name></person-group><article-title xml:lang="en">Breast cancer classification using deep belief networks</article-title><source>Expert Syst Appl</source><year>2016</year><pub-id pub-id-type="doi">10.1016/j.eswa.2015.10.015</pub-id></mixed-citation></ref><ref id="CR3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abedinia</surname><given-names>O</given-names></name><name><surname>Amjady</surname><given-names>N</given-names></name><name><surname>Ghadimi</surname><given-names>N</given-names></name></person-group><article-title xml:lang="en">Solar energy forecasting based on hybrid neural network and improved metaheuristic algorithm</article-title><source>Comput Intell</source><year>2018</year><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3789536</pub-id><pub-id pub-id-type="doi">10.1111/coin.12145</pub-id></mixed-citation></ref><ref id="CR4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Achanta</surname><given-names>S</given-names></name><name><surname>Gangashetty</surname><given-names>SV</given-names></name></person-group><article-title xml:lang="en">Deep Elman recurrent neural networks for statistical parametric speech synthesis</article-title><source>Speech Commun</source><year>2017</year><pub-id pub-id-type="doi">10.1016/j.specom.2017.08.003</pub-id></mixed-citation></ref><ref id="CR5"><mixed-citation publication-type="other">Adhikari A, Ram A, Tang R, Lin J (2019) DocBERT: BERT for document classification. <ext-link xlink:href="http://arxiv.org/abs/1904.08398" ext-link-type="uri">arXiv:1904.08398</ext-link></mixed-citation></ref><ref id="CR6"><mixed-citation publication-type="other">Afshar P, Mohammadi A, Plataniotis KN (2018) Brain tumor type classification via capsule networks. In: Proceedings - international conference on image processing, ICIP. <ext-link xlink:href="10.1109/ICIP.2018.8451379" ext-link-type="doi">https://doi.org/10.1109/ICIP.2018.8451379</ext-link></mixed-citation></ref><ref id="CR7"><mixed-citation publication-type="other">Ahmad J, Farman H, Jan Z (2019) Deep learning methods and applications. In: SpringerBriefs in computer science. <ext-link xlink:href="10.1007/978-981-13-3459-7_3" ext-link-type="doi">https://doi.org/10.1007/978-981-13-3459-7_3</ext-link></mixed-citation></ref><ref id="CR8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akkus</surname><given-names>Z</given-names></name><name><surname>Galimzianova</surname><given-names>A</given-names></name><name><surname>Hoogi</surname><given-names>A</given-names></name><name><surname>Rubin</surname><given-names>DL</given-names></name><name><surname>Erickson</surname><given-names>BJ</given-names></name></person-group><article-title xml:lang="en">Deep learning for brain MRI segmentation: state of the art and future directions</article-title><source>J Digit Imaging</source><year>2017</year><volume>30</volume><fpage>449</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1007/s10278-017-9983-4</pub-id></mixed-citation></ref><ref id="CR9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alain</surname><given-names>G</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name><name><surname>Fergus</surname><given-names>R</given-names></name><name><surname>Manning</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">What regularized auto-encoders learn from the data-generating distribution</article-title><source>J Mach Learn Res </source><year>2014</year><volume>15</volume><issue>1</issue><fpage>3563</fpage><lpage>3593</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3291406</pub-id></mixed-citation></ref><ref id="CR10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alam</surname><given-names>MR</given-names></name><name><surname>Bennamoun</surname><given-names>M</given-names></name><name><surname>Togneri</surname><given-names>R</given-names></name><name><surname>Sohel</surname><given-names>F</given-names></name></person-group><article-title xml:lang="en">A joint deep boltzmann machine (jdbm) model for person identification using mobile phone data</article-title><source>IEEE Trans Multimed</source><year>2017</year><pub-id pub-id-type="doi">10.1109/TMM.2016.2615524</pub-id></mixed-citation></ref><ref id="CR11"><mixed-citation publication-type="other">Alemany S, Beltran J, Perez A, Ganzfried S (2019) Predicting hurricane trajectories using a recurrent neural network. In: 33rd AAAI conference on artificial intelligence, AAAI 2019, 31st innovative applications of artificial intelligence conference, IAAI 2019 and the 9th AAAI symposium on educational advances in artificial intelligence, EAAI 2019.  <ext-link xlink:href="10.1609/aaai.v33i01.3301468" ext-link-type="doi">https://doi.org/10.1609/aaai.v33i01.3301468</ext-link></mixed-citation></ref><ref id="CR12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ali</surname><given-names>F</given-names></name><name><surname>Kwak</surname><given-names>D</given-names></name><name><surname>Khan</surname><given-names>P</given-names></name><name><surname>El-Sappagh</surname><given-names>S</given-names></name><name><surname>Ali</surname><given-names>A</given-names></name><name><surname>Ullah</surname><given-names>S</given-names></name><name><surname>Kim</surname><given-names>KH</given-names></name><name><surname>Kwak</surname><given-names>KS</given-names></name></person-group><article-title xml:lang="en">Transportation sentiment analysis using word embedding and ontology-based topic modeling</article-title><source>Knowledge-Based Syst</source><year>2019</year><pub-id pub-id-type="doi">10.1016/j.knosys.2019.02.033</pub-id></mixed-citation></ref><ref id="CR13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Al-Jumeily</surname><given-names>D</given-names></name><name><surname>Ghazali</surname><given-names>R</given-names></name><name><surname>Hussain</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Predicting physical time series using dynamic ridge polynomial neural networks</article-title><source>PLoS ONE</source><year>2014</year><pub-id pub-id-type="doi">10.1371/journal.pone.0105766</pub-id></mixed-citation></ref><ref id="CR14"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Alpaydin</surname><given-names>E</given-names></name></person-group><source>Introduction to Machine Learning</source><year>2020</year><publisher-loc>Cambridge</publisher-loc><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1191.68485</pub-id></mixed-citation></ref><ref id="CR15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arabasadi</surname><given-names>Z</given-names></name><name><surname>Alizadehsani</surname><given-names>R</given-names></name><name><surname>Roshanzamir</surname><given-names>M</given-names></name><name><surname>Moosaei</surname><given-names>H</given-names></name><name><surname>Yarifard</surname><given-names>AA</given-names></name></person-group><article-title xml:lang="en">Computer aided decision making for heart disease detection using hybrid neural network-genetic algorithm</article-title><source>Comput Methods Programs Biomed</source><year>2017</year><pub-id pub-id-type="doi">10.1016/j.cmpb.2017.01.004</pub-id></mixed-citation></ref><ref id="CR16"><mixed-citation publication-type="other">Arora S, Ma T, Moitra A (2015) Simple, efficient, and neural algorithms for sparse coding. PMLR, pp 113–149</mixed-citation></ref><ref id="CR17"><mixed-citation publication-type="other">Arulkumaran K, Deisenroth MP, Brundage M, Bharath AA (2017) A brief survey of deep reinforcement learning. In: IEEE signal processing magazine, special issue on deep learning for image understanding pp 1–16</mixed-citation></ref><ref id="CR18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ba</surname><given-names>J</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name><name><surname>Mnih</surname><given-names>V</given-names></name><name><surname>Leibo</surname><given-names>JZ</given-names></name><name><surname>Ionescu</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">Using fast weights to attend to the recent past</article-title><source>Adv Neural Inf Process Syst</source><year>2016</year><volume>29</volume><fpage>4338</fpage><lpage>4346</lpage></mixed-citation></ref><ref id="CR19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baecchi</surname><given-names>C</given-names></name><name><surname>Uricchio</surname><given-names>T</given-names></name><name><surname>Bertini</surname><given-names>M</given-names></name><name><surname>Del Bimbo</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">A multimodal feature learning approach for sentiment analysis of social network multimedia</article-title><source>Multimed Tools Appl</source><year>2016</year><pub-id pub-id-type="doi">10.1007/s11042-015-2646-x</pub-id></mixed-citation></ref><ref id="CR20"><mixed-citation publication-type="other">Bai Y, Fu J, Zhao T, Mei T (2018) Deep attention neural tensor network for visual question answering. In: Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics). <ext-link xlink:href="10.1007/978-3-030-01258-8_2" ext-link-type="doi">https://doi.org/10.1007/978-3-030-01258-8_2</ext-link></mixed-citation></ref><ref id="CR21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barré</surname><given-names>P</given-names></name><name><surname>Stöver</surname><given-names>BC</given-names></name><name><surname>Müller</surname><given-names>KF</given-names></name><name><surname>Steinhage</surname><given-names>V</given-names></name></person-group><article-title xml:lang="en">LeafNet: a computer vision system for automatic plant species identification</article-title><source>Ecol Inform</source><year>2017</year><pub-id pub-id-type="doi">10.1016/j.ecoinf.2017.05.005</pub-id></mixed-citation></ref><ref id="CR22"><mixed-citation publication-type="other">Bartunov S, Rae JW, Osindero S, Lillicrap TP (2019) Meta-learning deep energy-based memory models. <ext-link xlink:href="https://arXiv.org/1910.02720" ext-link-type="uri">https://arXiv.org/1910.02720</ext-link></mixed-citation></ref><ref id="CR23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Basiri</surname><given-names>ME</given-names></name><name><surname>Nemati</surname><given-names>S</given-names></name><name><surname>Abdar</surname><given-names>M</given-names></name><name><surname>Cambria</surname><given-names>E</given-names></name><name><surname>Acharya</surname><given-names>UR</given-names></name></person-group><article-title xml:lang="en">ABCDM: an attention-based bidirectional CNN-RNN deep model for sentiment analysis</article-title><source>Futur Gener Comput Syst</source><year>2021</year><pub-id pub-id-type="doi">10.1016/j.future.2020.08.005</pub-id></mixed-citation></ref><ref id="CR24"><mixed-citation publication-type="other">Bau D, Zhu JY, Strobelt H, Zhou B, Tenenbaum JB, Freeman WT, Torralba A (2019) GaN dissection: visualizing and understanding generative adversarial networks. In: 7th international conference on learning representations, ICLR 2019</mixed-citation></ref><ref id="CR25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Simard</surname><given-names>P</given-names></name><name><surname>Frasconi</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Learning long-term dependencies with gradient descent is difficult</article-title><source>IEEE Trans Neural Netw</source><year>1994</year><pub-id pub-id-type="doi">10.1109/72.279181</pub-id></mixed-citation></ref><ref id="CR26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name><name><surname>Vincent</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Representation learning : a review and new perspectives</article-title><source>IEEE Trans Pattern Anal Mach Intell</source><year>2013</year><volume>35</volume><fpage>1798</fpage><lpage>1828</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2013.50</pub-id></mixed-citation></ref><ref id="CR27"><mixed-citation publication-type="other">Ben-Younes H, Cadene R, Cord M, Thome N (2017) MUTAN: multimodal tucker fusion for visual question answering. In: Proceedings of the IEEE international conference on computer vision. <ext-link xlink:href="10.1109/ICCV.2017.285" ext-link-type="doi">https://doi.org/10.1109/ICCV.2017.285</ext-link></mixed-citation></ref><ref id="CR28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biancofiore</surname><given-names>F</given-names></name><name><surname>Busilacchio</surname><given-names>M</given-names></name><name><surname>Verdecchia</surname><given-names>M</given-names></name><name><surname>Tomassetti</surname><given-names>B</given-names></name><name><surname>Aruffo</surname><given-names>E</given-names></name><name><surname>Bianco</surname><given-names>S</given-names></name><name><surname>Di Tommaso</surname><given-names>S</given-names></name><name><surname>Colangeli</surname><given-names>C</given-names></name><name><surname>Rosatelli</surname><given-names>G</given-names></name><name><surname>Di Carlo</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Recursive neural network model for analysis and forecast of PM10 and PM25</article-title><source>Atmos Pollut Res</source><year>2017</year><pub-id pub-id-type="doi">10.1016/j.apr.2016.12.014</pub-id></mixed-citation></ref><ref id="CR29"><mixed-citation publication-type="other">Bordes A, Weston J, Chopra S (2014) Question answering with subgraph embeddings. <ext-link xlink:href="https://arXiv.org/1406.3676" ext-link-type="uri">https://arXiv.org/1406.3676</ext-link></mixed-citation></ref><ref id="CR30"><mixed-citation publication-type="other">Bousmalis K, Trigeorgis G, Silberman N, Krishnan D, Erhan D (2016) Domain separation networks. In: Advances in neural information processing systems</mixed-citation></ref><ref id="CR31"><mixed-citation publication-type="other">Brahma S (2018) Improved sentence modeling using suffix bidirectional LSTM. <ext-link xlink:href="https://arXiv.org/1805.07340" ext-link-type="uri">https://arXiv.org/1805.07340</ext-link></mixed-citation></ref><ref id="CR32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brocardo</surname><given-names>ML</given-names></name><name><surname>Traore</surname><given-names>I</given-names></name><name><surname>Woungang</surname><given-names>I</given-names></name><name><surname>Obaidat</surname><given-names>MS</given-names></name></person-group><article-title xml:lang="en">Authorship verification using deep belief network systems</article-title><source>Int J Commun Syst</source><year>2017</year><volume>30</volume><fpage>e3259</fpage><pub-id pub-id-type="doi">10.1002/dac.3259</pub-id></mixed-citation></ref><ref id="CR33"><mixed-citation publication-type="other">Brock A, Donahue J, Simonyan K (2019) Large scale GaN training for high fidelity natural image synthesis. In: 7th international conference on learning representations, ICLR 2019</mixed-citation></ref><ref id="CR34"><mixed-citation publication-type="other">Camgoz NC, Hadfield S, Koller O, Ney H, Bowden R (2018) Neural sign language translation. In: Proceedings of the IEEE computer society conference on computer vision and pattern recognition. <ext-link xlink:href="10.1109/CVPR.2018.00812" ext-link-type="doi">https://doi.org/10.1109/CVPR.2018.00812</ext-link></mixed-citation></ref><ref id="CR35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>Z</given-names></name><name><surname>Duan</surname><given-names>L</given-names></name><name><surname>Yang</surname><given-names>G</given-names></name><name><surname>Yue</surname><given-names>T</given-names></name><name><surname>Chen</surname><given-names>Q</given-names></name></person-group><article-title xml:lang="en">An experimental study on breast lesion detection and classification from ultrasound images using deep learning architectures</article-title><source>BMC Med Imaging</source><year>2019</year><volume>19</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1186/s12880-019-0349-x</pub-id></mixed-citation></ref><ref id="CR36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carrio</surname><given-names>A</given-names></name><name><surname>Sampedro</surname><given-names>C</given-names></name><name><surname>Rodriguez-ramos</surname><given-names>A</given-names></name><name><surname>Campoy</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">A review of deep learning methods and applications for unmanned aerial vehicles</article-title><source>J Sensors</source><year>2017</year><pub-id pub-id-type="doi">10.1155/2017/3296874</pub-id></mixed-citation></ref><ref id="CR37"><mixed-citation publication-type="other">Case C, Casper J, Catanzaro B, Diamos G, Elsen E (2014) Deep speech: scaling up end-to-end speech recognition. <ext-link xlink:href="https://arXiv.org/1412.5567" ext-link-type="uri">https://arXiv.org/1412.5567</ext-link></mixed-citation></ref><ref id="CR38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Multi-lane capsule network for classifying images with complex background</article-title><source>IEEE Access</source><year>2020</year><volume>8</volume><fpage>79876</fpage><lpage>79886</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2020.2990700</pub-id></mixed-citation></ref><ref id="CR39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Kundu</surname><given-names>K</given-names></name><name><surname>Zhu</surname><given-names>Y</given-names></name><name><surname>Ma</surname><given-names>H</given-names></name><name><surname>Fidler</surname><given-names>S</given-names></name><name><surname>Urtasun</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">3D object proposals using stereo imagery for accurate object class detection</article-title><source>IEEE Trans Pattern Anal Mach Intell</source><year>2018</year><pub-id pub-id-type="doi">10.1109/TPAMI.2017.2706685</pub-id></mixed-citation></ref><ref id="CR40"><mixed-citation publication-type="other">Chen Y, Li W, Sakaridis C, Dai D, Van Gool L (2018b) Domain adaptive faster R-CNN for object detection in the wild. In: Proceedings of the IEEE computer society conference on computer vision and pattern Recognition. <ext-link xlink:href="10.1109/CVPR.2018.00352" ext-link-type="doi">https://doi.org/10.1109/CVPR.2018.00352</ext-link></mixed-citation></ref><ref id="CR41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>YY</given-names></name><name><surname>Lin</surname><given-names>YH</given-names></name><name><surname>Kung</surname><given-names>CC</given-names></name><name><surname>Chung</surname><given-names>MH</given-names></name><name><surname>Yen</surname><given-names>I</given-names></name></person-group><article-title xml:lang="en">Design and implementation of cloud analytics-assisted smart power meters considering advanced artificial intelligence as edge analytics in demand-side managment for smart homes</article-title><source>Sensors</source><year>2019</year><volume>19</volume><fpage>2047</fpage><pub-id pub-id-type="doi">10.3390/s19092047</pub-id></mixed-citation></ref><ref id="CR42"><mixed-citation publication-type="other">Cheng J, Dong L, Lapata M (2016) Long short-term memory-networks for machine reading. EMNLP conference on empirical methods in natural language processing, proceedings. <ext-link xlink:href="10.18653/v1/d16-1053" ext-link-type="doi">https://doi.org/10.18653/v1/d16-1053</ext-link></mixed-citation></ref><ref id="CR43"><mixed-citation publication-type="other">Chicco D, Sadowski P, Baldi P, Milano P, Elettronica D (2014) Deep autoencoder neural networks for gene ontology annotation predictions. In: 5th ACM conference on bioinformatics, computational biology, and health informatics - BCB’14. pp 533–540. <ext-link xlink:href="10.1145/2649387.2649442" ext-link-type="doi">https://doi.org/10.1145/2649387.2649442</ext-link></mixed-citation></ref><ref id="CR44"><mixed-citation publication-type="other">Chu Q, Ouyang W, Li H, Wang X, Liu B, Yu N (2017) Online multi-object tracking using CNN-based single object tracker with spatial-temporal attention mechanism. In: Proceedings of the IEEE international conference on computer vision. <ext-link xlink:href="10.1109/ICCV.2017.518" ext-link-type="doi">https://doi.org/10.1109/ICCV.2017.518</ext-link></mixed-citation></ref><ref id="CR45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cireşan</surname><given-names>D</given-names></name><name><surname>Meier</surname><given-names>U</given-names></name><name><surname>Masci</surname><given-names>J</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Multi-column deep neural network for traffic sign classification</article-title><source>Neural Netw</source><year>2012</year><volume>32</volume><fpage>333</fpage><lpage>338</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2012.02.023</pub-id></mixed-citation></ref><ref id="CR46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collobert</surname><given-names>R</given-names></name><name><surname>Weston</surname><given-names>J</given-names></name><name><surname>Bottou</surname><given-names>L</given-names></name><name><surname>Karlen</surname><given-names>M</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name><name><surname>Kuksa</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Natural language processing (Almost) from scratch</article-title><source>J Mach Learn Res</source><year>2011</year><volume>12</volume><fpage>2493</fpage><lpage>2537</lpage><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1280.68161</pub-id></mixed-citation></ref><ref id="CR47"><mixed-citation publication-type="other">Cui J, Long J, Min E, Liu Q, Li Q (2018) Comparative study of CNN and RNN for deep learning based intrusion detection system. In: Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics). <ext-link xlink:href="10.1007/978-3-030-00018-9_15" ext-link-type="doi">https://doi.org/10.1007/978-3-030-00018-9_15</ext-link></mixed-citation></ref><ref id="CR48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Da’u</surname><given-names>A</given-names></name><name><surname>Salim</surname><given-names>N</given-names></name></person-group><article-title xml:lang="en">Recommendation system based on deep learning methods: a systematic review and new directions</article-title><source>Artif Intell Rev</source><year>2020</year><volume>53</volume><fpage>2709</fpage><lpage>2748</lpage><pub-id pub-id-type="doi">10.1007/s10462-019-09744-1</pub-id></mixed-citation></ref><ref id="CR49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dahl</surname><given-names>GE</given-names></name><name><surname>Ranzato</surname><given-names>M</given-names></name><name><surname>Mohamed</surname><given-names>AR</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Phone recognition with the mean-covariance restricted Boltzmann machine</article-title><source>Adv Neural Inf Process Syst</source><year>2010</year><volume>23</volume><fpage>469</fpage><lpage>477</lpage></mixed-citation></ref><ref id="CR50"><mixed-citation publication-type="other">De S, Maity A, Goel V, Shitole S, Bhattacharya A (2017) Predicting the popularity of instagram posts for a lifestyle magazine using deep learning. In: 2017 2nd international conference on communication systems, computing and IT applications (CSCITA) pp 174–177</mixed-citation></ref><ref id="CR51"><mixed-citation publication-type="other">Demeester T, Sutskever I, Chen K, Dean J, Corado G (2016) Distributed representations of words and phrases and their compositionality. EMNLP 2016 - Conference empirical methods natural language process processing</mixed-citation></ref><ref id="CR52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">A tutorial survey of architectures, algorithms, and applications for deep learning</article-title><source>APSIPA Trans Signal Inf Process</source><year>2014</year><pub-id pub-id-type="doi">10.1017/atsip.2013.9</pub-id></mixed-citation></ref><ref id="CR53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>L</given-names></name><name><surname>Yu</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Deep learning: methods and applications</article-title><source>Found Trends Signal Process</source><year>2014</year><volume>7</volume><fpage>197</fpage><lpage>387</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3295556</pub-id><pub-id pub-id-type="doi">10.1561/2000000039</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1315.68208</pub-id></mixed-citation></ref><ref id="CR54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>F</given-names></name><name><surname>Pu</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Shi</surname><given-names>Y</given-names></name><name><surname>Yuan</surname><given-names>T</given-names></name><name><surname>Shengyan</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Hyperspectral image classification with capsule network using limited training samples</article-title><source>Sensors (switzerland)</source><year>2018</year><pub-id pub-id-type="doi">10.3390/s18093153</pub-id></mixed-citation></ref><ref id="CR55"><mixed-citation publication-type="other">Deoras A, Povey D, Mikolov T, Burget L, Černocký J (2011) Strategies for training large scale neural network language models. In: IEEE workshop on automatic speech recognition and understanding pp 196–201</mixed-citation></ref><ref id="CR56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dhyani</surname><given-names>M</given-names></name><name><surname>Kumar</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">An intelligent Chatbot using deep learning with Bidirectional RNN and attention model</article-title><source>Mater Today Proceedings</source><year>2019</year><pub-id pub-id-type="doi">10.1016/j.matpr.2020.05.450</pub-id></mixed-citation></ref><ref id="CR57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dick</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Artificial intelligence</article-title><source>Harvard Data Sci Rev</source><year>2019</year><volume>1</volume><fpage>1</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1162/99608f92.92fe150c</pub-id></mixed-citation></ref><ref id="CR58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>L</given-names></name><name><surname>Fang</surname><given-names>W</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name><name><surname>Love</surname><given-names>PED</given-names></name><name><surname>Zhong</surname><given-names>B</given-names></name><name><surname>Ouyang</surname><given-names>X</given-names></name></person-group><article-title xml:lang="en">A deep hybrid learning model to detect unsafe behavior: integrating convolution neural networks and long short-term memory</article-title><source>Autom Constr</source><year>2018</year><volume>86</volume><fpage>118</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1016/j.autcon.2017.11.002</pub-id></mixed-citation></ref><ref id="CR59"><mixed-citation publication-type="other">Dixit M, Tiwari A, Pathak H, Astya R (2018) An overview of deep learning architectures, libraries and its applications areas. In 2018 international conference on advances in computing, communication control and networking. pp 293–297. <ext-link xlink:href="10.1109/ICACCCN.2018.8748442" ext-link-type="doi">https://doi.org/10.1109/ICACCCN.2018.8748442</ext-link></mixed-citation></ref><ref id="CR60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Do Rosario</surname><given-names>VM</given-names></name><name><surname>Borin</surname><given-names>E</given-names></name><name><surname>Breternitz</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">The multi-lane capsule network</article-title><source>IEEE Signal Process Lett</source><year>2019</year><volume>26</volume><fpage>1006</fpage><lpage>1010</lpage><pub-id pub-id-type="doi">10.1109/LSP.2019.2915661</pub-id></mixed-citation></ref><ref id="CR61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>do Rosario</surname><given-names>VM</given-names></name><name><surname>Breternitz</surname><given-names>M</given-names></name><name><surname>Borin</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Efficiency and scalability of multi-lane capsule networks (MLCN)</article-title><source>J. Parallel Distrib Comput.</source><year>2021</year><volume>155</volume><fpage>63</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1016/J.JPDC.2021.04.010</pub-id></mixed-citation></ref><ref id="CR62"><mixed-citation publication-type="other">Dora S, Pennartz C, Bohte S (2018) A deep predictive coding network for inferring hierarchical causes underlying sensory inputs, Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics). Springer. <ext-link xlink:href="10.1007/978-3-030-01424-7_45" ext-link-type="doi">https://doi.org/10.1007/978-3-030-01424-7_45</ext-link></mixed-citation></ref><ref id="CR63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumoulin</surname><given-names>V</given-names></name><name><surname>Perez</surname><given-names>E</given-names></name><name><surname>Schucher</surname><given-names>N</given-names></name><name><surname>Strub</surname><given-names>F</given-names></name><name><surname>Vries</surname><given-names>H</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Feature-wise transformations</article-title><source>Distill</source><year>2018</year><pub-id pub-id-type="doi">10.23915/distill.00011</pub-id></mixed-citation></ref><ref id="CR64"><mixed-citation publication-type="other">Dumoulin V, Shlens J, Kudlur M (2017) A learned representation for artistic style. In: 5th international conference on learning representations, ICLR 2017 - conference track proceedings</mixed-citation></ref><ref id="CR65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elman</surname><given-names>JL</given-names></name></person-group><article-title xml:lang="en">Finding structure in time</article-title><source>Cogn Sci</source><year>1990</year><pub-id pub-id-type="doi">10.1016/0364-0213(90)90002-E</pub-id></mixed-citation></ref><ref id="CR66"><mixed-citation publication-type="other">Elman JL (1998) Generalization, simple recurrent networks, and the emergence of structure. In: Proceedings 20th annual conference cognitive science society</mixed-citation></ref><ref id="CR67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eslami</surname><given-names>SMA</given-names></name><name><surname>Heess</surname><given-names>N</given-names></name><name><surname>Williams</surname><given-names>CKI</given-names></name><name><surname>Winn</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">The shape boltzmann machine: a strong model of object shape</article-title><source>Int J Comput Vis</source><year>2014</year><volume>107</volume><fpage>155</fpage><lpage>176</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3179602</pub-id><pub-id pub-id-type="doi">10.1007/s11263-013-0669-1</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1294.68135</pub-id></mixed-citation></ref><ref id="CR68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fayek</surname><given-names>HM</given-names></name><name><surname>Lech</surname><given-names>M</given-names></name><name><surname>Cavedon</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Evaluating deep learning architectures for speech emotion recognition</article-title><source>Neural Netw</source><year>2017</year><pub-id pub-id-type="doi">10.1016/j.neunet.2017.02.013</pub-id></mixed-citation></ref><ref id="CR69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feng</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Ren</surname><given-names>Y</given-names></name><name><surname>Shang</surname><given-names>P</given-names></name><name><surname>Zhu</surname><given-names>Y</given-names></name><name><surname>Liang</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">The deep learning-based recommender system “pubmender” for choosing a biomedical publication venue: development and validation study</article-title><source>J Med Internet Res</source><year>2019</year><volume>21</volume><fpage>e12957</fpage><pub-id pub-id-type="doi">10.2196/12957</pub-id></mixed-citation></ref><ref id="CR70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fink</surname><given-names>O</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Svensen</surname><given-names>M</given-names></name><name><surname>Dersin</surname><given-names>P</given-names></name><name><surname>Lee</surname><given-names>W-J</given-names></name><name><surname>Ducoffe</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Potential, challenges and future directions for deep learning in prognostics and health management applications</article-title><source>Eng Appl Artif Intell</source><year>2020</year><volume>92</volume><pub-id pub-id-type="doi">10.1016/j.engappai.2020.103678</pub-id></mixed-citation></ref><ref id="CR72"><mixed-citation publication-type="other">Gallicchio C Micheli A Pedrelli L (2018a) Deep echo state networks for diagnosis of Parkinson’s disease. In: ESANN 2018a - Proceedings, European symposium on artificial neural networks, computational intelligence and machine learning</mixed-citation></ref><ref id="CR71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallicchio</surname><given-names>C</given-names></name><name><surname>Micheli</surname><given-names>A</given-names></name><name><surname>Pedrelli</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Design of deep echo state networks</article-title><source>Neural Netw</source><year>2018</year><pub-id pub-id-type="doi">10.1016/j.neunet.2018.08.002</pub-id></mixed-citation></ref><ref id="CR73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>Y</given-names></name><name><surname>Gao</surname><given-names>F</given-names></name><name><surname>Dong</surname><given-names>J</given-names></name><name><surname>Li</surname><given-names>HC</given-names></name></person-group><article-title xml:lang="en">SAR image change detection based on multiscale capsule network</article-title><source>IEEE Geosci Remote Sens Lett</source><year>2021</year><pub-id pub-id-type="doi">10.1109/LGRS.2020.2977838</pub-id></mixed-citation></ref><ref id="CR74"><mixed-citation publication-type="other">Gehring J, Auli M, Grangier D, Yarats D, Dauphin YN (2017) Convolutional sequence to sequence learning. In: 34th International conference on machine learning, ICML 2017</mixed-citation></ref><ref id="CR75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gevaert</surname><given-names>CM</given-names></name><name><surname>Suomalainen</surname><given-names>J</given-names></name><name><surname>Tang</surname><given-names>J</given-names></name><name><surname>Kooistra</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Generation of spectral-temporal response surfaces by combining multispectral satellite and hyperspectral UAV imagery for precision agriculture applications</article-title><source>IEEE J Sel Top Appl Earth Obs Remote Sens</source><year>2015</year><pub-id pub-id-type="doi">10.1109/JSTARS.2015.2406339</pub-id></mixed-citation></ref><ref id="CR76"><mixed-citation publication-type="other">Gheisari M, Wang G, Bhuiyan ZA (2017) A survey on deep learning in big data. In: 2017 IEEE International conference on computational science and engineering (CSE) and IEEE international conference on embedded and ubiquitous computing (EUC) 2:173–180</mixed-citation></ref><ref id="CR77"><mixed-citation publication-type="other">Ghiasi G, Lee H, Kudlur M, Dumoulin V, Shlens J (2017) Exploring the structure of a real-time, arbitrary neural artistic stylization network. In: British machine vision conference 2017, BMVC 2017. <ext-link xlink:href="10.5244/c.31.114" ext-link-type="doi">https://doi.org/10.5244/c.31.114</ext-link></mixed-citation></ref><ref id="CR78"><mixed-citation publication-type="other">Ghosh R, Ravi K, Ravi V (2016) A novel deep learning architecture for sentiment classification. In: 2016 3rd International conference on recent advances in information technology, RAIT 2016. <ext-link xlink:href="10.1109/RAIT.2016.7507953" ext-link-type="doi">https://doi.org/10.1109/RAIT.2016.7507953</ext-link></mixed-citation></ref><ref id="CR79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Godarzi</surname><given-names>AA</given-names></name><name><surname>Amiri</surname><given-names>RM</given-names></name><name><surname>Talaei</surname><given-names>A</given-names></name><name><surname>Jamasb</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">Predicting oil price movements: a dynamic artificial neural network approach</article-title><source>Energy Policy</source><year>2014</year><pub-id pub-id-type="doi">10.1016/j.enpol.2013.12.049</pub-id></mixed-citation></ref><ref id="CR80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>IJ</given-names></name><name><surname>Pouget-Abadie</surname><given-names>J</given-names></name><name><surname>Mirza</surname><given-names>M</given-names></name><name><surname>Xu</surname><given-names>B</given-names></name><name><surname>Warde-Farley</surname><given-names>D</given-names></name><name><surname>Ozair</surname><given-names>S</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Generative adversarial nets</article-title><source>Adv Neural Inform Process Syst</source><year>2014</year><pub-id pub-id-type="doi">10.3156/jsoft.29.5_177_2</pub-id></mixed-citation></ref><ref id="CR81"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>I</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Courville</surname><given-names>A</given-names></name></person-group><source>Deep learning</source><year>2016</year><publisher-loc>Cambridge</publisher-loc><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1373.68009</pub-id></mixed-citation></ref><ref id="CR82"><mixed-citation publication-type="other">Goodfellow IJ, Warde-Farley D, Mirza M, Courville A, Bengio Y (2013) Maxout networks. In: 30th International conference on machine learning, ICML 2013.</mixed-citation></ref><ref id="CR83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Govender</surname><given-names>M</given-names></name><name><surname>Chetty</surname><given-names>K</given-names></name><name><surname>Bulcock</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">A review of hyperspectral remote sensing and its application in vegetation and water resource studies</article-title><source>Water SA</source><year>2007</year><pub-id pub-id-type="doi">10.4314/wsa.v33i2.49049</pub-id></mixed-citation></ref><ref id="CR85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graves</surname><given-names>A</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Framewise phoneme classification with bidirectional LSTM and other neural network architectures</article-title><source>Neural Netw</source><year>2005</year><pub-id pub-id-type="doi">10.1016/j.neunet.2005.06.042</pub-id></mixed-citation></ref><ref id="CR84"><mixed-citation publication-type="other">Graves A, Jaitly N, Mohamed AR (2013) Hybrid speech recognition with Deep Bidirectional LSTM. In: 2013 IEEE workshop on automatic speech recognition and understanding, ASRU 2013 - proceedings <ext-link xlink:href="10.1109/ASRU.2013.6707742" ext-link-type="doi">https://doi.org/10.1109/ASRU.2013.6707742</ext-link></mixed-citation></ref><ref id="CR86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Günther</surname><given-names>F</given-names></name><name><surname>Dudschig</surname><given-names>C</given-names></name><name><surname>Kaup</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Latent semantic analysis cosines as a cognitive similarity measure: evidence from priming studies</article-title><source>Q J Exp Psychol</source><year>2016</year><pub-id pub-id-type="doi">10.1080/17470218.2015.1038280</pub-id></mixed-citation></ref><ref id="CR87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Oerlemans</surname><given-names>A</given-names></name><name><surname>Lao</surname><given-names>S</given-names></name><name><surname>Wu</surname><given-names>S</given-names></name><name><surname>Lew</surname><given-names>MS</given-names></name></person-group><article-title xml:lang="en">Deep learning for visual understanding: a review</article-title><source>Neurocomputing</source><year>2016</year><volume>187</volume><fpage>27</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2015.09.116</pub-id></mixed-citation></ref><ref id="CR88"><mixed-citation publication-type="other">Gupta A, Anpalagan A, Guan L, Khwaja AS (2021) Deep learning for object detection and scene perception in self-driving cars: survey, challenges, and open issues. Array 100057</mixed-citation></ref><ref id="CR89"><mixed-citation publication-type="other">PA Gutiérrez and C Hervás-Martínez (2011) Hybrid artificial neural networks: models, algorithms and data. In: 11th international work-conference on artificial neural networks</mixed-citation></ref><ref id="CR90"><mixed-citation publication-type="other">Haarnoja T, Tang, H, Abbeel P, Levine S (2017) Reinforcement learning with deep energy-based policies</mixed-citation></ref><ref id="CR91"><mixed-citation publication-type="other">Hamilton WL, Ying R, Leskovec J (2017) Representation learning on graphs: methods and applications. <ext-link xlink:href="https://arXiv.org/1709.05584" ext-link-type="uri">https://arXiv.org/1709.05584</ext-link></mixed-citation></ref><ref id="CR92"><mixed-citation publication-type="other">Han Y, Huang G, Song S, Yang L, Wang H,  Wang Y (2021) Dynamic Neural networks: a survey. IEEE Transactions on Pattern Analysis and Machine Intelligence 44(11):7436–7456</mixed-citation></ref><ref id="CR93"><mixed-citation publication-type="other">Hasan M, Choi J, Neumann J, Roy-Chowdhury AK, Davis LS (2016) Learning temporal regularity in video sequences</mixed-citation></ref><ref id="CR94"><mixed-citation publication-type="other">Hassan M, Bin Alam MS, Ahsan, T (2018) Emotion detection from text using skip-thought vectors. In: 2018 International conference on innovations in science, engineering and technology, ICISET 2018. <ext-link xlink:href="10.1109/ICISET.2018.8745615" ext-link-type="doi">https://doi.org/10.1109/ICISET.2018.8745615</ext-link></mixed-citation></ref><ref id="CR95"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>J</given-names></name><name><surname>Cheng</surname><given-names>X</given-names></name><name><surname>He</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Cv-CapsNet: Complex-valued capsule network</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>85492</fpage><lpage>85499</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2924548</pub-id></mixed-citation></ref><ref id="CR96"><mixed-citation publication-type="other">He S, Wang S, Lan W, Fu H, Ji Q (2013) Facial expression recognition using deep boltzmann machine from thermal infrared images. In: Proceedings - 2013 humaine association conference on affective computing and intelligent interaction, ACII 2013. <ext-link xlink:href="10.1109/ACII.2013.46" ext-link-type="doi">https://doi.org/10.1109/ACII.2013.46</ext-link></mixed-citation></ref><ref id="CR97"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><article-title xml:lang="en">Deep belief networks</article-title><source>Scholarpedia</source><year>2009</year><pub-id pub-id-type="doi">10.4249/scholarpedia.5947</pub-id></mixed-citation></ref><ref id="CR98"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinton</surname><given-names>G</given-names></name><name><surname>Deng</surname><given-names>L</given-names></name><name><surname>Yu</surname><given-names>D</given-names></name><name><surname>Dahl</surname><given-names>GE</given-names></name><name><surname>Mohamed</surname><given-names>AR</given-names></name><name><surname>Jaitly</surname><given-names>N</given-names></name><name><surname>Senior</surname><given-names>A</given-names></name><name><surname>Vanhoucke</surname><given-names>V</given-names></name><name><surname>Nguyen</surname><given-names>P</given-names></name><name><surname>Sainath</surname><given-names>TN</given-names></name><name><surname>Kingsbury</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups</article-title><source>IEEE Signal Process Mag</source><year>2012</year><volume>29</volume><issue>6</issue><fpage>82</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1109/MSP.2012.2205597</pub-id></mixed-citation></ref><ref id="CR99"><mixed-citation publication-type="other">Hinton GE, Krizhevsky A, Wang SD (2011) Transforming auto-encoders. In: Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics). <ext-link xlink:href="10.1007/978-3-642-21735-7_6" ext-link-type="doi">https://doi.org/10.1007/978-3-642-21735-7_6</ext-link></mixed-citation></ref><ref id="CR100"><mixed-citation publication-type="other">Hong S, Yang D, Choi J, Lee H (2018) Inferring semantic layout for hierarchical text-to-image synthesis. In: Proceedings of the IEEE computer society conference on computer vision and pattern recognition. <ext-link xlink:href="10.1109/CVPR.2018.00833" ext-link-type="doi">https://doi.org/10.1109/CVPR.2018.00833</ext-link></mixed-citation></ref><ref id="CR101"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>F</given-names></name><name><surname>Xia</surname><given-names>GS</given-names></name><name><surname>Hu</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">Transferring deep convolutional neural networks for the scene classification of high-resolution remote sensing imagery</article-title><source>Remote Sens</source><year>2015</year><pub-id pub-id-type="doi">10.3390/rs71114680</pub-id></mixed-citation></ref><ref id="CR102"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>X</given-names></name><name><surname>Chu</surname><given-names>L</given-names></name><name><surname>Pei</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>W</given-names></name><name><surname>Bian</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Model complexity of deep learning: a survey</article-title><source>Knowl Inf Syst</source><year>2021</year><pub-id pub-id-type="doi">10.1007/s10115-021-01605-0</pub-id></mixed-citation></ref><ref id="CR103"><mixed-citation publication-type="other">Hu G, Hua Y, Yuan Y, Zhang Z, Lu Z, Mukherjee SS, Hospedales TM, Robertson NM, Yang Y (2017) Attribute-enhanced face recognition with neural tensor fusion networks. In: Proceedings of the IEEE international conference on computer vision. <ext-link xlink:href="10.1109/ICCV.2017.404" ext-link-type="doi">https://doi.org/10.1109/ICCV.2017.404</ext-link></mixed-citation></ref><ref id="CR104"><mixed-citation publication-type="other">Huang X, Belongie S (2017) Arbitrary style transfer in real-time with adaptive instance normalization. In: Proceedings of the IEEE international conference on computer vision. <ext-link xlink:href="10.1109/ICCV.2017.167" ext-link-type="doi">https://doi.org/10.1109/ICCV.2017.167</ext-link></mixed-citation></ref><ref id="CR105"><mixed-citation publication-type="other">Huang P, He X, Gao J, Deng L, Acero A, Heck L (2013) Learning deep structured semantic models for web search using clickthrough data. In: Proceedings of the 22nd ACM international conference on information and knowledge management pp 2333–2338</mixed-citation></ref><ref id="CR106"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hughes</surname><given-names>M</given-names></name><name><surname>Li</surname><given-names>I</given-names></name><name><surname>Kotoulas</surname><given-names>S</given-names></name><name><surname>Suzumura</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">Medical text classification using convolutional neural networks</article-title><source>Stud Health Technol Inform</source><year>2017</year><pub-id pub-id-type="doi">10.3233/978-1-61499-753-5-246</pub-id></mixed-citation></ref><ref id="CR107"><mixed-citation publication-type="other">Irsoy O, Cardie C (2014) Deep recursive neural networks for compositionality in language. In: Advances in neural information processing systems</mixed-citation></ref><ref id="CR108"><mixed-citation publication-type="other">Ishihara T, Hayashi K, Manabe H, Shimbo M, Nagata M (2018) Neural tensor networks with diagonal slice matrices. In: NAACL HLT 2018 - 2018 conference of the North American chapter of the association for computational linguistics: human language technologies - proceedings of the conference. <ext-link xlink:href="10.18653/v1/n18-1047" ext-link-type="doi">https://doi.org/10.18653/v1/n18-1047</ext-link></mixed-citation></ref><ref id="CR109"><mixed-citation publication-type="other">Jaiswal A, AbdAlmageed W, Wu Y, Natarajan P (2019) CapsuleGAN: generative adversarial capsule network. In: Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics). <ext-link xlink:href="10.1007/978-3-030-11015-4_38" ext-link-type="doi">https://doi.org/10.1007/978-3-030-11015-4_38</ext-link></mixed-citation></ref><ref id="CR110"><mixed-citation publication-type="other">Jayaraman S, Ramachandran M, Patan R, Daneshmand M, Gandomi AH (2022) Fuzzy deep neural learning based on goodman and Kruskal’s Gamma for Search Engine Optimization. IEEE Trans Big Data 8(1), 268–277</mixed-citation></ref><ref id="CR111"><mixed-citation publication-type="other">Jenkins IR, Gee LO, Knauss A, Yin H, Schroeder J (2018) Accident scenario generation with recurrent neural networks. In: 2018 21st International conference on intelligent transportation systems (ITSC). IEEE, pp 3340–3345</mixed-citation></ref><ref id="CR112"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>W</given-names></name><name><surname>Gao</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Lin</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Hyperspectral image classification with capsnet and markov random fields</article-title><source>IEEE Access</source><year>2020</year><pub-id pub-id-type="doi">10.1109/ACCESS.2020.3029174</pub-id></mixed-citation></ref><ref id="CR113"><mixed-citation publication-type="other">Jordan MI, Mitchell TM (2015) Machine learning: trends, perspectives, and prospects 349</mixed-citation></ref><ref id="CR114"><mixed-citation publication-type="other">Kae A, Sohn K, Lee H, Learned-Miller E (2013) Augmenting CRFs with Boltzmann machine shape priors for image labeling 2019–2026. <ext-link xlink:href="10.1109/CVPR.2013.263" ext-link-type="doi">https://doi.org/10.1109/CVPR.2013.263</ext-link></mixed-citation></ref><ref id="CR115"><mixed-citation publication-type="other">Kaiser Ł, Sutskever I (2016) Neural GPUs learn algorithms. In: 4th International conference on learning representations, ICLR 2016 - conference track proceedings</mixed-citation></ref><ref id="CR116"><mixed-citation publication-type="other">Karras T, Aila T, Laine S, Lehtinen J (2018) Progressive growing of GANs for improved quality, stability, and variation. In: 6th international conference on learning representations, ICLR 2018 - conference track proceedings</mixed-citation></ref><ref id="CR117"><mixed-citation publication-type="other">Karras T, Laine S, Aila T (2019) A style-based generator architecture for generative adversarial networks. In: Proceedings of the IEEE conference on computer vision and pattern recognition 2019 pp 4396–4405. <ext-link xlink:href="10.1109/CVPR.2019.00453" ext-link-type="doi">https://doi.org/10.1109/CVPR.2019.00453</ext-link></mixed-citation></ref><ref id="CR118"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kashyap</surname><given-names>PK</given-names></name><name><surname>Kumar</surname><given-names>S</given-names></name><name><surname>Jaiswal</surname><given-names>A</given-names></name><name><surname>Prasad</surname><given-names>M</given-names></name><name><surname>Gandomi</surname><given-names>AH</given-names></name></person-group><article-title xml:lang="en">Towards precision agriculture: iot-enabled intelligent irrigation systems using deep learning neural network</article-title><source>IEEE Sens J</source><year>2021</year><volume>21</volume><issue>16</issue><fpage>17479</fpage><lpage>17491</lpage><pub-id pub-id-type="doi">10.1109/JSEN.2021.3069266</pub-id></mixed-citation></ref><ref id="CR119"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kato</surname><given-names>N</given-names></name><name><surname>Fadlullah</surname><given-names>ZM</given-names></name><name><surname>Mao</surname><given-names>B</given-names></name><name><surname>Tang</surname><given-names>F</given-names></name><name><surname>Akashi</surname><given-names>O</given-names></name><name><surname>Inoue</surname><given-names>T</given-names></name><name><surname>Mizutani</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">The deep learning vision for heterogeneous network traffic control: proposal, challenges, and future perspective</article-title><source>IEEE Wirel Commun</source><year>2016</year><volume>24</volume><fpage>146</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1109/MWC.2016.1600317WC</pub-id></mixed-citation></ref><ref id="CR120"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khamparia</surname><given-names>A</given-names></name><name><surname>Singh</surname><given-names>MM</given-names></name></person-group><article-title xml:lang="en">A systematic review on deep learning architectures and applications</article-title><source>Expert Syst</source><year>2019</year><volume>36</volume><fpage>e12400</fpage><pub-id pub-id-type="doi">10.1111/exsy.12400</pub-id></mixed-citation></ref><ref id="CR121"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khan</surname><given-names>A</given-names></name><name><surname>Sohail</surname><given-names>A</given-names></name><name><surname>Zahoora</surname><given-names>U</given-names></name><name><surname>Qureshi</surname><given-names>AS</given-names></name></person-group><article-title xml:lang="en">A survey of the recent architectures of deep convolutional neural networks</article-title><source>Artif Intell Rev</source><year>2020</year><pub-id pub-id-type="doi">10.1007/s10462-020-09825-6</pub-id></mixed-citation></ref><ref id="CR122"><mixed-citation publication-type="other">Kim JH, On KW, Lim W, Kim J, Ha JW, Zhang BT (2017) Hadamard product for low-rank bilinear pooling. In: 5th international conference on learning representations, ICLR 2017 - conference track proceedings</mixed-citation></ref><ref id="CR123"><mixed-citation publication-type="other">Kim TS, Reiter A (2017) Interpretable 3D human action analysis with temporal convolutional networks. IEEE Computer society conference on computer vision and pattern recognition workshops. <ext-link xlink:href="10.1109/CVPRW.2017.207" ext-link-type="doi">https://doi.org/10.1109/CVPRW.2017.207</ext-link></mixed-citation></ref><ref id="CR124"><mixed-citation publication-type="other">Kiros R, Zhu Y, Salakhutdinov R, Zemel RS, Torralba A, Urtasun R, Fidler S (2015) Skip-thought vectors. Advances in neural information processing systems</mixed-citation></ref><ref id="CR125"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kotsiopoulos</surname><given-names>T</given-names></name><name><surname>Sarigiannidis</surname><given-names>P</given-names></name><name><surname>Ioannidis</surname><given-names>D</given-names></name><name><surname>Tzovaras</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Machine learning and deep learning in smart manufacturing: the smart grid paradigm</article-title><source>Comput Sci Rev</source><year>2021</year><volume>40</volume><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">4214941</pub-id><pub-id pub-id-type="doi">10.1016/j.cosrev.2020.100341</pub-id></mixed-citation></ref><ref id="CR126"><mixed-citation publication-type="other">Kraska T, Beutel A, Chi EH, Dean J, Polyzotis N (2018) The case for learned index structures. In: Proceedings of the ACM SIGMOD international conference on management of data. Association for computing machinery, New York, pp 489–504. <ext-link xlink:href="10.1145/3183713.3196909" ext-link-type="doi">https://doi.org/10.1145/3183713.3196909</ext-link></mixed-citation></ref><ref id="CR127"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krichene</surname><given-names>E</given-names></name><name><surname>Masmoudi</surname><given-names>Y</given-names></name><name><surname>Alimi</surname><given-names>AM</given-names></name><name><surname>Abraham</surname><given-names>A</given-names></name><name><surname>Chabchoub</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Forecasting using elman recurrent neural network</article-title><source>Adv Intell Syst Comput</source><year>2017</year><pub-id pub-id-type="doi">10.1007/978-3-319-53480-0_48</pub-id></mixed-citation></ref><ref id="CR128"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krizhevsky</surname><given-names>A</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><article-title xml:lang="en">ImageNet classification with deep convolutional neural networks</article-title><source>Commun ACM</source><year>2017</year><volume>60</volume><fpage>84</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1145/3065386</pub-id></mixed-citation></ref><ref id="CR129"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>A</given-names></name><name><surname>Ramachandran</surname><given-names>M</given-names></name><name><surname>Gandomi</surname><given-names>AH</given-names></name><name><surname>Patan</surname><given-names>R</given-names></name><name><surname>Lukasik</surname><given-names>S</given-names></name><name><surname>Soundarapandian</surname><given-names>RK</given-names></name></person-group><article-title xml:lang="en">A deep neural network based classifier for brain tumor diagnosis</article-title><source>Appl Soft Comput</source><year>2019</year><volume>82</volume><pub-id pub-id-type="doi">10.1016/j.asoc.2019.105528</pub-id></mixed-citation></ref><ref id="CR130"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Landgrebe</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Hyperspectral image data analysis</article-title><source>IEEE Signal Process Mag</source><year>2002</year><pub-id pub-id-type="doi">10.1109/79.974718</pub-id></mixed-citation></ref><ref id="CR131"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lara-ben</surname><given-names>P</given-names></name><name><surname>Carranza-garc</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">An experimental review on deep learning architectures for time series forecasting</article-title><source>Int J Neural Syst</source><year>2021</year><volume>31</volume><fpage>2130001</fpage><pub-id pub-id-type="doi">10.1142/S0129065721300011</pub-id></mixed-citation></ref><ref id="CR132"><mixed-citation publication-type="other">Lea C, Vidal R, Reiter A, Hager GD (2016) Temporal convolutional networks: a unified approach to action segmentation. In: Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics). <ext-link xlink:href="10.1007/978-3-319-49409-8_7" ext-link-type="doi">https://doi.org/10.1007/978-3-319-49409-8_7</ext-link></mixed-citation></ref><ref id="CR134"><mixed-citation publication-type="other">LeCun YA, Bottou L, Orr GB, Müller K-R (2012) Efficient backprop BT - neural networks: tricks of the trade. In: Neural networks: tricks of the trade</mixed-citation></ref><ref id="CR133"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lecun</surname><given-names>Y</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Deep learning</article-title><source>Nature</source><year>2015</year><volume>521</volume><fpage>463</fpage><lpage>444</lpage><pub-id pub-id-type="doi">10.1038/nature14539</pub-id></mixed-citation></ref><ref id="CR136"><mixed-citation publication-type="other">Ledig C, Theis L, Huszár F, Caballero J, Cunningham A, Acosta A, Aitken A, Tejani A., Totz J, Wang Z, Shi W (2017) Photo-realistic single image super-resolution using a generative adversarial network. In: Proceedings - 30th IEEE conference on computer vision and pattern recognition, CVPR 2017. <ext-link xlink:href="10.1109/CVPR.2017.19" ext-link-type="doi">https://doi.org/10.1109/CVPR.2017.19</ext-link></mixed-citation></ref><ref id="CR137"><mixed-citation publication-type="other">Lee R, Chen IY (2020) The time complexity analysis of neural network model configurations. In: Proceedings - 2nd international conference on mathematics and computers in science and engineering, MACISE 2020. <ext-link xlink:href="10.1109/MACISE49704.2020.00039" ext-link-type="doi">https://doi.org/10.1109/MACISE49704.2020.00039</ext-link></mixed-citation></ref><ref id="CR138"><mixed-citation publication-type="other">Lee H, Grosse R, Ranganath R, Ng AY (2009) Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In: Proceedings of the 26th international conference on machine learning, ICML 2009 <ext-link xlink:href="10.1145/1553374.1553453" ext-link-type="doi">https://doi.org/10.1145/1553374.1553453</ext-link></mixed-citation></ref><ref id="CR139"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lemley</surname><given-names>J</given-names></name><name><surname>Bazrafkan</surname><given-names>S</given-names></name><name><surname>Corcoran</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Deep learning for consumer devices and services</article-title><source>IEEE Consum Electron Mag</source><year>2017</year><volume>6</volume><fpage>48</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1109/MCE.2016.2640698</pub-id></mixed-citation></ref><ref id="CR140"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leng</surname><given-names>B</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Yao</surname><given-names>M</given-names></name><name><surname>Xiong</surname><given-names>Z</given-names></name></person-group><article-title xml:lang="en">A 3D model recognition mechanism based on deep Boltzmann machines</article-title><source>Neurocomputing</source><year>2015</year><pub-id pub-id-type="doi">10.1016/j.neucom.2014.06.084</pub-id></mixed-citation></ref><ref id="CR141"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leung</surname><given-names>MKK</given-names></name><name><surname>Xiong</surname><given-names>HY</given-names></name><name><surname>Lee</surname><given-names>LJ</given-names></name><name><surname>Frey</surname><given-names>BJ</given-names></name></person-group><article-title xml:lang="en">Deep learning of the tissue-regulated splicing code</article-title><source>Bioinformatics</source><year>2014</year><volume>30</volume><fpage>i121</fpage><lpage>i129</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btu277</pub-id></mixed-citation></ref><ref id="CR145"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Z</given-names></name><name><surname>Huang</surname><given-names>H</given-names></name><name><surname>Zhang</surname><given-names>Z</given-names></name><name><surname>Shi</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Manifold-based multi-deep belief network for feature extraction of hyperspectral image</article-title><source>Remote Sens</source><year>2022</year><volume>14</volume><fpage>1484</fpage><pub-id pub-id-type="doi">10.3390/rs14061484</pub-id></mixed-citation></ref><ref id="CR146"><mixed-citation publication-type="other">Li J, Xiong D, Tu Z, Zhu M, Zhang M, Zhou G (2017a) Modeling source syntax for neural machine translation. In: ACL 2017a - 55th annual meeting of the association for computational linguistics, proceedings of the conference (Long Papers). <ext-link xlink:href="10.18653/v1/P17-1064" ext-link-type="doi">https://doi.org/10.18653/v1/P17-1064</ext-link></mixed-citation></ref><ref id="CR147"><mixed-citation publication-type="other">Li Z, Yang Y, Liu X, Zhou F, Wen S, Xu W (2017b) Dynamic computational time for visual attention. In: Proceedings - 2017 IEEE international conference on computer vision workshops, ICCVW 2017. <ext-link xlink:href="10.1109/ICCVW.2017.145" ext-link-type="doi">https://doi.org/10.1109/ICCVW.2017.145</ext-link></mixed-citation></ref><ref id="CR148"><mixed-citation publication-type="other">Li JB, Schmidt FR, Kolter JZ (2019a) Adversarial camera stickers: a physical camera-based attack on deep learning systems. In: International conference on machine learning. pp 3896–3904</mixed-citation></ref><ref id="CR142"><mixed-citation publication-type="other">Li P, Chen X, Shen S (2019b) Stereo R-CNN based 3D object detection for autonomous driving. In: Proceedings of the IEEE computer society conference on computer vision and pattern recognition. <ext-link xlink:href="10.1109/CVPR.2019.00783" ext-link-type="doi">https://doi.org/10.1109/CVPR.2019.00783</ext-link></mixed-citation></ref><ref id="CR143"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Qian</surname><given-names>M</given-names></name><name><surname>Liu</surname><given-names>P</given-names></name><name><surname>Cai</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Guo</surname><given-names>J</given-names></name><name><surname>Yan</surname><given-names>H</given-names></name><name><surname>Yu</surname><given-names>F</given-names></name><name><surname>Yuan</surname><given-names>K</given-names></name><name><surname>Yu</surname><given-names>J</given-names></name><name><surname>Qin</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Wu</surname><given-names>W</given-names></name><name><surname>Xiao</surname><given-names>P</given-names></name><name><surname>Zhou</surname><given-names>Z</given-names></name></person-group><article-title xml:lang="en">The recognition of rice images by UAV based on capsule network</article-title><source>Cluster Comput</source><year>2019</year><pub-id pub-id-type="doi">10.1007/s10586-018-2482-7</pub-id></mixed-citation></ref><ref id="CR144"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Z</given-names></name><name><surname>Cai</surname><given-names>X</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Zhu</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">A Novel gaussian-bernoulli based convolutional deep belief networks for image feature extraction</article-title><source>Neural Process Lett</source><year>2019</year><pub-id pub-id-type="doi">10.1007/s11063-017-9751-y</pub-id></mixed-citation></ref><ref id="CR149"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liao</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Yu</surname><given-names>R</given-names></name><name><surname>Sato</surname><given-names>K</given-names></name><name><surname>Cheng</surname><given-names>Z</given-names></name></person-group><article-title xml:lang="en">CNN for situations understanding based on sentiment analysis of twitter data</article-title><source>Procedia Comput Sci</source><year>2017</year><pub-id pub-id-type="doi">10.1016/j.procs.2017.06.037</pub-id></mixed-citation></ref><ref id="CR150"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>S</given-names></name><name><surname>Kang</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Chemical-gene relation extraction using recursive neural network</article-title><source>Database 2018</source><year>2018</year><pub-id pub-id-type="doi">10.1093/database/bay060</pub-id></mixed-citation></ref><ref id="CR151"><mixed-citation publication-type="other">Lin Z, Feng M, Dos Santos CN, Yu M, Xiang B, Zhou B, Bengio Y (2017) A structured self-attentive sentence embedding. In: 5th international conference on learning representations, ICLR 2017 - conference track proceedings</mixed-citation></ref><ref id="CR152"><mixed-citation publication-type="other">Lin CY (2004) Rouge: a package for automatic evaluation of summaries. Proc work text summ branches out (WAS 2004)</mixed-citation></ref><ref id="CR153"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liou</surname><given-names>CY</given-names></name><name><surname>Cheng</surname><given-names>WC</given-names></name><name><surname>Liou</surname><given-names>JW</given-names></name><name><surname>Liou</surname><given-names>DR</given-names></name></person-group><article-title xml:lang="en">Autoencoder for words</article-title><source>Neurocomputing</source><year>2014</year><volume>139</volume><fpage>84</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2013.09.055</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1237.58019</pub-id></mixed-citation></ref><ref id="CR154"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Litjens</surname><given-names>G</given-names></name><name><surname>Kooi</surname><given-names>T</given-names></name><name><surname>Bejnordi</surname><given-names>BE</given-names></name><name><surname>Arindra</surname><given-names>A</given-names></name><name><surname>Setio</surname><given-names>A</given-names></name><name><surname>Ciompi</surname><given-names>F</given-names></name><name><surname>Ghafoorian</surname><given-names>M</given-names></name><name><surname>Laak</surname><given-names>JAWMV</given-names></name><name><surname>Der</surname><given-names>G</given-names></name><name><surname>Van</surname><given-names>B</given-names></name><name><surname>Clara</surname><given-names>IS</given-names></name></person-group><article-title xml:lang="en">A survey on deep learning in medical image analysis</article-title><source>Med Image Anal</source><year>2017</year><volume>42</volume><fpage>60</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1016/j.media.2017.07.005</pub-id></mixed-citation></ref><ref id="CR155"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Yang</surname><given-names>X</given-names></name><name><surname>Lei</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Xiang</surname><given-names>S</given-names></name><name><surname>Ni</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">Deep learning in medical ultrasound analysis: a review</article-title><source>Engineering</source><year>2019</year><volume>5</volume><fpage>261</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1016/j.eng.2018.11.020</pub-id></mixed-citation></ref><ref id="CR156"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>K</given-names></name><name><surname>Cheng</surname><given-names>J</given-names></name><name><surname>Yi</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Copper price forecasted by hybrid neural network with Bayesian optimization and wavelet transform</article-title><source>Resour Policy</source><year>2022</year><volume>75</volume><fpage>102520</fpage><pub-id pub-id-type="doi">10.1016/j.resourpol.2021.102520</pub-id></mixed-citation></ref><ref id="CR158"><mixed-citation publication-type="other">Liu P, Qiu X, Xuanjing H (2016) Recurrent neural network for text classification with multi-task learning. In: IJCAI international joint conference on artificial intelligence</mixed-citation></ref><ref id="CR159"><mixed-citation publication-type="other">Liu W, Luo W, Lian D, Gao S (2017) Future frame prediction for anomaly detection—a new baseline. In: Proceedings of the IEEE conference on computer vision and pattern recognition 6536–6545</mixed-citation></ref><ref id="CR160"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Chen</surname><given-names>M</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Serikawa</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">Brain intelligence: go beyond artificial intelligence</article-title><source>Mobile Netw Appl</source><year>2018</year><volume>23</volume><fpage>368</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1007/s11036-017-0932-8</pub-id></mixed-citation></ref><ref id="CR161"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lukoševičius</surname><given-names>M</given-names></name><name><surname>Jaeger</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Reservoir computing approaches to recurrent neural network training</article-title><source>Comput Sci Rev</source><year>2009</year><pub-id pub-id-type="doi">10.1016/j.cosrev.2009.03.005</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1302.68235</pub-id></mixed-citation></ref><ref id="CR162"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>J</given-names></name><name><surname>Sheridan</surname><given-names>RP</given-names></name><name><surname>Liaw</surname><given-names>A</given-names></name><name><surname>Dahl</surname><given-names>GE</given-names></name><name><surname>Svetnik</surname><given-names>V</given-names></name></person-group><article-title xml:lang="en">Deep neural nets as a method for quantitative structure—activity relationships</article-title><source>J Chem Inf Model</source><year>2015</year><volume>55</volume><fpage>263</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1021/ci500747n</pub-id></mixed-citation></ref><ref id="CR163"><mixed-citation publication-type="other">Ma J, Gao W, Wong KF (2018) Rumor detection on twitter with tree-structured recursive neural networks. In: ACL 2018 - 56th annual meeting of the association for computational linguistics, proceedings of the conference (Long Papers). <ext-link xlink:href="10.18653/v1/p18-1184" ext-link-type="doi">https://doi.org/10.18653/v1/p18-1184</ext-link></mixed-citation></ref><ref id="CR164"><mixed-citation publication-type="other">Majumder N, Poria S, Hazarika D, Mihalcea R, Gelbukh A, Cambria, E (2019) DialogueRNN: an attentive RNN for emotion detection in conversations. In: 33rd AAAI Conference on artificial intelligence, AAAI 2019, 31st innovative applications of artificial intelligence conference, IAAI 2019 and the 9th AAAI symposium on educational advances in artificial intelligence, EAAI 2019<ext-link xlink:href="10.1609/aaai.v33i01.33016818" ext-link-type="doi">https://doi.org/10.1609/aaai.v33i01.33016818</ext-link></mixed-citation></ref><ref id="CR165"><mixed-citation publication-type="other">Mendis GJ, Randeny T, Wei, J, Madanayake A (2016) Deep learning based doppler radar for micro VAS detection and classification Gihan J. Mendis. In: MILCOM 2016–2016 IEEE military communications conference pp 924–929</mixed-citation></ref><ref id="CR166"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mesnil</surname><given-names>G</given-names></name><name><surname>Dauphin</surname><given-names>Y</given-names></name><name><surname>Yao</surname><given-names>K</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Deng</surname><given-names>L</given-names></name><name><surname>Hakkani-tur</surname><given-names>D</given-names></name><name><surname>He</surname><given-names>X</given-names></name></person-group><article-title xml:lang="en">Using recurrent neural networks for slot filling in spoken language understanding. IEEE/ACM trans audio, speech</article-title><source>Lang Process</source><year>2015</year><volume>23</volume><fpage>530</fpage><lpage>539</lpage></mixed-citation></ref><ref id="CR167"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Micheli</surname><given-names>A</given-names></name><name><surname>Sperduti</surname><given-names>A</given-names></name><name><surname>Starita</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">An introduction to recursive neural networks and kernel methods for cheminformatics</article-title><source>Curr Pharm Des</source><year>2007</year><pub-id pub-id-type="doi">10.2174/138161207780765981</pub-id></mixed-citation></ref><ref id="CR168"><mixed-citation publication-type="other">Mikolov T, Karafiát M, Burget L, Jan C, Khudanpur, S (2010) Recurrent neural network based language model. In: Proceedings of the 11th annual conference of the international speech communication association, INTERSPEECH 2010</mixed-citation></ref><ref id="CR169"><mixed-citation publication-type="other">Mikolov T, Kombrink S, Burget L, Černocký J, Khudanpur S (2011) Extensions of recurrent neural network language model In: ICASSP, IEEE international conference on acoustics, speech and signal processing - proceedings. <ext-link xlink:href="10.1109/ICASSP.2011.5947611" ext-link-type="doi">https://doi.org/10.1109/ICASSP.2011.5947611</ext-link></mixed-citation></ref><ref id="CR170"><mixed-citation publication-type="other">Mikolov T, Chen K, Corrado G Dean J (2013) Efficient estimation of word representations in vector space. In: 1st international conference on learning representations, ICLR 2013 - workshop track proceedings</mixed-citation></ref><ref id="CR171"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miotto</surname><given-names>R</given-names></name><name><surname>Wang</surname><given-names>F</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Jiang</surname><given-names>X</given-names></name><name><surname>Dudley</surname><given-names>JT</given-names></name></person-group><article-title xml:lang="en">Deep learning for healthcare: review, opportunities and challenges</article-title><source>Brief Bioinform</source><year>2018</year><volume>19</volume><fpage>1236</fpage><lpage>1246</lpage><pub-id pub-id-type="doi">10.1093/bib/bbx044</pub-id></mixed-citation></ref><ref id="CR172"><mixed-citation publication-type="other">Misra D (2019) Mish: a self regularized non-monotonic neural activation function. <ext-link xlink:href="https://arXiv.org/1908.08681" ext-link-type="uri">https://arXiv.org/1908.08681</ext-link></mixed-citation></ref><ref id="CR173"><mixed-citation publication-type="other">Mitra B, Craswell N (2017) Neural text embeddings for information retrieval (WSDM 2017 tutorial) In: WSDM 2017 - Proceedings of the 10th ACM international conference on web search and data mining <ext-link xlink:href="10.1145/3018661.3022755" ext-link-type="doi">https://doi.org/10.1145/3018661.3022755</ext-link></mixed-citation></ref><ref id="CR174"><mixed-citation publication-type="other">Miyato T, Kataoka T, Koyama M, Yoshida Y (2018) Spectral normalization for generative adversarial networks. In: 6th international conference on learning representations, ICLR 2018 - conference track proceedings</mixed-citation></ref><ref id="CR175"><mixed-citation publication-type="other">Mobiny A, Van Nguyen H 2018 Fast CapsNet for lung cancer screening. In: Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics). <ext-link xlink:href="10.1007/978-3-030-00934-2_82" ext-link-type="doi">https://doi.org/10.1007/978-3-030-00934-2_82</ext-link></mixed-citation></ref><ref id="CR176"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohd</surname><given-names>M</given-names></name><name><surname>Jan</surname><given-names>R</given-names></name><name><surname>Shah</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Text document summarization using word embedding</article-title><source>Expert Syst Appl</source><year>2020</year><pub-id pub-id-type="doi">10.1016/j.eswa.2019.112958</pub-id></mixed-citation></ref><ref id="CR177"><mixed-citation publication-type="other">Mousavi M, Gandomi AH (2021) Deep learning for structural health monitoring under environmental and operational variations. In: Nondestructive characterization and monitoring of advanced materials, aerospace, civil infrastructure, and transportation XV. International society for optics and photonics p 115920H</mixed-citation></ref><ref id="CR178"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mühlhoff</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Human-aided artificial intelligence: or, how to run large computations in human brains? Toward a media sociology of machine learning</article-title><source>New Media Soc</source><year>2020</year><volume>22</volume><fpage>1868</fpage><lpage>1884</lpage><pub-id pub-id-type="doi">10.1177/1461444819885334</pub-id></mixed-citation></ref><ref id="CR179"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mukherjee</surname><given-names>S</given-names></name><name><surname>Zimmer</surname><given-names>A</given-names></name><name><surname>Sun</surname><given-names>X</given-names></name><name><surname>Ghuman</surname><given-names>P</given-names></name><name><surname>Cheng</surname><given-names>I</given-names></name></person-group><article-title xml:lang="en">An unsupervised generative neural approach for InSAR phase filtering and coherence estimation</article-title><source>IEEE Geosci Remote Sens Lett</source><year>2020</year><volume>18</volume><fpage>1971</fpage><lpage>1975</lpage><pub-id pub-id-type="doi">10.1109/LGRS.2020.3010504</pub-id></mixed-citation></ref><ref id="CR180"><mixed-citation publication-type="other">Murali S, Swapna TR (2019) An empirical evaluation of temporal convolutional network for offensive text classification. Int J Innov Technol Explor Eng 8(8)</mixed-citation></ref><ref id="CR181"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naylor</surname><given-names>CD</given-names></name></person-group><article-title xml:lang="en">On the prospects for a (deep) learning health care system</article-title><source>J Am Med Assoc</source><year>2018</year><volume>320</volume><fpage>1099</fpage><lpage>1100</lpage><pub-id pub-id-type="doi">10.1001/jama.2018.11103</pub-id></mixed-citation></ref><ref id="CR182"><mixed-citation publication-type="other">Ng A (2015) What data scientists should know about deep learning. <ext-link xlink:href="http://www.slideshare.net/ExtractConf44" ext-link-type="uri">www.slideshare.net/ExtractConf44</ext-link></mixed-citation></ref><ref id="CR183"><mixed-citation publication-type="other">Ngiam J, Chen Z, Wei Koh P, Ng AY (2011) Learning deep energy models. In: Proceedings of the 28th international conference on machine learning (ICML-11)  pp 1105–1112</mixed-citation></ref><ref id="CR184"><mixed-citation publication-type="other">Nguyen A, Yosinski J, Clune J (2015) Deep neural networks are easily fooled: high confidence predictions for unrecognizable images. In: Proceedings of the IEEE conference on computer vision and pattern recognition pp 427–436</mixed-citation></ref><ref id="CR185"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nguyen-Thanh</surname><given-names>VM</given-names></name><name><surname>Zhuang</surname><given-names>X</given-names></name><name><surname>Rabczuk</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">A deep energy method for finite deformation hyperelasticity</article-title><source>Eur J Mech</source><year>2020</year><pub-id pub-id-type="doi">10.1016/j.euromechsol.2019.103874</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1472.74213</pub-id></mixed-citation></ref><ref id="CR186"><mixed-citation publication-type="other">Niklaus S, Mai L, Liu F (2017) Video frame interpolation via adaptive separable convolution. In: Proceedings of the IEEE international conference on computer vision. <ext-link xlink:href="10.1109/ICCV.2017.37" ext-link-type="doi">https://doi.org/10.1109/ICCV.2017.37</ext-link></mixed-citation></ref><ref id="CR187"><mixed-citation publication-type="other">Norton AP, Qi Y (2017) Adversarial-playground: a visualization suite showing how adversarial examples fool deep learning. In: 2017 IEEE symposium on visualization for cyber security (VizSec) pp 1–14</mixed-citation></ref><ref id="CR188"><mixed-citation publication-type="other">Nwankpa CE, Ijomah W, Gachagan A, Marshall S (2018) Activation functions: comparison of trends in practice and research for deep learning.   <ext-link xlink:href="https://arXiv.org/1811.03378" ext-link-type="uri">https://arXiv.org/1811.03378</ext-link></mixed-citation></ref><ref id="CR189"><mixed-citation publication-type="other">Odena A, Olah C, Shlens J (2017) Conditional image synthesis with auxiliary classifier gans. In: 34th International conference on machine learning, ICML 2017</mixed-citation></ref><ref id="CR190"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oka</surname><given-names>A</given-names></name><name><surname>Ishimura</surname><given-names>N</given-names></name><name><surname>Ishihara</surname><given-names>S</given-names></name></person-group><article-title xml:lang="en">A new dawn for the use of artificial intelligence in gastroenterology</article-title><source>Hepatol Pancreatol Diagn</source><year>2021</year><volume>11</volume><fpage>1719</fpage></mixed-citation></ref><ref id="CR191"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oord</surname><given-names>VD</given-names></name><name><surname>Dieleman</surname><given-names>S</given-names></name><name><surname>Schrauwen</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Deep content-based music recommendation</article-title><source>Neural Inform Process Syst </source><year>2013</year><volume>26</volume><fpage>1</fpage><lpage>9</lpage></mixed-citation></ref><ref id="CR192"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orkphol</surname><given-names>K</given-names></name><name><surname>Yang</surname><given-names>W</given-names></name></person-group><article-title xml:lang="en">Word sense disambiguation using cosine similarity collaborates with Word2vec and WordNet</article-title><source>Futur Internet</source><year>2019</year><volume>11</volume><fpage>114</fpage><pub-id pub-id-type="doi">10.3390/fi11050114</pub-id></mixed-citation></ref><ref id="CR193"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ortiz</surname><given-names>A</given-names></name><name><surname>Munilla</surname><given-names>J</given-names></name><name><surname>Gorriz</surname><given-names>JM</given-names></name><name><surname>Ramirez</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Ensembles of deep learning architectures for the early diagnosis of the Alzheimer’s disease</article-title><source>Int J Neural Syst</source><year>2016</year><volume>26</volume><fpage>1</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1142/S0129065716500258</pub-id></mixed-citation></ref><ref id="CR194"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Palanichamy</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Integrative omic analysis of neuroblastoma</article-title><source>Computational epigenetics and diseases</source><year>2019</year><publisher-loc>Amsterdam</publisher-loc><publisher-name>Elsevier</publisher-name><fpage>311</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-814513-5.00019-2</pub-id></mixed-citation></ref><ref id="CR195"><mixed-citation publication-type="other">Pandey K, Shekhawat HS, Prasanna, SRM (2019) Deep learning techniques for speech emotion recognition : a review. 2019 29th international conference radioelektronika pp 1–6</mixed-citation></ref><ref id="CR196"><mixed-citation publication-type="other">Papernot N, Mcdaniel P, Jha S, Fredrikson M, Celik ZB, Swami A (2016) The limitations of deep learning in adversarial settings. In: 2016 IEEE European symposium on security and privacy (EuroS and P) pp 372–387</mixed-citation></ref><ref id="CR197"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Papineni</surname><given-names>K</given-names></name><name><surname>Roukos</surname><given-names>S</given-names></name><name><surname>Ward</surname><given-names>T</given-names></name><name><surname>Zhu</surname><given-names>W-J</given-names></name></person-group><article-title xml:lang="en">BLEU: a method for automatic evaluation of machine translation</article-title><source>Assoc Comput Linguist</source><year>2001</year><pub-id pub-id-type="doi">10.3115/10730831073135</pub-id></mixed-citation></ref><ref id="CR198"><mixed-citation publication-type="other">Parikh AP, Täckström O, Das, D, Uszkoreit J (2016) A decomposable attention model for natural language inference. In: EMNLP 2016 - conference on empirical methods in natural language processing, proceedings. <ext-link xlink:href="10.18653/v1/d16-1244" ext-link-type="doi">https://doi.org/10.18653/v1/d16-1244</ext-link></mixed-citation></ref><ref id="CR199"><mixed-citation publication-type="other">Park T, Liu MY, Wang TC, Zhu JY (2019) Semantic image synthesis with spatially-adaptive normalization. In: Proceedings of the IEEE computer society conference on computer vision and pattern recognition. <ext-link xlink:href="10.1109/CVPR.2019.00244" ext-link-type="doi">https://doi.org/10.1109/CVPR.2019.00244</ext-link></mixed-citation></ref><ref id="CR200"><mixed-citation publication-type="other">Park DC (2010) A time series data prediction scheme using bilinear recurrent neural network. In: 2010 International conference on information science and applications, ICISA 2010. <ext-link xlink:href="10.1109/ICISA.2010.5480383" ext-link-type="doi">https://doi.org/10.1109/ICISA.2010.5480383</ext-link></mixed-citation></ref><ref id="CR201"><mixed-citation publication-type="other">Parkhi OM, Vedaldi A, Zisserman A (2015) Deep face recognition. British machine vision association</mixed-citation></ref><ref id="CR202"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pashaei</surname><given-names>M</given-names></name><name><surname>Kamangir</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Review and evaluation of deep learning architectures for efficient land cover mapping with uas hyper-spatial imagery: a case study over a wetland</article-title><source>Remote Sens</source><year>2020</year><volume>12</volume><fpage>959</fpage><pub-id pub-id-type="doi">10.3390/rs12060959</pub-id></mixed-citation></ref><ref id="CR203"><mixed-citation publication-type="other">Paula EL, Ladeira M, Carvalho RN, Marzag T (2016) Deep learning anomaly detection as support fraud investigation in Brazilian exports and anti-money laundering. In: 2016 15th IEEE International conference on machine learning and applications (ICMLA) pp 954–960. <ext-link xlink:href="10.1109/ICMLA.2016.73" ext-link-type="doi">https://doi.org/10.1109/ICMLA.2016.73</ext-link></mixed-citation></ref><ref id="CR204"><mixed-citation publication-type="other">Paulus R, Xiong C, Socher R (2018) A deep reinforced model for abstractive summarization. In: 6th international conference on learning representations, ICLR 2018 - conference track proceedings</mixed-citation></ref><ref id="CR205"><mixed-citation publication-type="other">Perozzi B, Al-Rfou R, Skiena S (2014) DeepWalk: online learning of social representations. In: Proceedings of the ACM SIGKDD international conference on knowledge discovery and data mining. <ext-link xlink:href="10.1145/2623330.2623732" ext-link-type="doi">https://doi.org/10.1145/2623330.2623732</ext-link></mixed-citation></ref><ref id="CR206"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perraudin</surname><given-names>N</given-names></name><name><surname>Defferrard</surname><given-names>M</given-names></name><name><surname>Kacprzak</surname><given-names>T</given-names></name><name><surname>Sgier</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">DeepSphere: efficient spherical convolutional neural network with HEALPix sampling for cosmological applications</article-title><source>Astron Comput</source><year>2019</year><pub-id pub-id-type="doi">10.1016/j.ascom.2019.03.004</pub-id></mixed-citation></ref><ref id="CR207"><mixed-citation publication-type="other">Pfau D (2017) Unrolled GAN 1–25</mixed-citation></ref><ref id="CR208"><mixed-citation publication-type="other">Poliak A, Belinkov Y, Glass J, Van Durme B (2018) On the evaluation of semantic phenomena in neural machine translation using natural language inference. In: NAACL HLT 2018 - 2018 conference of the North American chapter of the association for computational linguistics: human language technologies - proceedings of the conference. <ext-link xlink:href="10.18653/v1/n18-2082" ext-link-type="doi">https://doi.org/10.18653/v1/n18-2082</ext-link></mixed-citation></ref><ref id="CR209"><mixed-citation publication-type="other">Popperli M, Gulagundi R, Yogamani S, Milz S (2019) Capsule neural network based height classification using low-cost automotive ultrasonic sensors. In: IEEE intelligent vehicles symposium, proceedings. <ext-link xlink:href="10.1109/IVS.2019.8813879" ext-link-type="doi">https://doi.org/10.1109/IVS.2019.8813879</ext-link></mixed-citation></ref><ref id="CR210"><mixed-citation publication-type="other">Pouyanfar S, Saad S., Yilin Y, Haiman T, Tao Y, Reyes MP, Shyu M, Chen S-C, Iyengar SS (2018) A survey on deep learning: algorithms, techniques, and applications. ACM Comput Surv 51(5):1–36</mixed-citation></ref><ref id="CR211"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qasim Abualigah</surname><given-names>LM</given-names></name><name><surname>Hanandeh</surname><given-names>ES</given-names></name></person-group><article-title xml:lang="en">Applying genetic algorithms to information retrieval using vector space model</article-title><source>Int J Comput Sci Eng Appl</source><year>2015</year><pub-id pub-id-type="doi">10.5121/ijcsea.2015.5102</pub-id></mixed-citation></ref><ref id="CR212"><mixed-citation publication-type="other">Qiu X, Huang X (2015) Convolutional neural tensor network architecture for community-based question answering. In: IJCAI International joint conference on artificial intelligence</mixed-citation></ref><ref id="CR213"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname><given-names>G</given-names></name><name><surname>Huang</surname><given-names>W</given-names></name><name><surname>Feng</surname><given-names>Z</given-names></name><name><surname>Cong</surname><given-names>Q</given-names></name></person-group><article-title xml:lang="en">LSTM with sentence representations for document-level sentiment classification</article-title><source>Neurocomputing</source><year>2018</year><pub-id pub-id-type="doi">10.1016/j.neucom.2018.04.045</pub-id></mixed-citation></ref><ref id="CR214"><mixed-citation publication-type="other">Rao K, Sak H, Prabhavalkar R (2018b) Exploring architectures, data and units for streaming end-to-end speech recognition with RNN-transducer. In: 2017 IEEE automatic speech recognition and understanding workshop, ASRU 2017 - proceedings. <ext-link xlink:href="10.1109/ASRU.2017.8268935" ext-link-type="doi">https://doi.org/10.1109/ASRU.2017.8268935</ext-link></mixed-citation></ref><ref id="CR215"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ravì</surname><given-names>D</given-names></name><name><surname>Wong</surname><given-names>C</given-names></name><name><surname>Deligianni</surname><given-names>F</given-names></name><name><surname>Berthelot</surname><given-names>M</given-names></name><name><surname>Andreu-perez</surname><given-names>J</given-names></name><name><surname>Lo</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Deep learning for health informatics</article-title><source>IEEE J Biomed Heal Inform</source><year>2017</year><volume>21</volume><fpage>4</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1109/JBHI.2016.2636665</pub-id></mixed-citation></ref><ref id="CR216"><mixed-citation publication-type="other">Rengasamy D, Figueredo GP, Advanced T, Analysis D (2018) Deep learning approaches to aircraft maintenance, repair and overhaul: a review. In: 2018 21st International conference on intelligent transportation systems (ITSC) pp 150–153</mixed-citation></ref><ref id="CR217"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roberto</surname><given-names>J</given-names></name><name><surname>Solares</surname><given-names>A</given-names></name><name><surname>Elisa</surname><given-names>F</given-names></name><name><surname>Raimondi</surname><given-names>D</given-names></name><name><surname>Zhu</surname><given-names>Y</given-names></name><name><surname>Rahimian</surname><given-names>F</given-names></name><name><surname>Canoy</surname><given-names>D</given-names></name><name><surname>Tran</surname><given-names>J</given-names></name><name><surname>Catarina</surname><given-names>A</given-names></name><name><surname>Gomes</surname><given-names>P</given-names></name><name><surname>Payberah</surname><given-names>AH</given-names></name><name><surname>Zottoli</surname><given-names>M</given-names></name><name><surname>Nazarzadeh</surname><given-names>M</given-names></name><name><surname>Conrad</surname><given-names>N</given-names></name></person-group><article-title xml:lang="en">Deep learning for electronic health records: a comparative review of multiple deep neural architectures</article-title><source>J Biomed Inform</source><year>2020</year><volume>101</volume><fpage>103337</fpage><pub-id pub-id-type="doi">10.1016/j.jbi.2019.103337</pub-id></mixed-citation></ref><ref id="CR218"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russakovsky</surname><given-names>O</given-names></name><name><surname>Deng</surname><given-names>J</given-names></name><name><surname>Su</surname><given-names>H</given-names></name><name><surname>Krause</surname><given-names>J</given-names></name><name><surname>Satheesh</surname><given-names>S</given-names></name><name><surname>Ma</surname><given-names>S</given-names></name><name><surname>Huang</surname><given-names>Z</given-names></name><name><surname>Karpathy</surname><given-names>A</given-names></name><name><surname>Khosla</surname><given-names>A</given-names></name><name><surname>Bernstein</surname><given-names>M</given-names></name><name><surname>Berg</surname><given-names>AC</given-names></name><name><surname>Fei-Fei</surname><given-names>L</given-names></name></person-group><article-title xml:lang="en">ImageNet large scale visual recognition challenge</article-title><source>Int J Comput vis</source><year>2015</year><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3422482</pub-id><pub-id pub-id-type="doi">10.1007/s11263-015-0816-y</pub-id></mixed-citation></ref><ref id="CR219"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sabour</surname><given-names>S</given-names></name><name><surname>Frosst</surname><given-names>N</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><article-title xml:lang="en">Dynamic routing between capsules</article-title><source>Adv Neural Inform Processing Syst</source><year>2017</year><pub-id pub-id-type="doi">10.48550/arXiv.1710.09829</pub-id></mixed-citation></ref><ref id="CR220"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sahoo</surname><given-names>BB</given-names></name><name><surname>Jha</surname><given-names>R</given-names></name><name><surname>Singh</surname><given-names>A</given-names></name><name><surname>Kumar</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Long short-term memory (LSTM) recurrent neural network for low-flow hydrological time series forecasting</article-title><source>Acta Geophys</source><year>2019</year><pub-id pub-id-type="doi">10.1007/s11600-019-00330-1</pub-id></mixed-citation></ref><ref id="CR221"><mixed-citation publication-type="other">Sainath TN, Mohamed A, Kingsbury, B, Ramabhadran B, Watson IBMTJ, Heights Y (2013) Deep convolutional neural networks for LVCSR. In: Proceedings  acoustics, speech and signal processing pp 8614–8618</mixed-citation></ref><ref id="CR222"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samaniego</surname><given-names>E</given-names></name><name><surname>Anitescu</surname><given-names>C</given-names></name><name><surname>Goswami</surname><given-names>S</given-names></name><name><surname>Nguyen-Thanh</surname><given-names>VM</given-names></name><name><surname>Guo</surname><given-names>H</given-names></name><name><surname>Hamdia</surname><given-names>K</given-names></name><name><surname>Zhuang</surname><given-names>X</given-names></name><name><surname>Rabczuk</surname><given-names>T</given-names></name></person-group><article-title xml:lang="en">An energy approach to the solution of partial differential equations in computational mechanics via machine learning: concepts, implementation and applications</article-title><source>Comput Methods Appl Mech Eng</source><year>2020</year><volume>362</volume><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">4053094</pub-id><pub-id pub-id-type="doi">10.1016/j.cma.2019.112790</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1439.74466</pub-id></mixed-citation></ref><ref id="CR223"><mixed-citation publication-type="other">Saremi S, Mehrjou A, Schölkopf B, Hyvärinen A (2018) Deep energy estimator networks. <ext-link xlink:href="http://arxiv.org/abs/1805.08306" ext-link-type="uri">https://arXiv.1805.08306</ext-link></mixed-citation></ref><ref id="CR224"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scellier</surname><given-names>B</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Equilibrium propagation: bridging the gap between energy-based models and backpropagation</article-title><source>Front Comput Neurosci</source><year>2017</year><pub-id pub-id-type="doi">10.3389/fncom.2017.00024</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1474.68271</pub-id></mixed-citation></ref><ref id="CR225"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Deep learning in neural networks: an overview</article-title><source>Neural Netw</source><year>2015</year><volume>61</volume><fpage>85</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2014.09.003</pub-id></mixed-citation></ref><ref id="CR226"><mixed-citation publication-type="other">Schmidt U (2014) Shrinkage fields for effective image restoration. In: Proceedings of the IEEE conference on computer vision and pattern recognition <ext-link xlink:href="10.1109/CVPR.2014.349" ext-link-type="doi">https://doi.org/10.1109/CVPR.2014.349</ext-link></mixed-citation></ref><ref id="CR227"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sengupta</surname><given-names>S</given-names></name><name><surname>Basak</surname><given-names>S</given-names></name><name><surname>Saikia</surname><given-names>P</given-names></name><name><surname>Paul</surname><given-names>S</given-names></name><name><surname>Tsalavoutis</surname><given-names>V</given-names></name><name><surname>Atiah</surname><given-names>FD</given-names></name><name><surname>Ravi</surname><given-names>V</given-names></name><name><surname>Alan</surname><given-names>R</given-names></name><name><surname>Ii</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">A review of deep learning with special emphasis on architectures applications and recent trends</article-title><source>Knowledge-Based Syst</source><year>2020</year><volume>194</volume><pub-id pub-id-type="doi">10.1016/j.knosys.2020.105596</pub-id></mixed-citation></ref><ref id="CR228"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seo</surname><given-names>S</given-names></name><name><surname>Kim</surname><given-names>C</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Mo</surname><given-names>K</given-names></name><name><surname>Kang</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">Comparative study of deep learning-based sentiment classification</article-title><source>IEEE Access</source><year>2020</year><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2963426</pub-id></mixed-citation></ref><ref id="CR229"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shakya</surname><given-names>SR</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Zhou</surname><given-names>Z</given-names></name></person-group><article-title xml:lang="en">Comparative study of machine learning and deep learning architecture for human activity recognition using accelerometer data</article-title><source>Int J Mach Learn Comput</source><year>2018</year><pub-id pub-id-type="doi">10.18178/ijmlc.2018.8.6.748</pub-id></mixed-citation></ref><ref id="CR230"><mixed-citation publication-type="other">Shen Y, He X, Gao J, Deng L, Mesnil G (2014) A latent semantic model with convolutional-pooling structure for information retrieval. In: Proceedings of the 23rd ACM international conference on conference on information and knowledge management. pp 101–110</mixed-citation></ref><ref id="CR231"><mixed-citation publication-type="other">Shi T, Kang K, Choo J, Reddy CK (2018) Short-text topic modeling via non-negative matrix factorization enriched with local word-context correlations. In: The web conference 2018 - proceedings of the world wide web conference, WWW 2018. <ext-link xlink:href="10.1145/3178876.3186009" ext-link-type="doi">https://doi.org/10.1145/3178876.3186009</ext-link></mixed-citation></ref><ref id="CR232"><mixed-citation publication-type="other">Shoeibi A, Ghassemi N, Khodatars M, Jafari M, Hussain S, Alizadehsani R (2020) Application of deep learning techniques for automated detection of epileptic seizures: a Review.  <ext-link xlink:href="https://arXiv.org/2007.01276" ext-link-type="uri">https://arXiv.org/2007.01276</ext-link></mixed-citation></ref><ref id="CR233"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shrestha</surname><given-names>A</given-names></name></person-group><article-title xml:lang="en">Review of deep learning algorithms and architectures</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>53040</fpage><lpage>53065</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2912200</pub-id></mixed-citation></ref><ref id="CR234"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Si</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Roberts</surname><given-names>K</given-names></name></person-group><article-title xml:lang="en">Enhancing clinical concept extraction with contextual embeddings</article-title><source>J Am Med Informatics Assoc</source><year>2019</year><pub-id pub-id-type="doi">10.1093/jamia/ocz096</pub-id></mixed-citation></ref><ref id="CR235"><mixed-citation publication-type="other">Siami-Namini S, Tavakoli N, Namin AS (2019) The performance of LSTM and BiLSTM in forecasting time series. In: Proceedings - 2019 IEEE International conference on big data, big data. <ext-link xlink:href="10.1109/BigData47090.2019.9005997" ext-link-type="doi">https://doi.org/10.1109/BigData47090.2019.9005997</ext-link></mixed-citation></ref><ref id="CR236"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegelmann</surname><given-names>HT</given-names></name></person-group><article-title xml:lang="en">Computation beyond the turing limit</article-title><source>Science</source><year>1995</year><volume>80</volume><fpage>268</fpage><pub-id pub-id-type="doi">10.1126/science.268.5210.545</pub-id></mixed-citation></ref><ref id="CR237"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Signorelli</surname><given-names>CM</given-names></name></person-group><article-title xml:lang="en">Can computers become conscious and overcome humans?</article-title><source>Front Robot AI</source><year>2018</year><volume>5</volume><fpage>121</fpage><pub-id pub-id-type="doi">10.3389/frobt.2018.00121</pub-id></mixed-citation></ref><ref id="CR400"><mixed-citation publication-type="other">Socher R, Chen D, Manning CD, Ng AY (2013) Reasoning with neural tensor networks for knowledge base completion. Adv Neural Inf Proc Syst 1:e2</mixed-citation></ref><ref id="CR239"><mixed-citation publication-type="other">Sønderby CK, Caballero J, Theis L, Shi W, Huszár F (2017) Amortised map inference for image super-resolution. In: 5th international conference on learning representations, ICLR 2017 - conference track proceedings</mixed-citation></ref><ref id="CR240"><mixed-citation publication-type="other">Srivastava N, Salakhutdinov R (2014) Multimodal learning with deep Boltzmann machines. J Mach Learn Res 15</mixed-citation></ref><ref id="CR241"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sugiyama</surname><given-names>S</given-names></name></person-group><source>Human behavior and another kind in consciousness: emerging research and opportunities</source><year>2019</year><publisher-loc>Hershey</publisher-loc><publisher-name>IGI Global</publisher-name><pub-id pub-id-type="doi">10.4018/978-1-5225-8217-5</pub-id></mixed-citation></ref><ref id="CR242"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sui</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>M</given-names></name><name><surname>Lee</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Calhoun</surname><given-names>V</given-names></name></person-group><article-title xml:lang="en">Deep learning methods and applications in neuroimaging</article-title><source>J Neurosci Methods</source><year>2020</year><volume>339</volume><fpage>108718</fpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2020.108718</pub-id></mixed-citation></ref><ref id="CR243"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>P</given-names></name><name><surname>Hui</surname><given-names>C</given-names></name><name><surname>Bai</surname><given-names>N</given-names></name><name><surname>Yang</surname><given-names>S</given-names></name><name><surname>Wan</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>Q</given-names></name><name><surname>Zhao</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Revealing the characteristics of a novel bioflocculant and its flocculation performance in <italic>Microcystis aeruginosa</italic> removal</article-title><source>Sci Rep</source><year>2015</year><volume>5</volume><fpage>17465</fpage><pub-id pub-id-type="doi">10.1038/srep17465</pub-id></mixed-citation></ref><ref id="CR244"><mixed-citation publication-type="other">Sun X, Nasrabadi NM, Tran TD (2017) Supervised deep sparse coding networks.  <ext-link xlink:href="http://arxiv.org/abs/1701.08349" ext-link-type="uri">https://arXiv.org/1701.08349</ext-link></mixed-citation></ref><ref id="CR245"><mixed-citation publication-type="other">Sun B, Feng J, Saenko K (2016) Return of frustratingly easy domain adaptation. In: 30th AAAI conference on artificial intelligence, AAAI 2016</mixed-citation></ref><ref id="CR246"><mixed-citation publication-type="other">Sutskever I, Hinton G, Taylor G (2009) The recurrent temporal restricted boltzmann machine. In: Advances in neural information processing systems 21 - proceedings of the 2008 conference</mixed-citation></ref><ref id="CR247"><mixed-citation publication-type="other">Sutskever I, Vinyals O, Le QV (2014) Sequence to sequence learning with neural networks. In: Advances in neural information processing systems</mixed-citation></ref><ref id="CR248"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title xml:lang="en">Learning multilevel distributed representations for high-dimensional sequences</article-title><source>J Machine Learn Res.</source><year>2007</year><volume>2</volume><fpage>548</fpage><lpage>555</lpage></mixed-citation></ref><ref id="CR250"><mixed-citation publication-type="other">Szegedy C, Liu W, Jia Y, Sermanet P, Reed S, Anguelov D, Erhan D, Vanhoucke V, Rabinovich A (2015) Going deeper with convolutions. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp 1–9</mixed-citation></ref><ref id="CR251"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taherkhani</surname><given-names>A</given-names></name><name><surname>Cosma</surname><given-names>G</given-names></name><name><surname>McGinnity</surname><given-names>TM</given-names></name></person-group><article-title xml:lang="en">Deep-FS: A feature selection algorithm for deep Boltzmann machines</article-title><source>Neurocomputing</source><year>2018</year><volume>322</volume><fpage>22</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2018.09.040</pub-id></mixed-citation></ref><ref id="CR252"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tahmassebi</surname><given-names>A</given-names></name><name><surname>Gandomi</surname><given-names>AH</given-names></name><name><surname>Fong</surname><given-names>S</given-names></name><name><surname>Meyer-Baese</surname><given-names>A</given-names></name><name><surname>Foo</surname><given-names>SY</given-names></name></person-group><article-title xml:lang="en">Multi-stage optimization of a deep model: a case study on ground motion modeling</article-title><source>PLoS ONE</source><year>2018</year><volume>13</volume><pub-id pub-id-type="doi">10.1371/journal.pone.0203829</pub-id></mixed-citation></ref><ref id="CR253"><mixed-citation publication-type="other">Tahmassebi A, Gandomi AH, McCann I, Schulte MHJ, Goudriaan AE, Meyer-Baese A (2018b) Deep learning in medical imaging: Fmri big data analysis via convolutional neural networks. In: Proceedings of the practice and experience on advanced research computing. pp 1–4</mixed-citation></ref><ref id="CR254"><mixed-citation publication-type="other">Tahmassebi A, Ehtemami A, Mohebali B, Gandomi AH, Pinker K, Meyer-Baese A (2019) Big data analytics in medical imaging using deep learning. In: Big data: learning, analytics, and applications. international society for optics and photonics, p 109890E</mixed-citation></ref><ref id="CR255"><mixed-citation publication-type="other">Tahmassebi A, Martin J, Meyer-Baese A, Gandomi AH (2020) An interpretable deep learning framework for health monitoring systems: a case study of eye state detection using EEG Signals. In: 2020 IEEE symposium series on computational intelligence (SSCI). IEEE pp 211–218</mixed-citation></ref><ref id="CR256"><mixed-citation publication-type="other">Taigman Y, Polyak A, Wolf L (2017) Unsupervised cross-domain image generation. In: 5th international conference on learning representations, ICLR 2017 - conference track proceedings</mixed-citation></ref><ref id="CR257"><mixed-citation publication-type="other">Tandiya N, Jauhar A, Marojevic V, Reed JH (2018) Deep predictive coding neural network for rf anomaly detection in wireless networks. arXiv:2018.8403654. <ext-link xlink:href="10.1109/ICCW.2018.8403654" ext-link-type="doi">https://doi.org/10.1109/ICCW.2018.8403654</ext-link></mixed-citation></ref><ref id="CR258"><mixed-citation publication-type="other">Tang Y (2013) Deep learning using linear support vector machines. <ext-link xlink:href="https://arXiv.org/1306.0239" ext-link-type="uri">https://arXiv.org/1306.0239</ext-link></mixed-citation></ref><ref id="CR259"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>Z</given-names></name><name><surname>Yang</surname><given-names>J</given-names></name><name><surname>Pei</surname><given-names>Z</given-names></name><name><surname>Song</surname><given-names>X</given-names></name><name><surname>Ge</surname><given-names>B</given-names></name></person-group><article-title xml:lang="en">Multi-process training gan for identity-preserving face synthesis</article-title><source>IEEE Access</source><year>2019</year><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2930203</pub-id></mixed-citation></ref><ref id="CR260"><mixed-citation publication-type="other">Tavarone Raffaele,   Badino L (2018) Conditional-computation-based recurrent neural networks for computationally efficient acoustic modelling. Interspeech, pp 1274–1278</mixed-citation></ref><ref id="CR261"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Telikani</surname><given-names>A</given-names></name><name><surname>Gandomi</surname><given-names>AH</given-names></name><name><surname>Choo</surname><given-names>K-KR</given-names></name><name><surname>Shen</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">A cost-sensitive deep learning based approach for network traffic classification</article-title><source>IEEE Trans Netw Serv Manag</source><year>2021</year><volume>19</volume><issue>1</issue><fpage>661</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1109/TNSM.2021.3112283</pub-id></mixed-citation></ref><ref id="CR262"><mixed-citation publication-type="other">Tkachenko Y (2015) Autonomous CRM control via CLV approximation with deep reinforcement learning in discrete and continuous action space.  arXiv:1504.01840. <ext-link xlink:href="https://arXiv.org/1504.01840" ext-link-type="uri">https://arXiv.org/1504.01840</ext-link></mixed-citation></ref><ref id="CR263"><mixed-citation publication-type="other">Tompson J, Jain A, Lecun Y, Bregler C (2014) Joint training of a convolutional network and a graphical model for human pose estimation. 27:1–9 <ext-link xlink:href="https://arXiv.org/1406.2984" ext-link-type="uri">https://arXiv.org/1406.2984</ext-link></mixed-citation></ref><ref id="CR264"><mixed-citation publication-type="other">Trabelsi C, Bilaniuk O, Zhang Y, Serdyuk D, Subramanian S, Santos JF, Mehri S, Rostamzadeh N, Bengio, Y, Pal CJ (2018) Deep complex networks. In: 6th international conference on learning representations, ICLR 2018 - conference track proceedings</mixed-citation></ref><ref id="CR265"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tran</surname><given-names>SN</given-names></name><name><surname>Garcez</surname><given-names>ADA</given-names></name><name><surname>Weyde</surname><given-names>T</given-names></name><name><surname>Yin</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>Q</given-names></name><name><surname>Karunanithi</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Sequence classification restricted boltzmann machines with gated units</article-title><source>IEEE Trans Neural Networks Learn Syst</source><year>2020</year><volume>31</volume><fpage>4806</fpage><lpage>4815</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">4169992</pub-id><pub-id pub-id-type="doi">10.1109/TNNLS.2019.2958103</pub-id></mixed-citation></ref><ref id="CR266"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tzafestas</surname><given-names>SG</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Tzafestas</surname><given-names>SG</given-names></name></person-group><article-title xml:lang="en">Mobile robot control IV: fuzzy and neural methods</article-title><source>Introduction to mobile robot control</source><year>2014</year><publisher-loc>Oxford</publisher-loc><publisher-name>Elsevier</publisher-name><fpage>269</fpage><lpage>317</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-417049-0.00008-0</pub-id></mixed-citation></ref><ref id="CR267"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uddin</surname><given-names>MZ</given-names></name><name><surname>Hassan</surname><given-names>MM</given-names></name><name><surname>Alsanad</surname><given-names>A</given-names></name><name><surname>Savaglio</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">A body sensor data fusion and deep recurrent neural network-based behavior recognition approach for robust healthcare</article-title><source>Inf Fusion</source><year>2020</year><pub-id pub-id-type="doi">10.1016/j.inffus.2019.08.004</pub-id></mixed-citation></ref><ref id="CR268"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Gysel</surname><given-names>C</given-names></name><name><surname>De Rijke</surname><given-names>M</given-names></name><name><surname>Kanoulas</surname><given-names>E</given-names></name></person-group><article-title xml:lang="en">Neural vector spaces for unsupervised information retrieval</article-title><source>ACM Trans Inf Syst</source><year>2018</year><pub-id pub-id-type="doi">10.1145/3196826</pub-id></mixed-citation></ref><ref id="CR269"><mixed-citation publication-type="other">Vargas R, Mosavi A, Ruiz R (2017) Deep learning: a review. Adv Intell Syst Comput</mixed-citation></ref><ref id="CR270"><mixed-citation publication-type="other">Vaswani A (2017) Attention is all you need . Adv Neural Inf Process Syst 2017 pp 5999–6009 <ext-link xlink:href="http://arxiv.org/abs/1706.03762v5" ext-link-type="uri">arXiv:1706.03762v5</ext-link></mixed-citation></ref><ref id="CR271"><mixed-citation publication-type="other">Vazhayil A, Vinayakumar R, Soman K (2018) Comparative study of the detection of malicious URLs using shallow and deep networks. In: 2018 9th international conference on computing, communication and networking technologies, ICCCNT 2018. <ext-link xlink:href="10.1109/ICCCNT.2018.8494159" ext-link-type="doi">https://doi.org/10.1109/ICCCNT.2018.8494159</ext-link></mixed-citation></ref><ref id="CR272"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vincent</surname><given-names>P</given-names></name></person-group><article-title xml:lang="en">A connection between scorematching and denoising autoencoders</article-title><source>Neural Comput</source><year>2011</year><volume>23</volume><fpage>1661</fpage><lpage>1674</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">2839543</pub-id><pub-id pub-id-type="doi">10.1162/NECO_a_00142</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1218.68133</pub-id></mixed-citation></ref><ref id="CR275"><mixed-citation publication-type="other">Wang J Yu LC, Lai KR, Zhang X (2016a) Dimensional sentiment analysis using a regional CNN-LSTM model. In: 54th Annual meeting of the association for computational linguistics, ACL 2016 - Short Papers. <ext-link xlink:href="10.18653/v1/p16-2037" ext-link-type="doi">https://doi.org/10.18653/v1/p16-2037</ext-link></mixed-citation></ref><ref id="CR273"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Fang</surname><given-names>W</given-names></name><name><surname>Niu</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">Financial time series prediction using elman recurrent random neural networks</article-title><source>Comput Intell Neurosci</source><year>2016</year><pub-id pub-id-type="doi">10.1155/2016/4742515</pub-id></mixed-citation></ref><ref id="CR276"><mixed-citation publication-type="other">Wang X, Jiang, W, Luo Z (2016c) Combination of convolutional and recurrent neural network for sentiment analysis of short texts. In: COLING 2016 - 26th international conference on computational linguistics, proceedings of COLING 2016: technical papers</mixed-citation></ref><ref id="CR274"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>D</given-names></name><name><surname>Liang</surname><given-names>Y</given-names></name><name><surname>Xu</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">Capsule network for protein post-translational modification site prediction</article-title><source>Bioinformatics</source><year>2019</year><pub-id pub-id-type="doi">10.1093/bioinformatics/bty977</pub-id></mixed-citation></ref><ref id="CR277"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>Q</given-names></name><name><surname>Kasabov</surname><given-names>N</given-names></name><name><surname>Polycarpou</surname><given-names>M</given-names></name><name><surname>Zeng</surname><given-names>Z</given-names></name></person-group><article-title xml:lang="en">Deep learning neural networks: methods, systems, and applications</article-title><source>Neurocomputing</source><year>2019</year><pub-id pub-id-type="doi">10.1016/j.neucom.2019.03.073</pub-id></mixed-citation></ref><ref id="CR278"><mixed-citation publication-type="other">Wieslander H, Forslid G, Bengtsson E, Wahlby C, Hirsch J-M, Stark CR, Sadanandan SK (2017) Deep convolutional neural networks for detecting cellular changes due to malignancy. In: Proceedings of the IEEE international conference on computer vision workshops pp 82–89</mixed-citation></ref><ref id="CR279"><mixed-citation publication-type="other">Wu Y, Guo Y (2020) Dual adversarial co-learning for multi-domain text classification. In: AAAI 2020 - 34th AAAI Conference artificial intelligence, pp 6438–6445. <ext-link xlink:href="10.1609/aaai.v34i04.6115" ext-link-type="doi">https://doi.org/10.1609/aaai.v34i04.6115</ext-link></mixed-citation></ref><ref id="CR280"><mixed-citation publication-type="other">Wu H, Soraghan J, Lowit A, Di Caterina G (2018) A deep learning method for pathological voice detection using convolutional deep belief network. In: Proceedings of the annual conference of the international speech communication association, INTERSPEECH. <ext-link xlink:href="10.21437/Interspeech.2018-1351" ext-link-type="doi">https://doi.org/10.21437/Interspeech.2018-1351</ext-link></mixed-citation></ref><ref id="CR281"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiang</surname><given-names>C</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Tang</surname><given-names>Y</given-names></name><name><surname>Zou</surname><given-names>W</given-names></name><name><surname>Xu</surname><given-names>C</given-names></name></person-group><article-title xml:lang="en">MS-capsnet: a novel multi-scale capsule network</article-title><source>IEEE Signal Process Lett</source><year>2018</year><volume>25</volume><fpage>1850</fpage><lpage>1854</lpage><pub-id pub-id-type="doi">10.1109/LSP.2018.2873892</pub-id></mixed-citation></ref><ref id="CR282"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>C</given-names></name><name><surname>Choi</surname><given-names>E</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Review Opportunities and challenges in developing deep learning models using electronic health records data: a systematic review</article-title><source>J Am Med Informatics Assoc</source><year>2018</year><volume>25</volume><fpage>1419</fpage><lpage>1428</lpage><pub-id pub-id-type="doi">10.1093/jamia/ocy068</pub-id></mixed-citation></ref><ref id="CR283"><mixed-citation publication-type="other">Xiong HY, Alipanahi B, Lee LJ, Bretschneider H, Yuen RKC, Hua Y, Gueroussov S, Hamed S, Hughes TR, Morris Q, Barash Y, Adrian R, Jojic N, Scherer SW, Blencowe BJ (2015) The human splicing code reveals new insights into the genetic determinants of disease. Science 347(6218):1254806. <ext-link xlink:href="10.1126/science.1254806" ext-link-type="doi">https://doi.org/10.1126/science.1254806</ext-link></mixed-citation></ref><ref id="CR284"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Understanding graph embedding methods and their applications</article-title><source>SIAM Rev</source><year>2020</year><volume>63</volume><issue>4</issue><fpage>825</fpage><lpage>853</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">4334532</pub-id><pub-id pub-id-type="doi">10.1137/20M1386062</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">07421047</pub-id></mixed-citation></ref><ref id="CR285"><mixed-citation publication-type="other">Xu T, Zhang P, Huang Q, Zhang H, Gan Z, Huang X, He X (2018) AttnGAN: fine-grained text to image generation with attentional generative adversarial networks. In: Proceedings of the IEEE computer society conference on computer vision and pattern recognition. <ext-link xlink:href="10.1109/CVPR.2018.00143" ext-link-type="doi">https://doi.org/10.1109/CVPR.2018.00143</ext-link></mixed-citation></ref><ref id="CR286"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>WY</given-names></name><name><surname>Shaker</surname><given-names>A</given-names></name><name><surname>El-Ashmawy</surname><given-names>N</given-names></name></person-group><article-title xml:lang="en">Urban land cover classification using airborne LiDAR data: a review</article-title><source>Remote Sens Environ</source><year>2015</year><pub-id pub-id-type="doi">10.1016/j.rse.2014.11.001</pub-id></mixed-citation></ref><ref id="CR287"><mixed-citation publication-type="other">Yan Y, Guo Y (2020) Multi-level generative models for partial label learning with non-random label noise. <ext-link xlink:href="10.24963/ijcai.2021/449" ext-link-type="doi">https://doi.org/10.24963/ijcai.2021/449</ext-link></mixed-citation></ref><ref id="CR288"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>Z</given-names></name><name><surname>Yu</surname><given-names>W</given-names></name><name><surname>Liang</surname><given-names>P</given-names></name><name><surname>Guo</surname><given-names>H</given-names></name><name><surname>Xia</surname><given-names>L</given-names></name><name><surname>Zhang</surname><given-names>F</given-names></name><name><surname>Ma</surname><given-names>Y</given-names></name><name><surname>Ma</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Deep transfer learning for military object recognition under small training set condition</article-title><source>Neural Comput Appl</source><year>2019</year><volume>31</volume><fpage>6469</fpage><lpage>6478</lpage><pub-id pub-id-type="doi">10.1007/s00521-018-3468-3</pub-id></mixed-citation></ref><ref id="CR289"><mixed-citation publication-type="other">Yang B, Yih W tau, He X, Gao J, Deng L (2015) Embedding entities and relations for learning and inference in knowledge bases. In: 3rd international conference on learning representations, ICLR 2015 - conference track proceedings</mixed-citation></ref><ref id="CR290"><mixed-citation publication-type="other">Yang D, Qu B, Yang J, Cudre-Mauroux P (2019) Revisiting user mobility and social relationships in LBSNs: a hypergraph embedding approach. In: The web conference 2019 - proceedings of the world wide web conference, WWW 2019. <ext-link xlink:href="10.1145/3308558.3313635" ext-link-type="doi">https://doi.org/10.1145/3308558.3313635</ext-link></mixed-citation></ref><ref id="CR291"><mixed-citation publication-type="other">Yao T, Pan Y, Li Y, Mei T (2017) Incorporating copying mechanism in image captioning for learning novel objects. In: Proceedings - 30th IEEE conference on computer vision and pattern recognition, CVPR 2017. <ext-link xlink:href="10.1109/CVPR.2017.559" ext-link-type="doi">https://doi.org/10.1109/CVPR.2017.559</ext-link></mixed-citation></ref><ref id="CR292"><mixed-citation publication-type="other">Ye M, Peng X, Gan W, Wu W, Qiao Y (2019) AnoPCN: video anomaly detection via deep predictive coding network. In:  MM 2019 - Proceedings 27th ACM international conference multimedia 1805–1813. <ext-link xlink:href="10.1145/3343031.3350899" ext-link-type="doi">https://doi.org/10.1145/3343031.3350899</ext-link></mixed-citation></ref><ref id="CR293"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Y</given-names></name><name><surname>Si</surname><given-names>X</given-names></name><name><surname>Hu</surname><given-names>C</given-names></name><name><surname>Zhang</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">A review of recurrent neural networks: LSTM cells and network architectures</article-title><source>Neural Comput</source><year>2019</year><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3988464</pub-id><pub-id pub-id-type="doi">10.1162/neco_a_01199</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1494.68236</pub-id></mixed-citation></ref><ref id="CR294"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zeiler</surname><given-names>MD</given-names></name><name><surname>Fergus</surname><given-names>R</given-names></name></person-group><article-title xml:lang="en">Visualizing and understanding convolutional networks</article-title><source>European conference on computer vision</source><year>2014</year><publisher-loc>Cham</publisher-loc><publisher-name>Springer</publisher-name><fpage>818</fpage><lpage>833</lpage></mixed-citation></ref><ref id="CR295"><mixed-citation publication-type="other">Zeng Z, Xiao S, Jia K, Chan TH, Gao S, Xu D, Ma Y (2013) Learning by associating ambiguously labeled images. In: Proceedings of the IEEE computer society conference on computer vision and pattern recognition. <ext-link xlink:href="10.1109/CVPR.2013.97" ext-link-type="doi">https://doi.org/10.1109/CVPR.2013.97</ext-link></mixed-citation></ref><ref id="CR296"><mixed-citation publication-type="other">Zeroual A, Harrou F, Dairi A, Sun Y (2020) Deep learning methods for forecasting COVID-19 time-series data: a comparative study. Chaos, Solitons Fractals 140:110121. <ext-link xlink:href="10.1016/j.chaos.2020.110121" ext-link-type="doi">https://doi.org/10.1016/j.chaos.2020.110121</ext-link></mixed-citation></ref><ref id="CR297"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>D</given-names></name><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Su</surname><given-names>Z</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Chinese comments sentiment classification based on word2vec and SVMperf</article-title><source>Expert Syst Appl</source><year>2015</year><pub-id pub-id-type="doi">10.1016/j.eswa.2014.09.011</pub-id></mixed-citation></ref><ref id="CR298"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Bengio</surname><given-names>S</given-names></name><name><surname>Hardt</surname><given-names>M</given-names></name><name><surname>Recht</surname><given-names>B</given-names></name><name><surname>Vinyals</surname><given-names>O</given-names></name></person-group><article-title xml:lang="en">Understanding deep learning requires rethinking generalization</article-title><source>Commun ACM</source><year>2016</year><volume>64</volume><fpage>107</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1145/3446776</pub-id></mixed-citation></ref><ref id="CR304"><mixed-citation publication-type="other">Zhang L, Lin L, Liang X, He K (2016b) Is faster R-CNN doing well for pedestrian detection?. In: Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics). <ext-link xlink:href="10.1007/978-3-319-46475-6_28" ext-link-type="doi">https://doi.org/10.1007/978-3-319-46475-6_28</ext-link></mixed-citation></ref><ref id="CR299"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>B</given-names></name><name><surname>Xiong</surname><given-names>D</given-names></name><name><surname>Su</surname><given-names>J</given-names></name><name><surname>Duan</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">A context-aware recurrent encoder for neural machine translation</article-title><source>IEEE/ACM Trans Audio Speech Lang Process</source><year>2017</year><volume>25</volume><fpage>12</fpage><pub-id pub-id-type="doi">10.1109/TASLP.2017.2751420</pub-id></mixed-citation></ref><ref id="CR300"><mixed-citation publication-type="other">Zhang H, Xu T, Li H, Zhang S, Wang X, Huang X, Metaxas D (2017b) StackGAN: text to photo-realistic image synthesis with stacked generative adversarial networks. In: Proceedings of the IEEE international conference on computer vision. <ext-link xlink:href="10.1109/ICCV.2017.629" ext-link-type="doi">https://doi.org/10.1109/ICCV.2017.629</ext-link></mixed-citation></ref><ref id="CR301"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>J</given-names></name><name><surname>Tao</surname><given-names>X</given-names></name><name><surname>Gong</surname><given-names>Y</given-names></name><name><surname>Zheng</surname><given-names>N</given-names></name></person-group><article-title xml:lang="en">Constructing deep sparse coding network for image classification</article-title><source>Pattern Recognit</source><year>2017</year><volume>64</volume><fpage>130</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/j.patcog.2016.10.032</pub-id></mixed-citation></ref><ref id="CR302"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Yao</surname><given-names>L</given-names></name><name><surname>Sun</surname><given-names>A</given-names></name><name><surname>Tay</surname><given-names>Y</given-names></name></person-group><article-title xml:lang="en">Deep learning based recommender system: a survey and new perspectives</article-title><source>ACM Comput Surv</source><year>2019</year><pub-id pub-id-type="doi">10.1145/3285029</pub-id></mixed-citation></ref><ref id="CR303"><mixed-citation publication-type="other">Zhang J, Lei YK, Zhang Z, Chang J, Li M, Han X, Yang L, Yang YI, Gao YQ (2020) A perspective on deep learning for molecular modeling and simulations. J Phys Chem A 124(34):6745–6763. <ext-link xlink:href="10.1021/acs.jpca.0c04473" ext-link-type="doi">https://doi.org/10.1021/acs.jpca.0c04473</ext-link></mixed-citation></ref><ref id="CR307"><mixed-citation publication-type="other">Zhao Y, Liu Z, Sun M (2015) Phrase type sensitive tensor indexing model for semantic composition. In: Proceedings of the national conference on artificial intelligence</mixed-citation></ref><ref id="CR305"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Z</given-names></name><name><surname>Jiao</surname><given-names>L</given-names></name><name><surname>Zhao</surname><given-names>J</given-names></name><name><surname>Gu</surname><given-names>J</given-names></name><name><surname>Zhao</surname><given-names>J</given-names></name></person-group><article-title xml:lang="en">Discriminant deep belief network for high-resolution SAR image classification</article-title><source>Pattern Recognit</source><year>2017</year><volume>61</volume><fpage>686</fpage><lpage>701</lpage><pub-id pub-id-type="doi">10.1016/j.patcog.2016.05.028</pub-id></mixed-citation></ref><ref id="CR306"><mixed-citation publication-type="other">Zhao H, Chen Z, Jiang H, Jing W, Sun L, Feng M (2019) Evaluation of three deep learning models for early crop classification using Sentinel-1A imagery time series-a case study in Zhanjiang. China Remote Sens 11(22):2673. <ext-link xlink:href="10.3390/rs11222673" ext-link-type="doi">https://doi.org/10.3390/rs11222673</ext-link></mixed-citation></ref><ref id="CR308"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhong</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Luo</surname><given-names>Z</given-names></name><name><surname>Chapman</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">Spectral-spatial residual network for hyperspectral image classification: a 3-D deep learning framework</article-title><source>IEEE Trans Geosci Remote Sens</source><year>2018</year><volume>56</volume><issue>2</issue><fpage>847</fpage><lpage>858</lpage><pub-id pub-id-type="doi">10.1109/TGRS.2017.2755542</pub-id></mixed-citation></ref><ref id="CR309"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>G</given-names></name><name><surname>Xie</surname><given-names>Z</given-names></name><name><surname>He</surname><given-names>T</given-names></name><name><surname>Zhao</surname><given-names>J</given-names></name><name><surname>Hu</surname><given-names>XT</given-names></name></person-group><article-title xml:lang="en">Learning the multilingual translation representations for question retrieval in community question answering via non-negative matrix factorization</article-title><source>IEEE/ACM Trans Audio Speech Lang Process</source><year>2016</year><volume>5</volume><fpage>5</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1109/TASLP.2016.2544661</pub-id></mixed-citation></ref><ref id="CR310"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>S</given-names></name><name><surname>Mumford</surname><given-names>D</given-names></name></person-group><article-title xml:lang="en">A stochastic grammar of images a stochastic grammar of images</article-title><source>Found Trends Comput Graph Vis</source><year>2006</year><volume>2</volume><issue>4</issue><fpage>2</fpage><pub-id pub-id-type="doi">10.1561/0600000018</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1198.68160</pub-id></mixed-citation></ref><ref id="CR311"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>Z</given-names></name><name><surname>Peng</surname><given-names>G</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Gao</surname><given-names>H</given-names></name></person-group><article-title xml:lang="en">A convolutional neural network based on a capsule network with strong generalization for bearing fault diagnosis</article-title><source>Neurocomputing</source><year>2019</year><pub-id pub-id-type="doi">10.1016/j.neucom.2018.09.050</pub-id></mixed-citation></ref><ref id="CR312"><mixed-citation publication-type="other">Ziebart BD, Fox D (2010) Modeling purposeful adaptive behavior with the principle of maximum causal entropy. Carnegie Mellon University</mixed-citation></ref><ref id="CR313"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zulqarnain</surname><given-names>M</given-names></name><name><surname>Ghazali</surname><given-names>R</given-names></name><name><surname>Mazwin</surname><given-names>Y</given-names></name><name><surname>Hassim</surname><given-names>M</given-names></name><name><surname>Rehan</surname><given-names>M</given-names></name></person-group><article-title xml:lang="en">A comparative review on deep learning models for text classification</article-title><source>Indones J Electr Eng Comput Sci</source><year>2020</year><volume>19</volume><fpage>325</fpage><lpage>335</lpage><pub-id pub-id-type="doi">10.11591/ijeecs.v19.i1.pp325-335</pub-id></mixed-citation></ref></ref-list></ref-list><notes notes-type="Misc"><title>Publisher's Note</title><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Artificial Intelligence</facet-value><facet-value count="1">Computer Science</facet-value><facet-value count="1">Computer Science, general</facet-value></facet><facet name="keyword"><facet-value count="1">Autoencoders</facet-value><facet-value count="1">Boltzmann machine</facet-value><facet-value count="1">Deep belief network</facet-value><facet-value count="1">Deep learning</facet-value><facet-value count="1">Deep learning architecture</facet-value><facet-value count="1">Neural network</facet-value></facet><facet name="pub"><facet-value count="1">Artificial Intelligence Review</facet-value></facet><facet name="year"><facet-value count="1">2023</facet-value></facet><facet name="country"><facet-value count="1">Australia</facet-value><facet-value count="1">Bangladesh</facet-value><facet-value count="1">Canada</facet-value><facet-value count="1">Fiji</facet-value><facet-value count="1">Hungary</facet-value><facet-value count="1">Saudi Arabia</facet-value><facet-value count="1">Thailand</facet-value><facet-value count="1">United Kingdom</facet-value><facet-value count="1">United States</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
