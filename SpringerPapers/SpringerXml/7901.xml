<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="/resources/spdi-openaccess-jats.xsl"?>
<!DOCTYPE response [
	
<!ENTITY % article SYSTEM "http://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<!ENTITY % book-part-wrapper SYSTEM "http://jats.nlm.nih.gov/extensions/bits/2.0/BITS-book2.dtd">
	]><response><apiMessage>This XML was provided by Springer Nature</apiMessage><query>doi:10.1007/s44267-023-00006-x</query><apiKey>87ba7cb21f89ce78154df796840621f4</apiKey><result><total>1</total><start>1</start><pageLength>2</pageLength><recordsDisplayed>1</recordsDisplayed></result><records><article dtd-version="1.2" article-type="review-article" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">44267</journal-id><journal-title-group><journal-title>Visual Intelligence</journal-title><abbrev-journal-title abbrev-type="publisher">Vis. Intell.</abbrev-journal-title></journal-title-group><issn pub-type="epub">2731-9008</issn><publisher><publisher-name>Springer Nature Singapore</publisher-name><publisher-loc>Singapore</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">s44267-023-00006-x</article-id><article-id pub-id-type="manuscript">6</article-id><article-id pub-id-type="doi">10.1007/s44267-023-00006-x</article-id><article-categories><subj-group subj-group-type="heading"><subject>Review</subject></subj-group></article-categories><title-group><article-title xml:lang="en">Modular design automation of the morphologies, controllers, and vision systems for intelligent robots: a survey</article-title></title-group><contrib-group><contrib contrib-type="author" id="Au1"><name><surname>Li</surname><given-names>Wenji</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au2"><name><surname>Wang</surname><given-names>Zhaojun</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au3"><name><surname>Mai</surname><given-names>Ruitao</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au4"><name><surname>Ren</surname><given-names>Pengxiang</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au5"><name><surname>Zhang</surname><given-names>Qinchang</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au6"><name><surname>Zhou</surname><given-names>Yutao</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au7"><name><surname>Xu</surname><given-names>Ning</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au8"><name><surname>Zhuang</surname><given-names>JiaFan</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" id="Au9"><name><surname>Xin</surname><given-names>Bin</given-names></name><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author" id="Au10"><name><surname>Gao</surname><given-names>Liang</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author" id="Au11"><name><surname>Hao</surname><given-names>Zhifeng</given-names></name><xref ref-type="aff" rid="Aff5">5</xref></contrib><contrib contrib-type="author" corresp="yes" id="Au12"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4232-8229</contrib-id><name><surname>Fan</surname><given-names>Zhun</given-names></name><address><email>zfan@stu.edu.cn</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="corresp" rid="IDs4426702300006x_cor12">n</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution content-type="org-name">International Cooperation Base of Evolutionary Intelligence and Robotics</institution></institution-wrap><addr-line content-type="city">Shantou</addr-line><addr-line content-type="state">Guangdong</addr-line><country country="CN">China</country></aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.263451.7</institution-id><institution-id institution-id-type="ISNI">0000 0000 9927 110X</institution-id><institution content-type="org-division">Department of Electronic Information Engineering</institution><institution content-type="org-name">Shantou University</institution></institution-wrap><addr-line content-type="postcode">515063</addr-line><addr-line content-type="city">Shantou</addr-line><country country="CN">China</country></aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.43555.32</institution-id><institution-id institution-id-type="ISNI">0000 0000 8841 6246</institution-id><institution content-type="org-division">School of Automation</institution><institution content-type="org-name">Beijing Institute of Technology</institution></institution-wrap><addr-line content-type="postcode">100081</addr-line><addr-line content-type="city">Beijing</addr-line><country country="CN">China</country></aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.33199.31</institution-id><institution-id institution-id-type="ISNI">0000 0004 0368 7223</institution-id><institution content-type="org-division">School of Mechanical Science &amp; Engineering</institution><institution content-type="org-name">HUST, Huazhong University of Science and Technology</institution></institution-wrap><addr-line content-type="postcode">430074</addr-line><addr-line content-type="city">Wuhan</addr-line><country country="CN">China</country></aff><aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.263451.7</institution-id><institution-id institution-id-type="ISNI">0000 0000 9927 110X</institution-id><institution content-type="org-division">College of Science</institution><institution content-type="org-name">Shantou University</institution></institution-wrap><addr-line content-type="postcode">515063</addr-line><addr-line content-type="city">Shantou</addr-line><country country="CN">China</country></aff></contrib-group><author-notes><corresp id="IDs4426702300006x_cor12"><label>n</label><email>zfan@stu.edu.cn</email></corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>8</day><month>5</month><year>2023</year></pub-date><pub-date date-type="collection" publication-format="electronic"><month>12</month><year>2023</year></pub-date><volume>1</volume><issue seq="2">1</issue><elocation-id>2</elocation-id><history><date date-type="registration"><day>4</day><month>4</month><year>2023</year></date><date date-type="received"><day>1</day><month>11</month><year>2022</year></date><date date-type="rev-recd"><day>29</day><month>12</month><year>2022</year></date><date date-type="accepted"><day>1</day><month>3</month><year>2023</year></date><date date-type="online"><day>8</day><month>5</month><year>2023</year></date></history><permissions><copyright-statement content-type="compact">© The Author(s) 2023</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xlink:href="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract xml:lang="en" id="Abs1"><title>Abstract</title><p id="Par1">Design automation is a core technology in industrial design software and an important branch of knowledge-worker automation. For example, electronic design automation (EDA) has played an important role in both academia and industry. Design automation for intelligent robots refers to the construction of unified modular graph models for the morphologies (body), controllers (brain), and vision systems (eye) of intelligent robots under digital twin architectures, which effectively supports the automation of the morphology, controller, and vision system design processes of intelligent robots by taking advantage of the powerful capabilities of genetic programming, evolutionary computation, deep learning, reinforcement learning, and causal reasoning in model representation, optimization, perception, decision making, and reasoning. Compared with traditional design methods, MOdular DEsigN Automation (MODENA) methods can significantly improve the design efficiency and performance of robots, effectively avoiding the repetitive trial-and-error processes of traditional design methods, and promoting automatic discovery of innovative designs. Thus, it is of considerable research significance to study MODENA methods for intelligent robots. To this end, this paper provides a systematic and comprehensive overview of applying MODENA in intelligent robots, analyzes the current problems and challenges in the field, and provides an outlook for future research. First, the design automation for the robot morphologies and controllers is reviewed, individually, with automated design of control strategies for swarm robots also discussed, which has emerged as a prominent research focus recently. Next, the integrated design automation of both the morphologies and controllers for robotic systems is presented. Then, the design automation of the vision systems of intelligent robots is summarized when vision systems have become one of the most important modules for intelligent robotic systems. Then, the future research trends of integrated “Body-Brain-Eye” design automation for intelligent robots are discussed. Finally, the common key technologies, research challenges and opportunities in MODENA for intelligent robots are summarized.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Modular design automation</kwd><kwd>Intelligent robots</kwd><kwd>Bond graph</kwd><kwd>Evolutionary computation</kwd><kwd>Neural architecture search</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution>Science and Technology Special Funds Project of Guangdong Province of China</institution></institution-wrap></funding-source><award-id award-type="FundRef grant">STKJ2021176</award-id><award-id award-type="FundRef grant">STKJ2021019</award-id><principal-award-recipient><name><surname>Li</surname><given-names>Wenji</given-names></name></principal-award-recipient><principal-award-recipient><name><surname>Hao</surname><given-names>Zhifeng</given-names></name></principal-award-recipient></award-group><award-group><funding-source><institution-wrap><institution>National Key R&amp;D Program of China</institution></institution-wrap></funding-source><award-id award-type="FundRef grant">2021ZD0111501</award-id><principal-award-recipient><name><surname>Fan</surname><given-names>Zhun</given-names></name></principal-award-recipient></award-group><award-group><funding-source><institution-wrap><institution>National Natural Science Foundation of China</institution><institution-id institution-id-type="doi" vocab="open-funder-registry">http://dx.doi.org/10.13039/501100001809</institution-id></institution-wrap></funding-source><award-id award-type="FundRef grant">62176147</award-id><principal-award-recipient><name><surname>Fan</surname><given-names>Zhun</given-names></name></principal-award-recipient></award-group><award-group><funding-source><institution-wrap><institution>Science and Technology Planning Project of Guangdong Province of China</institution></institution-wrap></funding-source><award-id award-type="FundRef grant">2021A0505030072</award-id><award-id award-type="FundRef grant">2022A1515110660</award-id><principal-award-recipient><name><surname>Fan</surname><given-names>Zhun</given-names></name></principal-award-recipient><principal-award-recipient><name><surname>Li</surname><given-names>Wenji</given-names></name></principal-award-recipient></award-group><award-group><funding-source><institution-wrap><institution>STU Scientific Research Foundation for Talents</institution></institution-wrap></funding-source><award-id award-type="FundRef grant">NTF21001</award-id><award-id award-type="FundRef grant">NTF22030</award-id><principal-award-recipient><name><surname>Li</surname><given-names>Wenji</given-names></name></principal-award-recipient><principal-award-recipient><name><surname>Zhuang</surname><given-names>JiaFan</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>publisher-imprint-name</meta-name><meta-value>Springer</meta-value></custom-meta><custom-meta><meta-name>volume-issue-count</meta-name><meta-value>1</meta-value></custom-meta><custom-meta><meta-name>issue-article-count</meta-name><meta-value>2</meta-value></custom-meta><custom-meta><meta-name>issue-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>issue-pricelist-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-holder</meta-name><meta-value>The Author(s)</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>article-contains-esm</meta-name><meta-value>No</meta-value></custom-meta><custom-meta><meta-name>article-numbering-style</meta-name><meta-value>ContentOnly</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-year</meta-name><meta-value>2023</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-month</meta-name><meta-value>4</meta-value></custom-meta><custom-meta><meta-name>article-registration-date-day</meta-name><meta-value>4</meta-value></custom-meta><custom-meta><meta-name>article-toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>toc-levels</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>volume-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>journal-product</meta-name><meta-value>ArchiveJournal</meta-value></custom-meta><custom-meta><meta-name>numbering-style</meta-name><meta-value>ContentOnly</meta-value></custom-meta><custom-meta><meta-name>article-grants-type</meta-name><meta-value>OpenChoice</meta-value></custom-meta><custom-meta><meta-name>metadata-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>abstract-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodypdf-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bodyhtml-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>bibliography-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>esm-grant</meta-name><meta-value>OpenAccess</meta-value></custom-meta><custom-meta><meta-name>online-first</meta-name><meta-value>false</meta-value></custom-meta><custom-meta><meta-name>pdf-file-reference</meta-name><meta-value>BodyRef/PDF/44267_2023_Article_6.pdf</meta-value></custom-meta><custom-meta><meta-name>pdf-type</meta-name><meta-value>Typeset</meta-value></custom-meta><custom-meta><meta-name>target-type</meta-name><meta-value>OnlinePDF</meta-value></custom-meta><custom-meta><meta-name>issue-type</meta-name><meta-value>Regular</meta-value></custom-meta><custom-meta><meta-name>article-type</meta-name><meta-value>ReviewPaper</meta-value></custom-meta><custom-meta><meta-name>journal-subject-primary</meta-name><meta-value>Computer Science</meta-value></custom-meta><custom-meta><meta-name>journal-subject-secondary</meta-name><meta-value>Artificial Intelligence</meta-value></custom-meta><custom-meta><meta-name>journal-subject-collection</meta-name><meta-value>Computer Science</meta-value></custom-meta><custom-meta><meta-name>open-access</meta-name><meta-value>true</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Robots are widely used in industrial manufacturing, agricultural production, services, and defense to help people perform repetitive, heavy, or dangerous tasks [<xref ref-type="bibr" rid="CR1">1</xref>]. However, in the case of complex and dynamic tasks and environments, robots without intelligence are unable to respond to changes in a correct and timely manner. Therefore, empowering robots with intelligence constitutes an important research trend [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>]. Intelligent robots combine artificial intelligence (AI) technology with robotics to produce an autonomous system with intelligence. These systems can learn and respond to dynamic requirements and environmental changes via machine learning, image recognition, target detection, and other AI techniques, rather than simply executing pre-defined commands. The main modules that affect how a robot functions as an intelligent machine include the morphology, the controller, and the vision perception system, which are analogous to the human body, brain, and eyes, respectively. Therefore, in the design automation of intelligent robotic systems, our work aims at developing an automated design methodology for the “Body-Brain-Eye” of intelligent robots.</p><p id="Par3">With the emergence of advanced technologies such as deep learning, evolutionary computing, machine learning, intelligent control, and robotics, the study of design automation for intelligent robots has received significant attention from scholars [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>], which is also considered to be an important branch of knowledge-worker automation [<xref ref-type="bibr" rid="CR6">6</xref>]. In this paper, we systematically provide a detailed explanation of the main concept of modular design automation. In general, modular design automation (MODENA) refers to an approach that decomposes the overall design process of an intelligent robot system into multiple relatively simple and independent functional modules. Each module can be modeled as a unified graph model, which facilitates the optimization of the design. This enables the automatic design and combination of modules. In particular, MODENA for intelligent robots refers to the decomposition of the morphology (body) [<xref ref-type="bibr" rid="CR7">7</xref>], controller (brain) [<xref ref-type="bibr" rid="CR8">8</xref>], and vision system (eyes) [<xref ref-type="bibr" rid="CR9">9</xref>] of an intelligent robot into some independent and interpretable graphical modular units in a digital twin architecture. Then, with the help of artificial intelligence technologies such as genetic programming [<xref ref-type="bibr" rid="CR10">10</xref>], evolutionary computation [<xref ref-type="bibr" rid="CR11">11</xref>], deep learning [<xref ref-type="bibr" rid="CR12">12</xref>], reinforcement learning [<xref ref-type="bibr" rid="CR13">13</xref>], and causal reasoning [<xref ref-type="bibr" rid="CR14">14</xref>], these modular units are combined automatically, and the evolution of combination rules is performed. Through this approach, the design process of intelligent robots can be automated. During the design automation process, it is notable that the system that is automatically discovered can be constructed into a new modular unit and added to the module library. This new modular unit can then be utilized in a closed-loop design automation process, allowing for systematical and continuous improvement in the performance of the intelligent robot system. Compared with traditional design methods, the MODENA method can significantly improve the design efficiency and performances of intelligent robots, by promoting the generation of innovative designs not limited by the experiences and intuitions of human designers, and the repetitive trial-and-error processes and laborious routine tasks to be conducted by traditional design methods.</p><p id="Par4">The proposed MODENA approach (see Fig. <xref rid="Fig1" ref-type="fig">1</xref>) has received increasing academic attention in recent decades. It applies a constrained multi-objective genetic programming method to automatically generate and evolve the topologies and parameters of graph models (e.g., bond graph, finite state machine, gene regulatory network, deep neural network, and Bayesian network). In this way, the design rules of intelligent robots can be constructed to generate robots with high performance. To efficiently solve the multi-objective programming problem, two key techniques, i.e., constrained multi-objective evolutionary algorithms and genetic programming methods, are simultaneously applied to optimize the topology and parameters of an arbitrary graph structure. Specifically, the constrained multi-objective evolutionary algorithm can efficiently solve multiple conflicting objectives with various types of constraints and a large number of discrete or continuous variables. Genetic programming is used to search for optimization of the topologies and internal parameters of graph models, which can obtain models with innovative optimized structures that perform well in specific aspects. To effectively represent the target object with an appropriate graph model according to its characteristics, we applied different types of graph models for various intelligent robot sub-systems, namely, the morphology, controller and vision systems. Specifically, for the morphology and controller sub-systems, bond graphs are used to unify the modeling of multi-domain physical systems and controller systems, which can conduct comprehensive analysis and modeling of dynamic characteristics. For controllers of swarm robot systems, finite state machines and gene regulatory networks are commonly applied. In particular, finite state machines can abstract robot behaviors into several states, allowing the moving robot to switch among different states. The gene regulatory network is a structural model that integrates the interactions among individuals and their environments, enabling the behavior control of each agent in swarm robots. In vision systems, deep neural networks and Bayesian networks are widely utilized. Deep neural networks are used to learn internal relationships and representation levels of data, enabling robots to achieve human-level analysis abilities on various forms of data, such as text, images and sounds. Bayesian networks, on the other hand, utilize a probabilistic graph model to describe causal relationships of uncertainty among variables, which can process environmental information received by vision systems. <fig id="Fig1"><label>Figure 1</label><caption xml:lang="en"><p>Key components in modular design automation</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig1_HTML.png"/></fig></p><p id="Par5">For example, Hod Lipson [<xref ref-type="bibr" rid="CR15">15</xref>] employed evolutionary computation to design robotic systems automatically in a computer and then created the corresponding prototypes using 3D printing, thereby realizing for the first time the concept of using a machine to design and build machines. That work was published in <italic>Nature</italic> in 2000. Subsequently, Lipson published a series of papers about design automation in <italic>Nature</italic> and <italic>Science</italic> [<xref ref-type="bibr" rid="CR16">16</xref>–<xref ref-type="bibr" rid="CR18">18</xref>]. There, he presented a more general research question: Can we automatically design a mechatronic or robotic system that can satisfy pre-defined design specifications using Lego-like building blocks? At about the same time, Erik Goodman (the founding director of Beacon center for the study of evolution in action) and his team made breakthrough research in the field of mechatronic design automation (MDA) by employing bond graph (BG) and genetic programming (GP) to automate the design process of general mechatronic systems [<xref ref-type="bibr" rid="CR19">19</xref>]. BG is a graphical modeling tool that can unify the modeling of multi-domain physical systems in a mechatronic system. GP is a powerful tool in the field of evolutionary computation that can simultaneously optimize the topology and parameters of an arbitrary graph structure. Several circuits and mechanical systems [<xref ref-type="bibr" rid="CR20">20</xref>–<xref ref-type="bibr" rid="CR23">23</xref>] have been designed automatically using the bond graph and genetic programming (BGGP) approach, and the combined automatic design of controllers and controlled objects in continuous systems has also been achieved in [<xref ref-type="bibr" rid="CR24">24</xref>]. In 2007, Clarence D. Silva and his team [<xref ref-type="bibr" rid="CR25">25</xref>] extended the BGGP approach to allow it to treat nonlinear systems, and proposed the concept of mechatronic design quotients to address design problems involving multiple objectives. In 2012, Zhun Fan and his team [<xref ref-type="bibr" rid="CR26">26</xref>] proposed an extension of BGGP, called hBGGP with the capability of dealing with both continuous and discrete dynamics as well as designing both the plant and the controller concurrently. The MODENA approach has also been effectively applied to swarm robots. In 2018, Garattoni utilized finite state machines to govern a swarm of robots with complex cognitive capabilities that can perform tasks successfully without knowing the exact execution sequence [<xref ref-type="bibr" rid="CR27">27</xref>].</p><p id="Par6">To summarize, existing design automation approaches usually pre-define a library of basic modules via a graphical modeling tool. Then, they employ optimization or metaheuristic methods, e.g., evolutionary computation, to search for optimal solutions. When designing mechatronic systems, the modeling language can be a bond graph [<xref ref-type="bibr" rid="CR28">28</xref>, <xref ref-type="bibr" rid="CR29">29</xref>]. In the design of a vision system, the representation can be deep neural networks [<xref ref-type="bibr" rid="CR30">30</xref>, <xref ref-type="bibr" rid="CR31">31</xref>]. When designing the behaviors of swarm robots, the modeling language includes finite state machines and gene regulatory networks [<xref ref-type="bibr" rid="CR32">32</xref>–<xref ref-type="bibr" rid="CR34">34</xref>]. These modeling languages are modular and parametric and can be uniformly represented by graphical models. In this paper, systematic and comprehensive reviews of the current state-of-the-art design automation approaches to intelligent robot bodies, controllers, and vision systems are presented. The current problems and challenges of this emerging research field are analyzed, and future research directions are discussed. We purport to attract the attention of the relevant scholars and promote the development of industrial software for design automation of intelligent robots.</p><p id="Par7">The remainder of this paper is organized as follows. Section <xref rid="Sec2" ref-type="sec">2</xref> provides an overview of the design automation for the morphologies of intelligent robots. The design automation for the controllers of intelligent robots is reviewed in Sect. <xref rid="Sec6" ref-type="sec">3</xref>. In Sect. <xref rid="Sec10" ref-type="sec">4</xref>, the integrated design automation for the morphologies and controllers is presented. Design automation for the vision systems of intelligent robots is summarized in Sect. <xref rid="Sec11" ref-type="sec">5</xref>. Section <xref rid="Sec20" ref-type="sec">6</xref> discusses the research and development trends of the integrated design automation of “Body-Brain-Eye” for intelligent robots. Section <xref rid="Sec21" ref-type="sec">7</xref> summarizes and discusses several key technologies, current problems, and challenges involved in the MODENA for intelligent robots. Finally, conclusions are drawn in Sect. <xref rid="Sec26" ref-type="sec">8</xref>.</p></sec><sec id="Sec2"><title>Design automation for the morphologies of intelligent robots</title><p id="Par8">MODENA for the morphologies of intelligent robots refers to the systematic use of intelligent design optimization methods to design the robot morphologies, i.e. the plants or mechanical infrastructures. The current research on the design automation for intelligent robot morphologies is primarily divided into two categories: 1) Fixing the morphological topology and optimizing the geometric parameters of the morphology [<xref ref-type="bibr" rid="CR35">35</xref>–<xref ref-type="bibr" rid="CR39">39</xref>]. 2) Establishing a library of parametric modules for the morphologies of intelligent robots [<xref ref-type="bibr" rid="CR40">40</xref>–<xref ref-type="bibr" rid="CR42">42</xref>], and then simultaneously optimizing the topologies and geometric parameters of the morphologies, by reconfiguring the parameterizable modules.</p><sec id="Sec3"><title>Parametric optimization of the morphologies</title><p id="Par9">The optimization of intelligent robots’ designs presents a challenging problem which is usually a constrained multi-objective problem with mixed discrete and continuous variables that exhibit non-differentiation, discontinuity, and nonlinearity. The evaluation of some objectives also requires time-consuming simulations. Consequently, evolutionary algorithms are popular choices in practical engineering applications. For example, West et al. [<xref ref-type="bibr" rid="CR43">43</xref>] utilized a genetic algorithm to optimize the output error system to identify problems for a seven-degree-of-freedom manipulator. The algorithm optimized the parameters of joints to generate a high-performance manipulator. Similarly, Xiao et al. [<xref ref-type="bibr" rid="CR44">44</xref>] applied NSGA-II to optimize the weight and manipulability of the manipulator, resulting in a lighter and more maneuverable manipulator than the original UR5 structure. Hassan et al. [<xref ref-type="bibr" rid="CR45">45</xref>] used NSGA-II to optimize a robotic gripper, achieving an optimal gripping force while also revealing significant relationships among objective functions and variable values from Pareto-optimal solutions. In addition, Fan et al. [<xref ref-type="bibr" rid="CR46">46</xref>] proposed a push and pull search framework [<xref ref-type="bibr" rid="CR47">47</xref>] combined with a multi-objective evolutionary algorithm based on decomposition to optimize a six-degree-of-freedom teaching manipulator. Their approach resulted in designs that outperformed those of human engineers and some popular constrained multi-objective evolutionary algorithms. Additionally, reinforcement learning has been employed to optimize the parameters of morphologies. As an example, Zhang et al. [<xref ref-type="bibr" rid="CR48">48</xref>] proposed an algorithm that utilizes reinforcement learning to automate optimal robot hand design, demonstrating its effectiveness in tasks such as grasping boxes, cylinders, and spheres.</p></sec><sec id="Sec4"><title>Integrated design automation for parameters and topologies of morphologies</title><p id="Par10">Modular robots [<xref ref-type="bibr" rid="CR49">49</xref>–<xref ref-type="bibr" rid="CR52">52</xref>] embody the principles of integrated design automation, which incorporates the optimization of parameters and topologies to create diverse morphologies. Modular graph models for the morphologies of intelligent robots are composed of either homogeneous or heterogeneous modules, each of which involves a variety of actuators and sensors [<xref ref-type="bibr" rid="CR53">53</xref>, <xref ref-type="bibr" rid="CR54">54</xref>], which allows intelligent robots to achieve self-assembly, self-reconfiguration and self-repair. For example, Lipson et al. [<xref ref-type="bibr" rid="CR15">15</xref>] were not only the first to use modules from a pre-defined library of modules to automatically assemble electromechanical systems that meet pre-defined functional requirements but were also the first to apply evolutionary algorithms to design robotic systems on the computer. Kelly et al. [<xref ref-type="bibr" rid="CR55">55</xref>] applied a stochastic optimization algorithm to autonomously assemble a model for planar distributed assembly, which achieved innovative designs. Inspired by the large and complex nests built by social insects, Werfel et al. [<xref ref-type="bibr" rid="CR56">56</xref>] established a distributed system for automating construction, which built some particular desired structures according to a high-level design provided by users. Inspired by the principles of biological evolution [<xref ref-type="bibr" rid="CR57">57</xref>], Dai et al. proposed the metamorphic theory [<xref ref-type="bibr" rid="CR58">58</xref>], which allows the topologies of morphologies to be reconfigured and metamorphosed [<xref ref-type="bibr" rid="CR59">59</xref>] and to evolve dynamically [<xref ref-type="bibr" rid="CR60">60</xref>] according to actual needs, thus flexibly adapting to changing working environments and functional requirements. On this basis, a variety of robots have been developed, such as a hybrid continuum robot based on pneumatic muscles [<xref ref-type="bibr" rid="CR61">61</xref>], a crawling robot [<xref ref-type="bibr" rid="CR62">62</xref>], and a quadruped robot based on the metamorphic mechanism [<xref ref-type="bibr" rid="CR63">63</xref>, <xref ref-type="bibr" rid="CR64">64</xref>].</p><p id="Par11">With the development of topology optimization design methods, modular robots are increasingly applying such methods to achieve innovative designs of morphologies [<xref ref-type="bibr" rid="CR66">66</xref>, <xref ref-type="bibr" rid="CR67">67</xref>]. Compared with traditional topology optimization design methods (e.g., the level set method [<xref ref-type="bibr" rid="CR68">68</xref>], the evolutionary structural optimization method [<xref ref-type="bibr" rid="CR69">69</xref>], and the moving morphable component method [<xref ref-type="bibr" rid="CR70">70</xref>]), isogeometric topology optimization (ITO) [<xref ref-type="bibr" rid="CR71">71</xref>] is a modern structural optimization technique that leverages isogeometric analysis. Specifically, ITO seamlessly integrates computer-aided design, computer-aided engineering, and structural topology optimization, laying a theoretical foundation for the integration of design, analysis, and optimization of the morphologies for intelligent robots [<xref ref-type="bibr" rid="CR72">72</xref>]. In recent years, ITO has been extensively studied and has driven the development of a new generation of digital design. For example, Gao et al. [<xref ref-type="bibr" rid="CR73">73</xref>–<xref ref-type="bibr" rid="CR75">75</xref>] studied the ITO method to design new materials and structures with special properties, such as auxetic metamaterials [<xref ref-type="bibr" rid="CR76">76</xref>] and ultra-lightweight architected materials [<xref ref-type="bibr" rid="CR77">77</xref>]. To improve the stability and accuracy of the optimization process and broaden the application scenarios of topology optimization, Seo et al. [<xref ref-type="bibr" rid="CR78">78</xref>] proposed a new ITO, which can eliminate the design space dependency. Wang et al. [<xref ref-type="bibr" rid="CR79">79</xref>] integrated isogeometric analysis with the level set method and proposed a high-precision ITO that satisfies geometric constraints. ITO enables the integration of digital design and analysis, thus significantly shortening the development cycle of the morphologies of intelligent robots and reducing research and development costs.</p><p id="Par12">BGGP combines the capability of bond graphs (BG) to represent the mixed-domain physics of generic mechatronic systems in a unified way, and of genetic programming (GP) to explore in an open-topology design space automatically and optimize both the topologies and parameters of design candidates represented by bond graphs. For example, Fan et al. [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR29">29</xref>, <xref ref-type="bibr" rid="CR81">81</xref>] proposed an automatic design method for mechatronic systems combining bond graphs and genetic programming, which has already been applied to the design of electrical and mechatronic systems, such as analog filters [<xref ref-type="bibr" rid="CR81">81</xref>], electric filters [<xref ref-type="bibr" rid="CR19">19</xref>] and the driver system of a printer [<xref ref-type="bibr" rid="CR29">29</xref>]. Meanwhile, Wang et al. [<xref ref-type="bibr" rid="CR24">24</xref>] proposed a knowledge-based evolutionary design framework for mechatronic systems by combining the BGGP method with human knowledge, as shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. In the BGGP method, BG is used to model multi-domain systems and GP is employed to search the open-end design spaces automatically. Figure <xref rid="Fig3" ref-type="fig">3</xref> illustrates the mapping from genotype to phenotype in the BGGP method. Compared with other methods, the BGGP method has a distinct advantage of being able to search in a topologically open-ended design space that is represented uniformly by bond graphs. As a special kind of mechatronic system, robotic systems can also utilize the BGGP approach to the design automation of their morphologies. Because modular robotic morphologies involve many physical sub-systems, they need a unified expression to model and analyze their performance. BG, as a modeling language that can describe all physical sub-systems (and continuous controllers) uniformly, can be utilized to model and analyze the dynamics of the designed mechatronic systems effectively and efficiently [<xref ref-type="bibr" rid="CR82">82</xref>, <xref ref-type="bibr" rid="CR83">83</xref>]. <fig id="Fig2"><label>Figure 2</label><caption xml:lang="en"><p>The framework of evolutionary synthesis of mechatronic systems [<xref ref-type="bibr" rid="CR65">65</xref>]</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig2_HTML.png"/></fig><fig id="Fig3"><label>Figure 3</label><caption xml:lang="en"><p>An example of genotype-phenotype mapping [<xref ref-type="bibr" rid="CR80">80</xref>]</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig3_HTML.png"/></fig></p><p id="Par13">In conclusion, many achievements have been made in design automation for the parameters and topologies of the robot morphologies. In particular, self-assembly [<xref ref-type="bibr" rid="CR84">84</xref>], self-reconfiguration [<xref ref-type="bibr" rid="CR85">85</xref>] and self-repair [<xref ref-type="bibr" rid="CR86">86</xref>, <xref ref-type="bibr" rid="CR87">87</xref>] characteristics of modular robots demonstrate the superiority of applying design automation for parameters and topologies of the morphologies. It is noted that the controller is also an important part of an intelligent robot, and the next section will detail the design automation for the controllers of intelligent robots.</p></sec><sec id="Sec5"><title>Summary</title><p id="Par14">In summary, design automation for the morphologies of intelligent robots has been widely applied, which can simultaneously optimize the geometric parameters and topologies of robots. Here, we present a concise overview of the various methods reviewed, highlighting the connections and differences among them from multiple perspectives, as displayed in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. <fig id="Fig4"><label>Figure 4</label><caption xml:lang="en"><p>A summary of design automation for the morphologies of intelligent robots</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig4_HTML.png"/></fig></p><p id="Par15">The research on the design automation for the morphologies of intelligent robots is mainly divided into three categories: (1) Optimizing geometric parameters while keeping a fixed morphological topology [<xref ref-type="bibr" rid="CR43">43</xref>–<xref ref-type="bibr" rid="CR46">46</xref>, <xref ref-type="bibr" rid="CR48">48</xref>]. These methods usually use multi-objective evolutionary algorithms [<xref ref-type="bibr" rid="CR43">43</xref>–<xref ref-type="bibr" rid="CR46">46</xref>] or reinforcement learning methods [<xref ref-type="bibr" rid="CR48">48</xref>] to optimize the geometric parameters to meet task-specific requirements and obtain an optimal design. Since the topology is fixed, it is difficult to adapt to complex tasks. (2) Topology optimization methods. These methods are represented by isogeometric topology optimization [<xref ref-type="bibr" rid="CR73">73</xref>–<xref ref-type="bibr" rid="CR75">75</xref>, <xref ref-type="bibr" rid="CR78">78</xref>, <xref ref-type="bibr" rid="CR79">79</xref>]. After setting the design space of the topology structure, optimization objectives and constraints, these methods can automatically perform topology optimization design of the robot system’s components based on the implementation of computer aided engineering (CAE) analysis. These topology optimization methods can not only shorten the design cycle but also improve the design quality. However, the current work is mainly focused on the topology design of the components of intelligent robots. (3) Simultaneous optimization of topologies and geometric parameters of robot morphologies [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR55">55</xref>, <xref ref-type="bibr" rid="CR56">56</xref>, <xref ref-type="bibr" rid="CR81">81</xref>]. These methods usually decompose the morphologies of intelligent robots into a series of independent modular units, and then achieve assembly automation and parameter design by using evolutionary computation or reinforcement learning techniques. However, these approaches rarely perform CAE analysis of the assembled morphologies, which cannot perform testing using computer simulations and provide valuable insights into the performance of robot morphologies during the early development phase. To summarize, although a large number of in-depth studies have been conducted on design automation for the morphologies of intelligent robots, further research is still required on how to conduct efficient design automation methods to meet the requirements of dynamic and complex tasks and environments.</p></sec></sec><sec id="Sec6"><title>Design automation for the controllers of intelligent robots</title><sec id="Sec7"><title>Design automation for the controllers of individual robots</title><p id="Par16">In an intelligent robotic system, the controller often plays a key role [<xref ref-type="bibr" rid="CR88">88</xref>, <xref ref-type="bibr" rid="CR89">89</xref>]. Many studies [<xref ref-type="bibr" rid="CR90">90</xref>] have conducted in-depth research on the design automation for the controllers of intelligent robots. For example, Zhong et al. [<xref ref-type="bibr" rid="CR91">91</xref>] proposed a novel kinematic calibration method based on an improved whale swarm algorithm to optimize the controller design of a biped robot to enable the robot to walk continuously and smoothly on complex ground. Due to the complexity of the walking dynamics of the biped robot, Gao et al. [<xref ref-type="bibr" rid="CR92">92</xref>] applied a pre-trained neural network to design an optimal gait control model. Simulation results showed that the control model could effectively improve the maximum walking speed and terrain adaptability in a short time. In addition, hydraulic actuators are frequently employed in biped robot controllers. Nevertheless, due to the nonlinearity of hydraulic systems, their dynamic performance of the systems under control requires further improvement [<xref ref-type="bibr" rid="CR93">93</xref>]. To this end, Dong et al. [<xref ref-type="bibr" rid="CR94">94</xref>] proposed an improved drone squadron optimization-based approach to optimize the design of the hydraulic controller. The comprehensive experimental results indicated that the optimized hydraulic controller had better stability and higher accuracy.</p><p id="Par17">In addition, proportional-integral-derivative (PID) controllers have been widely utilized in intelligent robots due to their advantages of simple design, easy implementation, fast response, and small steady-state error. Many studies [<xref ref-type="bibr" rid="CR95">95</xref>–<xref ref-type="bibr" rid="CR98">98</xref>] have conducted in-depth research on the design optimization of PID controllers. For example, Sharma et al. [<xref ref-type="bibr" rid="CR99">99</xref>] applied the cuckoo search algorithm to optimize the parameters of the fractional-order fuzzy PID controller for a two-link planar rigid robotic manipulator. Experimental results demonstrated that the optimized PID controller outperformed the other controllers in terms of trajectory tracking, model uncertainty, disturbance rejection, and noise suppression. For the trajectory tracking of autonomous mobile robots, Ali et al. [<xref ref-type="bibr" rid="CR100">100</xref>] employed an artificial bee colony to optimize the parameters of a PID controller, which obtained two high-performance PID controllers (speed controller and azimuth controller). Taherkhorsandi et al. [<xref ref-type="bibr" rid="CR101">101</xref>] proposed an adaptive and robust controller that combines PID with sliding control to better control the motion of a biped robot. They utilized a multi-objective genetic algorithm to optimize the controller, resulting in successful control of a biped robot walking on a slope in the lateral plane. In general, PID controllers have difficulty in achieving optimal control of complex and nonlinear control systems [<xref ref-type="bibr" rid="CR102">102</xref>]. To this end, Sun et al. [<xref ref-type="bibr" rid="CR103">103</xref>] established a set of component units and performance units, and designed an optimal controller using the differential evolution algorithm. On this basis, Xin et al. [<xref ref-type="bibr" rid="CR104">104</xref>] proposed a general design automation method for controllers to simultaneously optimize the structures and parameters of the controllers. Their approach combines basic controller components and related parameters to automatically create an optimal control model tailored to specific requirements.</p><p id="Par18">In addition to the design automation methods mentioned above for PID controllers, many studies have employed neural networks as controllers for intelligent robots [<xref ref-type="bibr" rid="CR105">105</xref>–<xref ref-type="bibr" rid="CR107">107</xref>]. For example, Gallagher et al. [<xref ref-type="bibr" rid="CR108">108</xref>] developed an approach in which they evolved neural networks in simulation to control the locomotion in an artificial insect, and successfully transferred the controller to a real hexapod robot. Nolfi et al. [<xref ref-type="bibr" rid="CR109">109</xref>] applied an evolutionary algorithm to design and optimize a neural controller, which makes a bipedal robot equipped with actuators and sensors move according to concentration differences. In Paul et al.’s study [<xref ref-type="bibr" rid="CR110">110</xref>], an evolutionary algorithm was used to optimize the design of a closed loop recurrent neural network controller, which achieved stable and bipedal movements on a 5-link biped robot in a physics-based simulation environment. In addition, Rahmani et al. [<xref ref-type="bibr" rid="CR111">111</xref>] proposed a novel adaptive neural network integral sliding-mode controller that utilized a bat algorithm to control a biped robot, and proved its stability using the Lyapunov theory.</p></sec><sec id="Sec8"><title>Design automation for the controllers of swarm robots</title><p id="Par19">Traditional control methods were initially designed to control the motions of individual robotic systems. However, when the scale of intelligent robotic systems is enlarged with numerous individual robots involved, traditional control approaches may face many challenges. These challenges include insufficient fault tolerance, meaning that the failure of a few individuals may lead to the failure of the whole system, a significant increase in computational overhead, making it difficult to respond to unexpected occurrences timely, and other issues. The design automation of controllers for swarm robots provides a viable solution to the above difficulties. To this end, some studies have extracted the basic unit of swarm behavior by exploring the mapping between swarm behavior and individual behavior [<xref ref-type="bibr" rid="CR112">112</xref>–<xref ref-type="bibr" rid="CR116">116</xref>]. Then, an evolutionary computation-based swarm behavior control framework suitable for dynamic and complex task environments is automatically designed. For example, Francesca et al. [<xref ref-type="bibr" rid="CR117">117</xref>] abstracted some individual behavior into several states (such as random motion and static state) and then applied an optimization algorithm (named F-Race) to automatically design controllers based on a probability finite state machine. In the following year, Francesca et al. [<xref ref-type="bibr" rid="CR118">118</xref>] improved the design of control software for robot swarms and proposed two automated design methods (Vanilla and EvoStick). The experimental results demonstrated that the proposed design automation methods outperformed human designers in specific experimental scenarios. Although the works [<xref ref-type="bibr" rid="CR117">117</xref>, <xref ref-type="bibr" rid="CR118">118</xref>] successfully addressed relatively simple or constrained problems, their limitations quickly emerged as the problem complexity increased [<xref ref-type="bibr" rid="CR119">119</xref>]. In particular, a complex task is made of several subtasks that may require cooperation and have mutual dependencies and time constraints [<xref ref-type="bibr" rid="CR120">120</xref>]. To this end, Fan et al. [<xref ref-type="bibr" rid="CR33">33</xref>] constructed a library of logical relationships of information exchange between agents by learning from the method of information exchange between cells in organisms. They then applied genetic programming to automatically design the optimal swarm behavior control model so that swarm robots can entrap targets in different patterns according to different environments (as shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>). Furthermore, Wu et al. [<xref ref-type="bibr" rid="CR121">121</xref>] refined individual simple behavioral rules with universal applicability (such as exploration, moving to the target, and avoiding obstacles) through an in-depth analysis of the flocking task. They then optimized these individual behavior rules by combining behavioral trees and the proposed heterogeneous–homogeneous co-evolution method to automatically design swarm behavior control strategies. Currently, these studies [<xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR121">121</xref>] are mainly in laboratory environments or simulation environments, and few studies are deployed in practical application environments. To this end, Vásárhelyi et al. [<xref ref-type="bibr" rid="CR122">122</xref>] applied CMA-ES to optimize the design of the swarm control mechanism by considering the presence of machine failures, communication delays, and airflow disturbances in actual flight, which achieved a successful flocking flight in the field with 30 unmanned aerial vehicles (UAVs). <fig id="Fig5"><label>Figure 5</label><caption xml:lang="en"><p>Diagram of the automated design framework [<xref ref-type="bibr" rid="CR33">33</xref>] for entrapping pattern generation</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig5_HTML.png"/></fig></p></sec><sec id="Sec9"><title>Summary</title><p id="Par20">To summarize, research on the design automation of the controllers is a key procedure to achieve the design automation of the entire intelligent robots. In this regard, we have summarized the characteristics and applicability of various design automation methods for controllers in two different aspects: the applied techniques and target objects, such as single robot controller and swarm robot controller, as shown in Fig. <xref rid="Fig6" ref-type="fig">6</xref>. <fig id="Fig6"><label>Figure 6</label><caption xml:lang="en"><p>A summary of design automation for the controllers of intelligent robots</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig6_HTML.png"/></fig></p><p id="Par21">The research on the design automation for controllers consists of two main aspects: (1) Optimizing the geometric parameters of the controller with a fixed controller topology. For example, evolutionary algorithms, such as MOGA [<xref ref-type="bibr" rid="CR101">101</xref>, <xref ref-type="bibr" rid="CR108">108</xref>–<xref ref-type="bibr" rid="CR110">110</xref>], CMA-ES [<xref ref-type="bibr" rid="CR122">122</xref>] and hybrid evolutionary algorithms (such as the improved whale swarm algorithm [<xref ref-type="bibr" rid="CR91">91</xref>], cuckoo search algorithm [<xref ref-type="bibr" rid="CR99">99</xref>], artificial bee colony [<xref ref-type="bibr" rid="CR100">100</xref>], and bat algorithm [<xref ref-type="bibr" rid="CR111">111</xref>]), are applied to optimize controller parameters [<xref ref-type="bibr" rid="CR91">91</xref>, <xref ref-type="bibr" rid="CR94">94</xref>, <xref ref-type="bibr" rid="CR99">99</xref>–<xref ref-type="bibr" rid="CR101">101</xref>, <xref ref-type="bibr" rid="CR108">108</xref>–<xref ref-type="bibr" rid="CR111">111</xref>, <xref ref-type="bibr" rid="CR122">122</xref>]. (2) Simultaneous optimization of the topologies and geometric parameters of the controller [<xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR92">92</xref>, <xref ref-type="bibr" rid="CR103">103</xref>, <xref ref-type="bibr" rid="CR104">104</xref>, <xref ref-type="bibr" rid="CR117">117</xref>, <xref ref-type="bibr" rid="CR118">118</xref>, <xref ref-type="bibr" rid="CR121">121</xref>]. These methods usually pre-build various modular control units and then apply evolutionary algorithms to automatically assemble and parameterize these units, resulting in the automatic design of the optimal controller topology and parameters.</p><p id="Par22">From the perspective of the scale of controlled objects, the design automation of controllers can be divided into two categories: (1) Design automation for the controllers of single robotic systems [<xref ref-type="bibr" rid="CR91">91</xref>, <xref ref-type="bibr" rid="CR94">94</xref>, <xref ref-type="bibr" rid="CR99">99</xref>–<xref ref-type="bibr" rid="CR101">101</xref>, <xref ref-type="bibr" rid="CR108">108</xref>–<xref ref-type="bibr" rid="CR111">111</xref>]. (2) Design automation for controllers of swarm robotic systems [<xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR103">103</xref>, <xref ref-type="bibr" rid="CR104">104</xref>, <xref ref-type="bibr" rid="CR117">117</xref>, <xref ref-type="bibr" rid="CR118">118</xref>, <xref ref-type="bibr" rid="CR121">121</xref>, <xref ref-type="bibr" rid="CR122">122</xref>]. Compared to the design of a single robot controller, designing a swarm robot controller is more complex. The main reason is that the mapping mechanism from swarm behavior control to individual behavior control is not clear. Designing behavior control rules for each robot in the swarm robot to generate intelligent swarm behavior at the system level is an important research direction in the future.</p></sec></sec><sec id="Sec10"><title>Integrated design automation for the morphologies and controllers of intelligent robots</title><p id="Par23">In recent years, researchers have introduced the idea of biological evolution into integrated design automation for morphologies and controllers of intelligent robots [<xref ref-type="bibr" rid="CR123">123</xref>–<xref ref-type="bibr" rid="CR126">126</xref>], which can automatically identify the optimal designs of intelligent robots according to fitness functions determined by given tasks or environments. Based on these ideas, some studies [<xref ref-type="bibr" rid="CR127">127</xref>–<xref ref-type="bibr" rid="CR129">129</xref>] have proposed an underlying system architecture called the triangle of life, which consists of three stages: morphogenesis, infancy, and mature life. This system allows for a population of robotic organisms that evolve and adapt to the given environment. Additionally, evolutionary computation, as a biologically-inspired algorithm, has been used in numerous studies for integrated design automation of morphologies and controllers of intelligent robots [<xref ref-type="bibr" rid="CR53">53</xref>, <xref ref-type="bibr" rid="CR130">130</xref>]. Modular robots can integrate the morphologies and controllers into a whole and simplify the search space, improving the efficiency of evolutionary computation [<xref ref-type="bibr" rid="CR51">51</xref>]. Thus, the design automation of modular robots based on evolutionary computing has become an important research method for integrated design automation for the morphologies and controllers of intelligent robots. For example, Marbach et al. [<xref ref-type="bibr" rid="CR131">131</xref>] utilized genetic programming to integrate configuration and control of locomoting homogenous modular robots, breaking through the limitations of human designers’ experience and intuitions in manual design methods. It is worth noting that crossover and mutation in the evolutionary process may cause mismatches between robot morphologies and controllers of the offspring. To alleviate this problem, Agrim Gupta et al. [<xref ref-type="bibr" rid="CR132">132</xref>] designed a deep evolutionary reinforcement learning framework, which learned challenging motor tasks in complex environments by evolving different surrogate models. The study confirmed that environmental complexity can promote the evolutionary design of robots, helping offspring robots learn new skills. Furthermore, the study confirmed that the robot structure is related to the learning efficiency of the controller. An excellent structure can promote the effective learning of the offspring robots.</p><p id="Par24">Recently, neural network-based approaches have been widely applied in integrated design automation for the morphologies and controllers of intelligent robots [<xref ref-type="bibr" rid="CR133">133</xref>, <xref ref-type="bibr" rid="CR134">134</xref>]. A RoboGrammar system inspired by arthropods was proposed by Zhao et al. [<xref ref-type="bibr" rid="CR135">135</xref>]. The proposed system could efficiently generate hundreds of thousands of robotic structures composed of the given components. Then, high-performance robots were found by applying graph heuristic search and model predictive control (MPC), achieving concurrent optimization of robot morphologies and controllers. By extending the single-objective graph heuristic search procedure based on the RoboGrammar system, Xu et al. [<xref ref-type="bibr" rid="CR136">136</xref>] proposed a new multi-objective co-design algorithm for obtaining Pareto-optimal robot topologies and controllers. Aslan Miriyev and Technology and Mirko Kovač [<xref ref-type="bibr" rid="CR137">137</xref>] created a symbiotic human–robot ecosystem (physical artificial intelligence) through the integrated evolution of the organism, control, morphology, action execution, and perception. The ecosystem decides and adapts in real-time for navigation, locomotion, and manipulation by processing combinations of signals simultaneously sent from multiple sensors in their “body” to their “brain”.</p><p id="Par25">In addition, genetic programming can also be utilized for efficient integrated design automation of the morphologies and controllers of electromechanical systems. For example, Wang et al. [<xref ref-type="bibr" rid="CR138">138</xref>] proposed a “body-brain” design automation method that integrates GP and bond graphs to automate the integrated design of a quarter-car suspension control system’s morphologies and controllers. Compared with traditional methods, this method can help designers to achieve more creative and flexible designs. In addition, Dupuis et al. [<xref ref-type="bibr" rid="CR26">26</xref>] proposed a design automation method called HBGGP, which merges hybrid bond graph (HBG) and genetic programming (GP) into the evolutionary design of topologies and parameters of a hybrid dynamical system. In the proposed method, HBG is utilized to represent dynamic systems involving both continuous and discrete system dynamics, and GP is used to explore the open-ended design space of HBGs to optimize the morphologies and parameters of DC-DC converters. Thereafter, they investigated the evolutionary design of controllers for hybrid mechatronic systems [<xref ref-type="bibr" rid="CR139">139</xref>] and employed a finite state automaton (FSA) to represent discrete controllers. A case study of a two-tank system demonstrated that the proposed evolutionary approach can lead to a successful design of an FSA controller for the hybrid mechatronic system.</p><p id="Par26">To summarize, the integrated design automation of the morphologies and controllers of intelligent robots is an important trend in future research. Separate consideration of the design automation of the morphologies and the controllers would lead to sub-optimal solutions and unsatisfactory overall performance. Here, we summarize the characteristics and applications of various methods from the perspective of research directions and applied optimization techniques of integrated “body-brain” design automation for intelligent robots, as illustrated in Fig. <xref rid="Fig7" ref-type="fig">7</xref>. <fig id="Fig7"><label>Figure 7</label><caption xml:lang="en"><p>A summary of integrated design automation for the morphologies and controllers of intelligent robots</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig7_HTML.png"/></fig></p><p id="Par27">The current research directions for morphologies and controllers mainly consist of three aspects: (1) Designing the search space [<xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR135">135</xref>, <xref ref-type="bibr" rid="CR138">138</xref>]. It is crucial to construct a reasonable search space so that novel solutions can be found. (2) Designing the search strategy [<xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR131">131</xref>, <xref ref-type="bibr" rid="CR132">132</xref>, <xref ref-type="bibr" rid="CR135">135</xref>, <xref ref-type="bibr" rid="CR136">136</xref>]. A good search strategy can improve the efficiency and effectiveness of the algorithm. (3) Designing evaluation indicators [<xref ref-type="bibr" rid="CR131">131</xref>, <xref ref-type="bibr" rid="CR135">135</xref>]. The evaluation indicators of comprehensive performance are designed to evaluate the performance of search candidates and guide the algorithm’s search.</p><p id="Par28">According to the applied optimization techniques, the integrated design automation for the morphologies and controllers is divided into three main categories: (1) Evolutionary computation-based approaches [<xref ref-type="bibr" rid="CR131">131</xref>, <xref ref-type="bibr" rid="CR136">136</xref>]. These approaches focus on finding the best design solutions for the integrated design of the morphologies and controllers by simulating the evolutionary process in nature. The advantage of these methods is that they allow the design of solutions that are superior to manual ones. However, due to the complex design space and randomness in the search process, the optimal design is not guaranteed. (2) Learning-based approaches [<xref ref-type="bibr" rid="CR135">135</xref>]. These approaches focus on learning the integrated design strategies for the morphologies and controllers by setting appropriate reward functions and making dynamic decisions with known knowledge to obtain a design solution that maximizes rewards. The method simplifies the design space and improves the search efficiency through a heuristic search method, and is suitable for the integrated design automation for the morphologies and controllers of intelligent robots with complex structures. (3) Combination evolution and learning approaches [<xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR132">132</xref>, <xref ref-type="bibr" rid="CR137">137</xref>, <xref ref-type="bibr" rid="CR138">138</xref>]. These methods mainly apply the evolution-based method to design the morphologies, and then apply the learning-based method to design the controllers, which can effectively reduce the search space and improve search efficiency.</p><p id="Par29">The integrated design automation of the morphologies and controllers of intelligent robots presents a challenge due to the strong coupling relationship between the morphology and controller, as it involves multi-energy domain physical systems. This makes it an important area for further research.</p></sec><sec id="Sec11"><title>Design automation for the vision systems of intelligent robots</title><p id="Par30">The vision systems of intelligent robots can provide rich visual perception information, such as depth information and motion information. This information is often one of the most important components for guiding the intelligent robot’s motion-decision-making process [<xref ref-type="bibr" rid="CR140">140</xref>]. However, in practice, vision systems are often designed manually. In most cases, designers require numerous trial-and-error experiments to obtain an appropriate design scheme for the vision system [<xref ref-type="bibr" rid="CR141">141</xref>, <xref ref-type="bibr" rid="CR142">142</xref>]. Design automation for vision systems can be used to automatically design an optimal or desired vision system design scheme for the robotic vision tasks needed. Therefore, design automation for vision systems represents an indispensable element of design automation for intelligent robots.</p><p id="Par31">Computer vision research provides an essential foundation for the design automation of robotic vision systems, where deep learning has become a crucial research direction in this field. Researchers can obtain desired results by constructing a neural network and using the corresponding image data for training, provided that the neural network architecture is properly designed. However, the design of neural network architecture requires designers to have a full understanding of various computing modules and training methods. In addition, designers have to conduct repeated experiments to adjust network architectures to produce optimal architectures with excellent performance [<xref ref-type="bibr" rid="CR142">142</xref>–<xref ref-type="bibr" rid="CR144">144</xref>]. In recent years, neural architecture search (NAS) has gradually emerged as a research hotspot. In a given search space, NAS can automatically identify optimized neural network architectures without manual design. Therefore, NAS provides an important foundation for the design automation of intelligent robotic vision systems.</p><p id="Par32">This section introduces the recent work related to NAS and highlights the shortcomings of existing research. It also identifies the problems that need to be addressed in the future to achieve the design automation of intelligent robotic vision systems.</p><sec id="Sec12"><title>Neural architecture search</title><p id="Par33">NAS is primarily composed of three parts: search space design, search strategy, and performance estimation strategy. Depending on the search strategy, NAS can be mainly classified into three categories [<xref ref-type="bibr" rid="CR145">145</xref>–<xref ref-type="bibr" rid="CR147">147</xref>]: (1) RL-based NAS, (2) differentiable NAS, and (3) evolutionary NAS.</p><p id="Par34">The RL-based NAS models the search task as a Markov decision process and offers rewards depending on the performance of the generated network after training on a test set. Then, the method trains the RL model according to the reward and adjusts the generated neural network architecture, thereby using the RL to guide the neural network architecture generation. Representative achievements include MetaQNN [<xref ref-type="bibr" rid="CR148">148</xref>] (proposed by MIT) and NASNet [<xref ref-type="bibr" rid="CR149">149</xref>, <xref ref-type="bibr" rid="CR150">150</xref>] (proposed by Google), both of which search the layers of the neural network. In contrast, BlockQNN [<xref ref-type="bibr" rid="CR151">151</xref>] (proposed by Shangtang Technology) searches modules of the neural network. Unlike the application of evolutionary algorithms or RL to a discrete and non-differentiable search space, differentiable methods make architecture searches more efficient by using gradient information through the continuous relaxation of the architecture representation [<xref ref-type="bibr" rid="CR152">152</xref>]. The network architectures designed by differentiable-based NAS have also achieved excellent performances with representative examples, including the differentiable architecture search (DARTS) [<xref ref-type="bibr" rid="CR152">152</xref>] (proposed by Google Brain) and PDARTS (proposed by Huawei’s Noah’s Ark Laboratory) [<xref ref-type="bibr" rid="CR153">153</xref>]. Evolutionary NAS regards the topological structure and super-parameter adjustments of the model as an optimization problem and adopts an evolutionary algorithm to optimize the neural network. In 2019, the Uber AI Lab published a review article in <italic>Nature Machine Intelligence</italic> that strongly advocated the evolutionary NAS and anticipated its future development [<xref ref-type="bibr" rid="CR154">154</xref>]. Representative evolutionary NAS examples include the neuroevolution of augmenting topologies (NEAT) [<xref ref-type="bibr" rid="CR155">155</xref>], CoDeepNEAT [<xref ref-type="bibr" rid="CR156">156</xref>], and NSGA-Net algorithms [<xref ref-type="bibr" rid="CR157">157</xref>].</p></sec><sec id="Sec13"><title>Design automation for vision systems</title><p id="Par35">In real life, robots assigned to different tasks require different visual capabilities. For example, drones use object detection [<xref ref-type="bibr" rid="CR158">158</xref>], object tracking [<xref ref-type="bibr" rid="CR159">159</xref>], motion estimation [<xref ref-type="bibr" rid="CR160">160</xref>] and depth estimation [<xref ref-type="bibr" rid="CR161">161</xref>] for autonomous obstacle avoidance. Autonomous cars use 3D object detection [<xref ref-type="bibr" rid="CR162">162</xref>] to establish the physical positions of obstacles for path planning. Medical robots use image segmentation [<xref ref-type="bibr" rid="CR163">163</xref>–<xref ref-type="bibr" rid="CR165">165</xref>] to analyze the information in medical examination reports and thereby help doctors diagnose a patient’s condition, and more (see Fig. <xref rid="Fig8" ref-type="fig">8</xref>). Different from laboratory studies, robots in practical applications typically are unable to provide sufficient computing resources with the embedded devices offered. Consequently, the development of light-weight models is a promising research area. <fig id="Fig8"><label>Figure 8</label><caption xml:lang="en"><p>Different visual tasks that robots often encountered, which include object detection [<xref ref-type="bibr" rid="CR166">166</xref>], semantic segmentation [<xref ref-type="bibr" rid="CR166">166</xref>], instance segmentation [<xref ref-type="bibr" rid="CR166">166</xref>], depth estimation [<xref ref-type="bibr" rid="CR167">167</xref>], image deraining [<xref ref-type="bibr" rid="CR168">168</xref>] and image dehazing [<xref ref-type="bibr" rid="CR169">169</xref>]</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig8_HTML.png"/></fig></p><p id="Par36">Thus, by investigating the vision tasks often encountered in current robot applications, this section introduces design automation for vision systems involved in the vision tasks that robots currently face, including (1) object detection, (2) image segmentation, (3) depth estimation, (4) video analysis, and (5) embedded device application.</p><sec id="Sec14"><title>Neural architecture search for object detection</title><p id="Par37">Object detection can enable a robot to identify the object of interest in an image and determine its position, allowing the robot to perform tasks such as object picking [<xref ref-type="bibr" rid="CR170">170</xref>, <xref ref-type="bibr" rid="CR171">171</xref>], object tracking [<xref ref-type="bibr" rid="CR172">172</xref>, <xref ref-type="bibr" rid="CR173">173</xref>], and other tasks. The network architecture of object detection is primarily classified into three parts: the backbone, neck, and head. The backbone is responsible for extracting image features, the neck is responsible for fusing features, and the head is responsible for classifying and locating objects. Currently, two main methods are available for object detection architectures: (1) searching for the overall network architecture [<xref ref-type="bibr" rid="CR174">174</xref>] and (2) searching for parts of the network architecture while using other parts of the existing network architecture [<xref ref-type="bibr" rid="CR175">175</xref>]. Depending on the problem characteristics of the object detection tasks and the characteristics of the network structures, various methods have been introduced for searching object detection network architectures.</p><p id="Par38">Chen et al. [<xref ref-type="bibr" rid="CR176">176</xref>] proposed the DetNAS algorithm to address the problem of losing object location features when directly using an image classification network as the backbone for object detection. To achieve this, they search the entire network architecture using ShuffleNetV2 as the search space. The algorithm is pre-trained on ImageNet datasets and fine-tuned on object detection task datasets to improve classification and localization capabilities. Meanwhile, DetNAS employs an evolutionary algorithm to search the sub-network. Wang et al. [<xref ref-type="bibr" rid="CR175">175</xref>] proposed NAS-FCOS, a fast neural architecture search algorithm for object detection, to reduce the computational burden and improve search speed. The algorithm uses an existing image classification network, such as ResNet or MobileNet, as the backbone network and constructs the network according to the feature pyramid network (FPN) and detection head. NAS-FCOS searches only the network structures of the FPN and detection header in different search spaces. The algorithm employs a long short-term memory (LSTM) network as an agent and uses an RL-based search strategy to build a network for the FPN and detection header. Structural-to-modular NAS [<xref ref-type="bibr" rid="CR177">177</xref>] adopts a two-stage search strategy to search network architectures for object detection. In the first stage, different existing networks are combined based on the structure of the target detection network to identify the combination of network structures that achieved the Pareto optimum in terms of inference speed and accuracy. In the second stage, all network structures in the Pareto solution set are further searched in different modules.</p><p id="Par39">In recent years, NAS for object detection has received increasing attention and achieved very competitive results. However, how to define an optimal search strategy and search space remains a problem for object-detection NAS.</p></sec><sec id="Sec15"><title>Neural architecture search for image segmentation</title><p id="Par40">Image segmentation is a process that involves classifying each pixel in an image, making it a dense prediction task. Robots can utilize image segmentation for various functions, including defect detection and measurement [<xref ref-type="bibr" rid="CR178">178</xref>] and medical analysis [<xref ref-type="bibr" rid="CR179">179</xref>, <xref ref-type="bibr" rid="CR180">180</xref>]. Currently, image segmentation architecture search methods fall into two categories. The first category involves searching for the module structure under a fixed network architecture, while the second category involves searching for both the network architecture and module structure simultaneously.</p><p id="Par41">Liu et al. [<xref ref-type="bibr" rid="CR181">181</xref>] proposed Auto-DeepLab, which first applied NAS to image segmentation. Auto-DeepLab uses architecture- and cell-level search methods to explore the overall architecture of the model and cell structure, respectively. It formulates the architecture search problem as a differentiable optimization one and uses the gradient-based method to search the model architecture. To quickly search a lightweight semantic segmentation network for mobile device applications, Nekrasov et al. [<xref ref-type="bibr" rid="CR182">182</xref>] employed the existing network architecture as the encoder and focused on searching the decoder network architecture under the encoder-decoder network architecture. Wei et al. [<xref ref-type="bibr" rid="CR183">183</xref>] proposed a Genetic U-Net estimation for retinal vessel segmentation, which takes U-shaped encoder-decoder structure as the network architecture and explores the network structure within each cell in the encoder network and decoder network by an evolutionary algorithm. Genetic U-Net uses binary coding to encode the network structure and regards the network performance on the test dataset as the fitness of individuals. Through genetic operations such as selection, crossover and mutation, better offspring individuals are evolved continuously and finally the network structures with the best performance are identified. Experimental results show that Genetic U-Net has higher segmentation accuracy yet fewer parameters than existing algorithms in DRIVE, STARE, CHAS_DB and HRF public datasets. It is worth noting that Genetic U-Net is a rather general framework, which can conveniently switch to different vision tasks and generate optimal models according to the provided training data, as depicted in Fig. <xref rid="Fig9" ref-type="fig">9</xref>. <fig id="Fig9"><label>Figure 9</label><caption xml:lang="en"><p>The framework of Genetic U-Net [<xref ref-type="bibr" rid="CR183">183</xref>]. In the framework, if the dataset is pose estimation [<xref ref-type="bibr" rid="CR184">184</xref>], object tracking [<xref ref-type="bibr" rid="CR185">185</xref>] or object detection [<xref ref-type="bibr" rid="CR186">186</xref>], the framework can automatically generate the corresponding optimal neural network model</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig9_HTML.png"/></fig></p></sec><sec id="Sec16"><title>Neural architecture search for depth estimation</title><p id="Par42">Depth estimation enables robots to calculate the distance to objects by analyzing images [<xref ref-type="bibr" rid="CR167">167</xref>, <xref ref-type="bibr" rid="CR187">187</xref>]. These estimations are crucial in downstream tasks such as autonomous obstacle avoidance [<xref ref-type="bibr" rid="CR188">188</xref>, <xref ref-type="bibr" rid="CR189">189</xref>] and path planning [<xref ref-type="bibr" rid="CR190">190</xref>, <xref ref-type="bibr" rid="CR191">191</xref>], making them important vision functions for robots. Monocular and binocular depth estimation techniques are the two most commonly used vision systems in robots. Therefore, this section primarily focuses on introducing architecture search algorithms for monocular and binocular depth estimation.</p><p id="Par43">Monocular depth estimation directly predicts the depth map of the input image, which is an intensive prediction task. Huynh et al. [<xref ref-type="bibr" rid="CR192">192</xref>] proposed LiDNAS to search for lightweight monocular depth estimation networks. Under the preset network architecture, each module structure is searched using an auxiliary tabu search algorithm. During network training, the prediction accuracy and the number of parameters are used to obtain a network model with fewer parameters and higher estimation accuracy. Saikia et al. [<xref ref-type="bibr" rid="CR193">193</xref>] extended DARTS [<xref ref-type="bibr" rid="CR152">152</xref>] and applied it to depth estimation tasks by using AutoML technology to efficiently search for optimal network structures. Nekrasov et al. [<xref ref-type="bibr" rid="CR182">182</xref>] utilized a method to search for a lightweight semantic segmentation network architecture for depth estimation, which resulted in competitive performance compared to manually designed depth estimation networks.</p><p id="Par44">Binocular depth estimation primarily involves identifying matching points in left and right images using stereo matching [<xref ref-type="bibr" rid="CR194">194</xref>]. A stereo vision system model is then used to estimate the depth map. Therefore, the architecture search in the binocular depth estimation task is one of the search tasks for the stereo matching network model. This network is typically composed of two parts: a feature extraction network and a matching network. Inspired by multi-resolution feature extraction and fusion, Cheng et al. [<xref ref-type="bibr" rid="CR195">195</xref>] proposed the learning effective architecture stereo algorithm. This algorithm, which is based on a gradient-based search strategy, adopts a two-level hierarchical search strategy to search the network architecture and the internal structures of the constitutive modules simultaneously. To solve the problem of decreased matching accuracy in unseen scenes, Zhang et al. [<xref ref-type="bibr" rid="CR196">196</xref>] established a reusable architecture growth framework that allows the resulting network to learn to match stereo unseen scenes. Wang et al. [<xref ref-type="bibr" rid="CR197">197</xref>] introduced an elastic and accurate network for stereo matching (EASNet), which divides the network architecture into four components based on different functions. The search space of each component includes manually designed calculation modules for stereo matching. Experiments show that EASNet achieves superior results in terms of both inference speed and matching accuracy.</p><p id="Par45">To summarize, depth estimation is primarily classified into monocular and binocular depth estimation. Different estimation methods produce different search models. Currently, the depth estimation architecture search is based on single images. However, depth estimations implementing multi-image information can exploit more spatial information. Therefore, multi-image-based depth estimation architecture search is a promising research direction in the field of depth estimation in the future.</p></sec><sec id="Sec17"><title>Neural architecture search for video analysis</title><p id="Par46">Different from rapid development towards image data, NAS on video data is still an under-explored area and only several video tasks are studied, including action recognition, super resolution and pose estimation. Existing methods mainly focus on introducing successful experiences from image data and further exploit spatio-temporal cues and motion information in video data.</p><p id="Par47">For action recognition, Peng et al. [<xref ref-type="bibr" rid="CR198">198</xref>] first proposed a NAS method for 3D models to achieve design automation. Specifically, it uses the pseudo 3D operator to process spatial and temporal features in the search space. To further exploit spatio-temporal relationships, Piergiovanni et al. [<xref ref-type="bibr" rid="CR199">199</xref>] proposed EvaNet by introducing an inflated temporal gaussian mixture (iTGM) to the search space, which enables the model to catch the spatial and temporal interactions among feature flows. In addition, Ryoo et al. [<xref ref-type="bibr" rid="CR200">200</xref>] established AssembleNet to consider object motion information in design automation. In particular, it first builds a two-stream model as directed graphs and then uses evolutionary algorithms to establish connections between different blocks on RGB and optical flow input at different temporal resolutions. This can better exploit appearance and motion information from videos. Unlike the previous methods, Wang et al. [<xref ref-type="bibr" rid="CR201">201</xref>] considered introducing an attention mechanism and proposed AttentionNAS, which builds a spatio-temporal attention cell search space and enables generated models to catch long-distance dependencies in video data. Additionally, Piergiovanni et al. [<xref ref-type="bibr" rid="CR202">202</xref>] focused on improving the computation efficiency of video models and proposed TinyVideoNet, which introduces model running time into the reward loss function and guides the search strategy to generate a desired model with low computing latency. For video super resolution, Liu et al. [<xref ref-type="bibr" rid="CR203">203</xref>] proposed EVSRNet to achieve high fidelity results and efficient computation. Specifically, it uses the residual block as the basic building block, and then similarly introduces the fidelity of results and computation cost of candidate models into the reward loss function. After that, a gradient descent method is performed to search the optical number and size of the residual blocks. Consequently, the generated model can produce more accurate details while keeping lower computation costs and fewer model parameters. For video pose estimation, Xu et al. [<xref ref-type="bibr" rid="CR204">204</xref>] proposed ViPNAS to utilize pose relationships between adjacent frames. Particularly, it established the search space by considering the correlation information between adjacent frames and then performed feature fusion on the heatmaps of the previous and current frames via a series of optional operations. Thus, the model can automatically learn the best fusion operation and the best stage to fuse.</p></sec><sec id="Sec18"><title>Neural architecture search for embedded devices</title><p id="Par48">Although current NAS methods can generate high-precision models, these models are often not applicable in real-world intelligent robots due to unacceptable computing latency. This is because real-world robots are usually built on embedded devices, which can only provide limited memory and computing resources. However, current NAS methods do not account for these important factors. Therefore, designing a suitable NAS method according to the characteristics and requirements of embedded devices is an urgent problem to be solved.</p><p id="Par49">On embedded devices, computing latency and memory consumption of models are two key factors. To optimize the computing latency, Cai et al. [<xref ref-type="bibr" rid="CR205">205</xref>] developed ProxylessNAS to model the computing latency of models as a continuous function and optimized it as a regularization loss to find a model with low latency. Similarly, Wu et al. [<xref ref-type="bibr" rid="CR206">206</xref>] established DANS, which uses the latency of each block to estimate the latency of the entire model and introduces a latency reward loss to guide the search strategy. López et al. [<xref ref-type="bibr" rid="CR207">207</xref>] introduced E-DNAS to use a multi-objective differentiable loss function combining classification accuracy and minimum latency on the feature map. Luo et al. [<xref ref-type="bibr" rid="CR208">208</xref>] proposed LightNAS with a two-step procedure, which first applies a large-scale and one-time search for models that satisfy the latency constraints and then iteratively selects the candidate with the best accuracy. To optimize the memory consumption, Cassimon et al. [<xref ref-type="bibr" rid="CR209">209</xref>] proposed introducing two soft constraints (cache and performance) and two hard constraints (memory cost and latency) into the reward loss function, which can guide the search strategy to find a model that meets resource requirements. In addition, Wan et al. [<xref ref-type="bibr" rid="CR210">210</xref>] developed DMaskingNAS with an efficient masking mechanism for feature reuse and effective shape propagation, drastically expanding the search space by supporting searches over spatial and channel dimensions.</p><p id="Par50">In addition to building models from scratch, another direction to consider is how to automatically compress an existing large model. He et al. [<xref ref-type="bibr" rid="CR211">211</xref>] first proposed automated model compression (AMC) to achieve automated model pruning by using reinforcement learning. Specifically, AMC models the pruning rate and parameter-related information of each layer as the action space and state space, respectively. Then it uses DDPG [<xref ref-type="bibr" rid="CR212">212</xref>] to train the agent to automatically determine the pruning rate of each layer. Motivated by AMC, Gupta et al. [<xref ref-type="bibr" rid="CR213">213</xref>] developed PuRL to provide rewards at each pruning step, achieving sparsity and accuracy comparable to state-of-the-art (SOTA) methods with a shorter training cycle. Yu et al. [<xref ref-type="bibr" rid="CR214">214</xref>] proposed introducing topological information into the model compression procedure, finding the optimal compression ratio while ensuring model accuracy instead of relying solely on the local importance of parameters. To consider the relationship between convolutional filters and channels, Wang et al. [<xref ref-type="bibr" rid="CR215">215</xref>] established MCTS-RL to prune unnecessary filters before channel pruning, effectively reducing the search space and making channel pruning ratio searching easier. In addition to network pruning, tensor decomposition [<xref ref-type="bibr" rid="CR216">216</xref>], data quantization [<xref ref-type="bibr" rid="CR217">217</xref>] and knowledge distillation [<xref ref-type="bibr" rid="CR218">218</xref>] are other effective techniques for model compression. We do not discuss them here because they rely on hand-crafted design and expert experience and are unrelated to the topic of design automation. Interested readers can refer to [<xref ref-type="bibr" rid="CR219">219</xref>–<xref ref-type="bibr" rid="CR222">222</xref>] for further investigation.</p></sec></sec><sec id="Sec19"><title>Summary</title><p id="Par51">To summarize, neural architecture search (NAS) has been widely applied in design automation for vision systems, which can automatically search for neural networks and offer improved performances in various vision tasks. In this section, we provide a brief overview from different angles to illustrate the connection and difference between the methods reviewed in this section, as displayed in Fig. <xref rid="Fig10" ref-type="fig">10</xref>. <fig id="Fig10"><label>Figure 10</label><caption xml:lang="en"><p>A summary of design automation for vision systems with NAS</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig10_HTML.png"/></fig></p><p id="Par52">Existing works in NAS mainly focus on three key components: (1) the search space [<xref ref-type="bibr" rid="CR176">176</xref>, <xref ref-type="bibr" rid="CR183">183</xref>, <xref ref-type="bibr" rid="CR196">196</xref>, <xref ref-type="bibr" rid="CR201">201</xref>, <xref ref-type="bibr" rid="CR204">204</xref>, <xref ref-type="bibr" rid="CR210">210</xref>, <xref ref-type="bibr" rid="CR211">211</xref>, <xref ref-type="bibr" rid="CR215">215</xref>], which contains all network architecture candidates to be chosen, (2) the search strategy [<xref ref-type="bibr" rid="CR175">175</xref>, <xref ref-type="bibr" rid="CR177">177</xref>, <xref ref-type="bibr" rid="CR181">181</xref>, <xref ref-type="bibr" rid="CR182">182</xref>, <xref ref-type="bibr" rid="CR192">192</xref>, <xref ref-type="bibr" rid="CR193">193</xref>, <xref ref-type="bibr" rid="CR195">195</xref>, <xref ref-type="bibr" rid="CR198">198</xref>–<xref ref-type="bibr" rid="CR200">200</xref>], guiding how to select a good candidate that meets a specific requirement from the search space, and (3) the performance evaluation [<xref ref-type="bibr" rid="CR197">197</xref>, <xref ref-type="bibr" rid="CR202">202</xref>, <xref ref-type="bibr" rid="CR203">203</xref>, <xref ref-type="bibr" rid="CR205">205</xref>–<xref ref-type="bibr" rid="CR209">209</xref>, <xref ref-type="bibr" rid="CR213">213</xref>, <xref ref-type="bibr" rid="CR214">214</xref>], which generates a performance matrix of a candidate and provides guidance information for the search strategy.</p><p id="Par53">From the view of applied techniques, existing works primarily lie in three categories: RL-based NAS [<xref ref-type="bibr" rid="CR148">148</xref>–<xref ref-type="bibr" rid="CR151">151</xref>], differentiable NAS [<xref ref-type="bibr" rid="CR152">152</xref>, <xref ref-type="bibr" rid="CR153">153</xref>] and evolutionary NAS [<xref ref-type="bibr" rid="CR155">155</xref>–<xref ref-type="bibr" rid="CR157">157</xref>]. Although RL-based NAS methods can achieve superior performance, they often require thousands of GPUs performing several days even on a median-scale dataset. Differentiable NAS methods are usually more efficient than RL-based methods. However, they often find ill-conditioned architectures due to improper gradient-based optimization. Because evolutionary NAS methods are insensitive to local minima and do not require gradient information, they have shown promising characteristics in solving complex non-convex optimization problems [<xref ref-type="bibr" rid="CR223">223</xref>], even when the objective function’s mathematical form is unknown [<xref ref-type="bibr" rid="CR224">224</xref>].</p><p id="Par54">Regarding applications, existing studies typically either incorporate specific prior information into the construction of a NAS method or tackle some special issues within a particular visual task. Taking binocular depth estimation as an example, existing works [<xref ref-type="bibr" rid="CR195">195</xref>–<xref ref-type="bibr" rid="CR197">197</xref>] are proposed to preset the network architecture as a stereo matching network and search for the internal structures. For embedded devices, since memory cost and computation latency are highly considered in practical applications, existing works [<xref ref-type="bibr" rid="CR205">205</xref>–<xref ref-type="bibr" rid="CR209">209</xref>] evaluate these two factors during searching and encode them in the rewarding functions. In this way, the proposed NAS method can automatically generate a reasonable network with low memory cost and latency.</p></sec></sec><sec id="Sec20"><title>Integrated design automation for the “body-brain-eye” of intelligent robots</title><p id="Par55">At present, most studies separately design the morphologies, controllers and vision systems of intelligent robots. However, strong couplings exist between the designs of the morphologies, controllers, and vision systems [<xref ref-type="bibr" rid="CR225">225</xref>]. Therefore, it is necessary to consider the integrated design relationship of morphologies, controllers, and vision systems of intelligent robots. These strong coupling relationships are also reflected in nature. According to the law of “survival of the fittest” in biological evolution, many creatures have evolved a large diversity of eye structures and corresponding body morphologies. For example, the morphologies of birds and primates are very different, and their eye locations on the face are also different. It is believed that their brains’ mechanisms of processing visual information are also quite different. It is notable that through the cooperation of biological populations, the perception of individual organisms can be further improved [<xref ref-type="bibr" rid="CR226">226</xref>]. If studies in intelligent robots can automate the design of morphologies, controllers and vision systems, such as in biological evolution, intelligent robots with significantly improved performance may be developed.</p><p id="Par56">Qiao et al. [<xref ref-type="bibr" rid="CR227">227</xref>–<xref ref-type="bibr" rid="CR229">229</xref>] took the lead in introducing a “hand-eye-brain” system of intelligent robots that imitates the mechanism, structure and function of the human brain, nervous system, and body motor system. In their proposed method, the role of the “hand” is the motion control of the intelligent robots. Inspired by the “muscle-tendon-bone” organization, Qiao et al. [<xref ref-type="bibr" rid="CR230">230</xref>] established a control framework based on synergistic activation of muscles and an “attractive region in environment” theory [<xref ref-type="bibr" rid="CR231">231</xref>, <xref ref-type="bibr" rid="CR232">232</xref>]. This framework enabled high-precision flexible operation under low-precision morphologies and low-precision sensors. The role of “eyes” is to construct the visual cognitive system of intelligent robots. Inspired by the brain-inspired visual cognition and memory mechanism of the hippocampus, Qiao et al. [<xref ref-type="bibr" rid="CR233">233</xref>–<xref ref-type="bibr" rid="CR235">235</xref>] established a new visual recognition framework, ensuring that intelligent robots can achieve higher recognition accuracy and faster recognition speed. The role of the “brain” is the decision-making of intelligent robots. Inspired by the brain’s nervous system, Qiao et al. [<xref ref-type="bibr" rid="CR236">236</xref>, <xref ref-type="bibr" rid="CR237">237</xref>] introduced a brain-inspired motor decision model based on emotion regulation modulation. This model implemented high-level decision-making with an “accuracy-efficiency-speed” balance. Compared with the traditional robot design method, the proposed “hand-eye-brain” system of intelligent robots realizes human-like manipulation with high precision, flexibility, and robustness.</p><p id="Par57">Inspired by Qiao et al.’s “Hand-Eye-Brain” system of intelligent robots, this paper proposes an integrated “Body-Brain-Eye” design automation for intelligent robots, as illustrated in Fig. <xref rid="Fig11" ref-type="fig">11</xref>. Specifically, this paper proposes the integrated MODENA framework for automatically designing the morphologies, controllers, and vision systems of intelligent robots, inspired by the evolution of biological forms as displayed in Fig. <xref rid="Fig12" ref-type="fig">12</xref>. By constructing a modular graph model for the morphologies, controllers, and vision systems of intelligent robots under digital twin architectures and by applying powerful capabilities of genetic programming, evolutionary computation, deep learning, reinforcement learning, and causal reasoning in optimization, decision-making, and reasoning, the MODENA framework can achieve the purpose of obtaining innovative and optimal designs of intelligent robots. <fig id="Fig11"><label>Figure 11</label><caption xml:lang="en"><p>“Hand-Eye-Brain” system of intelligent robots <italic>vs</italic> integrated “Body-Brain-Eye” design automation for intelligent robots</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig11_HTML.png"/></fig><fig id="Fig12"><label>Figure 12</label><caption xml:lang="en"><p>The proposed MODENA for the morphologies, controllers, and vision systems of intelligent robots</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig12_HTML.png"/></fig></p><p id="Par58">In the process of applying MODENA to design the morphologies, controllers, and vision systems of intelligent robots, the construction of a modular graph model is a fundamental task. These modules are selected or designed according to the application scopes, operating characteristics, and functionalities of the designed robotic systems to meet pre-defined design specifications. In the mechanical field, the modular graph model contains running modules, link modules, joint modules, and end-effector modules, which are used to build the morphologies of intelligent robots [<xref ref-type="bibr" rid="CR238">238</xref>]. For the image processing part, the modular graph models may contain convolutional layers, pooling layers, and fully connected layers, among others, which are components of a deep neural network architecture that can be used to construct the vision systems of intelligent robots [<xref ref-type="bibr" rid="CR239">239</xref>]. In the control field, the modular graph model contains main control units, actuators, detecting units, among others, which build the controller of intelligent robots [<xref ref-type="bibr" rid="CR240">240</xref>]. For the control of swarm robots, the modular graph model contains basic network motifs that can be employed to automatically construct gene regulatory network (GRN) models. A multi-objective genetic programming method can be applied to optimize the structure and parameters of the GRN-based model in parallel so that the behavior of swarm robots can be controlled [<xref ref-type="bibr" rid="CR33">33</xref>].</p></sec><sec id="Sec21"><title>Problems and prospects</title><sec id="Sec22"><title>Existing problems</title><p id="Par59">In this section, we will explore the various aspects that should be considered in the integrated design automation for the “Body-Brain-Eye” of intelligent robots. These include modeling, optimization, knowledge extraction, environment perception, swarm robots, and generalization in unseen scenarios.</p><p id="Par60">(1) Unified Modeling for the “Body-Brain-Eye” of Intelligent Robots</p><p id="Par61">Since intelligent robots are typically multi-energy domain physical systems [<xref ref-type="bibr" rid="CR241">241</xref>, <xref ref-type="bibr" rid="CR242">242</xref>], we need to build a unified graph model to facilitate the design automation process. However, for different categories of intelligent robot modules, we still need to use different modeling tools. For example, we use a geometric model or a bond graph for morphologies, a finite state machine or a model predictive controller for controllers, a gene regulatory network for swarm control, and a deep neural network model for vision systems. Although all these models can be abstracted to a graph model, they are still different modeling languages. Different parts of the graph models need to be decoded separately to obtain the complete intelligent robot. On the other hand, various modules within the intelligent robots are usually coupled with each other, and it is still challenging to express this coupling relationship through a unified graph model.</p><p id="Par62">(2) Efficient Methods for Solving Robot Optimization Problems</p><p id="Par63">In the integrated “Body-Brain-Eye” design automation process of intelligent robots, various types of decision variables (e.g., continuous variables, discrete variables) [<xref ref-type="bibr" rid="CR243">243</xref>] are included, along with various types of optimization objectives and constraints with different difficulty types [<xref ref-type="bibr" rid="CR46">46</xref>]. The calculation of objectives or constraints is usually time-consuming [<xref ref-type="bibr" rid="CR244">244</xref>], and in most cases, external simulators need to be called, making it a computationally expensive optimization problem. Therefore, efficiently solving these constrained multi-objective optimization problems with mixed decision variables and expensive fitness evaluation is a challenging task.</p><p id="Par64">(3) Knowledge Extraction during the Design Process</p><p id="Par65">The optimization of integrated “Body-Brain-Eye” systems of intelligent robots in various experimental scenarios generates a vast amount of data, including intermediate data that contain crucial design knowledge as well as optimization-related knowledge [<xref ref-type="bibr" rid="CR245">245</xref>]. To extract knowledge and rules from the data with good interpretability, genetic programming methods are effective. However, their accuracy is limited. Deep learning methods, on the other hand, offer high model accuracy, but their black-box characteristics pose a problem for model interpretability. A crucial challenge in creating an iterative optimization system with feedback is to identify causal relationships within and between modules of an intelligent robot to gain innovative design knowledge automatically.</p><p id="Par66">(4) Multi-modal Information Fusion for Environment Perception</p><p id="Par67">The working environments faced by intelligent robots are often complex and varied. Therefore, intelligent robots should have the capability to learn actively and continuously optimize their systems during operations, make efficient and accurate judgments, and respond quickly and appropriately in complex and dynamic working environments. Hence, solving the problem of combining multi-modal architecture search and active vision technology to endow robots with the ability to integrate multi-sensor information and actively optimize their hardware system in real-time is essential.</p><p id="Par68">(5) Design Automation for Swarm Robots</p><p id="Par69">The control of swarm robots is witnessing rapid progress in applications, which can be divided into two categories: centralized control and decentralized control. Centralized control is a natural and widely accepted approach, but it faces many challenges when the size of the swarm increases to a certain level. For example, a large system with centralized control has insufficient fault tolerance. Failures of just a few individuals may lead to the failure of the whole system’s functionality. Computational costs may also increase dramatically, making it difficult to react to unexpected factors timely. As a result, decentralized control has received increasing attention recently and has gradually become a new mainstream. The key idea here is to design a proper (and in most cases a common) control scheme for each robot in the swarm so that the swarm as a whole can accomplish the specified tasks. It is obviously a challenge to do so, especially when the size of the swarm is large. To address this challenge, design automation approaches play an increasingly important role [<xref ref-type="bibr" rid="CR246">246</xref>], where MODENA can also contribute greatly [<xref ref-type="bibr" rid="CR33">33</xref>]. To design and manage such a complex UAV swarm system, the key challenge is to define a rigorous engineering approach to program each robot so that the UAV swarm behaves in a desired manner. How to distill the basic units of the swarm behavior strategy and thus carry out the research on the design automation of unmanned swarm behavior strategy is another emerging issue.</p><p id="Par70">(6) Poor Generalization in Unseen Scenarios</p><p id="Par71">Existing methods mostly automatically generate a model and utilize this fixed model for practical applications. However, this paradigm usually results in unsatisfactory performance, because the model is unable to generalize well to unseen testing scenarios that are different from the training one. Typically, this domain gap between training and testing scenarios is common in real-world applications since the environment is changing all the time, especially for vision systems. Therefore, how to design a NAS method to search for a robust vision model that can perform consistently among different scenes is an urgent issue to be addressed.</p></sec><sec id="Sec23"><title>Future directions</title><p id="Par72">Although significant progress has been made in modular design automation over the past two decades, several important issues still need to be addressed, and new application areas are emerging. The following subsections will discuss potential future research directions from two perspectives: theoretical studies and practical applications.</p><sec id="Sec24"><title>Theoretical studies</title><p id="Par73">(1) Multi-view Unified Modeling of Intelligent Robots</p><p id="Par74">Building a unified model of the morphology, controller and vision system of an intelligent robot is an effective approach to facilitate the design of automation processes. Currently, morphology, controller and vision systems are usually represented by different modeling tools and composed of various modules [<xref ref-type="bibr" rid="CR241">241</xref>, <xref ref-type="bibr" rid="CR242">242</xref>]. For example, when designing a mechanical system, the modeling language might be a bond graph. When designing an unmanned swarm controller, the modeling language may be a finite state machine or a gene regulatory network. When designing a vision system, the modeling language may be a deep neural network. Different modeling languages have different application scopes and characteristics, and it is challenging to capture the coupling relationships among the modules represented by them. Therefore, constructing a multi-view unified modeling tool that can represent the morphology, controller and vision systems effectively and efficiently is an essential direction for the design automation of intelligent robots.</p><p id="Par75">(2) Surrogate-assisted Constrained Multi-objective Optimization for Intelligent Robots</p><p id="Par76">The optimization of intelligent robots often requires the simultaneous consideration of multiple conflicting design objectives and a large number of constraints. In addition, the calculations of objectives and constraints are usually time-consuming and often require the invocation of external simulation software. Therefore, the optimization problem of an intelligent robot can be defined as an expensive constrained multi-objective optimization problem [<xref ref-type="bibr" rid="CR46">46</xref>, <xref ref-type="bibr" rid="CR247">247</xref>]. In the research of MODENA for intelligent robots, constrained multi-objective evolutionary algorithms are gradually becoming a popular approach to solve the above multi-objective optimization problems. In the study of constrained multi-objective evolutionary algorithms, the conventional view is that each infeasible region is equally important. Only the constraints represented by infeasible regions close to the unconstrained Pareto front affect the true Pareto front. Therefore, how to take advantage of features like this to deal with the contradiction among convergence, diversity and feasibility has become a major consideration in designing constrained multi-objective optimization algorithms. In terms of surrogate models, considering an adaptive surrogate model approach by combining global and local surrogate models for optimization objectives and constraints to establish novel constrained multi-objective evolutionary algorithms is another direction worthy of in-depth investigation in the future.</p><p id="Par77">(3) Knowledge Extraction in Design Automation</p><p id="Par78">The knowledge extracted in the design automation process of intelligent robots involves both explicit knowledge and implicit knowledge. Explicit knowledge is also called human knowledge, which can often be directly understood by human experts and has very good interpretability. On the other hand, implicit knowledge is usually not directly understandable by humans, but can be stored and inferred by machines. Thus, it is also called machine knowledge, which has the potential to be understood by humans one day in the future. Symbolic regression, a method based on genetic programming, is usually used for explicit knowledge mining. This method can automatically mine the explicit knowledge contained in the data by manually defining a set of functions and terminals using prior knowledge of the problem domain. Causal reasoning, an emerging research field, can also be used to obtain explainable knowledge. This can, in turn, guide the search for expensive constrained multi-objective evolutionary algorithms and the adjustment of the problem formulation of the intelligent robot optimization problems.</p><p id="Par79">(4) MODENA for Intelligent Robots Based on Digital Twins</p><p id="Par80">MODENA for intelligent robots necessitates numerous simulations and experiments in both virtual and real-world environments. These efforts can be significantly expedited through the application of emerging digital twin technology. This technology creates a unique type of metaspace that replicates the physical laws of space with exceptional precision and is a subset of the Metaverse. Traditional methods of designing intelligent robots typically involve a laborious and time-consuming trial-and-error process. Conversely, implementing the digital twin approach enables the faithful mapping of the robot from real space to virtual space in four dimensions: geometry, contact dynamics, behavior, and rules. Moreover, it allows for the arbitrary adjustment of the morphology, controller, and vision systems, generating practically unlimited design candidates whose optimization is efficiently supported through the integration of the powerful capabilities of machine learning and evolutionary computing. Additionally, machine learning can be used to mine knowledge and rules from data generated during the design process, which can then be utilized in future design activities. Therefore, exploring how to fully harness the power of digital twin technology for MODENA is another crucial area of study.</p><p id="Par81">(5) Domain Adaptation and Generalization in Design Automation</p><p id="Par82">Since the poor generalization ability of designed models to unseen scenarios is an urgent issue, especially for vision systems, model robustness becomes an important factor when designing a NAS method. A promising solution is to introduce domain adaptation [<xref ref-type="bibr" rid="CR248">248</xref>] and generalization [<xref ref-type="bibr" rid="CR249">249</xref>] evaluation in the design procedure, which focuses on transferring learned knowledge in training scenarios to unseen testing ones. Specifically, we can introduce an additional evaluation matrix for generalization ability for candidate model selection. In this way, the search strategy can choose a model with a particular trade-off that can achieve good performance and be robust to noisy and varied environments. There are a few works [<xref ref-type="bibr" rid="CR250">250</xref>–<xref ref-type="bibr" rid="CR252">252</xref>] that concentrate on this appealing direction.</p><p id="Par83">(6) Active and Continual Learning in Design Automation</p><p id="Par84">In addition to designing a robust model, another solution to tackle the poor generalization issue is to perform online learning in testing scenarios, which can allow the model to quickly adjust its parameters and adapt to unknown environments. To achieve effective online learning, there are two key problems to be solved. First, the model needs to figure out what to learn in a given environment. To address this, active vision and learning [<xref ref-type="bibr" rid="CR253">253</xref>, <xref ref-type="bibr" rid="CR254">254</xref>] can guide models to explore valuable targets and learn superior decision-making behaviors, as studied in different applications, including robot exploration [<xref ref-type="bibr" rid="CR255">255</xref>–<xref ref-type="bibr" rid="CR257">257</xref>], unmanned aerial vehicle (UAV) swarm localization, and other tasks [<xref ref-type="bibr" rid="CR258">258</xref>–<xref ref-type="bibr" rid="CR260">260</xref>]. Second, the model needs to overcome the catastrophic forgetting issue during online learning. Specifically, when the model learns new knowledge in a new scene, the previously learned knowledge will be dramatically forgotten, leading to a severe overfitting issue and making the model harder to generalize to another unseen scene. To tackle this issue, continual learning [<xref ref-type="bibr" rid="CR261">261</xref>] has been proposed to guide models to continually learn over time by accommodating new knowledge while retaining previously learned experiences. Several works [<xref ref-type="bibr" rid="CR262">262</xref>–<xref ref-type="bibr" rid="CR264">264</xref>] have tried to introduce continual learning in NAS.</p><p id="Par85">To summarize, it is important and desirable for a model to automatically optimize itself and adapt to varied and unseen scenarios, achieving higher levels of intelligence. This remains as an open and attractive problem in the design automation of intelligent robotic vision systems.</p></sec><sec id="Sec25"><title>Practical applications</title><p id="Par86">In this section, we present some exemplary scenarios to illustrate the potential benefits of applying MODENA. For instance, power plants serve as the cornerstone of the power system, and their operational health plays a crucial role in ensuring the system’s safety. The intricate layout of pipelines in power plants makes manual inspection challenging. Moreover, manual inspection is vulnerable to problems such as missed inspections, false inspections, and concerns about the personal safety of inspectors, which can be influenced by various factors, such as labor intensity and weather conditions. With the advent of heterogeneous unmanned swarm technology, the integration of flying inspection robots, ground inspection robots, and pipeline leak-detecting and repairing robots has become technically feasible, offering significant advantages over manual inspections. This integration may also become a hot research theme in the future, as illustrated in Fig. <xref rid="Fig13" ref-type="fig">13</xref>. Therefore, we suggest considering the following prospects for future research in this paper. <fig id="Fig13"><label>Figure 13</label><caption xml:lang="en"><p>The integrated “Body-Brain-Eye” design automation for heterogeneous unmanned swarm system of inspection and repair robots used in the power plant</p></caption><graphic specific-use="web" mime-subtype="PNG" xlink:href="MediaObjects/44267_2023_6_Fig13_HTML.png"/></fig></p><p id="Par87">(1) Design Automation for the Morphologies of Unmanned Swarm Systems</p><p id="Par88">Unmanned swarm systems need to accomplish multiple tasks, and the relationship between their overall performance and component properties is extremely complex, which makes the morphological structure design of unmanned swarm systems complicated. The MODENA method provides a new idea for the morphological structure design of unmanned swarm systems. For example, in the power plant environment, the unmanned swarm contains flying inspection robots, ground inspection robots and pipeline leak-detecting and repairing robots. Their morphologies differ greatly, with different application scopes, operation characteristics, functions and performances. Designing corresponding morphological models based on the application scopes, operational characteristics, functions, and performances of various robots within unmanned swarm systems to achieve superior overall performance is a challenge and a focus of future research.</p><p id="Par89">(2) Design Automation for the Environmental Perception and Cognitive Systems of Unmanned Swarm Systems</p><p id="Par90">In complex environments with high dynamics, uncertainty and resource constraints, unmanned swarm systems need to achieve distributed sensing and cognition of the environment through multi-modal interaction techniques. For example, in the power plant environment, aerial inspection robots equipped with vision sensors, ground inspection robots equipped with high-precision LIDAR and vision sensors, and ground repair robots equipped with infrared vision sensors work together to achieve rapid and precise localization of power plant faults and timely repair through data obtained from different sensors. It is crucial to design a proper model that can process heterogeneous sensor data to achieve efficient perception and cognition of complex environments. Therefore, research on the design automation of the visual perception model is an important direction for distributed environment perception and cognition.</p><p id="Par91">(3) Design Automation for the Controllers of Unmanned Swarm Systems</p><p id="Par92">Because the environment faced by an unmanned swarm system is uncertain or unpredictable, it is difficult to design algorithms that can control swarm behaviors based on accurate models. In swarm control, the biggest challenge is to design a proper control scheme for each robot so that the swarm as a whole can generate collective behavior that can accomplish the pre-defined task for the swarm. Since each robot in the swarm follows the same behavioral model, designing controllers using traditional methods faces great difficulty. Design automation methods can play a significant role here since they can generate and explore a large number of potential candidates with the help of digital twin technology. Design automation techniques can also identify the optimal ones that satisfy the specified task requirements more efficiently by using metaheuristic methods, such as evolutionary computation. Therefore, the design automation of behavioral control strategies for UAV swarms based on evolutionary algorithms is another important research direction.</p></sec></sec></sec><sec id="Sec26" sec-type="conclusions"><title>Conclusion</title><p id="Par93">In this paper, we present a comprehensive survey of MODENA for designing the morphologies, controllers and vision systems of intelligent robots. Given the increasing complexity of working environments and the diversification of tasks, there is a growing need for MODENA to design the “Body-Brain-Eye” of intelligent robots. In the MODENA approach, the robot system’s morphology, controller, and vision systems can all be expressed as a graphical model. By automatically exploring the design space of the graphical model, a set of design candidates of intelligent robots that satisfy pre-defined functions and requirements can be obtained. The key components in MODENA include surrogate-assisted constrained multi-objective evolutionary algorithms (CMOEAs), topological search algorithms such as genetic programming, neural architecture search, and techniques for knowledge extraction during the design process, among others. MODENA is a core technology that can significantly improve the design efficiency and performance of robots, and it will become an increasingly important research theme in the future for designing either individual or swarm robots, just as EDA has played an important role in both academia and industry.</p></sec></body><back><ack><title>Acknowledgements</title><p>The authors would like to express their sincere gratitude to the International Cooperation Base of Evolutionary Intelligence and Robotics of Guangdong Province, China, and the Key Laboratory of Intelligent Manufacturing Technology (Shantou University), Ministry of Education, China, for their invaluable support and assistance in this study.</p></ack><sec sec-type="author-contribution"><title>Author contributions</title><p>All authors contributed to the study’s conception and design. The idea for the article was performed by ZH and ZF. The literature search and data analysis were performed by RM, PR, QZ, YZ and NX. The first draft of the manuscript was written by WL, JFZ and ZW. ZF, BX and LG revised the manuscript. In addition, all authors commented on previous versions of the manuscript, and read and approved the final manuscript.</p></sec><sec><title>Funding</title><p>This research was supported in part by National Key R&amp;D Program of China (No. 2021ZD0111501), National Natural Science Foundation of China (No. 62176147), Science and Technology Planning Project of Guangdong Province of China (Nos. 2021A0505030072 and 2022A1515110660), Science and Technology Special Funds Project of Guangdong Province of China (Nos. STKJ2021176 and STKJ2021019), and STU Scientific Research Foundation for Talents (Nos. NTF21001 and NTF22030).</p></sec><sec sec-type="data-availability"><title>Availability of data and materials</title><p>The datasets generated during and/or analyzed during the current study are available from the corresponding author upon reasonable request.</p></sec><sec sec-type="ethics-statement"><title>Declarations</title><sec id="FPar1" sec-type="COI-statement"><title>Competing interests</title><p id="Par119">The authors declare no competing interests.</p></sec></sec><glossary><title>Abbreviations</title><def-list><def-item><term>AI</term><def><p id="Par94">Artificial Intelligence</p></def></def-item><def-item><term>AMC</term><def><p id="Par95">Automated Model Compression</p></def></def-item><def-item><term>BG</term><def><p id="Par96">Bond Graph</p></def></def-item><def-item><term>BGGP</term><def><p id="Par97">Bond Graph and Genetic Programming</p></def></def-item><def-item><term>CAE</term><def><p id="Par98">Computer Aided Engineering</p></def></def-item><def-item><term>CMOEAs</term><def><p id="Par99">Constrained Multi-objective Evolutionary Algorithms</p></def></def-item><def-item><term>DARTS</term><def><p id="Par100">Differentiable Architecture Search</p></def></def-item><def-item><term>EASNet</term><def><p id="Par101">Elastic and Accurate Network for Stereo Matching</p></def></def-item><def-item><term>EDA</term><def><p id="Par102">Electronic Design Automation</p></def></def-item><def-item><term>FPN</term><def><p id="Par103">Feature Pyramid Network</p></def></def-item><def-item><term>FSA</term><def><p id="Par104">Finite State Automaton</p></def></def-item><def-item><term>GP</term><def><p id="Par105">Genetic Programming</p></def></def-item><def-item><term>GRN</term><def><p id="Par106">Gene Regulatory Network</p></def></def-item><def-item><term>HBG</term><def><p id="Par107">Hybrid Bond Graph</p></def></def-item><def-item><term>iTGM</term><def><p id="Par108">Inflated Temporal Gaussian Mixture</p></def></def-item><def-item><term>ITO</term><def><p id="Par109">Isogeometric Topology Optimization</p></def></def-item><def-item><term>LSTM</term><def><p id="Par110">Long Short-term Memory</p></def></def-item><def-item><term>MDA</term><def><p id="Par111">Mechatronic Design Automation</p></def></def-item><def-item><term>MODENA</term><def><p id="Par112">Modular Design Automation</p></def></def-item><def-item><term>MPC</term><def><p id="Par113">Model Predictive Control</p></def></def-item><def-item><term>NAS</term><def><p id="Par114">Neural Architecture Search</p></def></def-item><def-item><term>NEAT</term><def><p id="Par115">the Neuroevolution of Augmenting Topologies</p></def></def-item><def-item><term>PID</term><def><p id="Par116">Proportional-Integral-Derivative</p></def></def-item><def-item><term>SOTA</term><def><p id="Par117">State-of-the-art</p></def></def-item><def-item><term>UAVs</term><def><p id="Par118">Unmanned Aerial Vehicles</p></def></def-item></def-list></glossary><ref-list id="Bib1"><title>References</title><ref-list><ref id="CR1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>M. F.</given-names></name><name><surname>Cortese</surname><given-names>A. J.</given-names></name><name><surname>Liu</surname><given-names>Q.</given-names></name><name><surname>Zheng</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>W.</given-names></name><name><surname>Norris</surname><given-names>S. L.</given-names></name><etal/></person-group><article-title xml:lang="en">Microscopic robots with onboard digital control</article-title><source>Science Robotics</source><year>2022</year><volume>7</volume><issue>70</issue><pub-id pub-id-type="doi">10.1126/scirobotics.abq2296</pub-id></mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Billard</surname><given-names>A.</given-names></name><name><surname>Kragic</surname><given-names>D.</given-names></name></person-group><article-title xml:lang="en">Trends and challenges in robot manipulation</article-title><source>Science</source><year>2019</year><volume>364</volume><issue>6446</issue><pub-id pub-id-type="doi">10.1126/science.aat8414</pub-id></mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macenski</surname><given-names>S.</given-names></name><name><surname>Foote</surname><given-names>T.</given-names></name><name><surname>Gerkey</surname><given-names>B.</given-names></name><name><surname>Lalancette</surname><given-names>C.</given-names></name><name><surname>Woodall</surname><given-names>W.</given-names></name></person-group><article-title xml:lang="en">Robot operating system 2: design, architecture, and uses in the wild</article-title><source>Science Robotics</source><year>2022</year><volume>7</volume><issue>66</issue><pub-id pub-id-type="doi">10.1126/scirobotics.abm6074</pub-id></mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Honarpardaz</surname><given-names>M.</given-names></name><name><surname>Ölvander</surname><given-names>J.</given-names></name><name><surname>Tarkian</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">Fast finger design automation for industrial robots</article-title><source>Robotics and Autonomous Systems</source><year>2019</year><volume>113</volume><fpage>120</fpage><lpage>131</lpage><pub-id pub-id-type="doi">10.1016/j.robot.2018.12.011</pub-id></mixed-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lipson</surname><given-names>H.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Bar-Cohen</surname><given-names>Y.</given-names></name></person-group><article-title xml:lang="en">Evolutionary robotics and open-ended design automation</article-title><source>Biomimetics—biologically inspired technologies</source><year>2005</year><publisher-loc>Boca Raton</publisher-loc><publisher-name>CRC Press</publisher-name><fpage>147</fpage><lpage>174</lpage></mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoebert</surname><given-names>T.</given-names></name><name><surname>Lepuschitz</surname><given-names>W.</given-names></name><name><surname>Vincze</surname><given-names>M.</given-names></name><name><surname>Merdan</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">Knowledge-driven framework for industrial robotic systems</article-title><source>Journal of Intelligent Manufacturing</source><year>2021</year><volume>34</volume><issue>2</issue><fpage>771</fpage><lpage>788</lpage><pub-id pub-id-type="doi">10.1007/s10845-021-01826-8</pub-id></mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramos</surname><given-names>F.</given-names></name><name><surname>Vázquez</surname><given-names>A. S.</given-names></name><name><surname>Fernández</surname><given-names>R.</given-names></name><name><surname>Olivares-Alarcos</surname><given-names>A.</given-names></name></person-group><article-title xml:lang="en">Ontology based design, control and programming of modular robots</article-title><source>Integrated Computer-Aided Engineering</source><year>2018</year><volume>25</volume><issue>2</issue><fpage>173</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.3233/ICA-180569</pub-id></mixed-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Short</surname><given-names>M.</given-names></name><name><surname>Burn</surname><given-names>K.</given-names></name></person-group><article-title xml:lang="en">A generic controller architecture for intelligent robotic systems</article-title><source>Robotics and Computer-Integrated Manufacturing</source><year>2011</year><volume>27</volume><issue>2</issue><fpage>292</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1016/j.rcim.2010.07.013</pub-id></mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="other">
					Armangué Quintana, X. (2003). <italic>Modelling stereoscopic vision systems for robotic applications</italic>. PhD thesis, Universitat de Girona.
				</mixed-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Diveev</surname><given-names>A.</given-names></name><name><surname>Sofronova</surname><given-names>E.</given-names></name></person-group><article-title xml:lang="en">Automation of synthesized optimal control problem solution for mobile robot by genetic programming</article-title><source>Proceedings of SAI intelligent systems conference</source><year>2019</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>1054</fpage><lpage>1072</lpage></mixed-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alattas</surname><given-names>R. J.</given-names></name><name><surname>Patel</surname><given-names>S.</given-names></name><name><surname>Sobh</surname><given-names>T. M.</given-names></name></person-group><article-title xml:lang="en">Evolutionary modular robotics: survey and analysis</article-title><source>Journal of Intelligent &amp; Robotic Systems</source><year>2019</year><volume>95</volume><issue>3</issue><fpage>815</fpage><lpage>828</lpage><pub-id pub-id-type="doi">10.1007/s10846-018-0902-9</pub-id></mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pierson</surname><given-names>H. A.</given-names></name><name><surname>Gashler</surname><given-names>M. S.</given-names></name></person-group><article-title xml:lang="en">Deep learning in robotics: a review of recent research</article-title><source>Advanced Robotics</source><year>2017</year><volume>31</volume><issue>16</issue><fpage>821</fpage><lpage>835</lpage><pub-id pub-id-type="doi">10.1080/01691864.2017.1365009</pub-id></mixed-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>B.</given-names></name><name><surname>Kumar</surname><given-names>R.</given-names></name><name><surname>Singh</surname><given-names>V. P.</given-names></name></person-group><article-title xml:lang="en">Reinforcement learning in robotic applications: a comprehensive survey</article-title><source>Artificial Intelligence Review</source><year>2022</year><volume>55</volume><issue>2</issue><fpage>945</fpage><lpage>990</lpage><pub-id pub-id-type="doi">10.1007/s10462-021-09997-9</pub-id></mixed-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hellström</surname><given-names>T.</given-names></name></person-group><article-title xml:lang="en">The relevance of causation in robotics: a review, categorization, and analysis</article-title><source>Paladyn, Journal of Behavioral Robotics</source><year>2021</year><volume>12</volume><issue>1</issue><fpage>238</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1515/pjbr-2021-0017</pub-id></mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lipson</surname><given-names>H.</given-names></name><name><surname>Pollack</surname><given-names>J. B.</given-names></name></person-group><article-title xml:lang="en">Automatic design and manufacture of robotic lifeforms</article-title><source>Nature</source><year>2000</year><volume>406</volume><issue>6799</issue><fpage>974</fpage><lpage>978</lpage><pub-id pub-id-type="doi">10.1038/35023115</pub-id></mixed-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kwiatkowski</surname><given-names>R.</given-names></name><name><surname>Lipson</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Task-agnostic self-modeling machines</article-title><source>Science Robotics</source><year>2019</year><volume>4</volume><issue>26</issue><pub-id pub-id-type="doi">10.1126/scirobotics.aau9354</pub-id></mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>M.</given-names></name><name><surname>Lipson</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Distilling free-form natural laws from experimental data</article-title><source>Science</source><year>2009</year><volume>324</volume><issue>5923</issue><fpage>81</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1126/science.1165893</pub-id></mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zykov</surname><given-names>V.</given-names></name><name><surname>Mytilinaios</surname><given-names>E.</given-names></name><name><surname>Adams</surname><given-names>B.</given-names></name><name><surname>Lipson</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Self-reproducing machines</article-title><source>Nature</source><year>2005</year><volume>435</volume><issue>7039</issue><fpage>163</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1038/435163a</pub-id></mixed-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Seo</surname><given-names>K.</given-names></name><name><surname>Hu</surname><given-names>J.</given-names></name><name><surname>Goodman</surname><given-names>E. D.</given-names></name><name><surname>Rosenberg</surname><given-names>R. C.</given-names></name></person-group><article-title xml:lang="en">A novel evolutionary engineering design approach for mixed-domain systems</article-title><source>Engineering Optimization</source><year>2004</year><volume>36</volume><issue>2</issue><fpage>127</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1080/03052150410001647957</pub-id></mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>P.</given-names></name><name><surname>Wei</surname><given-names>Z.</given-names></name><name><surname>Guo</surname><given-names>Z.</given-names></name><name><surname>Jia</surname><given-names>L.</given-names></name><name><surname>Han</surname><given-names>G.</given-names></name><name><surname>Si</surname><given-names>C.</given-names></name><name><surname>Ning</surname><given-names>J.</given-names></name><name><surname>Yang</surname><given-names>F.</given-names></name></person-group><article-title xml:lang="en">A real-time circuit phase delay correction system for MEMS vibratory gyroscopes</article-title><source>Micromachines</source><year>2021</year><volume>12</volume><issue>5</issue><pub-id pub-id-type="doi">10.3390/mi12050506</pub-id></mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krylov</surname><given-names>G.</given-names></name><name><surname>Kawa</surname><given-names>J.</given-names></name><name><surname>Friedman</surname><given-names>E. G.</given-names></name></person-group><article-title xml:lang="en">Design automation of superconductive digital circuits: a review</article-title><source>IEEE Nanotechnology Magazine</source><year>2021</year><volume>15</volume><issue>6</issue><fpage>54</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1109/MNANO.2021.3113218</pub-id></mixed-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gongora</surname><given-names>A. E.</given-names></name><name><surname>Xu</surname><given-names>B.</given-names></name><name><surname>Perry</surname><given-names>W.</given-names></name><name><surname>Okoye</surname><given-names>C.</given-names></name><name><surname>Riley</surname><given-names>P.</given-names></name><name><surname>Reyes</surname><given-names>K. G.</given-names></name><name><surname>Morgan</surname><given-names>E. F.</given-names></name><name><surname>Brown</surname><given-names>K. A.</given-names></name></person-group><article-title xml:lang="en">A Bayesian experimental autonomous researcher for mechanical design</article-title><source>Science Advances</source><year>2020</year><volume>6</volume><issue>15</issue><pub-id pub-id-type="doi">10.1126/sciadv.aaz1708</pub-id></mixed-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sneineh</surname><given-names>A. A.</given-names></name><name><surname>Salah</surname><given-names>W. A.</given-names></name></person-group><article-title xml:lang="en">Design and implementation of an automatically aligned solar tracking system</article-title><source>International Journal of Power Electronics and Drive Systems</source><year>2019</year><volume>10</volume><issue>4</issue></mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Terpenny</surname><given-names>J. P.</given-names></name><name><surname>Goodman</surname><given-names>E. D.</given-names></name></person-group><article-title xml:lang="en">Knowledge interaction with genetic programming in mechatronic systems design using bond graphs</article-title><source>IEEE Transactions on Systems, Man and Cybernetics. Part C, Applications and Reviews</source><year>2005</year><volume>35</volume><issue>2</issue><fpage>172</fpage><lpage>182</lpage></mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behbahani</surname><given-names>S.</given-names></name><name><surname>de Silva</surname><given-names>C. W.</given-names></name></person-group><article-title xml:lang="en">System-based and concurrent design of a smart mechatronic system using the concept of mechatronic design quotient (MDQ)</article-title><source>IEEE/ASME Transactions on Mechatronics</source><year>2008</year><volume>13</volume><issue>1</issue><fpage>14</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1109/TMECH.2007.915058</pub-id></mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dupuis</surname><given-names>J.-F.</given-names></name><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Goodman</surname><given-names>E. D.</given-names></name></person-group><article-title xml:lang="en">Evolutionary design of both topologies and parameters of a hybrid dynamical system</article-title><source>IEEE Transactions on Evolutionary Computation</source><year>2012</year><volume>16</volume><issue>3</issue><fpage>391</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1109/TEVC.2011.2159724</pub-id></mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garattoni</surname><given-names>L.</given-names></name><name><surname>Birattari</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">Autonomous task sequencing in a robot swarm</article-title><source>Science Robotics</source><year>2018</year><volume>3</volume><issue>20</issue><pub-id pub-id-type="doi">10.1126/scirobotics.aat0430</pub-id></mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>Z.</given-names></name></person-group><source>Mechatronic design automation: an emerging research and recent advances</source><year>2010</year><publisher-loc>New York</publisher-loc><publisher-name>Nova Science Publishers</publisher-name></mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Goodman</surname><given-names>E.</given-names></name></person-group><article-title xml:lang="en">Exploring open-ended design space of mechatronic systems</article-title><source>International Journal of Advanced Robotic Systems</source><year>2004</year><volume>1</volume><issue>4</issue><fpage>295</fpage><lpage>302</lpage><pub-id pub-id-type="doi">10.5772/5636</pub-id></mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindsay</surname><given-names>G. W.</given-names></name></person-group><article-title xml:lang="en">Convolutional neural networks as a model of the visual system: past, present, and future</article-title><source>Journal of Cognitive Neuroscience</source><year>2021</year><volume>33</volume><issue>10</issue><fpage>2017</fpage><lpage>2031</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01544</pub-id></mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qian</surname><given-names>Y.</given-names></name><name><surname>Chen</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>S.</given-names></name></person-group><article-title xml:lang="en">Audio-visual deep neural network for robust person verification</article-title><source>IEEE/ACM Transactions on Audio, Speech and Language Processing</source><year>2021</year><volume>29</volume><fpage>1079</fpage><lpage>1092</lpage><pub-id pub-id-type="doi">10.1109/TASLP.2021.3057230</pub-id></mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="other">
					Cai, Y., Li, H., Fan, Z., Hong, J., Xu, P., Cheng, H., Zhu, X., Hu, B., &amp; Hao, Z. (2022). <italic>VGSwarm: a vision-based gene regulation network for UAVs swarm behavior emergence</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:2206.08669" ext-link-type="uri">arXiv:2206.08669</ext-link>.
				</mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">
					Fan, Z., Wang, Z., Zhu, X., Hu, B., Zou, A., &amp; Bao, D. (2019). <italic>An automatic design framework of swarm pattern formation based on multi-objective genetic programming</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:1910.14627" ext-link-type="uri">arXiv:1910.14627</ext-link>.
				</mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Tan</surname><given-names>Y.</given-names></name></person-group><article-title xml:lang="en">A probabilistic finite state machine based strategy for multi-target search using swarm robotics</article-title><source>Applied Soft Computing</source><year>2019</year><volume>77</volume><fpage>467</fpage><lpage>483</lpage><pub-id pub-id-type="doi">10.1016/j.asoc.2019.01.023</pub-id></mixed-citation></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>G.</given-names></name><name><surname>Ding</surname><given-names>H.</given-names></name><name><surname>Feng</surname><given-names>Z.</given-names></name></person-group><article-title xml:lang="en">Optimal design of hydraulic excavator shovel attachment based on multiobjective evolutionary algorithm</article-title><source>IEEE/ASME Transactions on Mechatronics</source><year>2019</year><volume>24</volume><issue>2</issue><fpage>808</fpage><lpage>819</lpage><pub-id pub-id-type="doi">10.1109/TMECH.2019.2903140</pub-id></mixed-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsiao</surname><given-names>J. C.</given-names></name><name><surname>Shivam</surname><given-names>K.</given-names></name><name><surname>Chou</surname><given-names>C. L.</given-names></name><name><surname>Kam</surname><given-names>T. Y.</given-names></name></person-group><article-title xml:lang="en">Shape design optimization of a robot arm using a surrogate-based evolutionary approach</article-title><source>Applied Sciences</source><year>2020</year><volume>10</volume><issue>7</issue><pub-id pub-id-type="doi">10.3390/app10072223</pub-id></mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Datta</surname><given-names>R.</given-names></name><name><surname>Deb</surname><given-names>K.</given-names></name></person-group><article-title xml:lang="en">Multi-objective design and analysis of robot gripper configurations using an evolutionary-classical approach</article-title><source>Proceedings of the 13th annual conference on genetic and evolutionary computation</source><year>2011</year><publisher-loc>New York</publisher-loc><publisher-name>ACM</publisher-name><fpage>1843</fpage><lpage>1850</lpage><pub-id pub-id-type="doi">10.1145/2001576.2001823</pub-id></mixed-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Datta</surname><given-names>R.</given-names></name><name><surname>Pradhan</surname><given-names>S.</given-names></name><name><surname>Bhattacharya</surname><given-names>B.</given-names></name></person-group><article-title xml:lang="en">Analysis and design optimization of a robotic gripper using multiobjective genetic algorithm</article-title><source>IEEE Transactions on Systems, Man, and Cybernetics: Systems</source><year>2015</year><volume>46</volume><issue>1</issue><fpage>16</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1109/TSMC.2015.2437847</pub-id></mixed-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rezazadeh</surname><given-names>S.</given-names></name><name><surname>Hurst</surname><given-names>J. W.</given-names></name></person-group><article-title xml:lang="en">On the optimal selection of motors and transmissions for electromechanical and robotic systems</article-title><source>2014 IEEE/RSJ international conference on intelligent robots and systems</source><year>2014</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>4605</fpage><lpage>4611</lpage><pub-id pub-id-type="doi">10.1109/IROS.2014.6943215</pub-id></mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murata</surname><given-names>S.</given-names></name><name><surname>Yoshida</surname><given-names>E.</given-names></name><name><surname>Kamimura</surname><given-names>A.</given-names></name><name><surname>Kurokawa</surname><given-names>H.</given-names></name><name><surname>Tomita</surname><given-names>K.</given-names></name><name><surname>Kokaji</surname><given-names>S.</given-names></name></person-group><article-title xml:lang="en">M-TRAN: self-reconfigurable modular robotic system</article-title><source>IEEE/ASME Transactions on Mechatronics</source><year>2002</year><volume>7</volume><issue>4</issue><fpage>431</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1109/TMECH.2002.806220</pub-id></mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>W.-M.</given-names></name><name><surname>Salemi</surname><given-names>B.</given-names></name><name><surname>Will</surname><given-names>P.</given-names></name></person-group><article-title xml:lang="en">Hormone-inspired adaptive communication and distributed control for CONRO self-reconfigurable robots</article-title><source>IEEE Transactions on Robotics and Automation</source><year>2002</year><volume>18</volume><issue>5</issue><fpage>700</fpage><lpage>712</lpage><pub-id pub-id-type="doi">10.1109/TRA.2002.804502</pub-id></mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brandt</surname><given-names>D.</given-names></name><name><surname>Christensen</surname><given-names>D. J.</given-names></name><name><surname>Lund</surname><given-names>H. H.</given-names></name></person-group><article-title xml:lang="en">ATRON robots: versatility from self-reconfigurable modules</article-title><source>2007 international conference on mechatronics and automation</source><year>2007</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>26</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1109/ICMA.2007.4303511</pub-id></mixed-citation></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>West</surname><given-names>C.</given-names></name><name><surname>Montazeri</surname><given-names>A.</given-names></name><name><surname>Monk</surname><given-names>S. D.</given-names></name><name><surname>Taylor</surname><given-names>C. J.</given-names></name></person-group><article-title xml:lang="en">A genetic algorithm approach for parameter optimization of a 7DOF robotic manipulator</article-title><source>IFAC-PapersOnLine</source><year>2016</year><volume>49</volume><issue>12</issue><fpage>1261</fpage><lpage>1266</lpage><pub-id pub-id-type="doi">10.1016/j.ifacol.2016.07.688</pub-id></mixed-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>Y.</given-names></name><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Li</surname><given-names>W.</given-names></name><name><surname>Chen</surname><given-names>S.</given-names></name><name><surname>Zhao</surname><given-names>L.</given-names></name><name><surname>Xie</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">A manipulator design optimization based on constrained multi-objective evolutionary algorithms</article-title><source>2016 international conference on industrial informatics-computing technology, intelligent technology, industrial information integration (ICIICII)</source><year>2016</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>199</fpage><lpage>205</lpage></mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassan</surname><given-names>A.</given-names></name><name><surname>Abomoharam</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">Modeling and design optimization of a robot gripper mechanism</article-title><source>Robotics and Computer-Integrated Manufacturing</source><year>2017</year><volume>46</volume><fpage>94</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1016/j.rcim.2016.12.012</pub-id></mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>You</surname><given-names>Y.</given-names></name><name><surname>Cai</surname><given-names>X.</given-names></name><name><surname>Zheng</surname><given-names>H.</given-names></name><name><surname>Zhu</surname><given-names>G.</given-names></name><name><surname>Li</surname><given-names>W.</given-names></name><name><surname>Garg</surname><given-names>A.</given-names></name><name><surname>Deb</surname><given-names>K.</given-names></name><name><surname>Goodman</surname><given-names>E.</given-names></name></person-group><article-title xml:lang="en">Analysis and multi-objective optimization of a kind of teaching manipulator</article-title><source>Swarm and Evolutionary Computation</source><year>2019</year><volume>50</volume><pub-id pub-id-type="doi">10.1016/j.swevo.2019.06.011</pub-id></mixed-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Li</surname><given-names>W.</given-names></name><name><surname>Cai</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>H.</given-names></name><name><surname>Wei</surname><given-names>C.</given-names></name><name><surname>Zhang</surname><given-names>Q.</given-names></name><name><surname>Deb</surname><given-names>K.</given-names></name><name><surname>Goodman</surname><given-names>E.</given-names></name></person-group><article-title xml:lang="en">Push and pull search for solving constrained multi-objective optimization problems</article-title><source>Swarm and Evolutionary Computation</source><year>2019</year><volume>44</volume><fpage>665</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1016/j.swevo.2018.08.017</pub-id></mixed-citation></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z.</given-names></name><name><surname>Zheng</surname><given-names>Y.</given-names></name><name><surname>Hu</surname><given-names>Z.</given-names></name><name><surname>Liu</surname><given-names>L.</given-names></name><name><surname>Zhao</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Pan</surname><given-names>J.</given-names></name></person-group><article-title xml:lang="en">A computational framework for robot hand design via reinforcement learning</article-title><source>2021 IEEE/RSJ international conference on intelligent robots and systems (IROS)</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>7216</fpage><lpage>7222</lpage><pub-id pub-id-type="doi">10.1109/IROS51168.2021.9636305</pub-id></mixed-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hornby</surname><given-names>G. S.</given-names></name><name><surname>Lipson</surname><given-names>H.</given-names></name><name><surname>Pollack</surname><given-names>J. B.</given-names></name></person-group><article-title xml:lang="en">Generative representations for the automated design of modular physical robots</article-title><source>IEEE Transactions on Robotics and Automation</source><year>2003</year><volume>19</volume><issue>4</issue><fpage>703</fpage><lpage>719</lpage><pub-id pub-id-type="doi">10.1109/TRA.2003.814502</pub-id></mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Faíña</surname><given-names>A.</given-names></name><name><surname>Bellas</surname><given-names>F.</given-names></name><name><surname>Souto</surname><given-names>D.</given-names></name><name><surname>Duro</surname><given-names>R. J.</given-names></name></person-group><article-title xml:lang="en">Towards an evolutionary design of modular robots for industry</article-title><source>International work-conference on the interplay between natural and artificial computation</source><year>2011</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>50</fpage><lpage>59</lpage></mixed-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faíña</surname><given-names>A.</given-names></name><name><surname>Bellas</surname><given-names>F.</given-names></name><name><surname>López-Peña</surname><given-names>F.</given-names></name><name><surname>Duro</surname><given-names>R. J.</given-names></name></person-group><article-title xml:lang="en">EDHMoR: evolutionary designer of heterogeneous modular robots</article-title><source>Engineering Applications of Artificial Intelligence</source><year>2013</year><volume>26</volume><issue>10</issue><fpage>2408</fpage><lpage>2423</lpage><pub-id pub-id-type="doi">10.1016/j.engappai.2013.09.009</pub-id></mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Veenstra</surname><given-names>F.</given-names></name><name><surname>Faina</surname><given-names>A.</given-names></name><name><surname>Risi</surname><given-names>S.</given-names></name><name><surname>Stoy</surname><given-names>K.</given-names></name></person-group><article-title xml:lang="en">Evolution and morphogenesis of simulated modular robots: a comparison between a direct and generative encoding</article-title><source>European conference on the applications of evolutionary computation</source><year>2017</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>870</fpage><lpage>885</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-55849-3_56</pub-id></mixed-citation></ref><ref id="CR53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silva</surname><given-names>F.</given-names></name><name><surname>Duarte</surname><given-names>M.</given-names></name><name><surname>Correia</surname><given-names>L.</given-names></name><name><surname>Oliveira</surname><given-names>S. M.</given-names></name><name><surname>Christensen</surname><given-names>A. L.</given-names></name></person-group><article-title xml:lang="en">Open issues in evolutionary robotics</article-title><source>Evolutionary Computation</source><year>2016</year><volume>24</volume><issue>2</issue><fpage>205</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1162/EVCO_a_00172</pub-id></mixed-citation></ref><ref id="CR54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dong</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>L.</given-names></name><name><surname>Xia</surname><given-names>N.</given-names></name><name><surname>Yang</surname><given-names>Z.</given-names></name><name><surname>Zhang</surname><given-names>C.</given-names></name><name><surname>Pan</surname><given-names>C.</given-names></name><name><surname>Jin</surname><given-names>D.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Majidi</surname><given-names>C.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name></person-group><article-title xml:lang="en">Untethered small-scale magnetic soft robot with programmable magnetization and integrated multifunctional modules</article-title><source>Science Advances</source><year>2022</year><volume>8</volume><issue>25</issue><pub-id pub-id-type="doi">10.1126/sciadv.abn8932</pub-id></mixed-citation></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kelly</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Combinatorial optimization of sensing for rule-based planar distributed assembly</article-title><source>2006 IEEE/RSJ international conference on intelligent robots and systems</source><year>2006</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>3728</fpage><lpage>3734</lpage><pub-id pub-id-type="doi">10.1109/IROS.2006.281754</pub-id></mixed-citation></ref><ref id="CR56"><label>56.</label><mixed-citation publication-type="other">
					Werfel, J. (2006). <italic>Anthills built to order: automating construction with artificial swarms</italic>. PhD thesis, Harvard University.
				</mixed-citation></ref><ref id="CR57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>X.</given-names></name><name><surname>Feng</surname><given-names>H.</given-names></name><name><surname>Dai</surname><given-names>J. S.</given-names></name><name><surname>Yu</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">High-order based revelation of bifurcation of novel Schatz-inspired metamorphic mechanisms using screw theory</article-title><source>Mechanism and Machine Theory</source><year>2020</year><volume>152</volume><pub-id pub-id-type="doi">10.1016/j.mechmachtheory.2020.103931</pub-id></mixed-citation></ref><ref id="CR58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dai</surname><given-names>J. S.</given-names></name><name><surname>Rees Jones</surname><given-names>J.</given-names></name></person-group><article-title xml:lang="en">Mobility in metamorphic mechanisms of foldable/erectable kinds</article-title><source>Journal of Mechanical Design</source><year>1999</year><volume>121</volume><issue>3</issue><fpage>375</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1115/1.2829470</pub-id></mixed-citation></ref><ref id="CR59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chai</surname><given-names>X.</given-names></name><name><surname>Dai</surname><given-names>J. S.</given-names></name></person-group><article-title xml:lang="en">Three novel symmetric Waldron–Bricard metamorphic and reconfigurable mechanisms and their isomerization</article-title><source>Journal of Mechanisms and Robotics</source><year>2019</year><volume>11</volume><issue>5</issue><pub-id pub-id-type="doi">10.1115/1.4044004</pub-id></mixed-citation></ref><ref id="CR60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Wang</surname><given-names>D.</given-names></name><name><surname>Dai</surname><given-names>J. S.</given-names></name></person-group><article-title xml:lang="en">Biological modeling and evolution based synthesis of metamorphic mechanisms</article-title><source>Journal of Mechanical Design</source><year>2008</year><volume>130</volume><issue>7</issue><pub-id pub-id-type="doi">10.1115/1.2900719</pub-id></mixed-citation></ref><ref id="CR61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>C.</given-names></name><name><surname>Chen</surname><given-names>L.</given-names></name><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Dai</surname><given-names>J. S.</given-names></name><name><surname>Kang</surname><given-names>R.</given-names></name></person-group><article-title xml:lang="en">A hybrid continuum robot based on pneumatic muscles with embedded elastic rods</article-title><source>Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science</source><year>2020</year><volume>234</volume><issue>1</issue><fpage>318</fpage><lpage>328</lpage></mixed-citation></ref><ref id="CR62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meng</surname><given-names>L.</given-names></name><name><surname>Kang</surname><given-names>R.</given-names></name><name><surname>Gan</surname><given-names>D.</given-names></name><name><surname>Chen</surname><given-names>G.</given-names></name><name><surname>Chen</surname><given-names>L.</given-names></name><name><surname>Branson</surname><given-names>D. T.</given-names></name><name><surname>Dai</surname><given-names>J. S.</given-names></name></person-group><article-title xml:lang="en">A mechanically intelligent crawling robot driven by shape memory alloy and compliant bistable mechanism</article-title><source>Journal of Mechanisms and Robotics</source><year>2020</year><volume>12</volume><issue>6</issue><pub-id pub-id-type="doi">10.1115/1.4046837</pub-id></mixed-citation></ref><ref id="CR63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>K.</given-names></name><name><surname>Spyrakos-Papastavridis</surname><given-names>E.</given-names></name><name><surname>Dai</surname><given-names>J. S.</given-names></name></person-group><article-title xml:lang="en">Origaker: a novel multi-mimicry quadruped robot based on a metamorphic mechanism</article-title><source>Journal of Mechanisms and Robotics</source><year>2022</year><volume>14</volume><issue>6</issue><pub-id pub-id-type="doi">10.1115/1.4054408</pub-id></mixed-citation></ref><ref id="CR64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>R.</given-names></name><name><surname>Song</surname><given-names>Y.</given-names></name><name><surname>Dai</surname><given-names>J. S.</given-names></name></person-group><article-title xml:lang="en">Reconfigurability of the origami-inspired integrated 8R kinematotropic metamorphic mechanism and its evolved 6R and 4R mechanisms</article-title><source>Mechanism and Machine Theory</source><year>2021</year><volume>161</volume><pub-id pub-id-type="doi">10.1016/j.mechmachtheory.2021.104245</pub-id></mixed-citation></ref><ref id="CR65"><label>65.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Zhu</surname><given-names>G.</given-names></name><name><surname>Li</surname><given-names>W.</given-names></name><etal/></person-group><person-group person-group-type="editor"><name><surname>Banzhaf</surname><given-names>W.</given-names></name><name><surname>Cheng</surname><given-names>B. H. C.</given-names></name><name><surname>Deb</surname><given-names>K.</given-names></name><etal/></person-group><article-title xml:lang="en">Mechatronic design automation: a short review</article-title><source>Evolution in action: past, present and future</source><year>2020</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>453</fpage><lpage>466</lpage><pub-id pub-id-type="doi">10.1007/978-3-030-39831-6_30</pub-id></mixed-citation></ref><ref id="CR66"><label>66.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Caasenbrood</surname><given-names>B.</given-names></name><name><surname>Pogromsky</surname><given-names>A.</given-names></name><name><surname>Nijmeijer</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">A computational design framework for pressure-driven soft robots through nonlinear topology optimization</article-title><source>2020 3rd IEEE international conference on soft robotics (RoboSoft)</source><year>2020</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>633</fpage><lpage>638</lpage><pub-id pub-id-type="doi">10.1109/RoboSoft48309.2020.9116010</pub-id></mixed-citation></ref><ref id="CR67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Z.-L.</given-names></name><name><surname>Zhou</surname><given-names>S.</given-names></name><name><surname>Feng</surname><given-names>X.-Q.</given-names></name><name><surname>Xie</surname><given-names>Y. M.</given-names></name></person-group><article-title xml:lang="en">Morphological optimization of scorpion telson</article-title><source>Journal of the Mechanics and Physics of Solids</source><year>2020</year><volume>135</volume><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">4031381</pub-id><pub-id pub-id-type="doi">10.1016/j.jmps.2019.103773</pub-id></mixed-citation></ref><ref id="CR68"><label>68.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ottaviano</surname><given-names>E.</given-names></name><name><surname>Husty</surname><given-names>M.</given-names></name><name><surname>Ceccarelli</surname><given-names>M.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Lenarcic</surname><given-names>J.</given-names></name><name><surname>Roth</surname><given-names>B.</given-names></name></person-group><article-title xml:lang="en">Level-set method for workspace analysis of serial manipulators</article-title><source>Advances in robot kinematics, mechanisms and motion</source><year>2006</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>307</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1007/978-1-4020-4941-5_33</pub-id></mixed-citation></ref><ref id="CR69"><label>69.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ye</surname><given-names>D.</given-names></name><name><surname>Sun</surname><given-names>S.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name><name><surname>Luo</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">The lightweight design of the humanoid robot frameworks based on evolutionary structural optimization</article-title><source>2014 IEEE international conference on robotics and biomimetics (ROBIO 2014)</source><year>2014</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>2286</fpage><lpage>2291</lpage><pub-id pub-id-type="doi">10.1109/ROBIO.2014.7090678</pub-id></mixed-citation></ref><ref id="CR70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lei</surname><given-names>X.</given-names></name><name><surname>Liu</surname><given-names>C.</given-names></name><name><surname>Du</surname><given-names>Z.</given-names></name><name><surname>Zhang</surname><given-names>W.</given-names></name><name><surname>Guo</surname><given-names>X.</given-names></name></person-group><article-title xml:lang="en">Machine learning-driven real-time topology optimization under moving morphable component-based framework</article-title><source>Journal of Applied Mechanics</source><year>2019</year><volume>86</volume><issue>1</issue><pub-id pub-id-type="doi">10.1115/1.4041319</pub-id></mixed-citation></ref><ref id="CR71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>L.</given-names></name><name><surname>Luo</surname><given-names>Z.</given-names></name><name><surname>Gao</surname><given-names>L.</given-names></name></person-group><article-title xml:lang="en">IgaTop: an implementation of topology optimization for structures using IGA in Matlab</article-title><source>Structural and Multidisciplinary Optimization</source><year>2021</year><volume>64</volume><issue>3</issue><fpage>1669</fpage><lpage>1700</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">4308968</pub-id><pub-id pub-id-type="doi">10.1007/s00158-021-02858-7</pub-id></mixed-citation></ref><ref id="CR72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>J.</given-names></name><name><surname>Xiao</surname><given-names>M.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Gao</surname><given-names>L.</given-names></name></person-group><article-title xml:lang="en">A comprehensive review of isogeometric topology optimization: methods, applications and prospects</article-title><source>Chinese Journal of Mechanical Engineering</source><year>2020</year><volume>33</volume><issue>6</issue><fpage>24</fpage><lpage>37</lpage></mixed-citation></ref><ref id="CR73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>J.</given-names></name><name><surname>Gao</surname><given-names>L.</given-names></name><name><surname>Luo</surname><given-names>Z.</given-names></name><name><surname>Li</surname><given-names>P.</given-names></name></person-group><article-title xml:lang="en">Isogeometric topology optimization for continuum structures using density distribution function</article-title><source>International Journal for Numerical Methods in Engineering</source><year>2019</year><volume>119</volume><issue>10</issue><fpage>991</fpage><lpage>1017</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3996533</pub-id><pub-id pub-id-type="doi">10.1002/nme.6081</pub-id></mixed-citation></ref><ref id="CR74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Xiao</surname><given-names>M.</given-names></name><name><surname>Xia</surname><given-names>Z.</given-names></name><name><surname>Li</surname><given-names>P.</given-names></name><name><surname>Gao</surname><given-names>L.</given-names></name></person-group><article-title xml:lang="en">From computer-aided design (CAD) toward human-aided design (HAD): an isogeometric topology optimization approach</article-title><source>Engineering</source><year>2022</year><volume>22</volume><issue>3</issue><fpage>94</fpage><lpage>105</lpage></mixed-citation></ref><ref id="CR75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>J.</given-names></name><name><surname>Xiao</surname><given-names>M.</given-names></name><name><surname>Yan</surname><given-names>Z.</given-names></name><name><surname>Gao</surname><given-names>L.</given-names></name><name><surname>Li</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Robust isogeometric topology optimization for piezoelectric actuators with uniform manufacturability</article-title><source>Frontiers of Mechanical Engineering</source><year>2022</year><volume>17</volume><issue>2</issue><fpage>205</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1007/s11465-022-0683-5</pub-id></mixed-citation></ref><ref id="CR76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>J.</given-names></name><name><surname>Xue</surname><given-names>H.</given-names></name><name><surname>Gao</surname><given-names>L.</given-names></name><name><surname>Luo</surname><given-names>Z.</given-names></name></person-group><article-title xml:lang="en">Topology optimization for auxetic metamaterials based on isogeometric analysis</article-title><source>Computer Methods in Applied Mechanics and Engineering</source><year>2019</year><volume>352</volume><fpage>211</fpage><lpage>236</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3948754</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1441.74160</pub-id><pub-id pub-id-type="doi">10.1016/j.cma.2019.04.021</pub-id></mixed-citation></ref><ref id="CR77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>J.</given-names></name><name><surname>Gao</surname><given-names>L.</given-names></name><name><surname>Xiao</surname><given-names>M.</given-names></name><name><surname>Gao</surname><given-names>J.</given-names></name><name><surname>Li</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Isogeometric topology optimization for rational design of ultra-lightweight architected materials</article-title><source>International Journal of Mechanical Sciences</source><year>2020</year><volume>166</volume><pub-id pub-id-type="doi">10.1016/j.ijmecsci.2019.105103</pub-id></mixed-citation></ref><ref id="CR78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seo</surname><given-names>Y.-D.</given-names></name><name><surname>Kim</surname><given-names>H.-J.</given-names></name><name><surname>Youn</surname><given-names>S.-K.</given-names></name></person-group><article-title xml:lang="en">Isogeometric topology optimization using trimmed spline surfaces</article-title><source>Computer Methods in Applied Mechanics and Engineering</source><year>2010</year><volume>199</volume><issue>49–52</issue><fpage>3270</fpage><lpage>3296</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">2740791</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1225.74068</pub-id><pub-id pub-id-type="doi">10.1016/j.cma.2010.06.033</pub-id></mixed-citation></ref><ref id="CR79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Benson</surname><given-names>D. J.</given-names></name></person-group><article-title xml:lang="en">Isogeometric analysis for parameterized LSM-based structural topology optimization</article-title><source>Computational Mechanics</source><year>2016</year><volume>57</volume><issue>1</issue><fpage>19</fpage><lpage>35</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3439783</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1381.74212</pub-id><pub-id pub-id-type="doi">10.1007/s00466-015-1219-1</pub-id></mixed-citation></ref><ref id="CR80"><label>80.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhun</surname><given-names>F.</given-names></name><name><surname>Jie</surname><given-names>Z. G.</given-names></name><name><surname>Ji</surname><given-names>L. W.</given-names></name><name><surname>Gen</surname><given-names>Y. Y.</given-names></name><name><surname>Ming</surname><given-names>L. X.</given-names></name><name><surname>Han</surname><given-names>L. P.</given-names></name><name><surname>Bin</surname><given-names>X.</given-names></name></person-group><article-title xml:lang="en">Applications of evolutionary computation in the design automation of complex mechatronic system: a survey</article-title><source>Acta Automatica Sinica</source><year>2021</year><volume>47</volume><issue>7</issue><fpage>1495</fpage><lpage>1515</lpage></mixed-citation></ref><ref id="CR81"><label>81.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seo</surname><given-names>K.</given-names></name><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Hu</surname><given-names>J.</given-names></name><name><surname>Goodman</surname><given-names>E. D.</given-names></name><name><surname>Rosenberg</surname><given-names>R. C.</given-names></name></person-group><article-title xml:lang="en">Toward a unified and automated design methodology for multi-domain dynamic systems using bond graphs and genetic programming</article-title><source>Mechatronics</source><year>2003</year><volume>13</volume><issue>8–9</issue><fpage>851</fpage><lpage>885</lpage><pub-id pub-id-type="doi">10.1016/S0957-4158(03)00006-0</pub-id></mixed-citation></ref><ref id="CR82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>Z.</given-names></name><name><surname>Campbell</surname><given-names>M. I.</given-names></name><name><surname>Fernández</surname><given-names>B. R.</given-names></name></person-group><article-title xml:lang="en">Bond graph based automated modeling for computer-aided design of dynamic systems</article-title><source>Journal of Mechanical Design</source><year>2008</year><volume>130</volume><issue>4</issue><pub-id pub-id-type="doi">10.1115/1.2885180</pub-id></mixed-citation></ref><ref id="CR83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>L.</given-names></name><name><surname>Yan</surname><given-names>B.</given-names></name></person-group><article-title xml:lang="en">Modeling and dynamic analysis of the dynamic stabilization unit based on bond graph</article-title><source>Archive of Applied Mechanics</source><year>2021</year><volume>91</volume><issue>6</issue><fpage>2681</fpage><lpage>2695</lpage><pub-id pub-id-type="doi">10.1007/s00419-021-01914-4</pub-id></mixed-citation></ref><ref id="CR84"><label>84.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tolley</surname><given-names>M. T.</given-names></name><name><surname>Hiller</surname><given-names>J. D.</given-names></name><name><surname>Lipson</surname><given-names>H.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Doncieux</surname><given-names>S.</given-names></name><name><surname>Bredèche</surname><given-names>N.</given-names></name><name><surname>Mouret</surname><given-names>J.-B.</given-names></name></person-group><article-title xml:lang="en">Evolutionary design and assembly planning for stochastic modular robots</article-title><source>New horizons in evolutionary robotics</source><year>2011</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>211</fpage><lpage>225</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-18272-3_14</pub-id></mixed-citation></ref><ref id="CR85"><label>85.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yim</surname><given-names>M.</given-names></name><name><surname>Shen</surname><given-names>W.-M.</given-names></name><name><surname>Salemi</surname><given-names>B.</given-names></name><name><surname>Rus</surname><given-names>D.</given-names></name><name><surname>Moll</surname><given-names>M.</given-names></name><name><surname>Lipson</surname><given-names>H.</given-names></name><name><surname>Klavins</surname><given-names>E.</given-names></name><name><surname>Chirikjian</surname><given-names>G. S.</given-names></name></person-group><article-title xml:lang="en">Modular self-reconfigurable robot systems [grand challenges of robotics]</article-title><source>IEEE Robotics &amp; Automation Magazine</source><year>2007</year><volume>14</volume><issue>1</issue><fpage>43</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1109/MRA.2007.339623</pub-id></mixed-citation></ref><ref id="CR86"><label>86.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>White</surname><given-names>P.</given-names></name><name><surname>Zykov</surname><given-names>V.</given-names></name><name><surname>Bongard</surname><given-names>J. C.</given-names></name><name><surname>Lipson</surname><given-names>H.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Thrun</surname><given-names>S.</given-names></name><name><surname>Sukhatme</surname><given-names>G. S.</given-names></name><name><surname>Schaal</surname><given-names>S.</given-names></name></person-group><article-title xml:lang="en">Three dimensional stochastic reconfiguration of modular robots</article-title><source>Robotics: science and systems I</source><year>2005</year><publisher-loc>Cambridge</publisher-loc><publisher-name>The MIT Press</publisher-name><fpage>161</fpage><lpage>168</lpage></mixed-citation></ref><ref id="CR87"><label>87.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Østergaard</surname><given-names>E. H.</given-names></name><name><surname>Kassow</surname><given-names>K.</given-names></name><name><surname>Beck</surname><given-names>R.</given-names></name><name><surname>Lund</surname><given-names>H. H.</given-names></name></person-group><article-title xml:lang="en">Design of the ATRON lattice-based self-reconfigurable robot</article-title><source>Autonomous Robots</source><year>2006</year><volume>21</volume><issue>2</issue><fpage>165</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1007/s10514-006-8546-1</pub-id></mixed-citation></ref><ref id="CR88"><label>88.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miki</surname><given-names>T.</given-names></name><name><surname>Lee</surname><given-names>J.</given-names></name><name><surname>Hwangbo</surname><given-names>J.</given-names></name><name><surname>Wellhausen</surname><given-names>L.</given-names></name><name><surname>Koltun</surname><given-names>V.</given-names></name><name><surname>Hutter</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">Learning robust perceptive locomotion for quadrupedal robots in the wild</article-title><source>Science Robotics</source><year>2022</year><volume>7</volume><issue>62</issue><pub-id pub-id-type="doi">10.1126/scirobotics.abk2822</pub-id></mixed-citation></ref><ref id="CR89"><label>89.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abadía</surname><given-names>I.</given-names></name><name><surname>Naveros</surname><given-names>F.</given-names></name><name><surname>Ros</surname><given-names>E.</given-names></name><name><surname>Carrillo</surname><given-names>R. R.</given-names></name><name><surname>Luque</surname><given-names>N. R.</given-names></name></person-group><article-title xml:lang="en">A cerebellar-based solution to the nondeterministic time delay problem in robotic control</article-title><source>Science Robotics</source><year>2021</year><volume>6</volume><issue>58</issue><pub-id pub-id-type="doi">10.1126/scirobotics.abf2756</pub-id></mixed-citation></ref><ref id="CR90"><label>90.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>T.</given-names></name><name><surname>He</surname><given-names>Z.</given-names></name><name><surname>Ciocarlie</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">Co-designing hardware and control for robot hands</article-title><source>Science Robotics</source><year>2021</year><volume>6</volume><issue>54</issue><pub-id pub-id-type="doi">10.1126/scirobotics.abg2133</pub-id></mixed-citation></ref><ref id="CR91"><label>91.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhong</surname><given-names>H.</given-names></name><name><surname>Hu</surname><given-names>C.</given-names></name><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Gao</surname><given-names>L.</given-names></name><name><surname>Zeng</surname><given-names>B.</given-names></name><name><surname>Dong</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Kinematic calibration method for a two-segment hydraulic leg based on an improved whale swarm algorithm</article-title><source>Robotics and Computer-Integrated Manufacturing</source><year>2019</year><volume>59</volume><fpage>361</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1016/j.rcim.2019.05.002</pub-id></mixed-citation></ref><ref id="CR92"><label>92.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhong</surname><given-names>H.</given-names></name><name><surname>Xie</surname><given-names>S.</given-names></name><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Gao</surname><given-names>L.</given-names></name><name><surname>Lu</surname><given-names>S.</given-names></name></person-group><article-title xml:lang="en">Online gait generation method based on neural network for humanoid robot fast walking on uneven terrain</article-title><source>International Journal of Control, Automation, and Systems</source><year>2022</year><volume>20</volume><issue>3</issue><fpage>941</fpage><lpage>955</lpage><pub-id pub-id-type="doi">10.1007/s12555-021-0099-8</pub-id></mixed-citation></ref><ref id="CR93"><label>93.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dong</surname><given-names>H.</given-names></name><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Shen</surname><given-names>P.</given-names></name><name><surname>Gao</surname><given-names>L.</given-names></name><name><surname>Zhong</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Interval type-2 fuzzy logic PID controller based on differential evolution with better and nearest option for hydraulic serial elastic actuator</article-title><source>International Journal of Control, Automation, and Systems</source><year>2021</year><volume>19</volume><issue>2</issue><fpage>1113</fpage><lpage>1132</lpage><pub-id pub-id-type="doi">10.1007/s12555-020-0141-2</pub-id></mixed-citation></ref><ref id="CR94"><label>94.</label><mixed-citation publication-type="other">
					Dong, H., Gao, L., Shen, P., Li, X., Lu, Y., &amp; Dai, W. (2019). An interval type-2 fuzzy logic controller design method for hydraulic actuators of a human-like robot by using improved drone squadron optimization. <italic>International Journal of Advanced Robotic Systems</italic>, <italic>16</italic>(6). <ext-link xlink:href="10.1177/1729881419891553" ext-link-type="doi">https://doi.org/10.1177/1729881419891553</ext-link>.
				</mixed-citation></ref><ref id="CR95"><label>95.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hai</surname><given-names>X.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Feng</surname><given-names>Q.</given-names></name><name><surname>Ren</surname><given-names>Y.</given-names></name><name><surname>Xu</surname><given-names>B.</given-names></name><name><surname>Cui</surname><given-names>J.</given-names></name><name><surname>Duan</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Mobile robot ADRC with an automatic parameter tuning mechanism via modified pigeon-inspired optimization</article-title><source>IEEE/ASME Transactions on Mechatronics</source><year>2019</year><volume>24</volume><issue>6</issue><fpage>2616</fpage><lpage>2626</lpage><pub-id pub-id-type="doi">10.1109/TMECH.2019.2953239</pub-id></mixed-citation></ref><ref id="CR96"><label>96.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cáceres Flórez</surname><given-names>C. A.</given-names></name><name><surname>Rosário</surname><given-names>J. M.</given-names></name><name><surname>Amaya</surname><given-names>D.</given-names></name></person-group><article-title xml:lang="en">Control structure for a car-like robot using artificial neural networks and genetic algorithms</article-title><source>Neural Computing &amp; Applications</source><year>2020</year><volume>32</volume><issue>20</issue><fpage>15771</fpage><lpage>15784</lpage><pub-id pub-id-type="doi">10.1007/s00521-018-3514-1</pub-id></mixed-citation></ref><ref id="CR97"><label>97.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chin</surname><given-names>C. S.</given-names></name><name><surname>Lin</surname><given-names>W. P.</given-names></name></person-group><article-title xml:lang="en">Robust genetic algorithm and fuzzy inference mechanism embedded in a sliding-mode controller for an uncertain underwater robot</article-title><source>IEEE/ASME Transactions on Mechatronics</source><year>2018</year><volume>23</volume><issue>2</issue><fpage>655</fpage><lpage>666</lpage><pub-id pub-id-type="doi">10.1109/TMECH.2018.2806389</pub-id></mixed-citation></ref><ref id="CR98"><label>98.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feng</surname><given-names>H.</given-names></name><name><surname>Yin</surname><given-names>C.-B.</given-names></name><name><surname>Weng</surname><given-names>W.</given-names></name><name><surname>Ma</surname><given-names>W.</given-names></name><name><surname>Zhou</surname><given-names>J.</given-names></name><name><surname>Jia</surname><given-names>W.</given-names></name><name><surname>Zhang</surname><given-names>Z.</given-names></name></person-group><article-title xml:lang="en">Robotic excavator trajectory control using an improved GA based PID controller</article-title><source>Mechanical Systems and Signal Processing</source><year>2018</year><volume>105</volume><fpage>153</fpage><lpage>168</lpage><pub-id pub-id-type="doi">10.1016/j.ymssp.2017.12.014</pub-id></mixed-citation></ref><ref id="CR99"><label>99.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharma</surname><given-names>R.</given-names></name><name><surname>Rana</surname><given-names>K. P. S.</given-names></name><name><surname>Kumar</surname><given-names>V.</given-names></name></person-group><article-title xml:lang="en">Performance analysis of fractional order fuzzy PID controllers applied to a robotic manipulator</article-title><source>Expert Systems with Applications</source><year>2014</year><volume>41</volume><issue>9</issue><fpage>4274</fpage><lpage>4289</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2013.12.030</pub-id></mixed-citation></ref><ref id="CR100"><label>100.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ali</surname><given-names>R. S.</given-names></name><name><surname>Aldair</surname><given-names>A. A.</given-names></name><name><surname>Almousawi</surname><given-names>A. K.</given-names></name></person-group><article-title xml:lang="en">Design an optimal PID controller using artificial bee colony and genetic algorithm for autonomous mobile robot</article-title><source>International Journal of Computer Applications</source><year>2014</year><volume>100</volume><issue>16</issue><fpage>8</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.5120/17607-8016</pub-id></mixed-citation></ref><ref id="CR101"><label>101.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taherkhorsandi</surname><given-names>M.</given-names></name><name><surname>Mahmoodabadi</surname><given-names>M. J.</given-names></name><name><surname>Talebipour</surname><given-names>M.</given-names></name><name><surname>Castillo-Villar</surname><given-names>K. K.</given-names></name></person-group><article-title xml:lang="en">Pareto design of an adaptive robust hybrid of PID and sliding control for a biped robot via genetic algorithm optimization</article-title><source>Nonlinear Dynamics</source><year>2015</year><volume>79</volume><issue>1</issue><fpage>251</fpage><lpage>263</lpage><pub-id pub-id-type="doi">10.1007/s11071-014-1661-1</pub-id></mixed-citation></ref><ref id="CR102"><label>102.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhenlu</surname><given-names>S.</given-names></name><name><surname>Bin</surname><given-names>X.</given-names></name><name><surname>Jie</surname><given-names>C.</given-names></name></person-group><article-title xml:lang="en">Optimal design of controllers based on libraries and differential evolution</article-title><source>2015 34th Chinese control conference (CCC)</source><year>2015</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>5599</fpage><lpage>5604</lpage><pub-id pub-id-type="doi">10.1109/ChiCC.2015.7260514</pub-id></mixed-citation></ref><ref id="CR103"><label>103.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jiaoyang</surname><given-names>Z.</given-names></name><name><surname>Bin</surname><given-names>X.</given-names></name><name><surname>Jie</surname><given-names>C.</given-names></name></person-group><article-title xml:lang="en">Evolutionary design of controllers with optimized structure and its application in a Maglev ball control system</article-title><source>2017 36th Chinese control conference (CCC)</source><year>2017</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>2545</fpage><lpage>2550</lpage><pub-id pub-id-type="doi">10.23919/ChiCC.2017.8027744</pub-id></mixed-citation></ref><ref id="CR104"><label>104.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xin</surname><given-names>B.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Xue</surname><given-names>W.</given-names></name><name><surname>Cai</surname><given-names>T.</given-names></name><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Zhan</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name></person-group><article-title xml:lang="en">Evolution of controllers under a generalized structure encoding/decoding scheme with application to magnetic levitation system</article-title><source>IEEE Transactions on Industrial Electronics</source><year>2021</year><volume>69</volume><issue>9</issue><fpage>9655</fpage><lpage>9666</lpage><pub-id pub-id-type="doi">10.1109/TIE.2021.3114700</pub-id></mixed-citation></ref><ref id="CR105"><label>105.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S.</given-names></name><name><surname>Yang</surname><given-names>P.</given-names></name><name><surname>Kong</surname><given-names>L.</given-names></name><name><surname>Chen</surname><given-names>W.</given-names></name><name><surname>Fu</surname><given-names>Q.</given-names></name><name><surname>Peng</surname><given-names>K.</given-names></name></person-group><article-title xml:lang="en">Neural networks-based fault tolerant control of a robot via fast terminal sliding mode</article-title><source>IEEE Transactions on Systems, Man, and Cybernetics: Systems</source><year>2019</year><volume>51</volume><issue>7</issue><fpage>4091</fpage><lpage>4101</lpage><pub-id pub-id-type="doi">10.1109/TSMC.2019.2933050</pub-id></mixed-citation></ref><ref id="CR106"><label>106.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Grzeszczuk</surname><given-names>R.</given-names></name><name><surname>Terzopoulos</surname><given-names>D.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Mair</surname><given-names>S. G.</given-names></name><name><surname>Cook</surname><given-names>R.</given-names></name></person-group><article-title xml:lang="en">Automated learning of muscle-actuated locomotion through control abstraction</article-title><source>Proceedings of the 22nd annual conference on computer graphics and interactive techniques</source><year>1995</year><publisher-loc>New York</publisher-loc><publisher-name>ACM</publisher-name><fpage>63</fpage><lpage>70</lpage></mixed-citation></ref><ref id="CR107"><label>107.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hornby</surname><given-names>G. S.</given-names></name><name><surname>Pollack</surname><given-names>J. B.</given-names></name></person-group><article-title xml:lang="en">Creating high-level components with a generative representation for body-brain evolution</article-title><source>Artificial Life</source><year>2002</year><volume>8</volume><issue>3</issue><fpage>223</fpage><lpage>246</lpage><pub-id pub-id-type="doi">10.1162/106454602320991837</pub-id></mixed-citation></ref><ref id="CR108"><label>108.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallagher</surname><given-names>J. C.</given-names></name><name><surname>Beer</surname><given-names>R. D.</given-names></name><name><surname>Espenschied</surname><given-names>K. S.</given-names></name><name><surname>Quinn</surname><given-names>R. D.</given-names></name></person-group><article-title xml:lang="en">Application of evolved locomotion controllers to a hexapod robot</article-title><source>Robotics and Autonomous Systems</source><year>1996</year><volume>19</volume><issue>1</issue><fpage>95</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1016/S0921-8890(96)00036-X</pub-id></mixed-citation></ref><ref id="CR109"><label>109.</label><mixed-citation publication-type="other">
					Floreano, D., Husbands, P., &amp; Nolfi, S. (2008). Evolutionary robotics. Technical report, Berlin: Springer.
				</mixed-citation></ref><ref id="CR110"><label>110.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Paul</surname><given-names>C.</given-names></name><name><surname>Bongard</surname><given-names>J. C.</given-names></name></person-group><article-title xml:lang="en">The road less travelled: morphology in the optimization of biped robot locomotion</article-title><source>Proceedings 2001 IEEE/RSJ international conference on intelligent robots and systems. Expanding the societal role of robotics in the the next millennium (cat. no.01CH37180)</source><year>2001</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>226</fpage><lpage>232</lpage><pub-id pub-id-type="doi">10.1109/IROS.2001.973363</pub-id></mixed-citation></ref><ref id="CR111"><label>111.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rahmani</surname><given-names>M.</given-names></name><name><surname>Ghanbari</surname><given-names>A.</given-names></name><name><surname>Ettefagh</surname><given-names>M. M.</given-names></name></person-group><article-title xml:lang="en">A novel adaptive neural network integral sliding-mode control of a biped robot using bat algorithm</article-title><source>Journal of Vibration and Control</source><year>2018</year><volume>24</volume><issue>10</issue><fpage>2045</fpage><lpage>2060</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3800200</pub-id><pub-id pub-id-type="doi">10.1177/1077546316676734</pub-id></mixed-citation></ref><ref id="CR112"><label>112.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dorigo</surname><given-names>M.</given-names></name><name><surname>Birattari</surname><given-names>M.</given-names></name><name><surname>Brambilla</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">Swarm robotics</article-title><source>Scholarpedia</source><year>2014</year><volume>9</volume><issue>1</issue><pub-id pub-id-type="doi">10.4249/scholarpedia.1463</pub-id></mixed-citation></ref><ref id="CR113"><label>113.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>G.</given-names></name><name><surname>Mei</surname><given-names>Y.</given-names></name><name><surname>Xin</surname><given-names>B.</given-names></name><name><surname>Jia</surname><given-names>Y.-H.</given-names></name><name><surname>Browne</surname><given-names>W. N.</given-names></name></person-group><article-title xml:lang="en">Automated coordination strategy design using genetic programming for dynamic multipoint dynamic aggregation</article-title><source>IEEE Transactions on Cybernetics</source><year>2022</year><volume>52</volume><issue>12</issue><fpage>13521</fpage><lpage>13535</lpage><pub-id pub-id-type="doi">10.1109/TCYB.2021.3080044</pub-id></mixed-citation></ref><ref id="CR114"><label>114.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kazadi</surname><given-names>S.</given-names></name></person-group><article-title xml:lang="en">Model independence in swarm robotics</article-title><source>International Journal of Intelligent Computing and Cybernetics</source><year>2009</year><volume>2</volume><issue>4</issue><fpage>672</fpage><lpage>694</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">2756409</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1185.68735</pub-id><pub-id pub-id-type="doi">10.1108/17563780911005836</pub-id></mixed-citation></ref><ref id="CR115"><label>115.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Berman</surname><given-names>S.</given-names></name><name><surname>Kumar</surname><given-names>V.</given-names></name><name><surname>Nagpal</surname><given-names>R.</given-names></name></person-group><article-title xml:lang="en">Design of control policies for spatially inhomogeneous robot swarms with application to commercial pollination</article-title><source>2011 IEEE international conference on robotics and automation</source><year>2011</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>378</fpage><lpage>385</lpage><pub-id pub-id-type="doi">10.1109/ICRA.2011.5980440</pub-id></mixed-citation></ref><ref id="CR116"><label>116.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brambilla</surname><given-names>M.</given-names></name><name><surname>Pinciroli</surname><given-names>C.</given-names></name><name><surname>Birattari</surname><given-names>M.</given-names></name><name><surname>Dorigo</surname><given-names>M.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Conitzer</surname><given-names>V.</given-names></name><name><surname>Winikoff</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">Property-driven design for swarm robotics</article-title><source>Proceedings of the 11th international conference on autonomous agents and multiagent systems</source><year>2012</year><fpage>139</fpage><lpage>146</lpage><comment>IFAAMAS</comment></mixed-citation></ref><ref id="CR117"><label>117.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Francesca</surname><given-names>G.</given-names></name><name><surname>Brambilla</surname><given-names>M.</given-names></name><name><surname>Brutschy</surname><given-names>A.</given-names></name><name><surname>Trianni</surname><given-names>V.</given-names></name><name><surname>Birattari</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">AutoMoDe: a novel approach to the automatic design of control software for robot swarms</article-title><source>Swarm Intelligence</source><year>2014</year><volume>8</volume><issue>2</issue><fpage>89</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1007/s11721-014-0092-4</pub-id></mixed-citation></ref><ref id="CR118"><label>118.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Francesca</surname><given-names>G.</given-names></name><name><surname>Brambilla</surname><given-names>M.</given-names></name><name><surname>Brutschy</surname><given-names>A.</given-names></name><name><surname>Garattoni</surname><given-names>L.</given-names></name><name><surname>Miletitch</surname><given-names>R.</given-names></name><name><surname>Podevijn</surname><given-names>G.</given-names></name><etal/></person-group><article-title xml:lang="en">AutoMoDe-Chocolate: automatic design of control software for robot swarms</article-title><source>Swarm Intelligence</source><year>2015</year><volume>9</volume><issue>2</issue><fpage>125</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1007/s11721-015-0107-9</pub-id></mixed-citation></ref><ref id="CR119"><label>119.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dorigo</surname><given-names>M.</given-names></name><name><surname>Theraulaz</surname><given-names>G.</given-names></name><name><surname>Trianni</surname><given-names>V.</given-names></name></person-group><article-title xml:lang="en">Swarm robotics: past, present, and future [point of view]</article-title><source>Proceedings of the IEEE</source><year>2021</year><volume>109</volume><issue>7</issue><fpage>1152</fpage><lpage>1165</lpage><pub-id pub-id-type="doi">10.1109/JPROC.2021.3072740</pub-id></mixed-citation></ref><ref id="CR120"><label>120.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nunes</surname><given-names>E.</given-names></name><name><surname>Manner</surname><given-names>M.</given-names></name><name><surname>Mitiche</surname><given-names>H.</given-names></name><name><surname>Gini</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">A taxonomy for task allocation problems with temporal and ordering constraints</article-title><source>Robotics and Autonomous Systems</source><year>2017</year><volume>90</volume><fpage>55</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1016/j.robot.2016.10.008</pub-id></mixed-citation></ref><ref id="CR121"><label>121.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>M.</given-names></name><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Ma</surname><given-names>L.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Bao</surname><given-names>W.</given-names></name><name><surname>Li</surname><given-names>W.</given-names></name><name><surname>Fan</surname><given-names>Z.</given-names></name></person-group><article-title xml:lang="en">Torch: strategy evolution in swarm robots using heterogeneous–homogeneous coevolution method</article-title><source>Journal of Industrial Information Integration</source><year>2022</year><volume>25</volume><pub-id pub-id-type="doi">10.1016/j.jii.2021.100239</pub-id></mixed-citation></ref><ref id="CR122"><label>122.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vásárhelyi</surname><given-names>G.</given-names></name><name><surname>Virágh</surname><given-names>C.</given-names></name><name><surname>Somorjai</surname><given-names>G.</given-names></name><name><surname>Nepusz</surname><given-names>T.</given-names></name><name><surname>Eiben</surname><given-names>A. E.</given-names></name><name><surname>Vicsek</surname><given-names>T.</given-names></name></person-group><article-title xml:lang="en">Optimized flocking of autonomous drones in confined environments</article-title><source>Science Robotics</source><year>2018</year><volume>3</volume><issue>20</issue><pub-id pub-id-type="doi">10.1126/scirobotics.aat3536</pub-id></mixed-citation></ref><ref id="CR123"><label>123.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeifer</surname><given-names>R.</given-names></name><name><surname>Lungarella</surname><given-names>M.</given-names></name><name><surname>Iida</surname><given-names>F.</given-names></name></person-group><article-title xml:lang="en">Self-organization, embodiment, and biologically inspired robotics</article-title><source>Science</source><year>2007</year><volume>318</volume><issue>5853</issue><fpage>1088</fpage><lpage>1093</lpage><pub-id pub-id-type="doi">10.1126/science.1145803</pub-id></mixed-citation></ref><ref id="CR124"><label>124.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shah</surname><given-names>D.</given-names></name><name><surname>Yang</surname><given-names>B.</given-names></name><name><surname>Kriegman</surname><given-names>S.</given-names></name><name><surname>Levin</surname><given-names>M.</given-names></name><name><surname>Bongard</surname><given-names>J.</given-names></name><name><surname>Kramer-Bottiglio</surname><given-names>R.</given-names></name></person-group><article-title xml:lang="en">Shape changing robots: bioinspiration, simulation, and physical realization</article-title><source>Advanced Materials</source><year>2021</year><volume>33</volume><issue>19</issue><pub-id pub-id-type="doi">10.1002/adma.202002882</pub-id></mixed-citation></ref><ref id="CR125"><label>125.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miras</surname><given-names>K.</given-names></name><name><surname>Ferrante</surname><given-names>E.</given-names></name><name><surname>Eiben</surname><given-names>A. E.</given-names></name></person-group><article-title xml:lang="en">Environmental influences on evolvable robots</article-title><source>PLoS ONE</source><year>2020</year><volume>15</volume><issue>5</issue><pub-id pub-id-type="doi">10.1371/journal.pone.0233848</pub-id></mixed-citation></ref><ref id="CR126"><label>126.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lan</surname><given-names>G.</given-names></name><name><surname>Jelisavcic</surname><given-names>M.</given-names></name><name><surname>Roijers</surname><given-names>D. M.</given-names></name><name><surname>Haasdijk</surname><given-names>E.</given-names></name><name><surname>Eiben</surname><given-names>A. E.</given-names></name></person-group><article-title xml:lang="en">Directed locomotion for modular robots with evolvable morphologies</article-title><source>International conference on parallel problem solving from nature</source><year>2018</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>476</fpage><lpage>487</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-99253-2_38</pub-id></mixed-citation></ref><ref id="CR127"><label>127.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Eiben</surname><given-names>A. E.</given-names></name><name><surname>Bredeche</surname><given-names>N.</given-names></name><name><surname>Hoogendoorn</surname><given-names>M.</given-names></name><name><surname>Stradner</surname><given-names>J.</given-names></name><name><surname>Timmis</surname><given-names>J.</given-names></name><name><surname>Tyrrell</surname><given-names>A.</given-names></name><name><surname>Winfield</surname><given-names>A.</given-names></name></person-group><article-title xml:lang="en">The triangle of life: evolving robots in real-time and real-space</article-title><source>European conference on artificial life (ECAL-2013)</source><year>2013</year><publisher-loc>Cambridge</publisher-loc><publisher-name>The MIT Press</publisher-name><fpage>1056</fpage><lpage>1063</lpage></mixed-citation></ref><ref id="CR128"><label>128.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eiben</surname><given-names>A. E.</given-names></name><name><surname>Smith</surname><given-names>J.</given-names></name></person-group><article-title xml:lang="en">From evolutionary computation to the evolution of things</article-title><source>Nature</source><year>2015</year><volume>521</volume><issue>7553</issue><fpage>476</fpage><lpage>482</lpage><pub-id pub-id-type="doi">10.1038/nature14544</pub-id></mixed-citation></ref><ref id="CR129"><label>129.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eiben</surname><given-names>A. E.</given-names></name><name><surname>Kernbach</surname><given-names>S.</given-names></name><name><surname>Haasdijk</surname><given-names>E.</given-names></name></person-group><article-title xml:lang="en">Embodied artificial evolution</article-title><source>Evolutionary Intelligence</source><year>2012</year><volume>5</volume><issue>4</issue><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1007/s12065-012-0071-x</pub-id></mixed-citation></ref><ref id="CR130"><label>130.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bongard</surname><given-names>J. C.</given-names></name></person-group><article-title xml:lang="en">Evolutionary robotics</article-title><source>Communications of the ACM</source><year>2013</year><volume>56</volume><issue>8</issue><fpage>74</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1145/2493883</pub-id></mixed-citation></ref><ref id="CR131"><label>131.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Marbach</surname><given-names>D.</given-names></name><name><surname>Ijspeert</surname><given-names>A. J.</given-names></name></person-group><article-title xml:lang="en">Co-evolution of configuration and control for homogenous modular robots</article-title><source>Proceedings of the eighth conference on intelligent autonomous systems (IAS8)</source><year>2004</year><fpage>712</fpage><lpage>719</lpage><comment>IOS Press</comment></mixed-citation></ref><ref id="CR132"><label>132.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>A.</given-names></name><name><surname>Savarese</surname><given-names>S.</given-names></name><name><surname>Ganguli</surname><given-names>S.</given-names></name><name><surname>Fei-Fei</surname><given-names>L.</given-names></name></person-group><article-title xml:lang="en">Embodied intelligence via learning and evolution</article-title><source>Nature Communications</source><year>2021</year><volume>12</volume><issue>1</issue><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41467-021-25874-z</pub-id></mixed-citation></ref><ref id="CR133"><label>133.</label><mixed-citation publication-type="other">
					Schaff, C. (2022). <italic>Neural approaches to co-optimization in robotics</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:2209.00579" ext-link-type="uri">arXiv:2209.00579</ext-link>.
				</mixed-citation></ref><ref id="CR134"><label>134.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Meeden</surname><given-names>L.</given-names></name><name><surname>Kumar</surname><given-names>D.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Jain</surname><given-names>L. C.</given-names></name><name><surname>Fukuda</surname><given-names>T.</given-names></name></person-group><article-title xml:lang="en">Trends in evolutionary robotics</article-title><source>Soft computing for intelligent robotic systems</source><year>1998</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>215</fpage><lpage>233</lpage><pub-id pub-id-type="doi">10.1007/978-3-7908-1882-6_9</pub-id></mixed-citation></ref><ref id="CR135"><label>135.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>A.</given-names></name><name><surname>Xu</surname><given-names>J.</given-names></name><name><surname>Konaković-Luković</surname><given-names>M.</given-names></name><name><surname>Hughes</surname><given-names>J.</given-names></name><name><surname>Spielberg</surname><given-names>A.</given-names></name><name><surname>Rus</surname><given-names>D.</given-names></name><name><surname>Matusik</surname><given-names>W.</given-names></name></person-group><article-title xml:lang="en">Robogrammar: graph grammar for terrain-optimized robot design</article-title><source>ACM Transactions on Graphics</source><year>2020</year><volume>39</volume><issue>6</issue><fpage>1</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1145/3414685.3417831</pub-id></mixed-citation></ref><ref id="CR136"><label>136.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>J.</given-names></name><name><surname>Spielberg</surname><given-names>A.</given-names></name><name><surname>Zhao</surname><given-names>A.</given-names></name><name><surname>Rus</surname><given-names>D.</given-names></name><name><surname>Matusik</surname><given-names>W.</given-names></name></person-group><article-title xml:lang="en">Multi-objective graph heuristic search for terrestrial robot design</article-title><source>2021 IEEE international conference on robotics and automation (ICRA)</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>9863</fpage><lpage>9869</lpage><pub-id pub-id-type="doi">10.1109/ICRA48506.2021.9561818</pub-id></mixed-citation></ref><ref id="CR137"><label>137.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miriyev</surname><given-names>A.</given-names></name><name><surname>Kovač</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">Skills for physical artificial intelligence</article-title><source>Nature Machine Intelligence</source><year>2020</year><volume>2</volume><issue>11</issue><fpage>658</fpage><lpage>660</lpage><pub-id pub-id-type="doi">10.1038/s42256-020-00258-y</pub-id></mixed-citation></ref><ref id="CR138"><label>138.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Terpenny</surname><given-names>J. P.</given-names></name><name><surname>Goodman</surname><given-names>E. D.</given-names></name></person-group><article-title xml:lang="en">Cooperative body–brain coevolutionary synthesis of mechatronic systems</article-title><source>Artificial Intelligence for Engineering Design, Analysis and Manufacturing</source><year>2008</year><volume>22</volume><issue>3</issue><fpage>219</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1017/S0890060408000152</pub-id></mixed-citation></ref><ref id="CR139"><label>139.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dupuis</surname><given-names>J.-F.</given-names></name><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Goodman</surname><given-names>E.</given-names></name></person-group><article-title xml:lang="en">Evolutionary design of discrete controllers for hybrid mechatronic systems</article-title><source>International Journal of Systems Science</source><year>2015</year><volume>46</volume><issue>2</issue><fpage>303</fpage><lpage>316</lpage><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1316.93076</pub-id><pub-id pub-id-type="doi">10.1080/00207721.2013.783643</pub-id></mixed-citation></ref><ref id="CR140"><label>140.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Liu</surname><given-names>L. Z.</given-names></name><name><surname>Xie</surname><given-names>H.</given-names></name><name><surname>Jiang</surname><given-names>Y.</given-names></name><name><surname>Zhou</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name></person-group><article-title xml:lang="en">Deep learning-based robot vision: high-end tools for smart manufacturing</article-title><source>IEEE Instrumentation &amp; Measurement Magazine</source><year>2022</year><volume>25</volume><issue>2</issue><fpage>27</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1109/MIM.2022.9756392</pub-id></mixed-citation></ref><ref id="CR141"><label>141.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Huang</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>N.</given-names></name><name><surname>Xiang</surname><given-names>S.</given-names></name><name><surname>Pan</surname><given-names>C.</given-names></name></person-group><article-title xml:lang="en">You only search once: single shot neural architecture search via direct sparse optimization</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><year>2021</year><volume>43</volume><issue>9</issue><fpage>2891</fpage><lpage>2904</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2020.3020300</pub-id></mixed-citation></ref><ref id="CR142"><label>142.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>X.</given-names></name><name><surname>Ji</surname><given-names>R.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>Q.</given-names></name><name><surname>Zhang</surname><given-names>B.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name><name><surname>Ye</surname><given-names>Q.</given-names></name><name><surname>Huang</surname><given-names>F.</given-names></name><name><surname>Tian</surname><given-names>Y.</given-names></name></person-group><article-title xml:lang="en">MIGO-NAS: towards fast and generalizable neural architecture search</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><year>2021</year><volume>43</volume><issue>9</issue><fpage>2936</fpage><lpage>2952</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2021.3065138</pub-id></mixed-citation></ref><ref id="CR143"><label>143.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Xiong</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name><name><surname>Gupta</surname><given-names>S.</given-names></name><name><surname>Akin</surname><given-names>B.</given-names></name><name><surname>Bender</surname><given-names>G.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><etal/></person-group><article-title xml:lang="en">Mobiledets: searching for object detection architectures for mobile accelerators</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>3825</fpage><lpage>3834</lpage></mixed-citation></ref><ref id="CR144"><label>144.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>M.</given-names></name><name><surname>Chen</surname><given-names>B.</given-names></name><name><surname>Pang</surname><given-names>R.</given-names></name><name><surname>Vasudevan</surname><given-names>V.</given-names></name><name><surname>Sandler</surname><given-names>M.</given-names></name><name><surname>Howard</surname><given-names>A.</given-names></name><name><surname>Le</surname><given-names>Q. V.</given-names></name></person-group><article-title xml:lang="en">MnasNet: platform-aware neural architecture search for mobile</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2019</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>2820</fpage><lpage>2828</lpage></mixed-citation></ref><ref id="CR145"><label>145.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>X.</given-names></name><name><surname>Qin</surname><given-names>A. K.</given-names></name><name><surname>Sun</surname><given-names>Y.</given-names></name><name><surname>Tan</surname><given-names>K. C.</given-names></name></person-group><article-title xml:lang="en">A survey of advances in evolutionary neural architecture search</article-title><source>2021 IEEE congress on evolutionary computation (CEC)</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>950</fpage><lpage>957</lpage><pub-id pub-id-type="doi">10.1109/CEC45853.2021.9504890</pub-id></mixed-citation></ref><ref id="CR146"><label>146.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baymurzina</surname><given-names>D.</given-names></name><name><surname>Golikov</surname><given-names>E.</given-names></name><name><surname>Burtsev</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">A review of neural architecture search</article-title><source>Neurocomputing</source><year>2022</year><volume>474</volume><fpage>82</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2021.12.014</pub-id></mixed-citation></ref><ref id="CR147"><label>147.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elsken</surname><given-names>T.</given-names></name><name><surname>Metzen</surname><given-names>J. H.</given-names></name><name><surname>Hutter</surname><given-names>F.</given-names></name></person-group><article-title xml:lang="en">Neural architecture search: a survey</article-title><source>Journal of Machine Learning Research</source><year>2019</year><volume>20</volume><issue>1</issue><fpage>1997</fpage><lpage>2017</lpage><pub-id pub-id-type="other" assigning-authority="American Mathematical Society">3948095</pub-id><pub-id pub-id-type="other" assigning-authority="Zentralblatt MATH">1485.68229</pub-id></mixed-citation></ref><ref id="CR148"><label>148.</label><mixed-citation publication-type="other">
					Baker, B., Gupta, O., Naik, N., &amp; Raskar, R. (2016). <italic>Designing neural network architectures using reinforcement learning</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:1611.02167" ext-link-type="uri">arXiv:1611.02167</ext-link>.
				</mixed-citation></ref><ref id="CR149"><label>149.</label><mixed-citation publication-type="other">
					Zoph, B., &amp; Le, Q. V. (2016). <italic>Neural architecture search with reinforcement learning</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:1611.01578" ext-link-type="uri">arXiv:1611.01578</ext-link>.
				</mixed-citation></ref><ref id="CR150"><label>150.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zoph</surname><given-names>B.</given-names></name><name><surname>Vasudevan</surname><given-names>V.</given-names></name><name><surname>Shlens</surname><given-names>J.</given-names></name><name><surname>Le</surname><given-names>Q. V.</given-names></name></person-group><article-title xml:lang="en">Learning transferable architectures for scalable image recognition</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2018</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>8697</fpage><lpage>8710</lpage></mixed-citation></ref><ref id="CR151"><label>151.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhong</surname><given-names>Z.</given-names></name><name><surname>Yan</surname><given-names>J.</given-names></name><name><surname>Wu</surname><given-names>W.</given-names></name><name><surname>Shao</surname><given-names>J.</given-names></name><name><surname>Liu</surname><given-names>C.-L.</given-names></name></person-group><article-title xml:lang="en">Practical block-wise neural network architecture generation</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2018</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>2423</fpage><lpage>2432</lpage></mixed-citation></ref><ref id="CR152"><label>152.</label><mixed-citation publication-type="other">
					Liu, H., Simonyan, K., &amp; Yang, Y. (2018). <italic>Darts: differentiable architecture search</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:1806.09055" ext-link-type="uri">arXiv:1806.09055</ext-link>.
				</mixed-citation></ref><ref id="CR153"><label>153.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Xie</surname><given-names>L.</given-names></name><name><surname>Wu</surname><given-names>J.</given-names></name><name><surname>Tian</surname><given-names>Q.</given-names></name></person-group><article-title xml:lang="en">Progressive differentiable architecture search: bridging the depth gap between search and evaluation</article-title><source>Proceedings of the IEEE international conference on computer vision</source><year>2019</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>1294</fpage><lpage>1303</lpage></mixed-citation></ref><ref id="CR154"><label>154.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stanley</surname><given-names>K. O.</given-names></name><name><surname>Clune</surname><given-names>J.</given-names></name><name><surname>Lehman</surname><given-names>J.</given-names></name><name><surname>Miikkulainen</surname><given-names>R.</given-names></name></person-group><article-title xml:lang="en">Designing neural networks through neuroevolution</article-title><source>Nature Machine Intelligence</source><year>2019</year><volume>1</volume><issue>1</issue><fpage>24</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1038/s42256-018-0006-z</pub-id></mixed-citation></ref><ref id="CR155"><label>155.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stanley</surname><given-names>K. O.</given-names></name><name><surname>Miikkulainen</surname><given-names>R.</given-names></name></person-group><article-title xml:lang="en">Evolving neural networks through augmenting topologies</article-title><source>Evolutionary Computation</source><year>2002</year><volume>10</volume><issue>2</issue><fpage>99</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1162/106365602320169811</pub-id></mixed-citation></ref><ref id="CR156"><label>156.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Miikkulainen</surname><given-names>R.</given-names></name><name><surname>Liang</surname><given-names>J.</given-names></name><name><surname>Meyerson</surname><given-names>E.</given-names></name><name><surname>Rawal</surname><given-names>A.</given-names></name><name><surname>Fink</surname><given-names>D.</given-names></name><name><surname>Francon</surname><given-names>O.</given-names></name><etal/><etal/></person-group><person-group person-group-type="editor"><name><surname>Kozma</surname><given-names>R.</given-names></name><name><surname>Alippi</surname><given-names>C.</given-names></name><name><surname>Choe</surname><given-names>Y.</given-names></name><etal/><etal/></person-group><article-title xml:lang="en">Evolving deep neural networks</article-title><source>Artificial intelligence in the age of neural networks and brain computing</source><year>2019</year><publisher-loc>Amsterdam</publisher-loc><publisher-name>Elsevier</publisher-name><fpage>293</fpage><lpage>312</lpage><pub-id pub-id-type="doi">10.1016/B978-0-12-815480-9.00015-3</pub-id></mixed-citation></ref><ref id="CR157"><label>157.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>Z.</given-names></name><name><surname>Whalen</surname><given-names>I.</given-names></name><name><surname>Boddeti</surname><given-names>V.</given-names></name><name><surname>Dhebar</surname><given-names>Y.</given-names></name><name><surname>Deb</surname><given-names>K.</given-names></name><name><surname>Goodman</surname><given-names>E.</given-names></name><name><surname>Banzhaf</surname><given-names>W.</given-names></name></person-group><article-title xml:lang="en">NSGA-NET: neural architecture search using multi-objective genetic algorithm</article-title><source>Proceedings of the genetic and evolutionary computation conference</source><year>2019</year><publisher-loc>New York</publisher-loc><publisher-name>ACM</publisher-name><fpage>419</fpage><lpage>427</lpage><pub-id pub-id-type="doi">10.1145/3321707.3321729</pub-id></mixed-citation></ref><ref id="CR158"><label>158.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Redmon</surname><given-names>J.</given-names></name><name><surname>Divvala</surname><given-names>S.</given-names></name><name><surname>Girshick</surname><given-names>R.</given-names></name><name><surname>Farhadi</surname><given-names>A.</given-names></name></person-group><article-title xml:lang="en">You only look once: unified, real-time object detection</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2016</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>779</fpage><lpage>788</lpage></mixed-citation></ref><ref id="CR159"><label>159.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Meinhardt</surname><given-names>T.</given-names></name><name><surname>Kirillov</surname><given-names>A.</given-names></name><name><surname>Leal-Taixe</surname><given-names>L.</given-names></name><name><surname>Feichtenhofer</surname><given-names>C.</given-names></name></person-group><article-title xml:lang="en">Trackformer: multi-object tracking with transformers</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2022</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>8844</fpage><lpage>8854</lpage></mixed-citation></ref><ref id="CR160"><label>160.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gilles</surname><given-names>T.</given-names></name><name><surname>Sabatini</surname><given-names>S.</given-names></name><name><surname>Tsishkou</surname><given-names>D.</given-names></name><name><surname>Stanciulescu</surname><given-names>B.</given-names></name><name><surname>Moutarde</surname><given-names>F.</given-names></name></person-group><article-title xml:lang="en">GOHOME: graph-oriented heatmap output for future motion estimation</article-title><source>2022 international conference on robotics and automation (ICRA)</source><year>2022</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>9107</fpage><lpage>9114</lpage><pub-id pub-id-type="doi">10.1109/ICRA46639.2022.9812253</pub-id></mixed-citation></ref><ref id="CR161"><label>161.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname><given-names>R.</given-names></name><name><surname>Li</surname><given-names>K.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Sun</surname><given-names>X.</given-names></name><name><surname>Guo</surname><given-names>F.</given-names></name><name><surname>Guo</surname><given-names>X.</given-names></name><name><surname>Wu</surname><given-names>Y.</given-names></name><name><surname>Huang</surname><given-names>F.</given-names></name><name><surname>Luo</surname><given-names>J.</given-names></name></person-group><article-title xml:lang="en">Semi-supervised adversarial monocular depth estimation</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><year>2019</year><volume>42</volume><issue>10</issue><fpage>2410</fpage><lpage>2422</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2019.2936024</pub-id></mixed-citation></ref><ref id="CR162"><label>162.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Liang</surname><given-names>Z.</given-names></name><name><surname>Li</surname><given-names>C.</given-names></name><name><surname>Zhong</surname><given-names>H.</given-names></name><name><surname>Liu</surname><given-names>L.</given-names></name><name><surname>Zhao</surname><given-names>C.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Wu</surname><given-names>Q. J.</given-names></name></person-group><article-title xml:lang="en">A practical robotic grasping method by using 6-d pose estimation with protective correction</article-title><source>IEEE Transactions on Industrial Electronics</source><year>2021</year><volume>69</volume><issue>4</issue><fpage>3876</fpage><lpage>3886</lpage><pub-id pub-id-type="doi">10.1109/TIE.2021.3075836</pub-id></mixed-citation></ref><ref id="CR163"><label>163.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>A.</given-names></name><name><surname>Sheth</surname><given-names>P.</given-names></name><name><surname>Xie</surname><given-names>P.</given-names></name></person-group><article-title xml:lang="en">Neural architecture search for pneumonia diagnosis from chest X-rays</article-title><source>Scientific Reports</source><year>2022</year><volume>12</volume><issue>1</issue><pub-id pub-id-type="doi">10.1038/s41598-022-15341-0</pub-id></mixed-citation></ref><ref id="CR164"><label>164.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oyelade</surname><given-names>O. N.</given-names></name><name><surname>Ezugwu</surname><given-names>A. E.</given-names></name></person-group><article-title xml:lang="en">A bioinspired neural architecture search based convolutional neural network for breast cancer detection using histopathology images</article-title><source>Scientific Reports</source><year>2021</year><volume>11</volume><issue>1</issue><pub-id pub-id-type="doi">10.1038/s41598-021-98978-7</pub-id></mixed-citation></ref><ref id="CR165"><label>165.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Yang</surname><given-names>Y.</given-names></name><name><surname>Zhou</surname><given-names>X.</given-names></name><name><surname>Wu</surname><given-names>Q. M. J.</given-names></name></person-group><article-title xml:lang="en">MAMA Net: multi-scale attention memory autoencoder network for anomaly detection</article-title><source>IEEE Transactions on Medical Imaging</source><year>2021</year><volume>40</volume><issue>3</issue><fpage>1032</fpage><lpage>1041</lpage><pub-id pub-id-type="doi">10.1109/TMI.2020.3045295</pub-id></mixed-citation></ref><ref id="CR166"><label>166.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>T.-Y.</given-names></name><name><surname>Maire</surname><given-names>M.</given-names></name><name><surname>Belongie</surname><given-names>S.</given-names></name><name><surname>Hays</surname><given-names>J.</given-names></name><name><surname>Perona</surname><given-names>P.</given-names></name><name><surname>Ramanan</surname><given-names>D.</given-names></name><name><surname>Dollár</surname><given-names>P.</given-names></name><name><surname>Zitnick</surname><given-names>C. L.</given-names></name></person-group><article-title xml:lang="en">Microsoft COCO: common objects in context</article-title><source>European conference on computer vision</source><year>2014</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>740</fpage><lpage>755</lpage></mixed-citation></ref><ref id="CR167"><label>167.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Godard</surname><given-names>C.</given-names></name><name><surname>Mac Aodha</surname><given-names>O.</given-names></name><name><surname>Firman</surname><given-names>M.</given-names></name><name><surname>Brostow</surname><given-names>G. J.</given-names></name></person-group><article-title xml:lang="en">Digging into self-supervised monocular depth estimation</article-title><source>Proceedings of the IEEE international conference on computer vision</source><year>2019</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>3828</fpage><lpage>3838</lpage></mixed-citation></ref><ref id="CR168"><label>168.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Song</surname><given-names>Y.</given-names></name><name><surname>Ma</surname><given-names>C.</given-names></name><name><surname>Zeng</surname><given-names>B.</given-names></name></person-group><article-title xml:lang="en">Rethinking image deraining via rain streaks and vapors</article-title><source>European conference on computer vision</source><year>2020</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>367</fpage><lpage>382</lpage></mixed-citation></ref><ref id="CR169"><label>169.</label><mixed-citation publication-type="other">
					Ren, W., Zhou, L., &amp; Chen, J. (2022). Unsupervised single image dehazing with generative adversarial network. <italic>Multimedia Systems</italic>, 1–11.
				</mixed-citation></ref><ref id="CR170"><label>170.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>J.</given-names></name><name><surname>Tang</surname><given-names>S.</given-names></name><name><surname>Li</surname><given-names>d.</given-names></name><name><surname>Imran</surname><given-names>M.</given-names></name><name><surname>Zhang</surname><given-names>C.</given-names></name><name><surname>Liu</surname><given-names>C.</given-names></name><name><surname>Pang</surname><given-names>Z.</given-names></name></person-group><article-title xml:lang="en">Reconfigurable smart factory for drug packing in healthcare industry 4.0</article-title><source>IEEE Transactions on Industrial Informatics</source><year>2018</year><volume>15</volume><issue>1</issue><fpage>507</fpage><lpage>516</lpage><pub-id pub-id-type="doi">10.1109/TII.2018.2843811</pub-id></mixed-citation></ref><ref id="CR171"><label>171.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>Q.</given-names></name><name><surname>Li</surname><given-names>H.</given-names></name><name><surname>Chirikjian</surname><given-names>G. S.</given-names></name></person-group><article-title xml:lang="en">New probabilistic approaches to the AX=XB hand-eye calibration without correspondence</article-title><source>2016 IEEE international conference on robotics and automation (ICRA)</source><year>2016</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>4365</fpage><lpage>4371</lpage></mixed-citation></ref><ref id="CR172"><label>172.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Niu</surname><given-names>C.</given-names></name><name><surname>Zhu</surname><given-names>Q.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Zhou</surname><given-names>X.</given-names></name><name><surname>Shen</surname><given-names>W.</given-names></name></person-group><article-title xml:lang="en">Real time counting system of glass bottle based on multi objects tracking</article-title><source>2021 China automation congress (CAC)</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>5402</fpage><lpage>5407</lpage><pub-id pub-id-type="doi">10.1109/CAC53003.2021.9728631</pub-id></mixed-citation></ref><ref id="CR173"><label>173.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yan</surname><given-names>B.</given-names></name><name><surname>Peng</surname><given-names>H.</given-names></name><name><surname>Wu</surname><given-names>K.</given-names></name><name><surname>Wang</surname><given-names>D.</given-names></name><name><surname>Fu</surname><given-names>J.</given-names></name><name><surname>Lu</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">LightTrack: finding lightweight neural networks for object tracking via one-shot architecture search</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>15180</fpage><lpage>15189</lpage></mixed-citation></ref><ref id="CR174"><label>174.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viriyasaranon</surname><given-names>T.</given-names></name><name><surname>Choi</surname><given-names>J.-H.</given-names></name></person-group><article-title xml:lang="en">Object detectors involving a NAS-gate convolutional module and capsule attention module</article-title><source>Scientific Reports</source><year>2022</year><volume>12</volume><issue>1</issue><pub-id pub-id-type="doi">10.1038/s41598-022-07898-7</pub-id></mixed-citation></ref><ref id="CR175"><label>175.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>N.</given-names></name><name><surname>Gao</surname><given-names>Y.</given-names></name><name><surname>Chen</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>P.</given-names></name><name><surname>Tian</surname><given-names>Z.</given-names></name><name><surname>Shen</surname><given-names>C.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name></person-group><article-title xml:lang="en">NAS-FCOS: fast neural architecture search for object detection</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2020</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>11943</fpage><lpage>11951</lpage></mixed-citation></ref><ref id="CR176"><label>176.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Yang</surname><given-names>T.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Meng</surname><given-names>G.</given-names></name><name><surname>Xiao</surname><given-names>X.</given-names></name><name><surname>Sun</surname><given-names>J.</given-names></name><etal/></person-group><person-group person-group-type="editor"><name><surname>Wallach</surname><given-names>H.</given-names></name><name><surname>Larochelle</surname><given-names>H.</given-names></name><name><surname>Beygelzimer</surname><given-names>A.</given-names></name><etal/></person-group><article-title xml:lang="en">DetNAS: backbone search for object detection</article-title><source>Advances in neural information processing systems 32</source><year>2019</year><publisher-loc>Red Hook</publisher-loc><publisher-name>Curran Associates</publisher-name><fpage>6642</fpage><lpage>6652</lpage></mixed-citation></ref><ref id="CR177"><label>177.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yao</surname><given-names>L.</given-names></name><name><surname>Xu</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>W.</given-names></name><name><surname>Liang</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>Z.</given-names></name></person-group><article-title xml:lang="en">SM-NAS: structural-to-modular neural architecture search for object detection</article-title><source>Proceedings of the AAAI Conference on Artificial Intelligence</source><year>2020</year><volume>34</volume><issue>7</issue><fpage>12661</fpage><lpage>12668</lpage><pub-id pub-id-type="doi">10.1609/aaai.v34i07.6958</pub-id><comment>Menlo Park: AAAI Press</comment></mixed-citation></ref><ref id="CR178"><label>178.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Wu</surname><given-names>L.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Chen</surname><given-names>R.</given-names></name><name><surname>Kong</surname><given-names>S.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Hu</surname><given-names>J.</given-names></name><name><surname>Wu</surname><given-names>J.</given-names></name></person-group><article-title xml:lang="en">Attention-guided multitask convolutional neural network for power line parts detection</article-title><source>IEEE Transactions on Instrumentation and Measurement</source><year>2022</year><volume>71</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1109/TIM.2022.3162615</pub-id></mixed-citation></ref><ref id="CR179"><label>179.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>Z.</given-names></name><name><surname>Rahman Siddiquee</surname><given-names>M. M.</given-names></name><name><surname>Tajbakhsh</surname><given-names>N.</given-names></name><name><surname>Liang</surname><given-names>J.</given-names></name><etal/></person-group><person-group person-group-type="editor"><name><surname>Stoyanov</surname><given-names>D.</given-names></name><name><surname>Taylor</surname><given-names>Z.</given-names></name><name><surname>Carneiro</surname><given-names>G.</given-names></name><etal/></person-group><article-title xml:lang="en">Unet++: a nested u-net architecture for medical image segmentation</article-title><source>Deep learning in medical image analysis and multimodal learning for clinical decision support</source><year>2018</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>3</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1007/978-3-030-00889-5_1</pub-id></mixed-citation></ref><ref id="CR180"><label>180.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Isensee</surname><given-names>F.</given-names></name><name><surname>Jaeger</surname><given-names>P. F.</given-names></name><name><surname>Kohl</surname><given-names>S. A.</given-names></name><name><surname>Petersen</surname><given-names>J.</given-names></name><name><surname>Maier-Hein</surname><given-names>K. H.</given-names></name></person-group><article-title xml:lang="en">NNU-NET: a self-configuring method for deep learning-based biomedical image segmentation</article-title><source>Nature Methods</source><year>2021</year><volume>18</volume><issue>2</issue><fpage>203</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1038/s41592-020-01008-z</pub-id></mixed-citation></ref><ref id="CR181"><label>181.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>C.</given-names></name><name><surname>Chen</surname><given-names>L.-C.</given-names></name><name><surname>Schroff</surname><given-names>F.</given-names></name><name><surname>Adam</surname><given-names>H.</given-names></name><name><surname>Hua</surname><given-names>W.</given-names></name><name><surname>Yuille</surname><given-names>A. L.</given-names></name><name><surname>Fei-Fei</surname><given-names>L.</given-names></name></person-group><article-title xml:lang="en">Auto-deeplab: hierarchical neural architecture search for semantic image segmentation</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2019</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>82</fpage><lpage>92</lpage></mixed-citation></ref><ref id="CR182"><label>182.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nekrasov</surname><given-names>V.</given-names></name><name><surname>Chen</surname><given-names>H.</given-names></name><name><surname>Shen</surname><given-names>C.</given-names></name><name><surname>Reid</surname><given-names>I.</given-names></name></person-group><article-title xml:lang="en">Fast neural architecture search of compact semantic segmentation models via auxiliary cells</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2019</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>9126</fpage><lpage>9135</lpage></mixed-citation></ref><ref id="CR183"><label>183.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>J.</given-names></name><name><surname>Zhu</surname><given-names>G.</given-names></name><name><surname>Fan</surname><given-names>Z.</given-names></name><name><surname>Liu</surname><given-names>J.</given-names></name><name><surname>Rong</surname><given-names>Y.</given-names></name><name><surname>Mo</surname><given-names>J.</given-names></name><name><surname>Li</surname><given-names>W.</given-names></name><name><surname>Chen</surname><given-names>X.</given-names></name></person-group><article-title xml:lang="en">Genetic U-Net: automatically designed deep networks for retinal vessel segmentation using a genetic algorithm</article-title><source>IEEE Transactions on Medical Imaging</source><year>2021</year><volume>41</volume><issue>2</issue><fpage>292</fpage><lpage>307</lpage><pub-id pub-id-type="doi">10.1109/TMI.2021.3111679</pub-id></mixed-citation></ref><ref id="CR184"><label>184.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>F.</given-names></name><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Ye</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">Fast human pose estimation</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2019</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>3517</fpage><lpage>3526</lpage></mixed-citation></ref><ref id="CR185"><label>185.</label><mixed-citation publication-type="other">
					Milan, A., Leal-Taixé, L., Reid, I., Roth, S., &amp; Schindler, K. (2016). <italic>MOT16: a benchmark for multi-object tracking</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:1603.00831" ext-link-type="uri">arXiv:1603.00831</ext-link>.
				</mixed-citation></ref><ref id="CR186"><label>186.</label><mixed-citation publication-type="other">
					Zou, Z., Shi, Z., Guo, Y., &amp; Ye, J. (2019). <italic>Object detection in 20 years: a survey</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:1905.05055" ext-link-type="uri">arXiv:1905.05055</ext-link>.
				</mixed-citation></ref><ref id="CR187"><label>187.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Godard</surname><given-names>C.</given-names></name><name><surname>Mac Aodha</surname><given-names>O.</given-names></name><name><surname>Brostow</surname><given-names>G. J.</given-names></name></person-group><article-title xml:lang="en">Unsupervised monocular depth estimation with left-right consistency</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2017</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>270</fpage><lpage>279</lpage></mixed-citation></ref><ref id="CR188"><label>188.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nagarajan</surname><given-names>V. R.</given-names></name><name><surname>Singh</surname><given-names>P.</given-names></name></person-group><article-title xml:lang="en">Obstacle detection and avoidance for mobile robots using monocular vision</article-title><source>2021 8th international conference on smart computing and communications (ICSCC)</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>275</fpage><lpage>279</lpage><pub-id pub-id-type="doi">10.1109/ICSCC51209.2021.9528162</pub-id></mixed-citation></ref><ref id="CR189"><label>189.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohya</surname><given-names>I.</given-names></name><name><surname>Kosaka</surname><given-names>A.</given-names></name><name><surname>Kak</surname><given-names>A.</given-names></name></person-group><article-title xml:lang="en">Vision-based navigation by a mobile robot with obstacle avoidance using single-camera vision and ultrasonic sensing</article-title><source>IEEE Transactions on Robotics and Automation</source><year>1998</year><volume>14</volume><issue>6</issue><fpage>969</fpage><lpage>978</lpage><pub-id pub-id-type="doi">10.1109/70.736780</pub-id></mixed-citation></ref><ref id="CR190"><label>190.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>T.</given-names></name><name><surname>Xiang</surname><given-names>Z.-Y.</given-names></name><name><surname>Liu</surname><given-names>J.-L.</given-names></name></person-group><article-title xml:lang="en">Perception in disparity: an efficient navigation framework for autonomous vehicles with stereo cameras</article-title><source>IEEE Transactions on Intelligent Transportation Systems</source><year>2015</year><volume>16</volume><issue>5</issue><fpage>2935</fpage><lpage>2948</lpage><pub-id pub-id-type="doi">10.1109/TITS.2015.2430896</pub-id></mixed-citation></ref><ref id="CR191"><label>191.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>S.</given-names></name><name><surname>Kim</surname><given-names>D.</given-names></name><name><surname>Choi</surname><given-names>S.</given-names></name></person-group><article-title xml:lang="en">View path planning via online multiview stereo for 3-D modeling of large-scale structures</article-title><source>IEEE Transactions on Robotics</source><year>2021</year><volume>38</volume><issue>1</issue><fpage>372</fpage><lpage>390</lpage><pub-id pub-id-type="doi">10.1109/TRO.2021.3083197</pub-id></mixed-citation></ref><ref id="CR192"><label>192.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Huynh</surname><given-names>L.</given-names></name><name><surname>Nguyen</surname><given-names>P.</given-names></name><name><surname>Matas</surname><given-names>J.</given-names></name><name><surname>Rahtu</surname><given-names>E.</given-names></name><name><surname>Heikkilä</surname><given-names>J.</given-names></name></person-group><article-title xml:lang="en">Lightweight monocular depth with a novel neural architecture search method</article-title><source>Proceedings of the IEEE winter conference on applications of computer vision</source><year>2022</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>3643</fpage><lpage>3653</lpage></mixed-citation></ref><ref id="CR193"><label>193.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Saikia</surname><given-names>T.</given-names></name><name><surname>Marrakchi</surname><given-names>Y.</given-names></name><name><surname>Zela</surname><given-names>A.</given-names></name><name><surname>Hutter</surname><given-names>F.</given-names></name><name><surname>Brox</surname><given-names>T.</given-names></name></person-group><article-title xml:lang="en">Autodispnet: Improving disparity estimation with automl</article-title><source>Proceedings of the IEEE international conference on computer vision</source><year>2019</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>1812</fpage><lpage>1823</lpage></mixed-citation></ref><ref id="CR194"><label>194.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeng</surname><given-names>K.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Mao</surname><given-names>J.</given-names></name><name><surname>Liu</surname><given-names>C.</given-names></name><name><surname>Peng</surname><given-names>W.</given-names></name><name><surname>Yang</surname><given-names>Y.</given-names></name></person-group><article-title xml:lang="en">Deep stereo matching with hysteresis attention and supervised cost volume construction</article-title><source>IEEE Transactions on Image Processing</source><year>2021</year><volume>31</volume><fpage>812</fpage><lpage>822</lpage><pub-id pub-id-type="doi">10.1109/TIP.2021.3135485</pub-id></mixed-citation></ref><ref id="CR195"><label>195.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>X.</given-names></name><name><surname>Zhong</surname><given-names>Y.</given-names></name><name><surname>Harandi</surname><given-names>M.</given-names></name><name><surname>Dai</surname><given-names>Y.</given-names></name><name><surname>Chang</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>H.</given-names></name><name><surname>Drummond</surname><given-names>T.</given-names></name><name><surname>Ge</surname><given-names>Z.</given-names></name><etal/></person-group><person-group person-group-type="editor"><name><surname>Larochelle</surname><given-names>H.</given-names></name><name><surname>Ranzato</surname><given-names>M.</given-names></name><name><surname>Hadsell</surname><given-names>R.</given-names></name><etal/></person-group><article-title xml:lang="en">Hierarchical neural architecture search for deep stereo matching</article-title><source>Advances in Neural Information Processing Systems 33</source><year>2020</year><publisher-loc>Red Hook</publisher-loc><publisher-name>Curran Associates</publisher-name><fpage>22158</fpage><lpage>22169</lpage></mixed-citation></ref><ref id="CR196"><label>196.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>C.</given-names></name><name><surname>Tian</surname><given-names>K.</given-names></name><name><surname>Fan</surname><given-names>B.</given-names></name><name><surname>Meng</surname><given-names>G.</given-names></name><name><surname>Zhang</surname><given-names>Z.</given-names></name><name><surname>Pan</surname><given-names>C.</given-names></name></person-group><article-title xml:lang="en">Continual stereo matching of continuous driving scenes with growing architecture</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2022</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>18901</fpage><lpage>18910</lpage></mixed-citation></ref><ref id="CR197"><label>197.</label><mixed-citation publication-type="other">
					Wang, Q., Shi, S., Zhao, K., &amp; Chu, X. (2022). <italic>EASNet: searching elastic and accurate network architecture for stereo matching</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:2207.09796" ext-link-type="uri">arXiv:2207.09796</ext-link>.
				</mixed-citation></ref><ref id="CR198"><label>198.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>W.</given-names></name><name><surname>Hong</surname><given-names>X.</given-names></name><name><surname>Zhao</surname><given-names>G.</given-names></name></person-group><article-title xml:lang="en">Video action recognition via neural architecture searching</article-title><source>2019 IEEE international conference on image processing (ICIP)</source><year>2019</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>11</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1109/ICIP.2019.8802919</pub-id></mixed-citation></ref><ref id="CR199"><label>199.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piergiovanni</surname><given-names>A. J.</given-names></name><name><surname>Angelova</surname><given-names>A.</given-names></name><name><surname>Ryoo</surname><given-names>M. S.</given-names></name></person-group><article-title xml:lang="en">Tiny video networks</article-title><source>Applied AI Letters</source><year>2022</year><volume>3</volume><issue>1</issue><pub-id pub-id-type="doi">10.1002/ail2.38</pub-id></mixed-citation></ref><ref id="CR200"><label>200.</label><mixed-citation publication-type="other">
					Ryoo, M. S., Piergiovanni, A. J., Tan, M., &amp; Angelova, A. (2019). <italic>AssembleNET: searching for multi-stream neural connectivity in video architectures</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:1905.13209" ext-link-type="uri">arXiv:1905.13209</ext-link>.
				</mixed-citation></ref><ref id="CR201"><label>201.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Xiong</surname><given-names>X.</given-names></name><name><surname>Neumann</surname><given-names>M.</given-names></name><name><surname>Piergiovanni</surname><given-names>A. J.</given-names></name><name><surname>Ryoo</surname><given-names>M. S.</given-names></name><name><surname>Angelova</surname><given-names>A.</given-names></name><name><surname>Kitani</surname><given-names>K. M.</given-names></name><name><surname>Hua</surname><given-names>W.</given-names></name></person-group><article-title xml:lang="en">AttentionNAS: spatiotemporal attention cell search for video classification</article-title><source>European conference on computer vision</source><year>2020</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>449</fpage><lpage>465</lpage></mixed-citation></ref><ref id="CR202"><label>202.</label><mixed-citation publication-type="other">
					Piergiovanni, A. J., Angelova, A., &amp; Ryoo, M. (2020). Tiny video networks: architecture search for efficient video models. [Paper presentation]. In <italic>ICML workshop on automated machine learning (AutoML)</italic>. <ext-link xlink:href="http://icml2020.automl.org" ext-link-type="uri">http://icml2020.automl.org</ext-link>.
				</mixed-citation></ref><ref id="CR203"><label>203.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Zheng</surname><given-names>C.</given-names></name><name><surname>Lu</surname><given-names>K.</given-names></name><name><surname>Gao</surname><given-names>S.</given-names></name><name><surname>Wang</surname><given-names>N.</given-names></name><name><surname>Wang</surname><given-names>B.</given-names></name><name><surname>Zhang</surname><given-names>D.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Xu</surname><given-names>T.</given-names></name></person-group><article-title xml:lang="en">Evsrnet: efficient video super-resolution with neural architecture search</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>2480</fpage><lpage>2485</lpage></mixed-citation></ref><ref id="CR204"><label>204.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>L.</given-names></name><name><surname>Guan</surname><given-names>Y.</given-names></name><name><surname>Jin</surname><given-names>S.</given-names></name><name><surname>Liu</surname><given-names>W.</given-names></name><name><surname>Qian</surname><given-names>C.</given-names></name><name><surname>Luo</surname><given-names>P.</given-names></name><name><surname>Ouyang</surname><given-names>W.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name></person-group><article-title xml:lang="en">Vipnas: efficient video pose estimation via neural architecture search</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>16072</fpage><lpage>16081</lpage></mixed-citation></ref><ref id="CR205"><label>205.</label><mixed-citation publication-type="other">
					Cai, H., Zhu, L., &amp; Han, S. (2018). <italic>ProxylessNAS: direct neural architecture search on target task and hardware</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:1812.00332" ext-link-type="uri">arXiv:1812.00332</ext-link>.
				</mixed-citation></ref><ref id="CR206"><label>206.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>B.</given-names></name><name><surname>Dai</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>P.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Sun</surname><given-names>F.</given-names></name><name><surname>Wu</surname><given-names>Y.</given-names></name><name><surname>Tian</surname><given-names>Y.</given-names></name><name><surname>Vajda</surname><given-names>P.</given-names></name><name><surname>Jia</surname><given-names>Y.</given-names></name><name><surname>Keutzer</surname><given-names>K.</given-names></name></person-group><article-title xml:lang="en">Fbnet: hardware-aware efficient convnet design via differentiable neural architecture search</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2019</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>10734</fpage><lpage>10742</lpage></mixed-citation></ref><ref id="CR207"><label>207.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>López</surname><given-names>J. G.</given-names></name><name><surname>Agudo</surname><given-names>A.</given-names></name><name><surname>Moreno-Noguer</surname><given-names>F.</given-names></name></person-group><article-title xml:lang="en">E-DNAS: differentiable neural architecture search for embedded systems</article-title><source>2020 25th international conference on pattern recognition (ICPR)</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>4704</fpage><lpage>4711</lpage><pub-id pub-id-type="doi">10.1109/ICPR48806.2021.9412130</pub-id></mixed-citation></ref><ref id="CR208"><label>208.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>X.</given-names></name><name><surname>Liu</surname><given-names>d.</given-names></name><name><surname>Kong</surname><given-names>H.</given-names></name><name><surname>Huai</surname><given-names>S.</given-names></name><name><surname>Chen</surname><given-names>H.</given-names></name><name><surname>Liu</surname><given-names>W.</given-names></name></person-group><article-title xml:lang="en">LightNAS: on lightweight and scalable neural architecture search for embedded platforms</article-title><source>IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</source><year>2022</year><pub-id pub-id-type="doi">10.1109/TCAD.2022.3208187</pub-id><comment>1–14</comment></mixed-citation></ref><ref id="CR209"><label>209.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cassimon</surname><given-names>T.</given-names></name><name><surname>Vanneste</surname><given-names>S.</given-names></name><name><surname>Bosmans</surname><given-names>S.</given-names></name><name><surname>Mercelis</surname><given-names>S.</given-names></name><name><surname>Hellinckx</surname><given-names>P.</given-names></name></person-group><article-title xml:lang="en">Designing resource-constrained neural networks using neural architecture search targeting embedded devices</article-title><source>Internet of Things</source><year>2020</year><volume>12</volume><pub-id pub-id-type="doi">10.1016/j.iot.2020.100234</pub-id></mixed-citation></ref><ref id="CR210"><label>210.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>A.</given-names></name><name><surname>Dai</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>P.</given-names></name><name><surname>He</surname><given-names>Z.</given-names></name><name><surname>Tian</surname><given-names>Y.</given-names></name><name><surname>Xie</surname><given-names>S.</given-names></name><etal/></person-group><article-title xml:lang="en">Fbnetv2: differentiable neural architecture search for spatial and channel dimensions</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2020</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>12965</fpage><lpage>12974</lpage></mixed-citation></ref><ref id="CR211"><label>211.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>He</surname><given-names>Y.</given-names></name><name><surname>Lin</surname><given-names>J.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>H.</given-names></name><name><surname>Li</surname><given-names>L.-J.</given-names></name><name><surname>Han</surname><given-names>S.</given-names></name></person-group><article-title xml:lang="en">AMC: automl for model compression and acceleration on mobile devices</article-title><source>Proceedings of the European conference on computer vision (ECCV)</source><year>2018</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>784</fpage><lpage>800</lpage></mixed-citation></ref><ref id="CR212"><label>212.</label><mixed-citation publication-type="other">
					Lillicrap, T. P., Hunt, J. J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., &amp; Wierstra, D. (2015). <italic>Continuous control with deep reinforcement learning</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:1509.02971" ext-link-type="uri">arXiv:1509.02971</ext-link>.
				</mixed-citation></ref><ref id="CR213"><label>213.</label><mixed-citation publication-type="other">
					Gupta, M., Aravindan, S., Kalisz, A., Chandrasekhar, V., &amp; Jie, L. (2020). <italic>Learning to prune deep neural networks via reinforcement learning</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:2007.04756" ext-link-type="uri">arXiv:2007.04756</ext-link>.
				</mixed-citation></ref><ref id="CR214"><label>214.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>S.</given-names></name><name><surname>Mazaheri</surname><given-names>A.</given-names></name><name><surname>Jannesari</surname><given-names>A.</given-names></name></person-group><article-title xml:lang="en">Topology-aware network pruning using multi-stage graph embedding and reinforcement learning</article-title><source>International conference on machine learning</source><year>2022</year><fpage>25656</fpage><lpage>25667</lpage><comment>PMLR</comment></mixed-citation></ref><ref id="CR215"><label>215.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Li</surname><given-names>C.</given-names></name></person-group><article-title xml:lang="en">Channel pruning via lookahead search guided reinforcement learning</article-title><source>Proceedings of the IEEE winter conference on applications of computer vision</source><year>2022</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>2029</fpage><lpage>2040</lpage></mixed-citation></ref><ref id="CR216"><label>216.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>M.</given-names></name><name><surname>Sui</surname><given-names>Y.</given-names></name><name><surname>Liao</surname><given-names>S.</given-names></name><name><surname>Yuan</surname><given-names>B.</given-names></name></person-group><article-title xml:lang="en">Towards efficient tensor decomposition-based dnn model compression with optimization framework</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>10674</fpage><lpage>10683</lpage></mixed-citation></ref><ref id="CR217"><label>217.</label><mixed-citation publication-type="other">
					Rokh, B., Azarpeyvand, A., &amp; Khanteymoori, A. (2022). <italic>A comprehensive survey on model quantization for deep neural networks</italic>. arXiv preprint <ext-link xlink:href="http://arxiv.org/abs/arXiv:2205.07877" ext-link-type="uri">arXiv:2205.07877</ext-link>.
				</mixed-citation></ref><ref id="CR218"><label>218.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>P.</given-names></name><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Zhao</surname><given-names>H.</given-names></name><name><surname>Jia</surname><given-names>J.</given-names></name></person-group><article-title xml:lang="en">Distilling knowledge via knowledge review</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>5008</fpage><lpage>5017</lpage></mixed-citation></ref><ref id="CR219"><label>219.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>P.</given-names></name><name><surname>Li</surname><given-names>G.</given-names></name><name><surname>Hu</surname><given-names>Q.</given-names></name><name><surname>Lu</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Recent advances in efficient computation of deep convolutional neural networks</article-title><source>Frontiers of Information Technology &amp; Electronic Engineering</source><year>2018</year><volume>19</volume><issue>1</issue><fpage>64</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1631/FITEE.1700789</pub-id></mixed-citation></ref><ref id="CR220"><label>220.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bhalgaonkar</surname><given-names>S. A.</given-names></name><name><surname>Munot</surname><given-names>M. V.</given-names></name><name><surname>Anuse</surname><given-names>A. D.</given-names></name><etal/></person-group><person-group person-group-type="editor"><name><surname>Gupta</surname><given-names>D.</given-names></name><name><surname>Goswami</surname><given-names>R. S.</given-names></name><name><surname>Banerjee</surname><given-names>S.</given-names></name><etal/></person-group><article-title xml:lang="en">Pruning for compression of visual pattern recognition networks: a survey from deep neural networks perspective</article-title><source>Pattern recognition and data analysis with applications</source><year>2022</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>675</fpage><lpage>687</lpage><pub-id pub-id-type="doi">10.1007/978-981-19-1520-8_55</pub-id></mixed-citation></ref><ref id="CR221"><label>221.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>D.</given-names></name><name><surname>Zhou</surname><given-names>P.</given-names></name><name><surname>Zhang</surname><given-names>T.</given-names></name></person-group><article-title xml:lang="en">Model compression and acceleration for deep neural networks: the principles, progress, and challenges</article-title><source>IEEE Signal Processing Magazine</source><year>2018</year><volume>35</volume><issue>1</issue><fpage>126</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1109/MSP.2017.2765695</pub-id></mixed-citation></ref><ref id="CR222"><label>222.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>C.-H.</given-names></name><name><surname>Huang</surname><given-names>K.-Y.</given-names></name><name><surname>Yao</surname><given-names>Y.</given-names></name><name><surname>Chen</surname><given-names>J.-C.</given-names></name><name><surname>Shuai</surname><given-names>H.-H.</given-names></name><name><surname>Cheng</surname><given-names>W.-H.</given-names></name></person-group><article-title xml:lang="en">Lightweight deep learning: an overview</article-title><source>IEEE Consumer Electronics Magazine</source><year>2022</year><pub-id pub-id-type="doi">10.1109/MCE.2022.3181759</pub-id><comment>1–12</comment></mixed-citation></ref><ref id="CR223"><label>223.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>Y.</given-names></name><name><surname>Yen</surname><given-names>G. G.</given-names></name><name><surname>Yi</surname><given-names>Z.</given-names></name></person-group><article-title xml:lang="en">IGD indicator-based evolutionary algorithm for many-objective optimization problems</article-title><source>IEEE Transactions on Evolutionary Computation</source><year>2018</year><volume>23</volume><issue>2</issue><fpage>173</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1109/TEVC.2018.2791283</pub-id></mixed-citation></ref><ref id="CR224"><label>224.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Darwish</surname><given-names>A.</given-names></name><name><surname>Hassanien</surname><given-names>A. E.</given-names></name><name><surname>Das</surname><given-names>S.</given-names></name></person-group><article-title xml:lang="en">A survey of swarm and evolutionary computing approaches for deep learning</article-title><source>Artificial Intelligence Review</source><year>2020</year><volume>53</volume><issue>3</issue><fpage>1767</fpage><lpage>1812</lpage><pub-id pub-id-type="doi">10.1007/s10462-019-09719-2</pub-id></mixed-citation></ref><ref id="CR225"><label>225.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stamenkovic</surname><given-names>A.</given-names></name><name><surname>Stapley</surname><given-names>P. J.</given-names></name><name><surname>Robins</surname><given-names>R.</given-names></name><name><surname>Hollands</surname><given-names>M. A.</given-names></name></person-group><article-title xml:lang="en">Do postural constraints affect eye, head, and arm coordination?</article-title><source>Journal of Neurophysiology</source><year>2018</year><volume>120</volume><issue>4</issue><fpage>2066</fpage><lpage>2082</lpage><pub-id pub-id-type="doi">10.1152/jn.00200.2018</pub-id></mixed-citation></ref><ref id="CR226"><label>226.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Glaeser</surname><given-names>G.</given-names></name><name><surname>Paulus</surname><given-names>H. F.</given-names></name></person-group><source>The evolution of the eye</source><year>2015</year><pub-id pub-id-type="doi">10.1007/978-3-319-17476-1</pub-id><comment>Springer</comment></mixed-citation></ref><ref id="CR227"><label>227.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Qiao</surname><given-names>H.</given-names></name><name><surname>Ma</surname><given-names>C.</given-names></name><name><surname>Li</surname><given-names>R.</given-names></name></person-group><source>The hand-eye-brain system of intelligent robot: from interdisciplinary perspective of information science and neuroscience</source><year>2021</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name></mixed-citation></ref><ref id="CR228"><label>228.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qiao</surname><given-names>H.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name><name><surname>Huang</surname><given-names>X.</given-names></name></person-group><article-title xml:lang="en">A survey of brain-inspired intelligent robots: integration of vision, decision, motion control, and musculoskeletal systems</article-title><source>IEEE Transactions on Cybernetics</source><year>2022</year><volume>52</volume><issue>10</issue><fpage>11267</fpage><lpage>11280</lpage><pub-id pub-id-type="doi">10.1109/TCYB.2021.3071312</pub-id></mixed-citation></ref><ref id="CR229"><label>229.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>X.</given-names></name><name><surname>Wu</surname><given-names>W.</given-names></name><name><surname>Qiao</surname><given-names>H.</given-names></name><name><surname>Ji</surname><given-names>Y.</given-names></name></person-group><article-title xml:lang="en">Brain-inspired motion learning in recurrent neural network with emotion modulation</article-title><source>IEEE Transactions on Cognitive and Developmental Systems</source><year>2018</year><volume>10</volume><issue>4</issue><fpage>1153</fpage><lpage>1164</lpage><pub-id pub-id-type="doi">10.1109/TCDS.2018.2843563</pub-id></mixed-citation></ref><ref id="CR230"><label>230.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>R.</given-names></name><name><surname>Qiao</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">A survey of methods and strategies for high-precision robotic grasping and assembly tasks—some new trends</article-title><source>IEEE/ASME Transactions on Mechatronics</source><year>2019</year><volume>24</volume><issue>6</issue><fpage>2718</fpage><lpage>2732</lpage><pub-id pub-id-type="doi">10.1109/TMECH.2019.2945135</pub-id></mixed-citation></ref><ref id="CR231"><label>231.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Z.</given-names></name><name><surname>Qiao</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Realizing compliant insertion task based on attractive-region-in-environment</article-title><source>2020 7th international conference on information science and control engineering (ICISCE)</source><year>2020</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>1063</fpage><lpage>1067</lpage><pub-id pub-id-type="doi">10.1109/ICISCE50968.2020.00216</pub-id></mixed-citation></ref><ref id="CR232"><label>232.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Qiao</surname><given-names>H.</given-names></name><name><surname>Ma</surname><given-names>C.</given-names></name><name><surname>Li</surname><given-names>R.</given-names></name></person-group><article-title xml:lang="en">The concept of “attractive region in environment (ARIE)” and its application in high-precision tasks with low-precision systems</article-title><source>The “hand-eye-brain” system of intelligent robot</source><year>2022</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>15</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1007/978-981-16-3575-5_5</pub-id></mixed-citation></ref><ref id="CR233"><label>233.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Qiao</surname><given-names>H.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Li</surname><given-names>F.</given-names></name><name><surname>Xi</surname><given-names>X.</given-names></name><name><surname>Wu</surname><given-names>W.</given-names></name></person-group><article-title xml:lang="en">Biologically inspired model for visual cognition achieving unsupervised episodic and semantic feature learning</article-title><source>IEEE Transactions on Cybernetics</source><year>2015</year><volume>46</volume><issue>10</issue><fpage>2335</fpage><lpage>2347</lpage><pub-id pub-id-type="doi">10.1109/TCYB.2015.2476706</pub-id></mixed-citation></ref><ref id="CR234"><label>234.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>P.</given-names></name><name><surname>Qiao</surname><given-names>H.</given-names></name><name><surname>Wu</surname><given-names>W.</given-names></name><name><surname>Qi</surname><given-names>L.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Zhong</surname><given-names>S.</given-names></name><name><surname>Zhang</surname><given-names>B.</given-names></name></person-group><article-title xml:lang="en">A novel biologically inspired visual cognition model: automatic extraction of semantics, formation of integrated concepts, and reselection features for ambiguity</article-title><source>IEEE Transactions on Cognitive and Developmental Systems</source><year>2017</year><volume>10</volume><issue>2</issue><fpage>420</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1109/TCDS.2017.2749978</pub-id></mixed-citation></ref><ref id="CR235"><label>235.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Qiao</surname><given-names>H.</given-names></name><name><surname>Ma</surname><given-names>C.</given-names></name><name><surname>Li</surname><given-names>R.</given-names></name></person-group><article-title xml:lang="en">Biologically inspired visual model with preliminary cognition and active attention adjustment</article-title><source>The “hand-eye-brain” system of intelligent robot</source><year>2022</year><publisher-loc>Berlin</publisher-loc><publisher-name>Springer</publisher-name><fpage>131</fpage><lpage>150</lpage><pub-id pub-id-type="doi">10.1007/978-981-16-3575-5_12</pub-id></mixed-citation></ref><ref id="CR236"><label>236.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>X.</given-names></name><name><surname>Wu</surname><given-names>W.</given-names></name><name><surname>Qiao</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Connecting model-based and model-free control with emotion modulation in learning systems</article-title><source>IEEE Transactions on Systems, Man, and Cybernetics: Systems</source><year>2019</year><volume>51</volume><issue>8</issue><fpage>4624</fpage><lpage>4638</lpage><pub-id pub-id-type="doi">10.1109/TSMC.2019.2933152</pub-id></mixed-citation></ref><ref id="CR237"><label>237.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>X.</given-names></name><name><surname>Wu</surname><given-names>W.</given-names></name><name><surname>Qiao</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Computational modeling of emotion-motivated decisions for continuous control of mobile robots</article-title><source>IEEE Transactions on Cognitive and Developmental Systems</source><year>2020</year><volume>13</volume><issue>1</issue><fpage>31</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1109/TCDS.2019.2963545</pub-id></mixed-citation></ref><ref id="CR238"><label>238.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>W.</given-names></name><name><surname>Hua</surname><given-names>W.</given-names></name><name><surname>Qi</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>G.</given-names></name><name><surname>Xiao</surname><given-names>H.</given-names></name><name><surname>Xu</surname><given-names>S.</given-names></name><name><surname>Ma</surname><given-names>G.</given-names></name></person-group><article-title xml:lang="en">Coupled magnetic field-thermal network analysis of modular-spoke-type permanent-magnet machine for electric motorcycle</article-title><source>IEEE Transactions on Energy Conversion</source><year>2020</year><volume>36</volume><issue>1</issue><fpage>120</fpage><lpage>130</lpage><pub-id pub-id-type="doi">10.1109/TEC.2020.3006098</pub-id></mixed-citation></ref><ref id="CR239"><label>239.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krizhevsky</surname><given-names>A.</given-names></name><name><surname>Sutskever</surname><given-names>I.</given-names></name><name><surname>Hinton</surname><given-names>G. E.</given-names></name></person-group><article-title xml:lang="en">Imagenet classification with deep convolutional neural networks</article-title><source>Communications of the ACM</source><year>2017</year><volume>60</volume><issue>6</issue><fpage>84</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1145/3065386</pub-id></mixed-citation></ref><ref id="CR240"><label>240.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nahian</surname><given-names>S. A.</given-names></name><name><surname>Truong</surname><given-names>D. Q.</given-names></name><name><surname>Chowdhury</surname><given-names>P.</given-names></name><name><surname>Das</surname><given-names>D.</given-names></name><name><surname>Ahn</surname><given-names>K. K.</given-names></name></person-group><article-title xml:lang="en">Modeling and fault tolerant control of an electro-hydraulic actuator</article-title><source>International Journal of Precision Engineering and Manufacturing</source><year>2016</year><volume>17</volume><issue>10</issue><fpage>1285</fpage><lpage>1297</lpage><pub-id pub-id-type="doi">10.1007/s12541-016-0153-2</pub-id></mixed-citation></ref><ref id="CR241"><label>241.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>H.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Tan</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>T.</given-names></name></person-group><article-title xml:lang="en">Sambot: a self-assembly modular robot system</article-title><source>IEEE/ASME Transactions on Mechatronics</source><year>2010</year><volume>16</volume><issue>4</issue><fpage>745</fpage><lpage>757</lpage><pub-id pub-id-type="doi">10.1109/TMECH.2010.2085009</pub-id></mixed-citation></ref><ref id="CR242"><label>242.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilpin</surname><given-names>K.</given-names></name><name><surname>Rus</surname><given-names>D.</given-names></name></person-group><article-title xml:lang="en">Modular robot systems</article-title><source>IEEE Robotics &amp; Automation Magazine</source><year>2010</year><volume>17</volume><issue>3</issue><fpage>38</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1109/MRA.2010.937859</pub-id></mixed-citation></ref><ref id="CR243"><label>243.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fukuda</surname><given-names>T.</given-names></name><name><surname>Kubota</surname><given-names>N.</given-names></name></person-group><article-title xml:lang="en">Computational intelligence for robotic systems</article-title><source>12th IEEE international conference on fuzzy systems</source><year>2003</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>1495</fpage><lpage>1508</lpage></mixed-citation></ref><ref id="CR244"><label>244.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallala</surname><given-names>A.</given-names></name><name><surname>Kumar</surname><given-names>A. A.</given-names></name><name><surname>Hichri</surname><given-names>B.</given-names></name><name><surname>Plapper</surname><given-names>P.</given-names></name></person-group><article-title xml:lang="en">Digital twin for human–robot interactions by means of industry 4.0 enabling technologies</article-title><source>Sensors</source><year>2022</year><volume>22</volume><issue>13</issue><pub-id pub-id-type="doi">10.3390/s22134950</pub-id></mixed-citation></ref><ref id="CR245"><label>245.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>S. G.</given-names></name><name><surname>Arnold</surname><given-names>V.</given-names></name><name><surname>Holt</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">How much automation is too much? Keeping the human relevant in knowledge work</article-title><source>Journal of Emerging Technologies in Accounting</source><year>2018</year><volume>15</volume><issue>2</issue><fpage>15</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.2308/jeta-52311</pub-id></mixed-citation></ref><ref id="CR246"><label>246.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dorigo</surname><given-names>M.</given-names></name><name><surname>Theraulaz</surname><given-names>G.</given-names></name><name><surname>Trianni</surname><given-names>V.</given-names></name></person-group><article-title xml:lang="en">Reflections on the future of swarm robotics</article-title><source>Science Robotics</source><year>2020</year><volume>5</volume><issue>49</issue><pub-id pub-id-type="doi">10.1126/scirobotics.abe4385</pub-id></mixed-citation></ref><ref id="CR247"><label>247.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodríguez-Molina</surname><given-names>A.</given-names></name><name><surname>Mezura-Montes</surname><given-names>E.</given-names></name><name><surname>Villarreal-Cervantes</surname><given-names>M. G.</given-names></name><name><surname>Aldape-Pérez</surname><given-names>M.</given-names></name></person-group><article-title xml:lang="en">Multi-objective meta-heuristic optimization in intelligent control: a survey on the controller tuning problem</article-title><source>Applied Soft Computing</source><year>2020</year><volume>93</volume><pub-id pub-id-type="doi">10.1016/j.asoc.2020.106342</pub-id></mixed-citation></ref><ref id="CR248"><label>248.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Deng</surname><given-names>W.</given-names></name></person-group><article-title xml:lang="en">Deep visual domain adaptation: a survey</article-title><source>Neurocomputing</source><year>2018</year><volume>312</volume><fpage>135</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2018.05.083</pub-id></mixed-citation></ref><ref id="CR249"><label>249.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Lan</surname><given-names>C.</given-names></name><name><surname>Liu</surname><given-names>C.</given-names></name><name><surname>Ouyang</surname><given-names>Y.</given-names></name><name><surname>Qin</surname><given-names>T.</given-names></name><name><surname>Lu</surname><given-names>W.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Zeng</surname><given-names>W.</given-names></name><name><surname>Yu</surname><given-names>P.</given-names></name></person-group><article-title xml:lang="en">Generalizing to unseen domains: a survey on domain generalization</article-title><source>IEEE Transactions on Knowledge and Data Engineering</source><year>2022</year><pub-id pub-id-type="doi">10.1109/TKDE.2022.3178128</pub-id><comment>1–14</comment></mixed-citation></ref><ref id="CR250"><label>250.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bai</surname><given-names>H.</given-names></name><name><surname>Zhou</surname><given-names>F.</given-names></name><name><surname>Hong</surname><given-names>L.</given-names></name><name><surname>Ye</surname><given-names>N.</given-names></name><name><surname>Chan</surname><given-names>S. G.</given-names></name><name><surname>Li</surname><given-names>Z.</given-names></name></person-group><article-title xml:lang="en">NAS-OOD: neural architecture search for out-of-distribution generalization</article-title><source>Proceedings of the IEEE international conference on computer vision</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>8320</fpage><lpage>8329</lpage></mixed-citation></ref><ref id="CR251"><label>251.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>Y.-W.</given-names></name><name><surname>Peng</surname><given-names>S.-H.</given-names></name><name><surname>Ting</surname><given-names>C.-K.</given-names></name></person-group><article-title xml:lang="en">Two-stage evolutionary neural architecture search for transfer learning</article-title><source>IEEE Transactions on Evolutionary Computation</source><year>2021</year><volume>25</volume><issue>5</issue><fpage>928</fpage><lpage>940</lpage><pub-id pub-id-type="doi">10.1109/TEVC.2021.3097937</pub-id></mixed-citation></ref><ref id="CR252"><label>252.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Yang</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Xu</surname><given-names>C.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Larochelle</surname><given-names>H.</given-names></name><name><surname>Ranzato</surname><given-names>M.</given-names></name><name><surname>Hadsell</surname><given-names>R.</given-names></name><name><surname>Balcan</surname><given-names>M. F.</given-names></name><name><surname>Lin</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Adapting neural architectures between domains</article-title><source>Advances in neural information processing systems 33</source><year>2020</year><publisher-loc>Red Hook</publisher-loc><publisher-name>Curran Associates</publisher-name><fpage>789</fpage><lpage>798</lpage></mixed-citation></ref><ref id="CR253"><label>253.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>N.</given-names></name><name><surname>Gu</surname><given-names>K.</given-names></name><name><surname>Qiao</surname><given-names>J.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name></person-group><article-title xml:lang="en">Active vision for deep visual learning: a unified pooling framework</article-title><source>IEEE Transactions on Industrial Informatics</source><year>2022</year><volume>18</volume><issue>10</issue><fpage>6610</fpage><lpage>6618</lpage><pub-id pub-id-type="doi">10.1109/TII.2021.3129813</pub-id></mixed-citation></ref><ref id="CR254"><label>254.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname><given-names>J.</given-names></name><name><surname>Joana</surname><given-names>C.</given-names></name><name><surname>Yamane</surname><given-names>Y.</given-names></name><name><surname>Fujita</surname><given-names>I.</given-names></name><name><surname>Tamura</surname><given-names>H.</given-names></name><name><surname>Maldonado</surname><given-names>P. E.</given-names></name><name><surname>Grün</surname><given-names>S.</given-names></name></person-group><article-title xml:lang="en">Latency shortening with enhanced sparseness and responsiveness in V1 during active visual sensing</article-title><source>Scientific Reports</source><year>2022</year><volume>12</volume><issue>1</issue><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1038/s41598-022-09405-4</pub-id></mixed-citation></ref><ref id="CR255"><label>255.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y.</given-names></name><name><surname>Xie</surname><given-names>L.</given-names></name><name><surname>Dai</surname><given-names>W.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Qi</surname><given-names>G.-J.</given-names></name><name><surname>Xiong</surname><given-names>H.</given-names></name><name><surname>Tian</surname><given-names>Q.</given-names></name></person-group><article-title xml:lang="en">Partially-connected neural architecture search for reduced computational redundancy</article-title><source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source><year>2021</year><volume>43</volume><issue>9</issue><fpage>2953</fpage><lpage>2970</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2021.3059510</pub-id></mixed-citation></ref><ref id="CR256"><label>256.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lan</surname><given-names>X.</given-names></name><name><surname>Schwager</surname><given-names>m.</given-names></name></person-group><article-title xml:lang="en">Rapidly exploring random cycles: persistent estimation of spatiotemporal fields with multiple sensing robots</article-title><source>IEEE Transactions on Robotics</source><year>2016</year><volume>32</volume><issue>5</issue><fpage>1230</fpage><lpage>1244</lpage><pub-id pub-id-type="doi">10.1109/TRO.2016.2596772</pub-id></mixed-citation></ref><ref id="CR257"><label>257.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Carrillo</surname><given-names>H.</given-names></name><name><surname>Dames</surname><given-names>P.</given-names></name><name><surname>Kumar</surname><given-names>V.</given-names></name><name><surname>Castellanos</surname><given-names>J. A.</given-names></name></person-group><article-title xml:lang="en">Autonomous robotic exploration using occupancy grid maps and graph slam based on Shannon and Rényi entropy</article-title><source>2015 IEEE international conference on robotics and automation (ICRA)</source><year>2015</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>487</fpage><lpage>494</lpage><pub-id pub-id-type="doi">10.1109/ICRA.2015.7139224</pub-id></mixed-citation></ref><ref id="CR258"><label>258.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meng</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>W.</given-names></name><name><surname>Han</surname><given-names>H.</given-names></name><name><surname>Ban</surname><given-names>J.</given-names></name></person-group><article-title xml:lang="en">A visual/inertial integrated landing guidance method for UAV landing on the ship</article-title><source>Aerospace Science and Technology</source><year>2019</year><volume>85</volume><fpage>474</fpage><lpage>480</lpage><pub-id pub-id-type="doi">10.1016/j.ast.2018.12.030</pub-id></mixed-citation></ref><ref id="CR259"><label>259.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>J.</given-names></name><name><surname>Yang</surname><given-names>T.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name><name><surname>Su</surname><given-names>T.</given-names></name><name><surname>Wan</surname><given-names>L.</given-names></name></person-group><article-title xml:lang="en">Accurate detection and localization of unmanned aerial vehicle swarms-enabled mobile edge computing system</article-title><source>IEEE Transactions on Industrial Informatics</source><year>2020</year><volume>17</volume><issue>7</issue><fpage>5059</fpage><lpage>5067</lpage><pub-id pub-id-type="doi">10.1109/TII.2020.3015730</pub-id></mixed-citation></ref><ref id="CR260"><label>260.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>R.</given-names></name><name><surname>Yang</surname><given-names>T.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name><name><surname>Su</surname><given-names>T.</given-names></name><name><surname>Wan</surname><given-names>L.</given-names></name></person-group><article-title xml:lang="en">An efficient strategy for accurate detection and localization of UAV swarms</article-title><source>IEEE Internet of Things Journal</source><year>2021</year><volume>8</volume><issue>20</issue><fpage>15372</fpage><lpage>15381</lpage><pub-id pub-id-type="doi">10.1109/JIOT.2021.3064376</pub-id></mixed-citation></ref><ref id="CR261"><label>261.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parisi</surname><given-names>G. I.</given-names></name><name><surname>Kemker</surname><given-names>R.</given-names></name><name><surname>Part</surname><given-names>J. L.</given-names></name><name><surname>Kanan</surname><given-names>C.</given-names></name><name><surname>Wermter</surname><given-names>S.</given-names></name></person-group><article-title xml:lang="en">Continual lifelong learning with neural networks: a review</article-title><source>Neural Networks</source><year>2019</year><volume>113</volume><fpage>54</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2019.01.012</pub-id></mixed-citation></ref><ref id="CR262"><label>262.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Du</surname><given-names>X.</given-names></name><name><surname>Li</surname><given-names>Z.</given-names></name><name><surname>Sun</surname><given-names>J.</given-names></name><name><surname>Liu</surname><given-names>F.</given-names></name><name><surname>Cao</surname><given-names>Y.</given-names></name></person-group><article-title xml:lang="en">Evolutionary NAS in light of model stability for accurate continual learning</article-title><source>2021 international joint conference on neural networks (IJCNN)</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>1</fpage><lpage>8</lpage></mixed-citation></ref><ref id="CR263"><label>263.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>Q.</given-names></name><name><surname>Luo</surname><given-names>Z.</given-names></name><name><surname>Klabjan</surname><given-names>D.</given-names></name><name><surname>Zhang</surname><given-names>F.</given-names></name></person-group><article-title xml:lang="en">Efficient architecture search for continual learning</article-title><source>IEEE Transactions on Neural Networks and Learning Systems</source><year>2022</year><volume>34</volume><issue>2</issue><fpage>690</fpage><lpage>702</lpage></mixed-citation></ref><ref id="CR264"><label>264.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mundt</surname><given-names>M.</given-names></name><name><surname>Pliushch</surname><given-names>I.</given-names></name><name><surname>Ramesh</surname><given-names>V.</given-names></name></person-group><article-title xml:lang="en">Neural architecture search of deep priors: towards continual learning without catastrophic interference</article-title><source>Proceedings of the IEEE conference on computer vision and pattern recognition</source><year>2021</year><publisher-loc>Los Alamitos</publisher-loc><publisher-name>IEEE</publisher-name><fpage>3523</fpage><lpage>3532</lpage></mixed-citation></ref></ref-list></ref-list><notes notes-type="Misc"><title>Publisher’s Note</title><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></notes></back></article></records><facets><facet name="subject"><facet-value count="1">Artificial Intelligence</facet-value><facet-value count="1">Computer Science</facet-value></facet><facet name="keyword"><facet-value count="1">Bond graph</facet-value><facet-value count="1">Evolutionary computation</facet-value><facet-value count="1">Intelligent robots</facet-value><facet-value count="1">Modular design automation</facet-value><facet-value count="1">Neural architecture search</facet-value></facet><facet name="pub"><facet-value count="1">Visual Intelligence</facet-value></facet><facet name="year"><facet-value count="1">2023</facet-value></facet><facet name="country"><facet-value count="1">China</facet-value></facet><facet name="type"><facet-value count="1">Journal</facet-value></facet></facets></response>
